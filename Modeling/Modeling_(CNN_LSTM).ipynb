{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Zo3kh86dzCP"
      },
      "source": [
        "# Classifying Noise sounds using Deep Learning\n",
        "**By:**\n",
        "- Shaikha Bin Ateeq \n",
        "- Alanoud Alosaimi \n",
        "- Raghad Althanyan "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcV91S5OdzCS"
      },
      "source": [
        "### OverView  :\n",
        "\n",
        "Following on from the previous notebook, we identifed the following audio properties that need preprocessing to ensure consistency across the whole dataset:\n",
        "- Audio Channels\n",
        "- Sample rate\n",
        "- Bit-depth\n",
        "\n",
        "also We use Mel-Frequency Cepstral Coefficients(MFCC) and extract it from audio samples.now lets move on to split and Build our model "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Sb0MQqSdzCT"
      },
      "source": [
        "**Import Libraries:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "pkrP-ivXdzCU"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import metrics \n",
        "import matplotlib.pyplot as plt\n",
        "from keras.utils import np_utils\n",
        "from sklearn.utils import shuffle\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import classification_report,confusion_matrix \n",
        "from tensorflow.keras.layers import InputLayer, BatchNormalization, MaxPooling2D\n",
        "from keras.callbacks import ModelCheckpoint \n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from datetime import datetime \n",
        "from keras.layers import Dense, Embedding, LSTM, Input, Flatten, Dropout, Activation, Conv1D, Conv2D,MaxPooling1D, AveragePooling1D, GlobalAveragePooling2D"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBp6HNpAdzCV"
      },
      "source": [
        "Read The Data From Pickle File:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBFtVeEJeZIE",
        "outputId": "4ae21271-ccab-4c57-d5d9-b0b1d600f7aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "FMQ9qGE9dzCV",
        "outputId": "b312ee39-e7ba-461c-f29e-042222f558d5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-a3c26652-e858-4bc6-b283-1a8ebfe44757\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MFCC</th>\n",
              "      <th>class_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[[-1.0, -1.0, -0.6859621, -0.4066782, -0.27337...</td>\n",
              "      <td>dog_bark</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[[-1.0, -0.92530745, -0.8827135, -0.83456916, ...</td>\n",
              "      <td>children_playing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[[-0.5573074, -0.52561057, -0.62860227, -0.678...</td>\n",
              "      <td>children_playing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[[-0.9489181, -0.8168003, -0.7987346, -0.78233...</td>\n",
              "      <td>children_playing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[[-0.21790166, -0.15364559, -0.22467631, -0.20...</td>\n",
              "      <td>children_playing</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a3c26652-e858-4bc6-b283-1a8ebfe44757')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a3c26652-e858-4bc6-b283-1a8ebfe44757 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a3c26652-e858-4bc6-b283-1a8ebfe44757');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                MFCC        class_name\n",
              "0  [[-1.0, -1.0, -0.6859621, -0.4066782, -0.27337...          dog_bark\n",
              "1  [[-1.0, -0.92530745, -0.8827135, -0.83456916, ...  children_playing\n",
              "2  [[-0.5573074, -0.52561057, -0.62860227, -0.678...  children_playing\n",
              "3  [[-0.9489181, -0.8168003, -0.7987346, -0.78233...  children_playing\n",
              "4  [[-0.21790166, -0.15364559, -0.22467631, -0.20...  children_playing"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "with open('/content/drive/MyDrive/Df_Final.pickle','rb') as read_file:\n",
        "    df5 = pickle.load(read_file)\n",
        "    \n",
        "df5.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t64XbW2edzCW",
        "outputId": "f63d4309-d9d0-495a-d602-d45765f3d6f4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10903, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "df5.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "JE0yrMESbhx7"
      },
      "outputs": [],
      "source": [
        "df = shuffle(df5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "l5DEHcWTbrT2",
        "outputId": "d91941c2-0c87-4ad3-f20f-0025142034e5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-6b1440c1-00e8-4777-b698-3008b479e071\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MFCC</th>\n",
              "      <th>class_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2017</th>\n",
              "      <td>[[-0.32703415, -0.30962744, -0.32634977, -0.33...</td>\n",
              "      <td>jackhammer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10322</th>\n",
              "      <td>[[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -0...</td>\n",
              "      <td>Laughter</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2554</th>\n",
              "      <td>[[-0.55797315, -0.39460784, 0.32954752, 0.0515...</td>\n",
              "      <td>children_playing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2374</th>\n",
              "      <td>[[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1...</td>\n",
              "      <td>engine_idling</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7367</th>\n",
              "      <td>[[-1.0, -1.0, -1.0, -1.0, -0.90335524, -0.7447...</td>\n",
              "      <td>dog_bark</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8714</th>\n",
              "      <td>[[-0.3960791, -0.36139658, -0.34552196, -0.330...</td>\n",
              "      <td>children_playing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4050</th>\n",
              "      <td>[[-0.27938482, -0.20506413, -0.21201873, -0.15...</td>\n",
              "      <td>children_playing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>679</th>\n",
              "      <td>[[-0.6639561, -0.6884442, -0.7704389, -0.85106...</td>\n",
              "      <td>dog_bark</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10614</th>\n",
              "      <td>[[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -0.97019...</td>\n",
              "      <td>Computer_keyboard</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108</th>\n",
              "      <td>[[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1...</td>\n",
              "      <td>dog_bark</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10903 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6b1440c1-00e8-4777-b698-3008b479e071')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6b1440c1-00e8-4777-b698-3008b479e071 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6b1440c1-00e8-4777-b698-3008b479e071');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                    MFCC         class_name\n",
              "2017   [[-0.32703415, -0.30962744, -0.32634977, -0.33...         jackhammer\n",
              "10322  [[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -0...           Laughter\n",
              "2554   [[-0.55797315, -0.39460784, 0.32954752, 0.0515...   children_playing\n",
              "2374   [[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1...      engine_idling\n",
              "7367   [[-1.0, -1.0, -1.0, -1.0, -0.90335524, -0.7447...           dog_bark\n",
              "...                                                  ...                ...\n",
              "8714   [[-0.3960791, -0.36139658, -0.34552196, -0.330...   children_playing\n",
              "4050   [[-0.27938482, -0.20506413, -0.21201873, -0.15...   children_playing\n",
              "679    [[-0.6639561, -0.6884442, -0.7704389, -0.85106...           dog_bark\n",
              "10614  [[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -0.97019...  Computer_keyboard\n",
              "108    [[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1...           dog_bark\n",
              "\n",
              "[10903 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "dWvyJzFGbuj8"
      },
      "outputs": [],
      "source": [
        "df2 = df.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "3Al9Eg5Xb14P",
        "outputId": "f57087c6-264b-43b0-a4fa-24b6bd1393d5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-9d49c4f0-a64f-43e5-a57d-d54804eb64b7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MFCC</th>\n",
              "      <th>class_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[[-0.32703415, -0.30962744, -0.32634977, -0.33...</td>\n",
              "      <td>jackhammer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -0...</td>\n",
              "      <td>Laughter</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[[-0.55797315, -0.39460784, 0.32954752, 0.0515...</td>\n",
              "      <td>children_playing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1...</td>\n",
              "      <td>engine_idling</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[[-1.0, -1.0, -1.0, -1.0, -0.90335524, -0.7447...</td>\n",
              "      <td>dog_bark</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10898</th>\n",
              "      <td>[[-0.3960791, -0.36139658, -0.34552196, -0.330...</td>\n",
              "      <td>children_playing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10899</th>\n",
              "      <td>[[-0.27938482, -0.20506413, -0.21201873, -0.15...</td>\n",
              "      <td>children_playing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10900</th>\n",
              "      <td>[[-0.6639561, -0.6884442, -0.7704389, -0.85106...</td>\n",
              "      <td>dog_bark</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10901</th>\n",
              "      <td>[[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -0.97019...</td>\n",
              "      <td>Computer_keyboard</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10902</th>\n",
              "      <td>[[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1...</td>\n",
              "      <td>dog_bark</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10903 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9d49c4f0-a64f-43e5-a57d-d54804eb64b7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9d49c4f0-a64f-43e5-a57d-d54804eb64b7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9d49c4f0-a64f-43e5-a57d-d54804eb64b7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                    MFCC         class_name\n",
              "0      [[-0.32703415, -0.30962744, -0.32634977, -0.33...         jackhammer\n",
              "1      [[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -0...           Laughter\n",
              "2      [[-0.55797315, -0.39460784, 0.32954752, 0.0515...   children_playing\n",
              "3      [[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1...      engine_idling\n",
              "4      [[-1.0, -1.0, -1.0, -1.0, -0.90335524, -0.7447...           dog_bark\n",
              "...                                                  ...                ...\n",
              "10898  [[-0.3960791, -0.36139658, -0.34552196, -0.330...   children_playing\n",
              "10899  [[-0.27938482, -0.20506413, -0.21201873, -0.15...   children_playing\n",
              "10900  [[-0.6639561, -0.6884442, -0.7704389, -0.85106...           dog_bark\n",
              "10901  [[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -0.97019...  Computer_keyboard\n",
              "10902  [[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1...           dog_bark\n",
              "\n",
              "[10903 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "df2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pwu-ODJwQhuU",
        "outputId": "1d382aae-f9cb-4d2a-e66e-e30055fb135f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['dog_bark', 'children_playing', 'car_horn', 'air_conditioner',\n",
              "       'street_music', 'gun_shot', 'siren', 'engine_idling', 'jackhammer',\n",
              "       'drilling', 'Computer_keyboard', 'Keys_jangling', 'Laughter',\n",
              "       'Tearing', 'Cough', 'Telephone', 'Bus', 'Scissors',\n",
              "       'Microwave_oven', 'Fireworks', 'Applause'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "className = df5.class_name.unique() \n",
        "className"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "belrlG4hdzCX"
      },
      "source": [
        "Check all the the data have the same size before feed if to the network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Pv6v2JrdzCY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ac944d9-d236-4644-b870-9aa72011c255"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 (40, 174)\n",
            "1 (40, 174)\n",
            "2 (40, 174)\n",
            "3 (40, 174)\n",
            "4 (40, 174)\n",
            "5 (40, 174)\n",
            "6 (40, 174)\n",
            "7 (40, 174)\n",
            "8 (40, 174)\n",
            "9 (40, 174)\n",
            "10 (40, 174)\n",
            "11 (40, 174)\n",
            "12 (40, 174)\n",
            "13 (40, 174)\n",
            "14 (40, 174)\n",
            "15 (40, 174)\n",
            "16 (40, 174)\n",
            "17 (40, 174)\n",
            "18 (40, 174)\n",
            "19 (40, 174)\n",
            "20 (40, 174)\n",
            "21 (40, 174)\n",
            "22 (40, 174)\n",
            "23 (40, 174)\n",
            "24 (40, 174)\n",
            "25 (40, 174)\n",
            "26 (40, 174)\n",
            "27 (40, 174)\n",
            "28 (40, 174)\n",
            "29 (40, 174)\n",
            "30 (40, 174)\n",
            "31 (40, 174)\n",
            "32 (40, 174)\n",
            "33 (40, 174)\n",
            "34 (40, 174)\n",
            "35 (40, 174)\n",
            "36 (40, 174)\n",
            "37 (40, 174)\n",
            "38 (40, 174)\n",
            "39 (40, 174)\n",
            "40 (40, 174)\n",
            "41 (40, 174)\n",
            "42 (40, 174)\n",
            "43 (40, 174)\n",
            "44 (40, 174)\n",
            "45 (40, 174)\n",
            "46 (40, 174)\n",
            "47 (40, 174)\n",
            "48 (40, 174)\n",
            "49 (40, 174)\n",
            "50 (40, 174)\n",
            "51 (40, 174)\n",
            "52 (40, 174)\n",
            "53 (40, 174)\n",
            "54 (40, 174)\n",
            "55 (40, 174)\n",
            "56 (40, 174)\n",
            "57 (40, 174)\n",
            "58 (40, 174)\n",
            "59 (40, 174)\n",
            "60 (40, 174)\n",
            "61 (40, 174)\n",
            "62 (40, 174)\n",
            "63 (40, 174)\n",
            "64 (40, 174)\n",
            "65 (40, 174)\n",
            "66 (40, 174)\n",
            "67 (40, 174)\n",
            "68 (40, 174)\n",
            "69 (40, 174)\n",
            "70 (40, 174)\n",
            "71 (40, 174)\n",
            "72 (40, 174)\n",
            "73 (40, 174)\n",
            "74 (40, 174)\n",
            "75 (40, 174)\n",
            "76 (40, 174)\n",
            "77 (40, 174)\n",
            "78 (40, 174)\n",
            "79 (40, 174)\n",
            "80 (40, 174)\n",
            "81 (40, 174)\n",
            "82 (40, 174)\n",
            "83 (40, 174)\n",
            "84 (40, 174)\n",
            "85 (40, 174)\n",
            "86 (40, 174)\n",
            "87 (40, 174)\n",
            "88 (40, 174)\n",
            "89 (40, 174)\n",
            "90 (40, 174)\n",
            "91 (40, 174)\n",
            "92 (40, 174)\n",
            "93 (40, 174)\n",
            "94 (40, 174)\n",
            "95 (40, 174)\n",
            "96 (40, 174)\n",
            "97 (40, 174)\n",
            "98 (40, 174)\n",
            "99 (40, 174)\n",
            "100 (40, 174)\n",
            "101 (40, 174)\n",
            "102 (40, 174)\n",
            "103 (40, 174)\n",
            "104 (40, 174)\n",
            "105 (40, 174)\n",
            "106 (40, 174)\n",
            "107 (40, 174)\n",
            "108 (40, 174)\n",
            "109 (40, 174)\n",
            "110 (40, 174)\n",
            "111 (40, 174)\n",
            "112 (40, 174)\n",
            "113 (40, 174)\n",
            "114 (40, 174)\n",
            "115 (40, 174)\n",
            "116 (40, 174)\n",
            "117 (40, 174)\n",
            "118 (40, 174)\n",
            "119 (40, 174)\n",
            "120 (40, 174)\n",
            "121 (40, 174)\n",
            "122 (40, 174)\n",
            "123 (40, 174)\n",
            "124 (40, 174)\n",
            "125 (40, 174)\n",
            "126 (40, 174)\n",
            "127 (40, 174)\n",
            "128 (40, 174)\n",
            "129 (40, 174)\n",
            "130 (40, 174)\n",
            "131 (40, 174)\n",
            "132 (40, 174)\n",
            "133 (40, 174)\n",
            "134 (40, 174)\n",
            "135 (40, 174)\n",
            "136 (40, 174)\n",
            "137 (40, 174)\n",
            "138 (40, 174)\n",
            "139 (40, 174)\n",
            "140 (40, 174)\n",
            "141 (40, 174)\n",
            "142 (40, 174)\n",
            "143 (40, 174)\n",
            "144 (40, 174)\n",
            "145 (40, 174)\n",
            "146 (40, 174)\n",
            "147 (40, 174)\n",
            "148 (40, 174)\n",
            "149 (40, 174)\n",
            "150 (40, 174)\n",
            "151 (40, 174)\n",
            "152 (40, 174)\n",
            "153 (40, 174)\n",
            "154 (40, 174)\n",
            "155 (40, 174)\n",
            "156 (40, 174)\n",
            "157 (40, 174)\n",
            "158 (40, 174)\n",
            "159 (40, 174)\n",
            "160 (40, 174)\n",
            "161 (40, 174)\n",
            "162 (40, 174)\n",
            "163 (40, 174)\n",
            "164 (40, 174)\n",
            "165 (40, 174)\n",
            "166 (40, 174)\n",
            "167 (40, 174)\n",
            "168 (40, 174)\n",
            "169 (40, 174)\n",
            "170 (40, 174)\n",
            "171 (40, 174)\n",
            "172 (40, 174)\n",
            "173 (40, 174)\n",
            "174 (40, 174)\n",
            "175 (40, 174)\n",
            "176 (40, 174)\n",
            "177 (40, 174)\n",
            "178 (40, 174)\n",
            "179 (40, 174)\n",
            "180 (40, 174)\n",
            "181 (40, 174)\n",
            "182 (40, 174)\n",
            "183 (40, 174)\n",
            "184 (40, 174)\n",
            "185 (40, 174)\n",
            "186 (40, 174)\n",
            "187 (40, 174)\n",
            "188 (40, 174)\n",
            "189 (40, 174)\n",
            "190 (40, 174)\n",
            "191 (40, 174)\n",
            "192 (40, 174)\n",
            "193 (40, 174)\n",
            "194 (40, 174)\n",
            "195 (40, 174)\n",
            "196 (40, 174)\n",
            "197 (40, 174)\n",
            "198 (40, 174)\n",
            "199 (40, 174)\n",
            "200 (40, 174)\n",
            "201 (40, 174)\n",
            "202 (40, 174)\n",
            "203 (40, 174)\n",
            "204 (40, 174)\n",
            "205 (40, 174)\n",
            "206 (40, 174)\n",
            "207 (40, 174)\n",
            "208 (40, 174)\n",
            "209 (40, 174)\n",
            "210 (40, 174)\n",
            "211 (40, 174)\n",
            "212 (40, 174)\n",
            "213 (40, 174)\n",
            "214 (40, 174)\n",
            "215 (40, 174)\n",
            "216 (40, 174)\n",
            "217 (40, 174)\n",
            "218 (40, 174)\n",
            "219 (40, 174)\n",
            "220 (40, 174)\n",
            "221 (40, 174)\n",
            "222 (40, 174)\n",
            "223 (40, 174)\n",
            "224 (40, 174)\n",
            "225 (40, 174)\n",
            "226 (40, 174)\n",
            "227 (40, 174)\n",
            "228 (40, 174)\n",
            "229 (40, 174)\n",
            "230 (40, 174)\n",
            "231 (40, 174)\n",
            "232 (40, 174)\n",
            "233 (40, 174)\n",
            "234 (40, 174)\n",
            "235 (40, 174)\n",
            "236 (40, 174)\n",
            "237 (40, 174)\n",
            "238 (40, 174)\n",
            "239 (40, 174)\n",
            "240 (40, 174)\n",
            "241 (40, 174)\n",
            "242 (40, 174)\n",
            "243 (40, 174)\n",
            "244 (40, 174)\n",
            "245 (40, 174)\n",
            "246 (40, 174)\n",
            "247 (40, 174)\n",
            "248 (40, 174)\n",
            "249 (40, 174)\n",
            "250 (40, 174)\n",
            "251 (40, 174)\n",
            "252 (40, 174)\n",
            "253 (40, 174)\n",
            "254 (40, 174)\n",
            "255 (40, 174)\n",
            "256 (40, 174)\n",
            "257 (40, 174)\n",
            "258 (40, 174)\n",
            "259 (40, 174)\n",
            "260 (40, 174)\n",
            "261 (40, 174)\n",
            "262 (40, 174)\n",
            "263 (40, 174)\n",
            "264 (40, 174)\n",
            "265 (40, 174)\n",
            "266 (40, 174)\n",
            "267 (40, 174)\n",
            "268 (40, 174)\n",
            "269 (40, 174)\n",
            "270 (40, 174)\n",
            "271 (40, 174)\n",
            "272 (40, 174)\n",
            "273 (40, 174)\n",
            "274 (40, 174)\n",
            "275 (40, 174)\n",
            "276 (40, 174)\n",
            "277 (40, 174)\n",
            "278 (40, 174)\n",
            "279 (40, 174)\n",
            "280 (40, 174)\n",
            "281 (40, 174)\n",
            "282 (40, 174)\n",
            "283 (40, 174)\n",
            "284 (40, 174)\n",
            "285 (40, 174)\n",
            "286 (40, 174)\n",
            "287 (40, 174)\n",
            "288 (40, 174)\n",
            "289 (40, 174)\n",
            "290 (40, 174)\n",
            "291 (40, 174)\n",
            "292 (40, 174)\n",
            "293 (40, 174)\n",
            "294 (40, 174)\n",
            "295 (40, 174)\n",
            "296 (40, 174)\n",
            "297 (40, 174)\n",
            "298 (40, 174)\n",
            "299 (40, 174)\n",
            "300 (40, 174)\n",
            "301 (40, 174)\n",
            "302 (40, 174)\n",
            "303 (40, 174)\n",
            "304 (40, 174)\n",
            "305 (40, 174)\n",
            "306 (40, 174)\n",
            "307 (40, 174)\n",
            "308 (40, 174)\n",
            "309 (40, 174)\n",
            "310 (40, 174)\n",
            "311 (40, 174)\n",
            "312 (40, 174)\n",
            "313 (40, 174)\n",
            "314 (40, 174)\n",
            "315 (40, 174)\n",
            "316 (40, 174)\n",
            "317 (40, 174)\n",
            "318 (40, 174)\n",
            "319 (40, 174)\n",
            "320 (40, 174)\n",
            "321 (40, 174)\n",
            "322 (40, 174)\n",
            "323 (40, 174)\n",
            "324 (40, 174)\n",
            "325 (40, 174)\n",
            "326 (40, 174)\n",
            "327 (40, 174)\n",
            "328 (40, 174)\n",
            "329 (40, 174)\n",
            "330 (40, 174)\n",
            "331 (40, 174)\n",
            "332 (40, 174)\n",
            "333 (40, 174)\n",
            "334 (40, 174)\n",
            "335 (40, 174)\n",
            "336 (40, 174)\n",
            "337 (40, 174)\n",
            "338 (40, 174)\n",
            "339 (40, 174)\n",
            "340 (40, 174)\n",
            "341 (40, 174)\n",
            "342 (40, 174)\n",
            "343 (40, 174)\n",
            "344 (40, 174)\n",
            "345 (40, 174)\n",
            "346 (40, 174)\n",
            "347 (40, 174)\n",
            "348 (40, 174)\n",
            "349 (40, 174)\n",
            "350 (40, 174)\n",
            "351 (40, 174)\n",
            "352 (40, 174)\n",
            "353 (40, 174)\n",
            "354 (40, 174)\n",
            "355 (40, 174)\n",
            "356 (40, 174)\n",
            "357 (40, 174)\n",
            "358 (40, 174)\n",
            "359 (40, 174)\n",
            "360 (40, 174)\n",
            "361 (40, 174)\n",
            "362 (40, 174)\n",
            "363 (40, 174)\n",
            "364 (40, 174)\n",
            "365 (40, 174)\n",
            "366 (40, 174)\n",
            "367 (40, 174)\n",
            "368 (40, 174)\n",
            "369 (40, 174)\n",
            "370 (40, 174)\n",
            "371 (40, 174)\n",
            "372 (40, 174)\n",
            "373 (40, 174)\n",
            "374 (40, 174)\n",
            "375 (40, 174)\n",
            "376 (40, 174)\n",
            "377 (40, 174)\n",
            "378 (40, 174)\n",
            "379 (40, 174)\n",
            "380 (40, 174)\n",
            "381 (40, 174)\n",
            "382 (40, 174)\n",
            "383 (40, 174)\n",
            "384 (40, 174)\n",
            "385 (40, 174)\n",
            "386 (40, 174)\n",
            "387 (40, 174)\n",
            "388 (40, 174)\n",
            "389 (40, 174)\n",
            "390 (40, 174)\n",
            "391 (40, 174)\n",
            "392 (40, 174)\n",
            "393 (40, 174)\n",
            "394 (40, 174)\n",
            "395 (40, 174)\n",
            "396 (40, 174)\n",
            "397 (40, 174)\n",
            "398 (40, 174)\n",
            "399 (40, 174)\n",
            "400 (40, 174)\n",
            "401 (40, 174)\n",
            "402 (40, 174)\n",
            "403 (40, 174)\n",
            "404 (40, 174)\n",
            "405 (40, 174)\n",
            "406 (40, 174)\n",
            "407 (40, 174)\n",
            "408 (40, 174)\n",
            "409 (40, 174)\n",
            "410 (40, 174)\n",
            "411 (40, 174)\n",
            "412 (40, 174)\n",
            "413 (40, 174)\n",
            "414 (40, 174)\n",
            "415 (40, 174)\n",
            "416 (40, 174)\n",
            "417 (40, 174)\n",
            "418 (40, 174)\n",
            "419 (40, 174)\n",
            "420 (40, 174)\n",
            "421 (40, 174)\n",
            "422 (40, 174)\n",
            "423 (40, 174)\n",
            "424 (40, 174)\n",
            "425 (40, 174)\n",
            "426 (40, 174)\n",
            "427 (40, 174)\n",
            "428 (40, 174)\n",
            "429 (40, 174)\n",
            "430 (40, 174)\n",
            "431 (40, 174)\n",
            "432 (40, 174)\n",
            "433 (40, 174)\n",
            "434 (40, 174)\n",
            "435 (40, 174)\n",
            "436 (40, 174)\n",
            "437 (40, 174)\n",
            "438 (40, 174)\n",
            "439 (40, 174)\n",
            "440 (40, 174)\n",
            "441 (40, 174)\n",
            "442 (40, 174)\n",
            "443 (40, 174)\n",
            "444 (40, 174)\n",
            "445 (40, 174)\n",
            "446 (40, 174)\n",
            "447 (40, 174)\n",
            "448 (40, 174)\n",
            "449 (40, 174)\n",
            "450 (40, 174)\n",
            "451 (40, 174)\n",
            "452 (40, 174)\n",
            "453 (40, 174)\n",
            "454 (40, 174)\n",
            "455 (40, 174)\n",
            "456 (40, 174)\n",
            "457 (40, 174)\n",
            "458 (40, 174)\n",
            "459 (40, 174)\n",
            "460 (40, 174)\n",
            "461 (40, 174)\n",
            "462 (40, 174)\n",
            "463 (40, 174)\n",
            "464 (40, 174)\n",
            "465 (40, 174)\n",
            "466 (40, 174)\n",
            "467 (40, 174)\n",
            "468 (40, 174)\n",
            "469 (40, 174)\n",
            "470 (40, 174)\n",
            "471 (40, 174)\n",
            "472 (40, 174)\n",
            "473 (40, 174)\n",
            "474 (40, 174)\n",
            "475 (40, 174)\n",
            "476 (40, 174)\n",
            "477 (40, 174)\n",
            "478 (40, 174)\n",
            "479 (40, 174)\n",
            "480 (40, 174)\n",
            "481 (40, 174)\n",
            "482 (40, 174)\n",
            "483 (40, 174)\n",
            "484 (40, 174)\n",
            "485 (40, 174)\n",
            "486 (40, 174)\n",
            "487 (40, 174)\n",
            "488 (40, 174)\n",
            "489 (40, 174)\n",
            "490 (40, 174)\n",
            "491 (40, 174)\n",
            "492 (40, 174)\n",
            "493 (40, 174)\n",
            "494 (40, 174)\n",
            "495 (40, 174)\n",
            "496 (40, 174)\n",
            "497 (40, 174)\n",
            "498 (40, 174)\n",
            "499 (40, 174)\n",
            "500 (40, 174)\n",
            "501 (40, 174)\n",
            "502 (40, 174)\n",
            "503 (40, 174)\n",
            "504 (40, 174)\n",
            "505 (40, 174)\n",
            "506 (40, 174)\n",
            "507 (40, 174)\n",
            "508 (40, 174)\n",
            "509 (40, 174)\n",
            "510 (40, 174)\n",
            "511 (40, 174)\n",
            "512 (40, 174)\n",
            "513 (40, 174)\n",
            "514 (40, 174)\n",
            "515 (40, 174)\n",
            "516 (40, 174)\n",
            "517 (40, 174)\n",
            "518 (40, 174)\n",
            "519 (40, 174)\n",
            "520 (40, 174)\n",
            "521 (40, 174)\n",
            "522 (40, 174)\n",
            "523 (40, 174)\n",
            "524 (40, 174)\n",
            "525 (40, 174)\n",
            "526 (40, 174)\n",
            "527 (40, 174)\n",
            "528 (40, 174)\n",
            "529 (40, 174)\n",
            "530 (40, 174)\n",
            "531 (40, 174)\n",
            "532 (40, 174)\n",
            "533 (40, 174)\n",
            "534 (40, 174)\n",
            "535 (40, 174)\n",
            "536 (40, 174)\n",
            "537 (40, 174)\n",
            "538 (40, 174)\n",
            "539 (40, 174)\n",
            "540 (40, 174)\n",
            "541 (40, 174)\n",
            "542 (40, 174)\n",
            "543 (40, 174)\n",
            "544 (40, 174)\n",
            "545 (40, 174)\n",
            "546 (40, 174)\n",
            "547 (40, 174)\n",
            "548 (40, 174)\n",
            "549 (40, 174)\n",
            "550 (40, 174)\n",
            "551 (40, 174)\n",
            "552 (40, 174)\n",
            "553 (40, 174)\n",
            "554 (40, 174)\n",
            "555 (40, 174)\n",
            "556 (40, 174)\n",
            "557 (40, 174)\n",
            "558 (40, 174)\n",
            "559 (40, 174)\n",
            "560 (40, 174)\n",
            "561 (40, 174)\n",
            "562 (40, 174)\n",
            "563 (40, 174)\n",
            "564 (40, 174)\n",
            "565 (40, 174)\n",
            "566 (40, 174)\n",
            "567 (40, 174)\n",
            "568 (40, 174)\n",
            "569 (40, 174)\n",
            "570 (40, 174)\n",
            "571 (40, 174)\n",
            "572 (40, 174)\n",
            "573 (40, 174)\n",
            "574 (40, 174)\n",
            "575 (40, 174)\n",
            "576 (40, 174)\n",
            "577 (40, 174)\n",
            "578 (40, 174)\n",
            "579 (40, 174)\n",
            "580 (40, 174)\n",
            "581 (40, 174)\n",
            "582 (40, 174)\n",
            "583 (40, 174)\n",
            "584 (40, 174)\n",
            "585 (40, 174)\n",
            "586 (40, 174)\n",
            "587 (40, 174)\n",
            "588 (40, 174)\n",
            "589 (40, 174)\n",
            "590 (40, 174)\n",
            "591 (40, 174)\n",
            "592 (40, 174)\n",
            "593 (40, 174)\n",
            "594 (40, 174)\n",
            "595 (40, 174)\n",
            "596 (40, 174)\n",
            "597 (40, 174)\n",
            "598 (40, 174)\n",
            "599 (40, 174)\n",
            "600 (40, 174)\n",
            "601 (40, 174)\n",
            "602 (40, 174)\n",
            "603 (40, 174)\n",
            "604 (40, 174)\n",
            "605 (40, 174)\n",
            "606 (40, 174)\n",
            "607 (40, 174)\n",
            "608 (40, 174)\n",
            "609 (40, 174)\n",
            "610 (40, 174)\n",
            "611 (40, 174)\n",
            "612 (40, 174)\n",
            "613 (40, 174)\n",
            "614 (40, 174)\n",
            "615 (40, 174)\n",
            "616 (40, 174)\n",
            "617 (40, 174)\n",
            "618 (40, 174)\n",
            "619 (40, 174)\n",
            "620 (40, 174)\n",
            "621 (40, 174)\n",
            "622 (40, 174)\n",
            "623 (40, 174)\n",
            "624 (40, 174)\n",
            "625 (40, 174)\n",
            "626 (40, 174)\n",
            "627 (40, 174)\n",
            "628 (40, 174)\n",
            "629 (40, 174)\n",
            "630 (40, 174)\n",
            "631 (40, 174)\n",
            "632 (40, 174)\n",
            "633 (40, 174)\n",
            "634 (40, 174)\n",
            "635 (40, 174)\n",
            "636 (40, 174)\n",
            "637 (40, 174)\n",
            "638 (40, 174)\n",
            "639 (40, 174)\n",
            "640 (40, 174)\n",
            "641 (40, 174)\n",
            "642 (40, 174)\n",
            "643 (40, 174)\n",
            "644 (40, 174)\n",
            "645 (40, 174)\n",
            "646 (40, 174)\n",
            "647 (40, 174)\n",
            "648 (40, 174)\n",
            "649 (40, 174)\n",
            "650 (40, 174)\n",
            "651 (40, 174)\n",
            "652 (40, 174)\n",
            "653 (40, 174)\n",
            "654 (40, 174)\n",
            "655 (40, 174)\n",
            "656 (40, 174)\n",
            "657 (40, 174)\n",
            "658 (40, 174)\n",
            "659 (40, 174)\n",
            "660 (40, 174)\n",
            "661 (40, 174)\n",
            "662 (40, 174)\n",
            "663 (40, 174)\n",
            "664 (40, 174)\n",
            "665 (40, 174)\n",
            "666 (40, 174)\n",
            "667 (40, 174)\n",
            "668 (40, 174)\n",
            "669 (40, 174)\n",
            "670 (40, 174)\n",
            "671 (40, 174)\n",
            "672 (40, 174)\n",
            "673 (40, 174)\n",
            "674 (40, 174)\n",
            "675 (40, 174)\n",
            "676 (40, 174)\n",
            "677 (40, 174)\n",
            "678 (40, 174)\n",
            "679 (40, 174)\n",
            "680 (40, 174)\n",
            "681 (40, 174)\n",
            "682 (40, 174)\n",
            "683 (40, 174)\n",
            "684 (40, 174)\n",
            "685 (40, 174)\n",
            "686 (40, 174)\n",
            "687 (40, 174)\n",
            "688 (40, 174)\n",
            "689 (40, 174)\n",
            "690 (40, 174)\n",
            "691 (40, 174)\n",
            "692 (40, 174)\n",
            "693 (40, 174)\n",
            "694 (40, 174)\n",
            "695 (40, 174)\n",
            "696 (40, 174)\n",
            "697 (40, 174)\n",
            "698 (40, 174)\n",
            "699 (40, 174)\n",
            "700 (40, 174)\n",
            "701 (40, 174)\n",
            "702 (40, 174)\n",
            "703 (40, 174)\n",
            "704 (40, 174)\n",
            "705 (40, 174)\n",
            "706 (40, 174)\n",
            "707 (40, 174)\n",
            "708 (40, 174)\n",
            "709 (40, 174)\n",
            "710 (40, 174)\n",
            "711 (40, 174)\n",
            "712 (40, 174)\n",
            "713 (40, 174)\n",
            "714 (40, 174)\n",
            "715 (40, 174)\n",
            "716 (40, 174)\n",
            "717 (40, 174)\n",
            "718 (40, 174)\n",
            "719 (40, 174)\n",
            "720 (40, 174)\n",
            "721 (40, 174)\n",
            "722 (40, 174)\n",
            "723 (40, 174)\n",
            "724 (40, 174)\n",
            "725 (40, 174)\n",
            "726 (40, 174)\n",
            "727 (40, 174)\n",
            "728 (40, 174)\n",
            "729 (40, 174)\n",
            "730 (40, 174)\n",
            "731 (40, 174)\n",
            "732 (40, 174)\n",
            "733 (40, 174)\n",
            "734 (40, 174)\n",
            "735 (40, 174)\n",
            "736 (40, 174)\n",
            "737 (40, 174)\n",
            "738 (40, 174)\n",
            "739 (40, 174)\n",
            "740 (40, 174)\n",
            "741 (40, 174)\n",
            "742 (40, 174)\n",
            "743 (40, 174)\n",
            "744 (40, 174)\n",
            "745 (40, 174)\n",
            "746 (40, 174)\n",
            "747 (40, 174)\n",
            "748 (40, 174)\n",
            "749 (40, 174)\n",
            "750 (40, 174)\n",
            "751 (40, 174)\n",
            "752 (40, 174)\n",
            "753 (40, 174)\n",
            "754 (40, 174)\n",
            "755 (40, 174)\n",
            "756 (40, 174)\n",
            "757 (40, 174)\n",
            "758 (40, 174)\n",
            "759 (40, 174)\n",
            "760 (40, 174)\n",
            "761 (40, 174)\n",
            "762 (40, 174)\n",
            "763 (40, 174)\n",
            "764 (40, 174)\n",
            "765 (40, 174)\n",
            "766 (40, 174)\n",
            "767 (40, 174)\n",
            "768 (40, 174)\n",
            "769 (40, 174)\n",
            "770 (40, 174)\n",
            "771 (40, 174)\n",
            "772 (40, 174)\n",
            "773 (40, 174)\n",
            "774 (40, 174)\n",
            "775 (40, 174)\n",
            "776 (40, 174)\n",
            "777 (40, 174)\n",
            "778 (40, 174)\n",
            "779 (40, 174)\n",
            "780 (40, 174)\n",
            "781 (40, 174)\n",
            "782 (40, 174)\n",
            "783 (40, 174)\n",
            "784 (40, 174)\n",
            "785 (40, 174)\n",
            "786 (40, 174)\n",
            "787 (40, 174)\n",
            "788 (40, 174)\n",
            "789 (40, 174)\n",
            "790 (40, 174)\n",
            "791 (40, 174)\n",
            "792 (40, 174)\n",
            "793 (40, 174)\n",
            "794 (40, 174)\n",
            "795 (40, 174)\n",
            "796 (40, 174)\n",
            "797 (40, 174)\n",
            "798 (40, 174)\n",
            "799 (40, 174)\n",
            "800 (40, 174)\n",
            "801 (40, 174)\n",
            "802 (40, 174)\n",
            "803 (40, 174)\n",
            "804 (40, 174)\n",
            "805 (40, 174)\n",
            "806 (40, 174)\n",
            "807 (40, 174)\n",
            "808 (40, 174)\n",
            "809 (40, 174)\n",
            "810 (40, 174)\n",
            "811 (40, 174)\n",
            "812 (40, 174)\n",
            "813 (40, 174)\n",
            "814 (40, 174)\n",
            "815 (40, 174)\n",
            "816 (40, 174)\n",
            "817 (40, 174)\n",
            "818 (40, 174)\n",
            "819 (40, 174)\n",
            "820 (40, 174)\n",
            "821 (40, 174)\n",
            "822 (40, 174)\n",
            "823 (40, 174)\n",
            "824 (40, 174)\n",
            "825 (40, 174)\n",
            "826 (40, 174)\n",
            "827 (40, 174)\n",
            "828 (40, 174)\n",
            "829 (40, 174)\n",
            "830 (40, 174)\n",
            "831 (40, 174)\n",
            "832 (40, 174)\n",
            "833 (40, 174)\n",
            "834 (40, 174)\n",
            "835 (40, 174)\n",
            "836 (40, 174)\n",
            "837 (40, 174)\n",
            "838 (40, 174)\n",
            "839 (40, 174)\n",
            "840 (40, 174)\n",
            "841 (40, 174)\n",
            "842 (40, 174)\n",
            "843 (40, 174)\n",
            "844 (40, 174)\n",
            "845 (40, 174)\n",
            "846 (40, 174)\n",
            "847 (40, 174)\n",
            "848 (40, 174)\n",
            "849 (40, 174)\n",
            "850 (40, 174)\n",
            "851 (40, 174)\n",
            "852 (40, 174)\n",
            "853 (40, 174)\n",
            "854 (40, 174)\n",
            "855 (40, 174)\n",
            "856 (40, 174)\n",
            "857 (40, 174)\n",
            "858 (40, 174)\n",
            "859 (40, 174)\n",
            "860 (40, 174)\n",
            "861 (40, 174)\n",
            "862 (40, 174)\n",
            "863 (40, 174)\n",
            "864 (40, 174)\n",
            "865 (40, 174)\n",
            "866 (40, 174)\n",
            "867 (40, 174)\n",
            "868 (40, 174)\n",
            "869 (40, 174)\n",
            "870 (40, 174)\n",
            "871 (40, 174)\n",
            "872 (40, 174)\n",
            "873 (40, 174)\n",
            "874 (40, 174)\n",
            "875 (40, 174)\n",
            "876 (40, 174)\n",
            "877 (40, 174)\n",
            "878 (40, 174)\n",
            "879 (40, 174)\n",
            "880 (40, 174)\n",
            "881 (40, 174)\n",
            "882 (40, 174)\n",
            "883 (40, 174)\n",
            "884 (40, 174)\n",
            "885 (40, 174)\n",
            "886 (40, 174)\n",
            "887 (40, 174)\n",
            "888 (40, 174)\n",
            "889 (40, 174)\n",
            "890 (40, 174)\n",
            "891 (40, 174)\n",
            "892 (40, 174)\n",
            "893 (40, 174)\n",
            "894 (40, 174)\n",
            "895 (40, 174)\n",
            "896 (40, 174)\n",
            "897 (40, 174)\n",
            "898 (40, 174)\n",
            "899 (40, 174)\n",
            "900 (40, 174)\n",
            "901 (40, 174)\n",
            "902 (40, 174)\n",
            "903 (40, 174)\n",
            "904 (40, 174)\n",
            "905 (40, 174)\n",
            "906 (40, 174)\n",
            "907 (40, 174)\n",
            "908 (40, 174)\n",
            "909 (40, 174)\n",
            "910 (40, 174)\n",
            "911 (40, 174)\n",
            "912 (40, 174)\n",
            "913 (40, 174)\n",
            "914 (40, 174)\n",
            "915 (40, 174)\n",
            "916 (40, 174)\n",
            "917 (40, 174)\n",
            "918 (40, 174)\n",
            "919 (40, 174)\n",
            "920 (40, 174)\n",
            "921 (40, 174)\n",
            "922 (40, 174)\n",
            "923 (40, 174)\n",
            "924 (40, 174)\n",
            "925 (40, 174)\n",
            "926 (40, 174)\n",
            "927 (40, 174)\n",
            "928 (40, 174)\n",
            "929 (40, 174)\n",
            "930 (40, 174)\n",
            "931 (40, 174)\n",
            "932 (40, 174)\n",
            "933 (40, 174)\n",
            "934 (40, 174)\n",
            "935 (40, 174)\n",
            "936 (40, 174)\n",
            "937 (40, 174)\n",
            "938 (40, 174)\n",
            "939 (40, 174)\n",
            "940 (40, 174)\n",
            "941 (40, 174)\n",
            "942 (40, 174)\n",
            "943 (40, 174)\n",
            "944 (40, 174)\n",
            "945 (40, 174)\n",
            "946 (40, 174)\n",
            "947 (40, 174)\n",
            "948 (40, 174)\n",
            "949 (40, 174)\n",
            "950 (40, 174)\n",
            "951 (40, 174)\n",
            "952 (40, 174)\n",
            "953 (40, 174)\n",
            "954 (40, 174)\n",
            "955 (40, 174)\n",
            "956 (40, 174)\n",
            "957 (40, 174)\n",
            "958 (40, 174)\n",
            "959 (40, 174)\n",
            "960 (40, 174)\n",
            "961 (40, 174)\n",
            "962 (40, 174)\n",
            "963 (40, 174)\n",
            "964 (40, 174)\n",
            "965 (40, 174)\n",
            "966 (40, 174)\n",
            "967 (40, 174)\n",
            "968 (40, 174)\n",
            "969 (40, 174)\n",
            "970 (40, 174)\n",
            "971 (40, 174)\n",
            "972 (40, 174)\n",
            "973 (40, 174)\n",
            "974 (40, 174)\n",
            "975 (40, 174)\n",
            "976 (40, 174)\n",
            "977 (40, 174)\n",
            "978 (40, 174)\n",
            "979 (40, 174)\n",
            "980 (40, 174)\n",
            "981 (40, 174)\n",
            "982 (40, 174)\n",
            "983 (40, 174)\n",
            "984 (40, 174)\n",
            "985 (40, 174)\n",
            "986 (40, 174)\n",
            "987 (40, 174)\n",
            "988 (40, 174)\n",
            "989 (40, 174)\n",
            "990 (40, 174)\n",
            "991 (40, 174)\n",
            "992 (40, 174)\n",
            "993 (40, 174)\n",
            "994 (40, 174)\n",
            "995 (40, 174)\n",
            "996 (40, 174)\n",
            "997 (40, 174)\n",
            "998 (40, 174)\n",
            "999 (40, 174)\n",
            "1000 (40, 174)\n",
            "1001 (40, 174)\n",
            "1002 (40, 174)\n",
            "1003 (40, 174)\n",
            "1004 (40, 174)\n",
            "1005 (40, 174)\n",
            "1006 (40, 174)\n",
            "1007 (40, 174)\n",
            "1008 (40, 174)\n",
            "1009 (40, 174)\n",
            "1010 (40, 174)\n",
            "1011 (40, 174)\n",
            "1012 (40, 174)\n",
            "1013 (40, 174)\n",
            "1014 (40, 174)\n",
            "1015 (40, 174)\n",
            "1016 (40, 174)\n",
            "1017 (40, 174)\n",
            "1018 (40, 174)\n",
            "1019 (40, 174)\n",
            "1020 (40, 174)\n",
            "1021 (40, 174)\n",
            "1022 (40, 174)\n",
            "1023 (40, 174)\n",
            "1024 (40, 174)\n",
            "1025 (40, 174)\n",
            "1026 (40, 174)\n",
            "1027 (40, 174)\n",
            "1028 (40, 174)\n",
            "1029 (40, 174)\n",
            "1030 (40, 174)\n",
            "1031 (40, 174)\n",
            "1032 (40, 174)\n",
            "1033 (40, 174)\n",
            "1034 (40, 174)\n",
            "1035 (40, 174)\n",
            "1036 (40, 174)\n",
            "1037 (40, 174)\n",
            "1038 (40, 174)\n",
            "1039 (40, 174)\n",
            "1040 (40, 174)\n",
            "1041 (40, 174)\n",
            "1042 (40, 174)\n",
            "1043 (40, 174)\n",
            "1044 (40, 174)\n",
            "1045 (40, 174)\n",
            "1046 (40, 174)\n",
            "1047 (40, 174)\n",
            "1048 (40, 174)\n",
            "1049 (40, 174)\n",
            "1050 (40, 174)\n",
            "1051 (40, 174)\n",
            "1052 (40, 174)\n",
            "1053 (40, 174)\n",
            "1054 (40, 174)\n",
            "1055 (40, 174)\n",
            "1056 (40, 174)\n",
            "1057 (40, 174)\n",
            "1058 (40, 174)\n",
            "1059 (40, 174)\n",
            "1060 (40, 174)\n",
            "1061 (40, 174)\n",
            "1062 (40, 174)\n",
            "1063 (40, 174)\n",
            "1064 (40, 174)\n",
            "1065 (40, 174)\n",
            "1066 (40, 174)\n",
            "1067 (40, 174)\n",
            "1068 (40, 174)\n",
            "1069 (40, 174)\n",
            "1070 (40, 174)\n",
            "1071 (40, 174)\n",
            "1072 (40, 174)\n",
            "1073 (40, 174)\n",
            "1074 (40, 174)\n",
            "1075 (40, 174)\n",
            "1076 (40, 174)\n",
            "1077 (40, 174)\n",
            "1078 (40, 174)\n",
            "1079 (40, 174)\n",
            "1080 (40, 174)\n",
            "1081 (40, 174)\n",
            "1082 (40, 174)\n",
            "1083 (40, 174)\n",
            "1084 (40, 174)\n",
            "1085 (40, 174)\n",
            "1086 (40, 174)\n",
            "1087 (40, 174)\n",
            "1088 (40, 174)\n",
            "1089 (40, 174)\n",
            "1090 (40, 174)\n",
            "1091 (40, 174)\n",
            "1092 (40, 174)\n",
            "1093 (40, 174)\n",
            "1094 (40, 174)\n",
            "1095 (40, 174)\n",
            "1096 (40, 174)\n",
            "1097 (40, 174)\n",
            "1098 (40, 174)\n",
            "1099 (40, 174)\n",
            "1100 (40, 174)\n",
            "1101 (40, 174)\n",
            "1102 (40, 174)\n",
            "1103 (40, 174)\n",
            "1104 (40, 174)\n",
            "1105 (40, 174)\n",
            "1106 (40, 174)\n",
            "1107 (40, 174)\n",
            "1108 (40, 174)\n",
            "1109 (40, 174)\n",
            "1110 (40, 174)\n",
            "1111 (40, 174)\n",
            "1112 (40, 174)\n",
            "1113 (40, 174)\n",
            "1114 (40, 174)\n",
            "1115 (40, 174)\n",
            "1116 (40, 174)\n",
            "1117 (40, 174)\n",
            "1118 (40, 174)\n",
            "1119 (40, 174)\n",
            "1120 (40, 174)\n",
            "1121 (40, 174)\n",
            "1122 (40, 174)\n",
            "1123 (40, 174)\n",
            "1124 (40, 174)\n",
            "1125 (40, 174)\n",
            "1126 (40, 174)\n",
            "1127 (40, 174)\n",
            "1128 (40, 174)\n",
            "1129 (40, 174)\n",
            "1130 (40, 174)\n",
            "1131 (40, 174)\n",
            "1132 (40, 174)\n",
            "1133 (40, 174)\n",
            "1134 (40, 174)\n",
            "1135 (40, 174)\n",
            "1136 (40, 174)\n",
            "1137 (40, 174)\n",
            "1138 (40, 174)\n",
            "1139 (40, 174)\n",
            "1140 (40, 174)\n",
            "1141 (40, 174)\n",
            "1142 (40, 174)\n",
            "1143 (40, 174)\n",
            "1144 (40, 174)\n",
            "1145 (40, 174)\n",
            "1146 (40, 174)\n",
            "1147 (40, 174)\n",
            "1148 (40, 174)\n",
            "1149 (40, 174)\n",
            "1150 (40, 174)\n",
            "1151 (40, 174)\n",
            "1152 (40, 174)\n",
            "1153 (40, 174)\n",
            "1154 (40, 174)\n",
            "1155 (40, 174)\n",
            "1156 (40, 174)\n",
            "1157 (40, 174)\n",
            "1158 (40, 174)\n",
            "1159 (40, 174)\n",
            "1160 (40, 174)\n",
            "1161 (40, 174)\n",
            "1162 (40, 174)\n",
            "1163 (40, 174)\n",
            "1164 (40, 174)\n",
            "1165 (40, 174)\n",
            "1166 (40, 174)\n",
            "1167 (40, 174)\n",
            "1168 (40, 174)\n",
            "1169 (40, 174)\n",
            "1170 (40, 174)\n",
            "1171 (40, 174)\n",
            "1172 (40, 174)\n",
            "1173 (40, 174)\n",
            "1174 (40, 174)\n",
            "1175 (40, 174)\n",
            "1176 (40, 174)\n",
            "1177 (40, 174)\n",
            "1178 (40, 174)\n",
            "1179 (40, 174)\n",
            "1180 (40, 174)\n",
            "1181 (40, 174)\n",
            "1182 (40, 174)\n",
            "1183 (40, 174)\n",
            "1184 (40, 174)\n",
            "1185 (40, 174)\n",
            "1186 (40, 174)\n",
            "1187 (40, 174)\n",
            "1188 (40, 174)\n",
            "1189 (40, 174)\n",
            "1190 (40, 174)\n",
            "1191 (40, 174)\n",
            "1192 (40, 174)\n",
            "1193 (40, 174)\n",
            "1194 (40, 174)\n",
            "1195 (40, 174)\n",
            "1196 (40, 174)\n",
            "1197 (40, 174)\n",
            "1198 (40, 174)\n",
            "1199 (40, 174)\n",
            "1200 (40, 174)\n",
            "1201 (40, 174)\n",
            "1202 (40, 174)\n",
            "1203 (40, 174)\n",
            "1204 (40, 174)\n",
            "1205 (40, 174)\n",
            "1206 (40, 174)\n",
            "1207 (40, 174)\n",
            "1208 (40, 174)\n",
            "1209 (40, 174)\n",
            "1210 (40, 174)\n",
            "1211 (40, 174)\n",
            "1212 (40, 174)\n",
            "1213 (40, 174)\n",
            "1214 (40, 174)\n",
            "1215 (40, 174)\n",
            "1216 (40, 174)\n",
            "1217 (40, 174)\n",
            "1218 (40, 174)\n",
            "1219 (40, 174)\n",
            "1220 (40, 174)\n",
            "1221 (40, 174)\n",
            "1222 (40, 174)\n",
            "1223 (40, 174)\n",
            "1224 (40, 174)\n",
            "1225 (40, 174)\n",
            "1226 (40, 174)\n",
            "1227 (40, 174)\n",
            "1228 (40, 174)\n",
            "1229 (40, 174)\n",
            "1230 (40, 174)\n",
            "1231 (40, 174)\n",
            "1232 (40, 174)\n",
            "1233 (40, 174)\n",
            "1234 (40, 174)\n",
            "1235 (40, 174)\n",
            "1236 (40, 174)\n",
            "1237 (40, 174)\n",
            "1238 (40, 174)\n",
            "1239 (40, 174)\n",
            "1240 (40, 174)\n",
            "1241 (40, 174)\n",
            "1242 (40, 174)\n",
            "1243 (40, 174)\n",
            "1244 (40, 174)\n",
            "1245 (40, 174)\n",
            "1246 (40, 174)\n",
            "1247 (40, 174)\n",
            "1248 (40, 174)\n",
            "1249 (40, 174)\n",
            "1250 (40, 174)\n",
            "1251 (40, 174)\n",
            "1252 (40, 174)\n",
            "1253 (40, 174)\n",
            "1254 (40, 174)\n",
            "1255 (40, 174)\n",
            "1256 (40, 174)\n",
            "1257 (40, 174)\n",
            "1258 (40, 174)\n",
            "1259 (40, 174)\n",
            "1260 (40, 174)\n",
            "1261 (40, 174)\n",
            "1262 (40, 174)\n",
            "1263 (40, 174)\n",
            "1264 (40, 174)\n",
            "1265 (40, 174)\n",
            "1266 (40, 174)\n",
            "1267 (40, 174)\n",
            "1268 (40, 174)\n",
            "1269 (40, 174)\n",
            "1270 (40, 174)\n",
            "1271 (40, 174)\n",
            "1272 (40, 174)\n",
            "1273 (40, 174)\n",
            "1274 (40, 174)\n",
            "1275 (40, 174)\n",
            "1276 (40, 174)\n",
            "1277 (40, 174)\n",
            "1278 (40, 174)\n",
            "1279 (40, 174)\n",
            "1280 (40, 174)\n",
            "1281 (40, 174)\n",
            "1282 (40, 174)\n",
            "1283 (40, 174)\n",
            "1284 (40, 174)\n",
            "1285 (40, 174)\n",
            "1286 (40, 174)\n",
            "1287 (40, 174)\n",
            "1288 (40, 174)\n",
            "1289 (40, 174)\n",
            "1290 (40, 174)\n",
            "1291 (40, 174)\n",
            "1292 (40, 174)\n",
            "1293 (40, 174)\n",
            "1294 (40, 174)\n",
            "1295 (40, 174)\n",
            "1296 (40, 174)\n",
            "1297 (40, 174)\n",
            "1298 (40, 174)\n",
            "1299 (40, 174)\n",
            "1300 (40, 174)\n",
            "1301 (40, 174)\n",
            "1302 (40, 174)\n",
            "1303 (40, 174)\n",
            "1304 (40, 174)\n",
            "1305 (40, 174)\n",
            "1306 (40, 174)\n",
            "1307 (40, 174)\n",
            "1308 (40, 174)\n",
            "1309 (40, 174)\n",
            "1310 (40, 174)\n",
            "1311 (40, 174)\n",
            "1312 (40, 174)\n",
            "1313 (40, 174)\n",
            "1314 (40, 174)\n",
            "1315 (40, 174)\n",
            "1316 (40, 174)\n",
            "1317 (40, 174)\n",
            "1318 (40, 174)\n",
            "1319 (40, 174)\n",
            "1320 (40, 174)\n",
            "1321 (40, 174)\n",
            "1322 (40, 174)\n",
            "1323 (40, 174)\n",
            "1324 (40, 174)\n",
            "1325 (40, 174)\n",
            "1326 (40, 174)\n",
            "1327 (40, 174)\n",
            "1328 (40, 174)\n",
            "1329 (40, 174)\n",
            "1330 (40, 174)\n",
            "1331 (40, 174)\n",
            "1332 (40, 174)\n",
            "1333 (40, 174)\n",
            "1334 (40, 174)\n",
            "1335 (40, 174)\n",
            "1336 (40, 174)\n",
            "1337 (40, 174)\n",
            "1338 (40, 174)\n",
            "1339 (40, 174)\n",
            "1340 (40, 174)\n",
            "1341 (40, 174)\n",
            "1342 (40, 174)\n",
            "1343 (40, 174)\n",
            "1344 (40, 174)\n",
            "1345 (40, 174)\n",
            "1346 (40, 174)\n",
            "1347 (40, 174)\n",
            "1348 (40, 174)\n",
            "1349 (40, 174)\n",
            "1350 (40, 174)\n",
            "1351 (40, 174)\n",
            "1352 (40, 174)\n",
            "1353 (40, 174)\n",
            "1354 (40, 174)\n",
            "1355 (40, 174)\n",
            "1356 (40, 174)\n",
            "1357 (40, 174)\n",
            "1358 (40, 174)\n",
            "1359 (40, 174)\n",
            "1360 (40, 174)\n",
            "1361 (40, 174)\n",
            "1362 (40, 174)\n",
            "1363 (40, 174)\n",
            "1364 (40, 174)\n",
            "1365 (40, 174)\n",
            "1366 (40, 174)\n",
            "1367 (40, 174)\n",
            "1368 (40, 174)\n",
            "1369 (40, 174)\n",
            "1370 (40, 174)\n",
            "1371 (40, 174)\n",
            "1372 (40, 174)\n",
            "1373 (40, 174)\n",
            "1374 (40, 174)\n",
            "1375 (40, 174)\n",
            "1376 (40, 174)\n",
            "1377 (40, 174)\n",
            "1378 (40, 174)\n",
            "1379 (40, 174)\n",
            "1380 (40, 174)\n",
            "1381 (40, 174)\n",
            "1382 (40, 174)\n",
            "1383 (40, 174)\n",
            "1384 (40, 174)\n",
            "1385 (40, 174)\n",
            "1386 (40, 174)\n",
            "1387 (40, 174)\n",
            "1388 (40, 174)\n",
            "1389 (40, 174)\n",
            "1390 (40, 174)\n",
            "1391 (40, 174)\n",
            "1392 (40, 174)\n",
            "1393 (40, 174)\n",
            "1394 (40, 174)\n",
            "1395 (40, 174)\n",
            "1396 (40, 174)\n",
            "1397 (40, 174)\n",
            "1398 (40, 174)\n",
            "1399 (40, 174)\n",
            "1400 (40, 174)\n",
            "1401 (40, 174)\n",
            "1402 (40, 174)\n",
            "1403 (40, 174)\n",
            "1404 (40, 174)\n",
            "1405 (40, 174)\n",
            "1406 (40, 174)\n",
            "1407 (40, 174)\n",
            "1408 (40, 174)\n",
            "1409 (40, 174)\n",
            "1410 (40, 174)\n",
            "1411 (40, 174)\n",
            "1412 (40, 174)\n",
            "1413 (40, 174)\n",
            "1414 (40, 174)\n",
            "1415 (40, 174)\n",
            "1416 (40, 174)\n",
            "1417 (40, 174)\n",
            "1418 (40, 174)\n",
            "1419 (40, 174)\n",
            "1420 (40, 174)\n",
            "1421 (40, 174)\n",
            "1422 (40, 174)\n",
            "1423 (40, 174)\n",
            "1424 (40, 174)\n",
            "1425 (40, 174)\n",
            "1426 (40, 174)\n",
            "1427 (40, 174)\n",
            "1428 (40, 174)\n",
            "1429 (40, 174)\n",
            "1430 (40, 174)\n",
            "1431 (40, 174)\n",
            "1432 (40, 174)\n",
            "1433 (40, 174)\n",
            "1434 (40, 174)\n",
            "1435 (40, 174)\n",
            "1436 (40, 174)\n",
            "1437 (40, 174)\n",
            "1438 (40, 174)\n",
            "1439 (40, 174)\n",
            "1440 (40, 174)\n",
            "1441 (40, 174)\n",
            "1442 (40, 174)\n",
            "1443 (40, 174)\n",
            "1444 (40, 174)\n",
            "1445 (40, 174)\n",
            "1446 (40, 174)\n",
            "1447 (40, 174)\n",
            "1448 (40, 174)\n",
            "1449 (40, 174)\n",
            "1450 (40, 174)\n",
            "1451 (40, 174)\n",
            "1452 (40, 174)\n",
            "1453 (40, 174)\n",
            "1454 (40, 174)\n",
            "1455 (40, 174)\n",
            "1456 (40, 174)\n",
            "1457 (40, 174)\n",
            "1458 (40, 174)\n",
            "1459 (40, 174)\n",
            "1460 (40, 174)\n",
            "1461 (40, 174)\n",
            "1462 (40, 174)\n",
            "1463 (40, 174)\n",
            "1464 (40, 174)\n",
            "1465 (40, 174)\n",
            "1466 (40, 174)\n",
            "1467 (40, 174)\n",
            "1468 (40, 174)\n",
            "1469 (40, 174)\n",
            "1470 (40, 174)\n",
            "1471 (40, 174)\n",
            "1472 (40, 174)\n",
            "1473 (40, 174)\n",
            "1474 (40, 174)\n",
            "1475 (40, 174)\n",
            "1476 (40, 174)\n",
            "1477 (40, 174)\n",
            "1478 (40, 174)\n",
            "1479 (40, 174)\n",
            "1480 (40, 174)\n",
            "1481 (40, 174)\n",
            "1482 (40, 174)\n",
            "1483 (40, 174)\n",
            "1484 (40, 174)\n",
            "1485 (40, 174)\n",
            "1486 (40, 174)\n",
            "1487 (40, 174)\n",
            "1488 (40, 174)\n",
            "1489 (40, 174)\n",
            "1490 (40, 174)\n",
            "1491 (40, 174)\n",
            "1492 (40, 174)\n",
            "1493 (40, 174)\n",
            "1494 (40, 174)\n",
            "1495 (40, 174)\n",
            "1496 (40, 174)\n",
            "1497 (40, 174)\n",
            "1498 (40, 174)\n",
            "1499 (40, 174)\n",
            "1500 (40, 174)\n",
            "1501 (40, 174)\n",
            "1502 (40, 174)\n",
            "1503 (40, 174)\n",
            "1504 (40, 174)\n",
            "1505 (40, 174)\n",
            "1506 (40, 174)\n",
            "1507 (40, 174)\n",
            "1508 (40, 174)\n",
            "1509 (40, 174)\n",
            "1510 (40, 174)\n",
            "1511 (40, 174)\n",
            "1512 (40, 174)\n",
            "1513 (40, 174)\n",
            "1514 (40, 174)\n",
            "1515 (40, 174)\n",
            "1516 (40, 174)\n",
            "1517 (40, 174)\n",
            "1518 (40, 174)\n",
            "1519 (40, 174)\n",
            "1520 (40, 174)\n",
            "1521 (40, 174)\n",
            "1522 (40, 174)\n",
            "1523 (40, 174)\n",
            "1524 (40, 174)\n",
            "1525 (40, 174)\n",
            "1526 (40, 174)\n",
            "1527 (40, 174)\n",
            "1528 (40, 174)\n",
            "1529 (40, 174)\n",
            "1530 (40, 174)\n",
            "1531 (40, 174)\n",
            "1532 (40, 174)\n",
            "1533 (40, 174)\n",
            "1534 (40, 174)\n",
            "1535 (40, 174)\n",
            "1536 (40, 174)\n",
            "1537 (40, 174)\n",
            "1538 (40, 174)\n",
            "1539 (40, 174)\n",
            "1540 (40, 174)\n",
            "1541 (40, 174)\n",
            "1542 (40, 174)\n",
            "1543 (40, 174)\n",
            "1544 (40, 174)\n",
            "1545 (40, 174)\n",
            "1546 (40, 174)\n",
            "1547 (40, 174)\n",
            "1548 (40, 174)\n",
            "1549 (40, 174)\n",
            "1550 (40, 174)\n",
            "1551 (40, 174)\n",
            "1552 (40, 174)\n",
            "1553 (40, 174)\n",
            "1554 (40, 174)\n",
            "1555 (40, 174)\n",
            "1556 (40, 174)\n",
            "1557 (40, 174)\n",
            "1558 (40, 174)\n",
            "1559 (40, 174)\n",
            "1560 (40, 174)\n",
            "1561 (40, 174)\n",
            "1562 (40, 174)\n",
            "1563 (40, 174)\n",
            "1564 (40, 174)\n",
            "1565 (40, 174)\n",
            "1566 (40, 174)\n",
            "1567 (40, 174)\n",
            "1568 (40, 174)\n",
            "1569 (40, 174)\n",
            "1570 (40, 174)\n",
            "1571 (40, 174)\n",
            "1572 (40, 174)\n",
            "1573 (40, 174)\n",
            "1574 (40, 174)\n",
            "1575 (40, 174)\n",
            "1576 (40, 174)\n",
            "1577 (40, 174)\n",
            "1578 (40, 174)\n",
            "1579 (40, 174)\n",
            "1580 (40, 174)\n",
            "1581 (40, 174)\n",
            "1582 (40, 174)\n",
            "1583 (40, 174)\n",
            "1584 (40, 174)\n",
            "1585 (40, 174)\n",
            "1586 (40, 174)\n",
            "1587 (40, 174)\n",
            "1588 (40, 174)\n",
            "1589 (40, 174)\n",
            "1590 (40, 174)\n",
            "1591 (40, 174)\n",
            "1592 (40, 174)\n",
            "1593 (40, 174)\n",
            "1594 (40, 174)\n",
            "1595 (40, 174)\n",
            "1596 (40, 174)\n",
            "1597 (40, 174)\n",
            "1598 (40, 174)\n",
            "1599 (40, 174)\n",
            "1600 (40, 174)\n",
            "1601 (40, 174)\n",
            "1602 (40, 174)\n",
            "1603 (40, 174)\n",
            "1604 (40, 174)\n",
            "1605 (40, 174)\n",
            "1606 (40, 174)\n",
            "1607 (40, 174)\n",
            "1608 (40, 174)\n",
            "1609 (40, 174)\n",
            "1610 (40, 174)\n",
            "1611 (40, 174)\n",
            "1612 (40, 174)\n",
            "1613 (40, 174)\n",
            "1614 (40, 174)\n",
            "1615 (40, 174)\n",
            "1616 (40, 174)\n",
            "1617 (40, 174)\n",
            "1618 (40, 174)\n",
            "1619 (40, 174)\n",
            "1620 (40, 174)\n",
            "1621 (40, 174)\n",
            "1622 (40, 174)\n",
            "1623 (40, 174)\n",
            "1624 (40, 174)\n",
            "1625 (40, 174)\n",
            "1626 (40, 174)\n",
            "1627 (40, 174)\n",
            "1628 (40, 174)\n",
            "1629 (40, 174)\n",
            "1630 (40, 174)\n",
            "1631 (40, 174)\n",
            "1632 (40, 174)\n",
            "1633 (40, 174)\n",
            "1634 (40, 174)\n",
            "1635 (40, 174)\n",
            "1636 (40, 174)\n",
            "1637 (40, 174)\n",
            "1638 (40, 174)\n",
            "1639 (40, 174)\n",
            "1640 (40, 174)\n",
            "1641 (40, 174)\n",
            "1642 (40, 174)\n",
            "1643 (40, 174)\n",
            "1644 (40, 174)\n",
            "1645 (40, 174)\n",
            "1646 (40, 174)\n",
            "1647 (40, 174)\n",
            "1648 (40, 174)\n",
            "1649 (40, 174)\n",
            "1650 (40, 174)\n",
            "1651 (40, 174)\n",
            "1652 (40, 174)\n",
            "1653 (40, 174)\n",
            "1654 (40, 174)\n",
            "1655 (40, 174)\n",
            "1656 (40, 174)\n",
            "1657 (40, 174)\n",
            "1658 (40, 174)\n",
            "1659 (40, 174)\n",
            "1660 (40, 174)\n",
            "1661 (40, 174)\n",
            "1662 (40, 174)\n",
            "1663 (40, 174)\n",
            "1664 (40, 174)\n",
            "1665 (40, 174)\n",
            "1666 (40, 174)\n",
            "1667 (40, 174)\n",
            "1668 (40, 174)\n",
            "1669 (40, 174)\n",
            "1670 (40, 174)\n",
            "1671 (40, 174)\n",
            "1672 (40, 174)\n",
            "1673 (40, 174)\n",
            "1674 (40, 174)\n",
            "1675 (40, 174)\n",
            "1676 (40, 174)\n",
            "1677 (40, 174)\n",
            "1678 (40, 174)\n",
            "1679 (40, 174)\n",
            "1680 (40, 174)\n",
            "1681 (40, 174)\n",
            "1682 (40, 174)\n",
            "1683 (40, 174)\n",
            "1684 (40, 174)\n",
            "1685 (40, 174)\n",
            "1686 (40, 174)\n",
            "1687 (40, 174)\n",
            "1688 (40, 174)\n",
            "1689 (40, 174)\n",
            "1690 (40, 174)\n",
            "1691 (40, 174)\n",
            "1692 (40, 174)\n",
            "1693 (40, 174)\n",
            "1694 (40, 174)\n",
            "1695 (40, 174)\n",
            "1696 (40, 174)\n",
            "1697 (40, 174)\n",
            "1698 (40, 174)\n",
            "1699 (40, 174)\n",
            "1700 (40, 174)\n",
            "1701 (40, 174)\n",
            "1702 (40, 174)\n",
            "1703 (40, 174)\n",
            "1704 (40, 174)\n",
            "1705 (40, 174)\n",
            "1706 (40, 174)\n",
            "1707 (40, 174)\n",
            "1708 (40, 174)\n",
            "1709 (40, 174)\n",
            "1710 (40, 174)\n",
            "1711 (40, 174)\n",
            "1712 (40, 174)\n",
            "1713 (40, 174)\n",
            "1714 (40, 174)\n",
            "1715 (40, 174)\n",
            "1716 (40, 174)\n",
            "1717 (40, 174)\n",
            "1718 (40, 174)\n",
            "1719 (40, 174)\n",
            "1720 (40, 174)\n",
            "1721 (40, 174)\n",
            "1722 (40, 174)\n",
            "1723 (40, 174)\n",
            "1724 (40, 174)\n",
            "1725 (40, 174)\n",
            "1726 (40, 174)\n",
            "1727 (40, 174)\n",
            "1728 (40, 174)\n",
            "1729 (40, 174)\n",
            "1730 (40, 174)\n",
            "1731 (40, 174)\n",
            "1732 (40, 174)\n",
            "1733 (40, 174)\n",
            "1734 (40, 174)\n",
            "1735 (40, 174)\n",
            "1736 (40, 174)\n",
            "1737 (40, 174)\n",
            "1738 (40, 174)\n",
            "1739 (40, 174)\n",
            "1740 (40, 174)\n",
            "1741 (40, 174)\n",
            "1742 (40, 174)\n",
            "1743 (40, 174)\n",
            "1744 (40, 174)\n",
            "1745 (40, 174)\n",
            "1746 (40, 174)\n",
            "1747 (40, 174)\n",
            "1748 (40, 174)\n",
            "1749 (40, 174)\n",
            "1750 (40, 174)\n",
            "1751 (40, 174)\n",
            "1752 (40, 174)\n",
            "1753 (40, 174)\n",
            "1754 (40, 174)\n",
            "1755 (40, 174)\n",
            "1756 (40, 174)\n",
            "1757 (40, 174)\n",
            "1758 (40, 174)\n",
            "1759 (40, 174)\n",
            "1760 (40, 174)\n",
            "1761 (40, 174)\n",
            "1762 (40, 174)\n",
            "1763 (40, 174)\n",
            "1764 (40, 174)\n",
            "1765 (40, 174)\n",
            "1766 (40, 174)\n",
            "1767 (40, 174)\n",
            "1768 (40, 174)\n",
            "1769 (40, 174)\n",
            "1770 (40, 174)\n",
            "1771 (40, 174)\n",
            "1772 (40, 174)\n",
            "1773 (40, 174)\n",
            "1774 (40, 174)\n",
            "1775 (40, 174)\n",
            "1776 (40, 174)\n",
            "1777 (40, 174)\n",
            "1778 (40, 174)\n",
            "1779 (40, 174)\n",
            "1780 (40, 174)\n",
            "1781 (40, 174)\n",
            "1782 (40, 174)\n",
            "1783 (40, 174)\n",
            "1784 (40, 174)\n",
            "1785 (40, 174)\n",
            "1786 (40, 174)\n",
            "1787 (40, 174)\n",
            "1788 (40, 174)\n",
            "1789 (40, 174)\n",
            "1790 (40, 174)\n",
            "1791 (40, 174)\n",
            "1792 (40, 174)\n",
            "1793 (40, 174)\n",
            "1794 (40, 174)\n",
            "1795 (40, 174)\n",
            "1796 (40, 174)\n",
            "1797 (40, 174)\n",
            "1798 (40, 174)\n",
            "1799 (40, 174)\n",
            "1800 (40, 174)\n",
            "1801 (40, 174)\n",
            "1802 (40, 174)\n",
            "1803 (40, 174)\n",
            "1804 (40, 174)\n",
            "1805 (40, 174)\n",
            "1806 (40, 174)\n",
            "1807 (40, 174)\n",
            "1808 (40, 174)\n",
            "1809 (40, 174)\n",
            "1810 (40, 174)\n",
            "1811 (40, 174)\n",
            "1812 (40, 174)\n",
            "1813 (40, 174)\n",
            "1814 (40, 174)\n",
            "1815 (40, 174)\n",
            "1816 (40, 174)\n",
            "1817 (40, 174)\n",
            "1818 (40, 174)\n",
            "1819 (40, 174)\n",
            "1820 (40, 174)\n",
            "1821 (40, 174)\n",
            "1822 (40, 174)\n",
            "1823 (40, 174)\n",
            "1824 (40, 174)\n",
            "1825 (40, 174)\n",
            "1826 (40, 174)\n",
            "1827 (40, 174)\n",
            "1828 (40, 174)\n",
            "1829 (40, 174)\n",
            "1830 (40, 174)\n",
            "1831 (40, 174)\n",
            "1832 (40, 174)\n",
            "1833 (40, 174)\n",
            "1834 (40, 174)\n",
            "1835 (40, 174)\n",
            "1836 (40, 174)\n",
            "1837 (40, 174)\n",
            "1838 (40, 174)\n",
            "1839 (40, 174)\n",
            "1840 (40, 174)\n",
            "1841 (40, 174)\n",
            "1842 (40, 174)\n",
            "1843 (40, 174)\n",
            "1844 (40, 174)\n",
            "1845 (40, 174)\n",
            "1846 (40, 174)\n",
            "1847 (40, 174)\n",
            "1848 (40, 174)\n",
            "1849 (40, 174)\n",
            "1850 (40, 174)\n",
            "1851 (40, 174)\n",
            "1852 (40, 174)\n",
            "1853 (40, 174)\n",
            "1854 (40, 174)\n",
            "1855 (40, 174)\n",
            "1856 (40, 174)\n",
            "1857 (40, 174)\n",
            "1858 (40, 174)\n",
            "1859 (40, 174)\n",
            "1860 (40, 174)\n",
            "1861 (40, 174)\n",
            "1862 (40, 174)\n",
            "1863 (40, 174)\n",
            "1864 (40, 174)\n",
            "1865 (40, 174)\n",
            "1866 (40, 174)\n",
            "1867 (40, 174)\n",
            "1868 (40, 174)\n",
            "1869 (40, 174)\n",
            "1870 (40, 174)\n",
            "1871 (40, 174)\n",
            "1872 (40, 174)\n",
            "1873 (40, 174)\n",
            "1874 (40, 174)\n",
            "1875 (40, 174)\n",
            "1876 (40, 174)\n",
            "1877 (40, 174)\n",
            "1878 (40, 174)\n",
            "1879 (40, 174)\n",
            "1880 (40, 174)\n",
            "1881 (40, 174)\n",
            "1882 (40, 174)\n",
            "1883 (40, 174)\n",
            "1884 (40, 174)\n",
            "1885 (40, 174)\n",
            "1886 (40, 174)\n",
            "1887 (40, 174)\n",
            "1888 (40, 174)\n",
            "1889 (40, 174)\n",
            "1890 (40, 174)\n",
            "1891 (40, 174)\n",
            "1892 (40, 174)\n",
            "1893 (40, 174)\n",
            "1894 (40, 174)\n",
            "1895 (40, 174)\n",
            "1896 (40, 174)\n",
            "1897 (40, 174)\n",
            "1898 (40, 174)\n",
            "1899 (40, 174)\n",
            "1900 (40, 174)\n",
            "1901 (40, 174)\n",
            "1902 (40, 174)\n",
            "1903 (40, 174)\n",
            "1904 (40, 174)\n",
            "1905 (40, 174)\n",
            "1906 (40, 174)\n",
            "1907 (40, 174)\n",
            "1908 (40, 174)\n",
            "1909 (40, 174)\n",
            "1910 (40, 174)\n",
            "1911 (40, 174)\n",
            "1912 (40, 174)\n",
            "1913 (40, 174)\n",
            "1914 (40, 174)\n",
            "1915 (40, 174)\n",
            "1916 (40, 174)\n",
            "1917 (40, 174)\n",
            "1918 (40, 174)\n",
            "1919 (40, 174)\n",
            "1920 (40, 174)\n",
            "1921 (40, 174)\n",
            "1922 (40, 174)\n",
            "1923 (40, 174)\n",
            "1924 (40, 174)\n",
            "1925 (40, 174)\n",
            "1926 (40, 174)\n",
            "1927 (40, 174)\n",
            "1928 (40, 174)\n",
            "1929 (40, 174)\n",
            "1930 (40, 174)\n",
            "1931 (40, 174)\n",
            "1932 (40, 174)\n",
            "1933 (40, 174)\n",
            "1934 (40, 174)\n",
            "1935 (40, 174)\n",
            "1936 (40, 174)\n",
            "1937 (40, 174)\n",
            "1938 (40, 174)\n",
            "1939 (40, 174)\n",
            "1940 (40, 174)\n",
            "1941 (40, 174)\n",
            "1942 (40, 174)\n",
            "1943 (40, 174)\n",
            "1944 (40, 174)\n",
            "1945 (40, 174)\n",
            "1946 (40, 174)\n",
            "1947 (40, 174)\n",
            "1948 (40, 174)\n",
            "1949 (40, 174)\n",
            "1950 (40, 174)\n",
            "1951 (40, 174)\n",
            "1952 (40, 174)\n",
            "1953 (40, 174)\n",
            "1954 (40, 174)\n",
            "1955 (40, 174)\n",
            "1956 (40, 174)\n",
            "1957 (40, 174)\n",
            "1958 (40, 174)\n",
            "1959 (40, 174)\n",
            "1960 (40, 174)\n",
            "1961 (40, 174)\n",
            "1962 (40, 174)\n",
            "1963 (40, 174)\n",
            "1964 (40, 174)\n",
            "1965 (40, 174)\n",
            "1966 (40, 174)\n",
            "1967 (40, 174)\n",
            "1968 (40, 174)\n",
            "1969 (40, 174)\n",
            "1970 (40, 174)\n",
            "1971 (40, 174)\n",
            "1972 (40, 174)\n",
            "1973 (40, 174)\n",
            "1974 (40, 174)\n",
            "1975 (40, 174)\n",
            "1976 (40, 174)\n",
            "1977 (40, 174)\n",
            "1978 (40, 174)\n",
            "1979 (40, 174)\n",
            "1980 (40, 174)\n",
            "1981 (40, 174)\n",
            "1982 (40, 174)\n",
            "1983 (40, 174)\n",
            "1984 (40, 174)\n",
            "1985 (40, 174)\n",
            "1986 (40, 174)\n",
            "1987 (40, 174)\n",
            "1988 (40, 174)\n",
            "1989 (40, 174)\n",
            "1990 (40, 174)\n",
            "1991 (40, 174)\n",
            "1992 (40, 174)\n",
            "1993 (40, 174)\n",
            "1994 (40, 174)\n",
            "1995 (40, 174)\n",
            "1996 (40, 174)\n",
            "1997 (40, 174)\n",
            "1998 (40, 174)\n",
            "1999 (40, 174)\n",
            "2000 (40, 174)\n",
            "2001 (40, 174)\n",
            "2002 (40, 174)\n",
            "2003 (40, 174)\n",
            "2004 (40, 174)\n",
            "2005 (40, 174)\n",
            "2006 (40, 174)\n",
            "2007 (40, 174)\n",
            "2008 (40, 174)\n",
            "2009 (40, 174)\n",
            "2010 (40, 174)\n",
            "2011 (40, 174)\n",
            "2012 (40, 174)\n",
            "2013 (40, 174)\n",
            "2014 (40, 174)\n",
            "2015 (40, 174)\n",
            "2016 (40, 174)\n",
            "2017 (40, 174)\n",
            "2018 (40, 174)\n",
            "2019 (40, 174)\n",
            "2020 (40, 174)\n",
            "2021 (40, 174)\n",
            "2022 (40, 174)\n",
            "2023 (40, 174)\n",
            "2024 (40, 174)\n",
            "2025 (40, 174)\n",
            "2026 (40, 174)\n",
            "2027 (40, 174)\n",
            "2028 (40, 174)\n",
            "2029 (40, 174)\n",
            "2030 (40, 174)\n",
            "2031 (40, 174)\n",
            "2032 (40, 174)\n",
            "2033 (40, 174)\n",
            "2034 (40, 174)\n",
            "2035 (40, 174)\n",
            "2036 (40, 174)\n",
            "2037 (40, 174)\n",
            "2038 (40, 174)\n",
            "2039 (40, 174)\n",
            "2040 (40, 174)\n",
            "2041 (40, 174)\n",
            "2042 (40, 174)\n",
            "2043 (40, 174)\n",
            "2044 (40, 174)\n",
            "2045 (40, 174)\n",
            "2046 (40, 174)\n",
            "2047 (40, 174)\n",
            "2048 (40, 174)\n",
            "2049 (40, 174)\n",
            "2050 (40, 174)\n",
            "2051 (40, 174)\n",
            "2052 (40, 174)\n",
            "2053 (40, 174)\n",
            "2054 (40, 174)\n",
            "2055 (40, 174)\n",
            "2056 (40, 174)\n",
            "2057 (40, 174)\n",
            "2058 (40, 174)\n",
            "2059 (40, 174)\n",
            "2060 (40, 174)\n",
            "2061 (40, 174)\n",
            "2062 (40, 174)\n",
            "2063 (40, 174)\n",
            "2064 (40, 174)\n",
            "2065 (40, 174)\n",
            "2066 (40, 174)\n",
            "2067 (40, 174)\n",
            "2068 (40, 174)\n",
            "2069 (40, 174)\n",
            "2070 (40, 174)\n",
            "2071 (40, 174)\n",
            "2072 (40, 174)\n",
            "2073 (40, 174)\n",
            "2074 (40, 174)\n",
            "2075 (40, 174)\n",
            "2076 (40, 174)\n",
            "2077 (40, 174)\n",
            "2078 (40, 174)\n",
            "2079 (40, 174)\n",
            "2080 (40, 174)\n",
            "2081 (40, 174)\n",
            "2082 (40, 174)\n",
            "2083 (40, 174)\n",
            "2084 (40, 174)\n",
            "2085 (40, 174)\n",
            "2086 (40, 174)\n",
            "2087 (40, 174)\n",
            "2088 (40, 174)\n",
            "2089 (40, 174)\n",
            "2090 (40, 174)\n",
            "2091 (40, 174)\n",
            "2092 (40, 174)\n",
            "2093 (40, 174)\n",
            "2094 (40, 174)\n",
            "2095 (40, 174)\n",
            "2096 (40, 174)\n",
            "2097 (40, 174)\n",
            "2098 (40, 174)\n",
            "2099 (40, 174)\n",
            "2100 (40, 174)\n",
            "2101 (40, 174)\n",
            "2102 (40, 174)\n",
            "2103 (40, 174)\n",
            "2104 (40, 174)\n",
            "2105 (40, 174)\n",
            "2106 (40, 174)\n",
            "2107 (40, 174)\n",
            "2108 (40, 174)\n",
            "2109 (40, 174)\n",
            "2110 (40, 174)\n",
            "2111 (40, 174)\n",
            "2112 (40, 174)\n",
            "2113 (40, 174)\n",
            "2114 (40, 174)\n",
            "2115 (40, 174)\n",
            "2116 (40, 174)\n",
            "2117 (40, 174)\n",
            "2118 (40, 174)\n",
            "2119 (40, 174)\n",
            "2120 (40, 174)\n",
            "2121 (40, 174)\n",
            "2122 (40, 174)\n",
            "2123 (40, 174)\n",
            "2124 (40, 174)\n",
            "2125 (40, 174)\n",
            "2126 (40, 174)\n",
            "2127 (40, 174)\n",
            "2128 (40, 174)\n",
            "2129 (40, 174)\n",
            "2130 (40, 174)\n",
            "2131 (40, 174)\n",
            "2132 (40, 174)\n",
            "2133 (40, 174)\n",
            "2134 (40, 174)\n",
            "2135 (40, 174)\n",
            "2136 (40, 174)\n",
            "2137 (40, 174)\n",
            "2138 (40, 174)\n",
            "2139 (40, 174)\n",
            "2140 (40, 174)\n",
            "2141 (40, 174)\n",
            "2142 (40, 174)\n",
            "2143 (40, 174)\n",
            "2144 (40, 174)\n",
            "2145 (40, 174)\n",
            "2146 (40, 174)\n",
            "2147 (40, 174)\n",
            "2148 (40, 174)\n",
            "2149 (40, 174)\n",
            "2150 (40, 174)\n",
            "2151 (40, 174)\n",
            "2152 (40, 174)\n",
            "2153 (40, 174)\n",
            "2154 (40, 174)\n",
            "2155 (40, 174)\n",
            "2156 (40, 174)\n",
            "2157 (40, 174)\n",
            "2158 (40, 174)\n",
            "2159 (40, 174)\n",
            "2160 (40, 174)\n",
            "2161 (40, 174)\n",
            "2162 (40, 174)\n",
            "2163 (40, 174)\n",
            "2164 (40, 174)\n",
            "2165 (40, 174)\n",
            "2166 (40, 174)\n",
            "2167 (40, 174)\n",
            "2168 (40, 174)\n",
            "2169 (40, 174)\n",
            "2170 (40, 174)\n",
            "2171 (40, 174)\n",
            "2172 (40, 174)\n",
            "2173 (40, 174)\n",
            "2174 (40, 174)\n",
            "2175 (40, 174)\n",
            "2176 (40, 174)\n",
            "2177 (40, 174)\n",
            "2178 (40, 174)\n",
            "2179 (40, 174)\n",
            "2180 (40, 174)\n",
            "2181 (40, 174)\n",
            "2182 (40, 174)\n",
            "2183 (40, 174)\n",
            "2184 (40, 174)\n",
            "2185 (40, 174)\n",
            "2186 (40, 174)\n",
            "2187 (40, 174)\n",
            "2188 (40, 174)\n",
            "2189 (40, 174)\n",
            "2190 (40, 174)\n",
            "2191 (40, 174)\n",
            "2192 (40, 174)\n",
            "2193 (40, 174)\n",
            "2194 (40, 174)\n",
            "2195 (40, 174)\n",
            "2196 (40, 174)\n",
            "2197 (40, 174)\n",
            "2198 (40, 174)\n",
            "2199 (40, 174)\n",
            "2200 (40, 174)\n",
            "2201 (40, 174)\n",
            "2202 (40, 174)\n",
            "2203 (40, 174)\n",
            "2204 (40, 174)\n",
            "2205 (40, 174)\n",
            "2206 (40, 174)\n",
            "2207 (40, 174)\n",
            "2208 (40, 174)\n",
            "2209 (40, 174)\n",
            "2210 (40, 174)\n",
            "2211 (40, 174)\n",
            "2212 (40, 174)\n",
            "2213 (40, 174)\n",
            "2214 (40, 174)\n",
            "2215 (40, 174)\n",
            "2216 (40, 174)\n",
            "2217 (40, 174)\n",
            "2218 (40, 174)\n",
            "2219 (40, 174)\n",
            "2220 (40, 174)\n",
            "2221 (40, 174)\n",
            "2222 (40, 174)\n",
            "2223 (40, 174)\n",
            "2224 (40, 174)\n",
            "2225 (40, 174)\n",
            "2226 (40, 174)\n",
            "2227 (40, 174)\n",
            "2228 (40, 174)\n",
            "2229 (40, 174)\n",
            "2230 (40, 174)\n",
            "2231 (40, 174)\n",
            "2232 (40, 174)\n",
            "2233 (40, 174)\n",
            "2234 (40, 174)\n",
            "2235 (40, 174)\n",
            "2236 (40, 174)\n",
            "2237 (40, 174)\n",
            "2238 (40, 174)\n",
            "2239 (40, 174)\n",
            "2240 (40, 174)\n",
            "2241 (40, 174)\n",
            "2242 (40, 174)\n",
            "2243 (40, 174)\n",
            "2244 (40, 174)\n",
            "2245 (40, 174)\n",
            "2246 (40, 174)\n",
            "2247 (40, 174)\n",
            "2248 (40, 174)\n",
            "2249 (40, 174)\n",
            "2250 (40, 174)\n",
            "2251 (40, 174)\n",
            "2252 (40, 174)\n",
            "2253 (40, 174)\n",
            "2254 (40, 174)\n",
            "2255 (40, 174)\n",
            "2256 (40, 174)\n",
            "2257 (40, 174)\n",
            "2258 (40, 174)\n",
            "2259 (40, 174)\n",
            "2260 (40, 174)\n",
            "2261 (40, 174)\n",
            "2262 (40, 174)\n",
            "2263 (40, 174)\n",
            "2264 (40, 174)\n",
            "2265 (40, 174)\n",
            "2266 (40, 174)\n",
            "2267 (40, 174)\n",
            "2268 (40, 174)\n",
            "2269 (40, 174)\n",
            "2270 (40, 174)\n",
            "2271 (40, 174)\n",
            "2272 (40, 174)\n",
            "2273 (40, 174)\n",
            "2274 (40, 174)\n",
            "2275 (40, 174)\n",
            "2276 (40, 174)\n",
            "2277 (40, 174)\n",
            "2278 (40, 174)\n",
            "2279 (40, 174)\n",
            "2280 (40, 174)\n",
            "2281 (40, 174)\n",
            "2282 (40, 174)\n",
            "2283 (40, 174)\n",
            "2284 (40, 174)\n",
            "2285 (40, 174)\n",
            "2286 (40, 174)\n",
            "2287 (40, 174)\n",
            "2288 (40, 174)\n",
            "2289 (40, 174)\n",
            "2290 (40, 174)\n",
            "2291 (40, 174)\n",
            "2292 (40, 174)\n",
            "2293 (40, 174)\n",
            "2294 (40, 174)\n",
            "2295 (40, 174)\n",
            "2296 (40, 174)\n",
            "2297 (40, 174)\n",
            "2298 (40, 174)\n",
            "2299 (40, 174)\n",
            "2300 (40, 174)\n",
            "2301 (40, 174)\n",
            "2302 (40, 174)\n",
            "2303 (40, 174)\n",
            "2304 (40, 174)\n",
            "2305 (40, 174)\n",
            "2306 (40, 174)\n",
            "2307 (40, 174)\n",
            "2308 (40, 174)\n",
            "2309 (40, 174)\n",
            "2310 (40, 174)\n",
            "2311 (40, 174)\n",
            "2312 (40, 174)\n",
            "2313 (40, 174)\n",
            "2314 (40, 174)\n",
            "2315 (40, 174)\n",
            "2316 (40, 174)\n",
            "2317 (40, 174)\n",
            "2318 (40, 174)\n",
            "2319 (40, 174)\n",
            "2320 (40, 174)\n",
            "2321 (40, 174)\n",
            "2322 (40, 174)\n",
            "2323 (40, 174)\n",
            "2324 (40, 174)\n",
            "2325 (40, 174)\n",
            "2326 (40, 174)\n",
            "2327 (40, 174)\n",
            "2328 (40, 174)\n",
            "2329 (40, 174)\n",
            "2330 (40, 174)\n",
            "2331 (40, 174)\n",
            "2332 (40, 174)\n",
            "2333 (40, 174)\n",
            "2334 (40, 174)\n",
            "2335 (40, 174)\n",
            "2336 (40, 174)\n",
            "2337 (40, 174)\n",
            "2338 (40, 174)\n",
            "2339 (40, 174)\n",
            "2340 (40, 174)\n",
            "2341 (40, 174)\n",
            "2342 (40, 174)\n",
            "2343 (40, 174)\n",
            "2344 (40, 174)\n",
            "2345 (40, 174)\n",
            "2346 (40, 174)\n",
            "2347 (40, 174)\n",
            "2348 (40, 174)\n",
            "2349 (40, 174)\n",
            "2350 (40, 174)\n",
            "2351 (40, 174)\n",
            "2352 (40, 174)\n",
            "2353 (40, 174)\n",
            "2354 (40, 174)\n",
            "2355 (40, 174)\n",
            "2356 (40, 174)\n",
            "2357 (40, 174)\n",
            "2358 (40, 174)\n",
            "2359 (40, 174)\n",
            "2360 (40, 174)\n",
            "2361 (40, 174)\n",
            "2362 (40, 174)\n",
            "2363 (40, 174)\n",
            "2364 (40, 174)\n",
            "2365 (40, 174)\n",
            "2366 (40, 174)\n",
            "2367 (40, 174)\n",
            "2368 (40, 174)\n",
            "2369 (40, 174)\n",
            "2370 (40, 174)\n",
            "2371 (40, 174)\n",
            "2372 (40, 174)\n",
            "2373 (40, 174)\n",
            "2374 (40, 174)\n",
            "2375 (40, 174)\n",
            "2376 (40, 174)\n",
            "2377 (40, 174)\n",
            "2378 (40, 174)\n",
            "2379 (40, 174)\n",
            "2380 (40, 174)\n",
            "2381 (40, 174)\n",
            "2382 (40, 174)\n",
            "2383 (40, 174)\n",
            "2384 (40, 174)\n",
            "2385 (40, 174)\n",
            "2386 (40, 174)\n",
            "2387 (40, 174)\n",
            "2388 (40, 174)\n",
            "2389 (40, 174)\n",
            "2390 (40, 174)\n",
            "2391 (40, 174)\n",
            "2392 (40, 174)\n",
            "2393 (40, 174)\n",
            "2394 (40, 174)\n",
            "2395 (40, 174)\n",
            "2396 (40, 174)\n",
            "2397 (40, 174)\n",
            "2398 (40, 174)\n",
            "2399 (40, 174)\n",
            "2400 (40, 174)\n",
            "2401 (40, 174)\n",
            "2402 (40, 174)\n",
            "2403 (40, 174)\n",
            "2404 (40, 174)\n",
            "2405 (40, 174)\n",
            "2406 (40, 174)\n",
            "2407 (40, 174)\n",
            "2408 (40, 174)\n",
            "2409 (40, 174)\n",
            "2410 (40, 174)\n",
            "2411 (40, 174)\n",
            "2412 (40, 174)\n",
            "2413 (40, 174)\n",
            "2414 (40, 174)\n",
            "2415 (40, 174)\n",
            "2416 (40, 174)\n",
            "2417 (40, 174)\n",
            "2418 (40, 174)\n",
            "2419 (40, 174)\n",
            "2420 (40, 174)\n",
            "2421 (40, 174)\n",
            "2422 (40, 174)\n",
            "2423 (40, 174)\n",
            "2424 (40, 174)\n",
            "2425 (40, 174)\n",
            "2426 (40, 174)\n",
            "2427 (40, 174)\n",
            "2428 (40, 174)\n",
            "2429 (40, 174)\n",
            "2430 (40, 174)\n",
            "2431 (40, 174)\n",
            "2432 (40, 174)\n",
            "2433 (40, 174)\n",
            "2434 (40, 174)\n",
            "2435 (40, 174)\n",
            "2436 (40, 174)\n",
            "2437 (40, 174)\n",
            "2438 (40, 174)\n",
            "2439 (40, 174)\n",
            "2440 (40, 174)\n",
            "2441 (40, 174)\n",
            "2442 (40, 174)\n",
            "2443 (40, 174)\n",
            "2444 (40, 174)\n",
            "2445 (40, 174)\n",
            "2446 (40, 174)\n",
            "2447 (40, 174)\n",
            "2448 (40, 174)\n",
            "2449 (40, 174)\n",
            "2450 (40, 174)\n",
            "2451 (40, 174)\n",
            "2452 (40, 174)\n",
            "2453 (40, 174)\n",
            "2454 (40, 174)\n",
            "2455 (40, 174)\n",
            "2456 (40, 174)\n",
            "2457 (40, 174)\n",
            "2458 (40, 174)\n",
            "2459 (40, 174)\n",
            "2460 (40, 174)\n",
            "2461 (40, 174)\n",
            "2462 (40, 174)\n",
            "2463 (40, 174)\n",
            "2464 (40, 174)\n",
            "2465 (40, 174)\n",
            "2466 (40, 174)\n",
            "2467 (40, 174)\n",
            "2468 (40, 174)\n",
            "2469 (40, 174)\n",
            "2470 (40, 174)\n",
            "2471 (40, 174)\n",
            "2472 (40, 174)\n",
            "2473 (40, 174)\n",
            "2474 (40, 174)\n",
            "2475 (40, 174)\n",
            "2476 (40, 174)\n",
            "2477 (40, 174)\n",
            "2478 (40, 174)\n",
            "2479 (40, 174)\n",
            "2480 (40, 174)\n",
            "2481 (40, 174)\n",
            "2482 (40, 174)\n",
            "2483 (40, 174)\n",
            "2484 (40, 174)\n",
            "2485 (40, 174)\n",
            "2486 (40, 174)\n",
            "2487 (40, 174)\n",
            "2488 (40, 174)\n",
            "2489 (40, 174)\n",
            "2490 (40, 174)\n",
            "2491 (40, 174)\n",
            "2492 (40, 174)\n",
            "2493 (40, 174)\n",
            "2494 (40, 174)\n",
            "2495 (40, 174)\n",
            "2496 (40, 174)\n",
            "2497 (40, 174)\n",
            "2498 (40, 174)\n",
            "2499 (40, 174)\n",
            "2500 (40, 174)\n",
            "2501 (40, 174)\n",
            "2502 (40, 174)\n",
            "2503 (40, 174)\n",
            "2504 (40, 174)\n",
            "2505 (40, 174)\n",
            "2506 (40, 174)\n",
            "2507 (40, 174)\n",
            "2508 (40, 174)\n",
            "2509 (40, 174)\n",
            "2510 (40, 174)\n",
            "2511 (40, 174)\n",
            "2512 (40, 174)\n",
            "2513 (40, 174)\n",
            "2514 (40, 174)\n",
            "2515 (40, 174)\n",
            "2516 (40, 174)\n",
            "2517 (40, 174)\n",
            "2518 (40, 174)\n",
            "2519 (40, 174)\n",
            "2520 (40, 174)\n",
            "2521 (40, 174)\n",
            "2522 (40, 174)\n",
            "2523 (40, 174)\n",
            "2524 (40, 174)\n",
            "2525 (40, 174)\n",
            "2526 (40, 174)\n",
            "2527 (40, 174)\n",
            "2528 (40, 174)\n",
            "2529 (40, 174)\n",
            "2530 (40, 174)\n",
            "2531 (40, 174)\n",
            "2532 (40, 174)\n",
            "2533 (40, 174)\n",
            "2534 (40, 174)\n",
            "2535 (40, 174)\n",
            "2536 (40, 174)\n",
            "2537 (40, 174)\n",
            "2538 (40, 174)\n",
            "2539 (40, 174)\n",
            "2540 (40, 174)\n",
            "2541 (40, 174)\n",
            "2542 (40, 174)\n",
            "2543 (40, 174)\n",
            "2544 (40, 174)\n",
            "2545 (40, 174)\n",
            "2546 (40, 174)\n",
            "2547 (40, 174)\n",
            "2548 (40, 174)\n",
            "2549 (40, 174)\n",
            "2550 (40, 174)\n",
            "2551 (40, 174)\n",
            "2552 (40, 174)\n",
            "2553 (40, 174)\n",
            "2554 (40, 174)\n",
            "2555 (40, 174)\n",
            "2556 (40, 174)\n",
            "2557 (40, 174)\n",
            "2558 (40, 174)\n",
            "2559 (40, 174)\n",
            "2560 (40, 174)\n",
            "2561 (40, 174)\n",
            "2562 (40, 174)\n",
            "2563 (40, 174)\n",
            "2564 (40, 174)\n",
            "2565 (40, 174)\n",
            "2566 (40, 174)\n",
            "2567 (40, 174)\n",
            "2568 (40, 174)\n",
            "2569 (40, 174)\n",
            "2570 (40, 174)\n",
            "2571 (40, 174)\n",
            "2572 (40, 174)\n",
            "2573 (40, 174)\n",
            "2574 (40, 174)\n",
            "2575 (40, 174)\n",
            "2576 (40, 174)\n",
            "2577 (40, 174)\n",
            "2578 (40, 174)\n",
            "2579 (40, 174)\n",
            "2580 (40, 174)\n",
            "2581 (40, 174)\n",
            "2582 (40, 174)\n",
            "2583 (40, 174)\n",
            "2584 (40, 174)\n",
            "2585 (40, 174)\n",
            "2586 (40, 174)\n",
            "2587 (40, 174)\n",
            "2588 (40, 174)\n",
            "2589 (40, 174)\n",
            "2590 (40, 174)\n",
            "2591 (40, 174)\n",
            "2592 (40, 174)\n",
            "2593 (40, 174)\n",
            "2594 (40, 174)\n",
            "2595 (40, 174)\n",
            "2596 (40, 174)\n",
            "2597 (40, 174)\n",
            "2598 (40, 174)\n",
            "2599 (40, 174)\n",
            "2600 (40, 174)\n",
            "2601 (40, 174)\n",
            "2602 (40, 174)\n",
            "2603 (40, 174)\n",
            "2604 (40, 174)\n",
            "2605 (40, 174)\n",
            "2606 (40, 174)\n",
            "2607 (40, 174)\n",
            "2608 (40, 174)\n",
            "2609 (40, 174)\n",
            "2610 (40, 174)\n",
            "2611 (40, 174)\n",
            "2612 (40, 174)\n",
            "2613 (40, 174)\n",
            "2614 (40, 174)\n",
            "2615 (40, 174)\n",
            "2616 (40, 174)\n",
            "2617 (40, 174)\n",
            "2618 (40, 174)\n",
            "2619 (40, 174)\n",
            "2620 (40, 174)\n",
            "2621 (40, 174)\n",
            "2622 (40, 174)\n",
            "2623 (40, 174)\n",
            "2624 (40, 174)\n",
            "2625 (40, 174)\n",
            "2626 (40, 174)\n",
            "2627 (40, 174)\n",
            "2628 (40, 174)\n",
            "2629 (40, 174)\n",
            "2630 (40, 174)\n",
            "2631 (40, 174)\n",
            "2632 (40, 174)\n",
            "2633 (40, 174)\n",
            "2634 (40, 174)\n",
            "2635 (40, 174)\n",
            "2636 (40, 174)\n",
            "2637 (40, 174)\n",
            "2638 (40, 174)\n",
            "2639 (40, 174)\n",
            "2640 (40, 174)\n",
            "2641 (40, 174)\n",
            "2642 (40, 174)\n",
            "2643 (40, 174)\n",
            "2644 (40, 174)\n",
            "2645 (40, 174)\n",
            "2646 (40, 174)\n",
            "2647 (40, 174)\n",
            "2648 (40, 174)\n",
            "2649 (40, 174)\n",
            "2650 (40, 174)\n",
            "2651 (40, 174)\n",
            "2652 (40, 174)\n",
            "2653 (40, 174)\n",
            "2654 (40, 174)\n",
            "2655 (40, 174)\n",
            "2656 (40, 174)\n",
            "2657 (40, 174)\n",
            "2658 (40, 174)\n",
            "2659 (40, 174)\n",
            "2660 (40, 174)\n",
            "2661 (40, 174)\n",
            "2662 (40, 174)\n",
            "2663 (40, 174)\n",
            "2664 (40, 174)\n",
            "2665 (40, 174)\n",
            "2666 (40, 174)\n",
            "2667 (40, 174)\n",
            "2668 (40, 174)\n",
            "2669 (40, 174)\n",
            "2670 (40, 174)\n",
            "2671 (40, 174)\n",
            "2672 (40, 174)\n",
            "2673 (40, 174)\n",
            "2674 (40, 174)\n",
            "2675 (40, 174)\n",
            "2676 (40, 174)\n",
            "2677 (40, 174)\n",
            "2678 (40, 174)\n",
            "2679 (40, 174)\n",
            "2680 (40, 174)\n",
            "2681 (40, 174)\n",
            "2682 (40, 174)\n",
            "2683 (40, 174)\n",
            "2684 (40, 174)\n",
            "2685 (40, 174)\n",
            "2686 (40, 174)\n",
            "2687 (40, 174)\n",
            "2688 (40, 174)\n",
            "2689 (40, 174)\n",
            "2690 (40, 174)\n",
            "2691 (40, 174)\n",
            "2692 (40, 174)\n",
            "2693 (40, 174)\n",
            "2694 (40, 174)\n",
            "2695 (40, 174)\n",
            "2696 (40, 174)\n",
            "2697 (40, 174)\n",
            "2698 (40, 174)\n",
            "2699 (40, 174)\n",
            "2700 (40, 174)\n",
            "2701 (40, 174)\n",
            "2702 (40, 174)\n",
            "2703 (40, 174)\n",
            "2704 (40, 174)\n",
            "2705 (40, 174)\n",
            "2706 (40, 174)\n",
            "2707 (40, 174)\n",
            "2708 (40, 174)\n",
            "2709 (40, 174)\n",
            "2710 (40, 174)\n",
            "2711 (40, 174)\n",
            "2712 (40, 174)\n",
            "2713 (40, 174)\n",
            "2714 (40, 174)\n",
            "2715 (40, 174)\n",
            "2716 (40, 174)\n",
            "2717 (40, 174)\n",
            "2718 (40, 174)\n",
            "2719 (40, 174)\n",
            "2720 (40, 174)\n",
            "2721 (40, 174)\n",
            "2722 (40, 174)\n",
            "2723 (40, 174)\n",
            "2724 (40, 174)\n",
            "2725 (40, 174)\n",
            "2726 (40, 174)\n",
            "2727 (40, 174)\n",
            "2728 (40, 174)\n",
            "2729 (40, 174)\n",
            "2730 (40, 174)\n",
            "2731 (40, 174)\n",
            "2732 (40, 174)\n",
            "2733 (40, 174)\n",
            "2734 (40, 174)\n",
            "2735 (40, 174)\n",
            "2736 (40, 174)\n",
            "2737 (40, 174)\n",
            "2738 (40, 174)\n",
            "2739 (40, 174)\n",
            "2740 (40, 174)\n",
            "2741 (40, 174)\n",
            "2742 (40, 174)\n",
            "2743 (40, 174)\n",
            "2744 (40, 174)\n",
            "2745 (40, 174)\n",
            "2746 (40, 174)\n",
            "2747 (40, 174)\n",
            "2748 (40, 174)\n",
            "2749 (40, 174)\n",
            "2750 (40, 174)\n",
            "2751 (40, 174)\n",
            "2752 (40, 174)\n",
            "2753 (40, 174)\n",
            "2754 (40, 174)\n",
            "2755 (40, 174)\n",
            "2756 (40, 174)\n",
            "2757 (40, 174)\n",
            "2758 (40, 174)\n",
            "2759 (40, 174)\n",
            "2760 (40, 174)\n",
            "2761 (40, 174)\n",
            "2762 (40, 174)\n",
            "2763 (40, 174)\n",
            "2764 (40, 174)\n",
            "2765 (40, 174)\n",
            "2766 (40, 174)\n",
            "2767 (40, 174)\n",
            "2768 (40, 174)\n",
            "2769 (40, 174)\n",
            "2770 (40, 174)\n",
            "2771 (40, 174)\n",
            "2772 (40, 174)\n",
            "2773 (40, 174)\n",
            "2774 (40, 174)\n",
            "2775 (40, 174)\n",
            "2776 (40, 174)\n",
            "2777 (40, 174)\n",
            "2778 (40, 174)\n",
            "2779 (40, 174)\n",
            "2780 (40, 174)\n",
            "2781 (40, 174)\n",
            "2782 (40, 174)\n",
            "2783 (40, 174)\n",
            "2784 (40, 174)\n",
            "2785 (40, 174)\n",
            "2786 (40, 174)\n",
            "2787 (40, 174)\n",
            "2788 (40, 174)\n",
            "2789 (40, 174)\n",
            "2790 (40, 174)\n",
            "2791 (40, 174)\n",
            "2792 (40, 174)\n",
            "2793 (40, 174)\n",
            "2794 (40, 174)\n",
            "2795 (40, 174)\n",
            "2796 (40, 174)\n",
            "2797 (40, 174)\n",
            "2798 (40, 174)\n",
            "2799 (40, 174)\n",
            "2800 (40, 174)\n",
            "2801 (40, 174)\n",
            "2802 (40, 174)\n",
            "2803 (40, 174)\n",
            "2804 (40, 174)\n",
            "2805 (40, 174)\n",
            "2806 (40, 174)\n",
            "2807 (40, 174)\n",
            "2808 (40, 174)\n",
            "2809 (40, 174)\n",
            "2810 (40, 174)\n",
            "2811 (40, 174)\n",
            "2812 (40, 174)\n",
            "2813 (40, 174)\n",
            "2814 (40, 174)\n",
            "2815 (40, 174)\n",
            "2816 (40, 174)\n",
            "2817 (40, 174)\n",
            "2818 (40, 174)\n",
            "2819 (40, 174)\n",
            "2820 (40, 174)\n",
            "2821 (40, 174)\n",
            "2822 (40, 174)\n",
            "2823 (40, 174)\n",
            "2824 (40, 174)\n",
            "2825 (40, 174)\n",
            "2826 (40, 174)\n",
            "2827 (40, 174)\n",
            "2828 (40, 174)\n",
            "2829 (40, 174)\n",
            "2830 (40, 174)\n",
            "2831 (40, 174)\n",
            "2832 (40, 174)\n",
            "2833 (40, 174)\n",
            "2834 (40, 174)\n",
            "2835 (40, 174)\n",
            "2836 (40, 174)\n",
            "2837 (40, 174)\n",
            "2838 (40, 174)\n",
            "2839 (40, 174)\n",
            "2840 (40, 174)\n",
            "2841 (40, 174)\n",
            "2842 (40, 174)\n",
            "2843 (40, 174)\n",
            "2844 (40, 174)\n",
            "2845 (40, 174)\n",
            "2846 (40, 174)\n",
            "2847 (40, 174)\n",
            "2848 (40, 174)\n",
            "2849 (40, 174)\n",
            "2850 (40, 174)\n",
            "2851 (40, 174)\n",
            "2852 (40, 174)\n",
            "2853 (40, 174)\n",
            "2854 (40, 174)\n",
            "2855 (40, 174)\n",
            "2856 (40, 174)\n",
            "2857 (40, 174)\n",
            "2858 (40, 174)\n",
            "2859 (40, 174)\n",
            "2860 (40, 174)\n",
            "2861 (40, 174)\n",
            "2862 (40, 174)\n",
            "2863 (40, 174)\n",
            "2864 (40, 174)\n",
            "2865 (40, 174)\n",
            "2866 (40, 174)\n",
            "2867 (40, 174)\n",
            "2868 (40, 174)\n",
            "2869 (40, 174)\n",
            "2870 (40, 174)\n",
            "2871 (40, 174)\n",
            "2872 (40, 174)\n",
            "2873 (40, 174)\n",
            "2874 (40, 174)\n",
            "2875 (40, 174)\n",
            "2876 (40, 174)\n",
            "2877 (40, 174)\n",
            "2878 (40, 174)\n",
            "2879 (40, 174)\n",
            "2880 (40, 174)\n",
            "2881 (40, 174)\n",
            "2882 (40, 174)\n",
            "2883 (40, 174)\n",
            "2884 (40, 174)\n",
            "2885 (40, 174)\n",
            "2886 (40, 174)\n",
            "2887 (40, 174)\n",
            "2888 (40, 174)\n",
            "2889 (40, 174)\n",
            "2890 (40, 174)\n",
            "2891 (40, 174)\n",
            "2892 (40, 174)\n",
            "2893 (40, 174)\n",
            "2894 (40, 174)\n",
            "2895 (40, 174)\n",
            "2896 (40, 174)\n",
            "2897 (40, 174)\n",
            "2898 (40, 174)\n",
            "2899 (40, 174)\n",
            "2900 (40, 174)\n",
            "2901 (40, 174)\n",
            "2902 (40, 174)\n",
            "2903 (40, 174)\n",
            "2904 (40, 174)\n",
            "2905 (40, 174)\n",
            "2906 (40, 174)\n",
            "2907 (40, 174)\n",
            "2908 (40, 174)\n",
            "2909 (40, 174)\n",
            "2910 (40, 174)\n",
            "2911 (40, 174)\n",
            "2912 (40, 174)\n",
            "2913 (40, 174)\n",
            "2914 (40, 174)\n",
            "2915 (40, 174)\n",
            "2916 (40, 174)\n",
            "2917 (40, 174)\n",
            "2918 (40, 174)\n",
            "2919 (40, 174)\n",
            "2920 (40, 174)\n",
            "2921 (40, 174)\n",
            "2922 (40, 174)\n",
            "2923 (40, 174)\n",
            "2924 (40, 174)\n",
            "2925 (40, 174)\n",
            "2926 (40, 174)\n",
            "2927 (40, 174)\n",
            "2928 (40, 174)\n",
            "2929 (40, 174)\n",
            "2930 (40, 174)\n",
            "2931 (40, 174)\n",
            "2932 (40, 174)\n",
            "2933 (40, 174)\n",
            "2934 (40, 174)\n",
            "2935 (40, 174)\n",
            "2936 (40, 174)\n",
            "2937 (40, 174)\n",
            "2938 (40, 174)\n",
            "2939 (40, 174)\n",
            "2940 (40, 174)\n",
            "2941 (40, 174)\n",
            "2942 (40, 174)\n",
            "2943 (40, 174)\n",
            "2944 (40, 174)\n",
            "2945 (40, 174)\n",
            "2946 (40, 174)\n",
            "2947 (40, 174)\n",
            "2948 (40, 174)\n",
            "2949 (40, 174)\n",
            "2950 (40, 174)\n",
            "2951 (40, 174)\n",
            "2952 (40, 174)\n",
            "2953 (40, 174)\n",
            "2954 (40, 174)\n",
            "2955 (40, 174)\n",
            "2956 (40, 174)\n",
            "2957 (40, 174)\n",
            "2958 (40, 174)\n",
            "2959 (40, 174)\n",
            "2960 (40, 174)\n",
            "2961 (40, 174)\n",
            "2962 (40, 174)\n",
            "2963 (40, 174)\n",
            "2964 (40, 174)\n",
            "2965 (40, 174)\n",
            "2966 (40, 174)\n",
            "2967 (40, 174)\n",
            "2968 (40, 174)\n",
            "2969 (40, 174)\n",
            "2970 (40, 174)\n",
            "2971 (40, 174)\n",
            "2972 (40, 174)\n",
            "2973 (40, 174)\n",
            "2974 (40, 174)\n",
            "2975 (40, 174)\n",
            "2976 (40, 174)\n",
            "2977 (40, 174)\n",
            "2978 (40, 174)\n",
            "2979 (40, 174)\n",
            "2980 (40, 174)\n",
            "2981 (40, 174)\n",
            "2982 (40, 174)\n",
            "2983 (40, 174)\n",
            "2984 (40, 174)\n",
            "2985 (40, 174)\n",
            "2986 (40, 174)\n",
            "2987 (40, 174)\n",
            "2988 (40, 174)\n",
            "2989 (40, 174)\n",
            "2990 (40, 174)\n",
            "2991 (40, 174)\n",
            "2992 (40, 174)\n",
            "2993 (40, 174)\n",
            "2994 (40, 174)\n",
            "2995 (40, 174)\n",
            "2996 (40, 174)\n",
            "2997 (40, 174)\n",
            "2998 (40, 174)\n",
            "2999 (40, 174)\n",
            "3000 (40, 174)\n",
            "3001 (40, 174)\n",
            "3002 (40, 174)\n",
            "3003 (40, 174)\n",
            "3004 (40, 174)\n",
            "3005 (40, 174)\n",
            "3006 (40, 174)\n",
            "3007 (40, 174)\n",
            "3008 (40, 174)\n",
            "3009 (40, 174)\n",
            "3010 (40, 174)\n",
            "3011 (40, 174)\n",
            "3012 (40, 174)\n",
            "3013 (40, 174)\n",
            "3014 (40, 174)\n",
            "3015 (40, 174)\n",
            "3016 (40, 174)\n",
            "3017 (40, 174)\n",
            "3018 (40, 174)\n",
            "3019 (40, 174)\n",
            "3020 (40, 174)\n",
            "3021 (40, 174)\n",
            "3022 (40, 174)\n",
            "3023 (40, 174)\n",
            "3024 (40, 174)\n",
            "3025 (40, 174)\n",
            "3026 (40, 174)\n",
            "3027 (40, 174)\n",
            "3028 (40, 174)\n",
            "3029 (40, 174)\n",
            "3030 (40, 174)\n",
            "3031 (40, 174)\n",
            "3032 (40, 174)\n",
            "3033 (40, 174)\n",
            "3034 (40, 174)\n",
            "3035 (40, 174)\n",
            "3036 (40, 174)\n",
            "3037 (40, 174)\n",
            "3038 (40, 174)\n",
            "3039 (40, 174)\n",
            "3040 (40, 174)\n",
            "3041 (40, 174)\n",
            "3042 (40, 174)\n",
            "3043 (40, 174)\n",
            "3044 (40, 174)\n",
            "3045 (40, 174)\n",
            "3046 (40, 174)\n",
            "3047 (40, 174)\n",
            "3048 (40, 174)\n",
            "3049 (40, 174)\n",
            "3050 (40, 174)\n",
            "3051 (40, 174)\n",
            "3052 (40, 174)\n",
            "3053 (40, 174)\n",
            "3054 (40, 174)\n",
            "3055 (40, 174)\n",
            "3056 (40, 174)\n",
            "3057 (40, 174)\n",
            "3058 (40, 174)\n",
            "3059 (40, 174)\n",
            "3060 (40, 174)\n",
            "3061 (40, 174)\n",
            "3062 (40, 174)\n",
            "3063 (40, 174)\n",
            "3064 (40, 174)\n",
            "3065 (40, 174)\n",
            "3066 (40, 174)\n",
            "3067 (40, 174)\n",
            "3068 (40, 174)\n",
            "3069 (40, 174)\n",
            "3070 (40, 174)\n",
            "3071 (40, 174)\n",
            "3072 (40, 174)\n",
            "3073 (40, 174)\n",
            "3074 (40, 174)\n",
            "3075 (40, 174)\n",
            "3076 (40, 174)\n",
            "3077 (40, 174)\n",
            "3078 (40, 174)\n",
            "3079 (40, 174)\n",
            "3080 (40, 174)\n",
            "3081 (40, 174)\n",
            "3082 (40, 174)\n",
            "3083 (40, 174)\n",
            "3084 (40, 174)\n",
            "3085 (40, 174)\n",
            "3086 (40, 174)\n",
            "3087 (40, 174)\n",
            "3088 (40, 174)\n",
            "3089 (40, 174)\n",
            "3090 (40, 174)\n",
            "3091 (40, 174)\n",
            "3092 (40, 174)\n",
            "3093 (40, 174)\n",
            "3094 (40, 174)\n",
            "3095 (40, 174)\n",
            "3096 (40, 174)\n",
            "3097 (40, 174)\n",
            "3098 (40, 174)\n",
            "3099 (40, 174)\n",
            "3100 (40, 174)\n",
            "3101 (40, 174)\n",
            "3102 (40, 174)\n",
            "3103 (40, 174)\n",
            "3104 (40, 174)\n",
            "3105 (40, 174)\n",
            "3106 (40, 174)\n",
            "3107 (40, 174)\n",
            "3108 (40, 174)\n",
            "3109 (40, 174)\n",
            "3110 (40, 174)\n",
            "3111 (40, 174)\n",
            "3112 (40, 174)\n",
            "3113 (40, 174)\n",
            "3114 (40, 174)\n",
            "3115 (40, 174)\n",
            "3116 (40, 174)\n",
            "3117 (40, 174)\n",
            "3118 (40, 174)\n",
            "3119 (40, 174)\n",
            "3120 (40, 174)\n",
            "3121 (40, 174)\n",
            "3122 (40, 174)\n",
            "3123 (40, 174)\n",
            "3124 (40, 174)\n",
            "3125 (40, 174)\n",
            "3126 (40, 174)\n",
            "3127 (40, 174)\n",
            "3128 (40, 174)\n",
            "3129 (40, 174)\n",
            "3130 (40, 174)\n",
            "3131 (40, 174)\n",
            "3132 (40, 174)\n",
            "3133 (40, 174)\n",
            "3134 (40, 174)\n",
            "3135 (40, 174)\n",
            "3136 (40, 174)\n",
            "3137 (40, 174)\n",
            "3138 (40, 174)\n",
            "3139 (40, 174)\n",
            "3140 (40, 174)\n",
            "3141 (40, 174)\n",
            "3142 (40, 174)\n",
            "3143 (40, 174)\n",
            "3144 (40, 174)\n",
            "3145 (40, 174)\n",
            "3146 (40, 174)\n",
            "3147 (40, 174)\n",
            "3148 (40, 174)\n",
            "3149 (40, 174)\n",
            "3150 (40, 174)\n",
            "3151 (40, 174)\n",
            "3152 (40, 174)\n",
            "3153 (40, 174)\n",
            "3154 (40, 174)\n",
            "3155 (40, 174)\n",
            "3156 (40, 174)\n",
            "3157 (40, 174)\n",
            "3158 (40, 174)\n",
            "3159 (40, 174)\n",
            "3160 (40, 174)\n",
            "3161 (40, 174)\n",
            "3162 (40, 174)\n",
            "3163 (40, 174)\n",
            "3164 (40, 174)\n",
            "3165 (40, 174)\n",
            "3166 (40, 174)\n",
            "3167 (40, 174)\n",
            "3168 (40, 174)\n",
            "3169 (40, 174)\n",
            "3170 (40, 174)\n",
            "3171 (40, 174)\n",
            "3172 (40, 174)\n",
            "3173 (40, 174)\n",
            "3174 (40, 174)\n",
            "3175 (40, 174)\n",
            "3176 (40, 174)\n",
            "3177 (40, 174)\n",
            "3178 (40, 174)\n",
            "3179 (40, 174)\n",
            "3180 (40, 174)\n",
            "3181 (40, 174)\n",
            "3182 (40, 174)\n",
            "3183 (40, 174)\n",
            "3184 (40, 174)\n",
            "3185 (40, 174)\n",
            "3186 (40, 174)\n",
            "3187 (40, 174)\n",
            "3188 (40, 174)\n",
            "3189 (40, 174)\n",
            "3190 (40, 174)\n",
            "3191 (40, 174)\n",
            "3192 (40, 174)\n",
            "3193 (40, 174)\n",
            "3194 (40, 174)\n",
            "3195 (40, 174)\n",
            "3196 (40, 174)\n",
            "3197 (40, 174)\n",
            "3198 (40, 174)\n",
            "3199 (40, 174)\n",
            "3200 (40, 174)\n",
            "3201 (40, 174)\n",
            "3202 (40, 174)\n",
            "3203 (40, 174)\n",
            "3204 (40, 174)\n",
            "3205 (40, 174)\n",
            "3206 (40, 174)\n",
            "3207 (40, 174)\n",
            "3208 (40, 174)\n",
            "3209 (40, 174)\n",
            "3210 (40, 174)\n",
            "3211 (40, 174)\n",
            "3212 (40, 174)\n",
            "3213 (40, 174)\n",
            "3214 (40, 174)\n",
            "3215 (40, 174)\n",
            "3216 (40, 174)\n",
            "3217 (40, 174)\n",
            "3218 (40, 174)\n",
            "3219 (40, 174)\n",
            "3220 (40, 174)\n",
            "3221 (40, 174)\n",
            "3222 (40, 174)\n",
            "3223 (40, 174)\n",
            "3224 (40, 174)\n",
            "3225 (40, 174)\n",
            "3226 (40, 174)\n",
            "3227 (40, 174)\n",
            "3228 (40, 174)\n",
            "3229 (40, 174)\n",
            "3230 (40, 174)\n",
            "3231 (40, 174)\n",
            "3232 (40, 174)\n",
            "3233 (40, 174)\n",
            "3234 (40, 174)\n",
            "3235 (40, 174)\n",
            "3236 (40, 174)\n",
            "3237 (40, 174)\n",
            "3238 (40, 174)\n",
            "3239 (40, 174)\n",
            "3240 (40, 174)\n",
            "3241 (40, 174)\n",
            "3242 (40, 174)\n",
            "3243 (40, 174)\n",
            "3244 (40, 174)\n",
            "3245 (40, 174)\n",
            "3246 (40, 174)\n",
            "3247 (40, 174)\n",
            "3248 (40, 174)\n",
            "3249 (40, 174)\n",
            "3250 (40, 174)\n",
            "3251 (40, 174)\n",
            "3252 (40, 174)\n",
            "3253 (40, 174)\n",
            "3254 (40, 174)\n",
            "3255 (40, 174)\n",
            "3256 (40, 174)\n",
            "3257 (40, 174)\n",
            "3258 (40, 174)\n",
            "3259 (40, 174)\n",
            "3260 (40, 174)\n",
            "3261 (40, 174)\n",
            "3262 (40, 174)\n",
            "3263 (40, 174)\n",
            "3264 (40, 174)\n",
            "3265 (40, 174)\n",
            "3266 (40, 174)\n",
            "3267 (40, 174)\n",
            "3268 (40, 174)\n",
            "3269 (40, 174)\n",
            "3270 (40, 174)\n",
            "3271 (40, 174)\n",
            "3272 (40, 174)\n",
            "3273 (40, 174)\n",
            "3274 (40, 174)\n",
            "3275 (40, 174)\n",
            "3276 (40, 174)\n",
            "3277 (40, 174)\n",
            "3278 (40, 174)\n",
            "3279 (40, 174)\n",
            "3280 (40, 174)\n",
            "3281 (40, 174)\n",
            "3282 (40, 174)\n",
            "3283 (40, 174)\n",
            "3284 (40, 174)\n",
            "3285 (40, 174)\n",
            "3286 (40, 174)\n",
            "3287 (40, 174)\n",
            "3288 (40, 174)\n",
            "3289 (40, 174)\n",
            "3290 (40, 174)\n",
            "3291 (40, 174)\n",
            "3292 (40, 174)\n",
            "3293 (40, 174)\n",
            "3294 (40, 174)\n",
            "3295 (40, 174)\n",
            "3296 (40, 174)\n",
            "3297 (40, 174)\n",
            "3298 (40, 174)\n",
            "3299 (40, 174)\n",
            "3300 (40, 174)\n",
            "3301 (40, 174)\n",
            "3302 (40, 174)\n",
            "3303 (40, 174)\n",
            "3304 (40, 174)\n",
            "3305 (40, 174)\n",
            "3306 (40, 174)\n",
            "3307 (40, 174)\n",
            "3308 (40, 174)\n",
            "3309 (40, 174)\n",
            "3310 (40, 174)\n",
            "3311 (40, 174)\n",
            "3312 (40, 174)\n",
            "3313 (40, 174)\n",
            "3314 (40, 174)\n",
            "3315 (40, 174)\n",
            "3316 (40, 174)\n",
            "3317 (40, 174)\n",
            "3318 (40, 174)\n",
            "3319 (40, 174)\n",
            "3320 (40, 174)\n",
            "3321 (40, 174)\n",
            "3322 (40, 174)\n",
            "3323 (40, 174)\n",
            "3324 (40, 174)\n",
            "3325 (40, 174)\n",
            "3326 (40, 174)\n",
            "3327 (40, 174)\n",
            "3328 (40, 174)\n",
            "3329 (40, 174)\n",
            "3330 (40, 174)\n",
            "3331 (40, 174)\n",
            "3332 (40, 174)\n",
            "3333 (40, 174)\n",
            "3334 (40, 174)\n",
            "3335 (40, 174)\n",
            "3336 (40, 174)\n",
            "3337 (40, 174)\n",
            "3338 (40, 174)\n",
            "3339 (40, 174)\n",
            "3340 (40, 174)\n",
            "3341 (40, 174)\n",
            "3342 (40, 174)\n",
            "3343 (40, 174)\n",
            "3344 (40, 174)\n",
            "3345 (40, 174)\n",
            "3346 (40, 174)\n",
            "3347 (40, 174)\n",
            "3348 (40, 174)\n",
            "3349 (40, 174)\n",
            "3350 (40, 174)\n",
            "3351 (40, 174)\n",
            "3352 (40, 174)\n",
            "3353 (40, 174)\n",
            "3354 (40, 174)\n",
            "3355 (40, 174)\n",
            "3356 (40, 174)\n",
            "3357 (40, 174)\n",
            "3358 (40, 174)\n",
            "3359 (40, 174)\n",
            "3360 (40, 174)\n",
            "3361 (40, 174)\n",
            "3362 (40, 174)\n",
            "3363 (40, 174)\n",
            "3364 (40, 174)\n",
            "3365 (40, 174)\n",
            "3366 (40, 174)\n",
            "3367 (40, 174)\n",
            "3368 (40, 174)\n",
            "3369 (40, 174)\n",
            "3370 (40, 174)\n",
            "3371 (40, 174)\n",
            "3372 (40, 174)\n",
            "3373 (40, 174)\n",
            "3374 (40, 174)\n",
            "3375 (40, 174)\n",
            "3376 (40, 174)\n",
            "3377 (40, 174)\n",
            "3378 (40, 174)\n",
            "3379 (40, 174)\n",
            "3380 (40, 174)\n",
            "3381 (40, 174)\n",
            "3382 (40, 174)\n",
            "3383 (40, 174)\n",
            "3384 (40, 174)\n",
            "3385 (40, 174)\n",
            "3386 (40, 174)\n",
            "3387 (40, 174)\n",
            "3388 (40, 174)\n",
            "3389 (40, 174)\n",
            "3390 (40, 174)\n",
            "3391 (40, 174)\n",
            "3392 (40, 174)\n",
            "3393 (40, 174)\n",
            "3394 (40, 174)\n",
            "3395 (40, 174)\n",
            "3396 (40, 174)\n",
            "3397 (40, 174)\n",
            "3398 (40, 174)\n",
            "3399 (40, 174)\n",
            "3400 (40, 174)\n",
            "3401 (40, 174)\n",
            "3402 (40, 174)\n",
            "3403 (40, 174)\n",
            "3404 (40, 174)\n",
            "3405 (40, 174)\n",
            "3406 (40, 174)\n",
            "3407 (40, 174)\n",
            "3408 (40, 174)\n",
            "3409 (40, 174)\n",
            "3410 (40, 174)\n",
            "3411 (40, 174)\n",
            "3412 (40, 174)\n",
            "3413 (40, 174)\n",
            "3414 (40, 174)\n",
            "3415 (40, 174)\n",
            "3416 (40, 174)\n",
            "3417 (40, 174)\n",
            "3418 (40, 174)\n",
            "3419 (40, 174)\n",
            "3420 (40, 174)\n",
            "3421 (40, 174)\n",
            "3422 (40, 174)\n",
            "3423 (40, 174)\n",
            "3424 (40, 174)\n",
            "3425 (40, 174)\n",
            "3426 (40, 174)\n",
            "3427 (40, 174)\n",
            "3428 (40, 174)\n",
            "3429 (40, 174)\n",
            "3430 (40, 174)\n",
            "3431 (40, 174)\n",
            "3432 (40, 174)\n",
            "3433 (40, 174)\n",
            "3434 (40, 174)\n",
            "3435 (40, 174)\n",
            "3436 (40, 174)\n",
            "3437 (40, 174)\n",
            "3438 (40, 174)\n",
            "3439 (40, 174)\n",
            "3440 (40, 174)\n",
            "3441 (40, 174)\n",
            "3442 (40, 174)\n",
            "3443 (40, 174)\n",
            "3444 (40, 174)\n",
            "3445 (40, 174)\n",
            "3446 (40, 174)\n",
            "3447 (40, 174)\n",
            "3448 (40, 174)\n",
            "3449 (40, 174)\n",
            "3450 (40, 174)\n",
            "3451 (40, 174)\n",
            "3452 (40, 174)\n",
            "3453 (40, 174)\n",
            "3454 (40, 174)\n",
            "3455 (40, 174)\n",
            "3456 (40, 174)\n",
            "3457 (40, 174)\n",
            "3458 (40, 174)\n",
            "3459 (40, 174)\n",
            "3460 (40, 174)\n",
            "3461 (40, 174)\n",
            "3462 (40, 174)\n",
            "3463 (40, 174)\n",
            "3464 (40, 174)\n",
            "3465 (40, 174)\n",
            "3466 (40, 174)\n",
            "3467 (40, 174)\n",
            "3468 (40, 174)\n",
            "3469 (40, 174)\n",
            "3470 (40, 174)\n",
            "3471 (40, 174)\n",
            "3472 (40, 174)\n",
            "3473 (40, 174)\n",
            "3474 (40, 174)\n",
            "3475 (40, 174)\n",
            "3476 (40, 174)\n",
            "3477 (40, 174)\n",
            "3478 (40, 174)\n",
            "3479 (40, 174)\n",
            "3480 (40, 174)\n",
            "3481 (40, 174)\n",
            "3482 (40, 174)\n",
            "3483 (40, 174)\n",
            "3484 (40, 174)\n",
            "3485 (40, 174)\n",
            "3486 (40, 174)\n",
            "3487 (40, 174)\n",
            "3488 (40, 174)\n",
            "3489 (40, 174)\n",
            "3490 (40, 174)\n",
            "3491 (40, 174)\n",
            "3492 (40, 174)\n",
            "3493 (40, 174)\n",
            "3494 (40, 174)\n",
            "3495 (40, 174)\n",
            "3496 (40, 174)\n",
            "3497 (40, 174)\n",
            "3498 (40, 174)\n",
            "3499 (40, 174)\n",
            "3500 (40, 174)\n",
            "3501 (40, 174)\n",
            "3502 (40, 174)\n",
            "3503 (40, 174)\n",
            "3504 (40, 174)\n",
            "3505 (40, 174)\n",
            "3506 (40, 174)\n",
            "3507 (40, 174)\n",
            "3508 (40, 174)\n",
            "3509 (40, 174)\n",
            "3510 (40, 174)\n",
            "3511 (40, 174)\n",
            "3512 (40, 174)\n",
            "3513 (40, 174)\n",
            "3514 (40, 174)\n",
            "3515 (40, 174)\n",
            "3516 (40, 174)\n",
            "3517 (40, 174)\n",
            "3518 (40, 174)\n",
            "3519 (40, 174)\n",
            "3520 (40, 174)\n",
            "3521 (40, 174)\n",
            "3522 (40, 174)\n",
            "3523 (40, 174)\n",
            "3524 (40, 174)\n",
            "3525 (40, 174)\n",
            "3526 (40, 174)\n",
            "3527 (40, 174)\n",
            "3528 (40, 174)\n",
            "3529 (40, 174)\n",
            "3530 (40, 174)\n",
            "3531 (40, 174)\n",
            "3532 (40, 174)\n",
            "3533 (40, 174)\n",
            "3534 (40, 174)\n",
            "3535 (40, 174)\n",
            "3536 (40, 174)\n",
            "3537 (40, 174)\n",
            "3538 (40, 174)\n",
            "3539 (40, 174)\n",
            "3540 (40, 174)\n",
            "3541 (40, 174)\n",
            "3542 (40, 174)\n",
            "3543 (40, 174)\n",
            "3544 (40, 174)\n",
            "3545 (40, 174)\n",
            "3546 (40, 174)\n",
            "3547 (40, 174)\n",
            "3548 (40, 174)\n",
            "3549 (40, 174)\n",
            "3550 (40, 174)\n",
            "3551 (40, 174)\n",
            "3552 (40, 174)\n",
            "3553 (40, 174)\n",
            "3554 (40, 174)\n",
            "3555 (40, 174)\n",
            "3556 (40, 174)\n",
            "3557 (40, 174)\n",
            "3558 (40, 174)\n",
            "3559 (40, 174)\n",
            "3560 (40, 174)\n",
            "3561 (40, 174)\n",
            "3562 (40, 174)\n",
            "3563 (40, 174)\n",
            "3564 (40, 174)\n",
            "3565 (40, 174)\n",
            "3566 (40, 174)\n",
            "3567 (40, 174)\n",
            "3568 (40, 174)\n",
            "3569 (40, 174)\n",
            "3570 (40, 174)\n",
            "3571 (40, 174)\n",
            "3572 (40, 174)\n",
            "3573 (40, 174)\n",
            "3574 (40, 174)\n",
            "3575 (40, 174)\n",
            "3576 (40, 174)\n",
            "3577 (40, 174)\n",
            "3578 (40, 174)\n",
            "3579 (40, 174)\n",
            "3580 (40, 174)\n",
            "3581 (40, 174)\n",
            "3582 (40, 174)\n",
            "3583 (40, 174)\n",
            "3584 (40, 174)\n",
            "3585 (40, 174)\n",
            "3586 (40, 174)\n",
            "3587 (40, 174)\n",
            "3588 (40, 174)\n",
            "3589 (40, 174)\n",
            "3590 (40, 174)\n",
            "3591 (40, 174)\n",
            "3592 (40, 174)\n",
            "3593 (40, 174)\n",
            "3594 (40, 174)\n",
            "3595 (40, 174)\n",
            "3596 (40, 174)\n",
            "3597 (40, 174)\n",
            "3598 (40, 174)\n",
            "3599 (40, 174)\n",
            "3600 (40, 174)\n",
            "3601 (40, 174)\n",
            "3602 (40, 174)\n",
            "3603 (40, 174)\n",
            "3604 (40, 174)\n",
            "3605 (40, 174)\n",
            "3606 (40, 174)\n",
            "3607 (40, 174)\n",
            "3608 (40, 174)\n",
            "3609 (40, 174)\n",
            "3610 (40, 174)\n",
            "3611 (40, 174)\n",
            "3612 (40, 174)\n",
            "3613 (40, 174)\n",
            "3614 (40, 174)\n",
            "3615 (40, 174)\n",
            "3616 (40, 174)\n",
            "3617 (40, 174)\n",
            "3618 (40, 174)\n",
            "3619 (40, 174)\n",
            "3620 (40, 174)\n",
            "3621 (40, 174)\n",
            "3622 (40, 174)\n",
            "3623 (40, 174)\n",
            "3624 (40, 174)\n",
            "3625 (40, 174)\n",
            "3626 (40, 174)\n",
            "3627 (40, 174)\n",
            "3628 (40, 174)\n",
            "3629 (40, 174)\n",
            "3630 (40, 174)\n",
            "3631 (40, 174)\n",
            "3632 (40, 174)\n",
            "3633 (40, 174)\n",
            "3634 (40, 174)\n",
            "3635 (40, 174)\n",
            "3636 (40, 174)\n",
            "3637 (40, 174)\n",
            "3638 (40, 174)\n",
            "3639 (40, 174)\n",
            "3640 (40, 174)\n",
            "3641 (40, 174)\n",
            "3642 (40, 174)\n",
            "3643 (40, 174)\n",
            "3644 (40, 174)\n",
            "3645 (40, 174)\n",
            "3646 (40, 174)\n",
            "3647 (40, 174)\n",
            "3648 (40, 174)\n",
            "3649 (40, 174)\n",
            "3650 (40, 174)\n",
            "3651 (40, 174)\n",
            "3652 (40, 174)\n",
            "3653 (40, 174)\n",
            "3654 (40, 174)\n",
            "3655 (40, 174)\n",
            "3656 (40, 174)\n",
            "3657 (40, 174)\n",
            "3658 (40, 174)\n",
            "3659 (40, 174)\n",
            "3660 (40, 174)\n",
            "3661 (40, 174)\n",
            "3662 (40, 174)\n",
            "3663 (40, 174)\n",
            "3664 (40, 174)\n",
            "3665 (40, 174)\n",
            "3666 (40, 174)\n",
            "3667 (40, 174)\n",
            "3668 (40, 174)\n",
            "3669 (40, 174)\n",
            "3670 (40, 174)\n",
            "3671 (40, 174)\n",
            "3672 (40, 174)\n",
            "3673 (40, 174)\n",
            "3674 (40, 174)\n",
            "3675 (40, 174)\n",
            "3676 (40, 174)\n",
            "3677 (40, 174)\n",
            "3678 (40, 174)\n",
            "3679 (40, 174)\n",
            "3680 (40, 174)\n",
            "3681 (40, 174)\n",
            "3682 (40, 174)\n",
            "3683 (40, 174)\n",
            "3684 (40, 174)\n",
            "3685 (40, 174)\n",
            "3686 (40, 174)\n",
            "3687 (40, 174)\n",
            "3688 (40, 174)\n",
            "3689 (40, 174)\n",
            "3690 (40, 174)\n",
            "3691 (40, 174)\n",
            "3692 (40, 174)\n",
            "3693 (40, 174)\n",
            "3694 (40, 174)\n",
            "3695 (40, 174)\n",
            "3696 (40, 174)\n",
            "3697 (40, 174)\n",
            "3698 (40, 174)\n",
            "3699 (40, 174)\n",
            "3700 (40, 174)\n",
            "3701 (40, 174)\n",
            "3702 (40, 174)\n",
            "3703 (40, 174)\n",
            "3704 (40, 174)\n",
            "3705 (40, 174)\n",
            "3706 (40, 174)\n",
            "3707 (40, 174)\n",
            "3708 (40, 174)\n",
            "3709 (40, 174)\n",
            "3710 (40, 174)\n",
            "3711 (40, 174)\n",
            "3712 (40, 174)\n",
            "3713 (40, 174)\n",
            "3714 (40, 174)\n",
            "3715 (40, 174)\n",
            "3716 (40, 174)\n",
            "3717 (40, 174)\n",
            "3718 (40, 174)\n",
            "3719 (40, 174)\n",
            "3720 (40, 174)\n",
            "3721 (40, 174)\n",
            "3722 (40, 174)\n",
            "3723 (40, 174)\n",
            "3724 (40, 174)\n",
            "3725 (40, 174)\n",
            "3726 (40, 174)\n",
            "3727 (40, 174)\n",
            "3728 (40, 174)\n",
            "3729 (40, 174)\n",
            "3730 (40, 174)\n",
            "3731 (40, 174)\n",
            "3732 (40, 174)\n",
            "3733 (40, 174)\n",
            "3734 (40, 174)\n",
            "3735 (40, 174)\n",
            "3736 (40, 174)\n",
            "3737 (40, 174)\n",
            "3738 (40, 174)\n",
            "3739 (40, 174)\n",
            "3740 (40, 174)\n",
            "3741 (40, 174)\n",
            "3742 (40, 174)\n",
            "3743 (40, 174)\n",
            "3744 (40, 174)\n",
            "3745 (40, 174)\n",
            "3746 (40, 174)\n",
            "3747 (40, 174)\n",
            "3748 (40, 174)\n",
            "3749 (40, 174)\n",
            "3750 (40, 174)\n",
            "3751 (40, 174)\n",
            "3752 (40, 174)\n",
            "3753 (40, 174)\n",
            "3754 (40, 174)\n",
            "3755 (40, 174)\n",
            "3756 (40, 174)\n",
            "3757 (40, 174)\n",
            "3758 (40, 174)\n",
            "3759 (40, 174)\n",
            "3760 (40, 174)\n",
            "3761 (40, 174)\n",
            "3762 (40, 174)\n",
            "3763 (40, 174)\n",
            "3764 (40, 174)\n",
            "3765 (40, 174)\n",
            "3766 (40, 174)\n",
            "3767 (40, 174)\n",
            "3768 (40, 174)\n",
            "3769 (40, 174)\n",
            "3770 (40, 174)\n",
            "3771 (40, 174)\n",
            "3772 (40, 174)\n",
            "3773 (40, 174)\n",
            "3774 (40, 174)\n",
            "3775 (40, 174)\n",
            "3776 (40, 174)\n",
            "3777 (40, 174)\n",
            "3778 (40, 174)\n",
            "3779 (40, 174)\n",
            "3780 (40, 174)\n",
            "3781 (40, 174)\n",
            "3782 (40, 174)\n",
            "3783 (40, 174)\n",
            "3784 (40, 174)\n",
            "3785 (40, 174)\n",
            "3786 (40, 174)\n",
            "3787 (40, 174)\n",
            "3788 (40, 174)\n",
            "3789 (40, 174)\n",
            "3790 (40, 174)\n",
            "3791 (40, 174)\n",
            "3792 (40, 174)\n",
            "3793 (40, 174)\n",
            "3794 (40, 174)\n",
            "3795 (40, 174)\n",
            "3796 (40, 174)\n",
            "3797 (40, 174)\n",
            "3798 (40, 174)\n",
            "3799 (40, 174)\n",
            "3800 (40, 174)\n",
            "3801 (40, 174)\n",
            "3802 (40, 174)\n",
            "3803 (40, 174)\n",
            "3804 (40, 174)\n",
            "3805 (40, 174)\n",
            "3806 (40, 174)\n",
            "3807 (40, 174)\n",
            "3808 (40, 174)\n",
            "3809 (40, 174)\n",
            "3810 (40, 174)\n",
            "3811 (40, 174)\n",
            "3812 (40, 174)\n",
            "3813 (40, 174)\n",
            "3814 (40, 174)\n",
            "3815 (40, 174)\n",
            "3816 (40, 174)\n",
            "3817 (40, 174)\n",
            "3818 (40, 174)\n",
            "3819 (40, 174)\n",
            "3820 (40, 174)\n",
            "3821 (40, 174)\n",
            "3822 (40, 174)\n",
            "3823 (40, 174)\n",
            "3824 (40, 174)\n",
            "3825 (40, 174)\n",
            "3826 (40, 174)\n",
            "3827 (40, 174)\n",
            "3828 (40, 174)\n",
            "3829 (40, 174)\n",
            "3830 (40, 174)\n",
            "3831 (40, 174)\n",
            "3832 (40, 174)\n",
            "3833 (40, 174)\n",
            "3834 (40, 174)\n",
            "3835 (40, 174)\n",
            "3836 (40, 174)\n",
            "3837 (40, 174)\n",
            "3838 (40, 174)\n",
            "3839 (40, 174)\n",
            "3840 (40, 174)\n",
            "3841 (40, 174)\n",
            "3842 (40, 174)\n",
            "3843 (40, 174)\n",
            "3844 (40, 174)\n",
            "3845 (40, 174)\n",
            "3846 (40, 174)\n",
            "3847 (40, 174)\n",
            "3848 (40, 174)\n",
            "3849 (40, 174)\n",
            "3850 (40, 174)\n",
            "3851 (40, 174)\n",
            "3852 (40, 174)\n",
            "3853 (40, 174)\n",
            "3854 (40, 174)\n",
            "3855 (40, 174)\n",
            "3856 (40, 174)\n",
            "3857 (40, 174)\n",
            "3858 (40, 174)\n",
            "3859 (40, 174)\n",
            "3860 (40, 174)\n",
            "3861 (40, 174)\n",
            "3862 (40, 174)\n",
            "3863 (40, 174)\n",
            "3864 (40, 174)\n",
            "3865 (40, 174)\n",
            "3866 (40, 174)\n",
            "3867 (40, 174)\n",
            "3868 (40, 174)\n",
            "3869 (40, 174)\n",
            "3870 (40, 174)\n",
            "3871 (40, 174)\n",
            "3872 (40, 174)\n",
            "3873 (40, 174)\n",
            "3874 (40, 174)\n",
            "3875 (40, 174)\n",
            "3876 (40, 174)\n",
            "3877 (40, 174)\n",
            "3878 (40, 174)\n",
            "3879 (40, 174)\n",
            "3880 (40, 174)\n",
            "3881 (40, 174)\n",
            "3882 (40, 174)\n",
            "3883 (40, 174)\n",
            "3884 (40, 174)\n",
            "3885 (40, 174)\n",
            "3886 (40, 174)\n",
            "3887 (40, 174)\n",
            "3888 (40, 174)\n",
            "3889 (40, 174)\n",
            "3890 (40, 174)\n",
            "3891 (40, 174)\n",
            "3892 (40, 174)\n",
            "3893 (40, 174)\n",
            "3894 (40, 174)\n",
            "3895 (40, 174)\n",
            "3896 (40, 174)\n",
            "3897 (40, 174)\n",
            "3898 (40, 174)\n",
            "3899 (40, 174)\n",
            "3900 (40, 174)\n",
            "3901 (40, 174)\n",
            "3902 (40, 174)\n",
            "3903 (40, 174)\n",
            "3904 (40, 174)\n",
            "3905 (40, 174)\n",
            "3906 (40, 174)\n",
            "3907 (40, 174)\n",
            "3908 (40, 174)\n",
            "3909 (40, 174)\n",
            "3910 (40, 174)\n",
            "3911 (40, 174)\n",
            "3912 (40, 174)\n",
            "3913 (40, 174)\n",
            "3914 (40, 174)\n",
            "3915 (40, 174)\n",
            "3916 (40, 174)\n",
            "3917 (40, 174)\n",
            "3918 (40, 174)\n",
            "3919 (40, 174)\n",
            "3920 (40, 174)\n",
            "3921 (40, 174)\n",
            "3922 (40, 174)\n",
            "3923 (40, 174)\n",
            "3924 (40, 174)\n",
            "3925 (40, 174)\n",
            "3926 (40, 174)\n",
            "3927 (40, 174)\n",
            "3928 (40, 174)\n",
            "3929 (40, 174)\n",
            "3930 (40, 174)\n",
            "3931 (40, 174)\n",
            "3932 (40, 174)\n",
            "3933 (40, 174)\n",
            "3934 (40, 174)\n",
            "3935 (40, 174)\n",
            "3936 (40, 174)\n",
            "3937 (40, 174)\n",
            "3938 (40, 174)\n",
            "3939 (40, 174)\n",
            "3940 (40, 174)\n",
            "3941 (40, 174)\n",
            "3942 (40, 174)\n",
            "3943 (40, 174)\n",
            "3944 (40, 174)\n",
            "3945 (40, 174)\n",
            "3946 (40, 174)\n",
            "3947 (40, 174)\n",
            "3948 (40, 174)\n",
            "3949 (40, 174)\n",
            "3950 (40, 174)\n",
            "3951 (40, 174)\n",
            "3952 (40, 174)\n",
            "3953 (40, 174)\n",
            "3954 (40, 174)\n",
            "3955 (40, 174)\n",
            "3956 (40, 174)\n",
            "3957 (40, 174)\n",
            "3958 (40, 174)\n",
            "3959 (40, 174)\n",
            "3960 (40, 174)\n",
            "3961 (40, 174)\n",
            "3962 (40, 174)\n",
            "3963 (40, 174)\n",
            "3964 (40, 174)\n",
            "3965 (40, 174)\n",
            "3966 (40, 174)\n",
            "3967 (40, 174)\n",
            "3968 (40, 174)\n",
            "3969 (40, 174)\n",
            "3970 (40, 174)\n",
            "3971 (40, 174)\n",
            "3972 (40, 174)\n",
            "3973 (40, 174)\n",
            "3974 (40, 174)\n",
            "3975 (40, 174)\n",
            "3976 (40, 174)\n",
            "3977 (40, 174)\n",
            "3978 (40, 174)\n",
            "3979 (40, 174)\n",
            "3980 (40, 174)\n",
            "3981 (40, 174)\n",
            "3982 (40, 174)\n",
            "3983 (40, 174)\n",
            "3984 (40, 174)\n",
            "3985 (40, 174)\n",
            "3986 (40, 174)\n",
            "3987 (40, 174)\n",
            "3988 (40, 174)\n",
            "3989 (40, 174)\n",
            "3990 (40, 174)\n",
            "3991 (40, 174)\n",
            "3992 (40, 174)\n",
            "3993 (40, 174)\n",
            "3994 (40, 174)\n",
            "3995 (40, 174)\n",
            "3996 (40, 174)\n",
            "3997 (40, 174)\n",
            "3998 (40, 174)\n",
            "3999 (40, 174)\n",
            "4000 (40, 174)\n",
            "4001 (40, 174)\n",
            "4002 (40, 174)\n",
            "4003 (40, 174)\n",
            "4004 (40, 174)\n",
            "4005 (40, 174)\n",
            "4006 (40, 174)\n",
            "4007 (40, 174)\n",
            "4008 (40, 174)\n",
            "4009 (40, 174)\n",
            "4010 (40, 174)\n",
            "4011 (40, 174)\n",
            "4012 (40, 174)\n",
            "4013 (40, 174)\n",
            "4014 (40, 174)\n",
            "4015 (40, 174)\n",
            "4016 (40, 174)\n",
            "4017 (40, 174)\n",
            "4018 (40, 174)\n",
            "4019 (40, 174)\n",
            "4020 (40, 174)\n",
            "4021 (40, 174)\n",
            "4022 (40, 174)\n",
            "4023 (40, 174)\n",
            "4024 (40, 174)\n",
            "4025 (40, 174)\n",
            "4026 (40, 174)\n",
            "4027 (40, 174)\n",
            "4028 (40, 174)\n",
            "4029 (40, 174)\n",
            "4030 (40, 174)\n",
            "4031 (40, 174)\n",
            "4032 (40, 174)\n",
            "4033 (40, 174)\n",
            "4034 (40, 174)\n",
            "4035 (40, 174)\n",
            "4036 (40, 174)\n",
            "4037 (40, 174)\n",
            "4038 (40, 174)\n",
            "4039 (40, 174)\n",
            "4040 (40, 174)\n",
            "4041 (40, 174)\n",
            "4042 (40, 174)\n",
            "4043 (40, 174)\n",
            "4044 (40, 174)\n",
            "4045 (40, 174)\n",
            "4046 (40, 174)\n",
            "4047 (40, 174)\n",
            "4048 (40, 174)\n",
            "4049 (40, 174)\n",
            "4050 (40, 174)\n",
            "4051 (40, 174)\n",
            "4052 (40, 174)\n",
            "4053 (40, 174)\n",
            "4054 (40, 174)\n",
            "4055 (40, 174)\n",
            "4056 (40, 174)\n",
            "4057 (40, 174)\n",
            "4058 (40, 174)\n",
            "4059 (40, 174)\n",
            "4060 (40, 174)\n",
            "4061 (40, 174)\n",
            "4062 (40, 174)\n",
            "4063 (40, 174)\n",
            "4064 (40, 174)\n",
            "4065 (40, 174)\n",
            "4066 (40, 174)\n",
            "4067 (40, 174)\n",
            "4068 (40, 174)\n",
            "4069 (40, 174)\n",
            "4070 (40, 174)\n",
            "4071 (40, 174)\n",
            "4072 (40, 174)\n",
            "4073 (40, 174)\n",
            "4074 (40, 174)\n",
            "4075 (40, 174)\n",
            "4076 (40, 174)\n",
            "4077 (40, 174)\n",
            "4078 (40, 174)\n",
            "4079 (40, 174)\n",
            "4080 (40, 174)\n",
            "4081 (40, 174)\n",
            "4082 (40, 174)\n",
            "4083 (40, 174)\n",
            "4084 (40, 174)\n",
            "4085 (40, 174)\n",
            "4086 (40, 174)\n",
            "4087 (40, 174)\n",
            "4088 (40, 174)\n",
            "4089 (40, 174)\n",
            "4090 (40, 174)\n",
            "4091 (40, 174)\n",
            "4092 (40, 174)\n",
            "4093 (40, 174)\n",
            "4094 (40, 174)\n",
            "4095 (40, 174)\n",
            "4096 (40, 174)\n",
            "4097 (40, 174)\n",
            "4098 (40, 174)\n",
            "4099 (40, 174)\n",
            "4100 (40, 174)\n",
            "4101 (40, 174)\n",
            "4102 (40, 174)\n",
            "4103 (40, 174)\n",
            "4104 (40, 174)\n",
            "4105 (40, 174)\n",
            "4106 (40, 174)\n",
            "4107 (40, 174)\n",
            "4108 (40, 174)\n",
            "4109 (40, 174)\n",
            "4110 (40, 174)\n",
            "4111 (40, 174)\n",
            "4112 (40, 174)\n",
            "4113 (40, 174)\n",
            "4114 (40, 174)\n",
            "4115 (40, 174)\n",
            "4116 (40, 174)\n",
            "4117 (40, 174)\n",
            "4118 (40, 174)\n",
            "4119 (40, 174)\n",
            "4120 (40, 174)\n",
            "4121 (40, 174)\n",
            "4122 (40, 174)\n",
            "4123 (40, 174)\n",
            "4124 (40, 174)\n",
            "4125 (40, 174)\n",
            "4126 (40, 174)\n",
            "4127 (40, 174)\n",
            "4128 (40, 174)\n",
            "4129 (40, 174)\n",
            "4130 (40, 174)\n",
            "4131 (40, 174)\n",
            "4132 (40, 174)\n",
            "4133 (40, 174)\n",
            "4134 (40, 174)\n",
            "4135 (40, 174)\n",
            "4136 (40, 174)\n",
            "4137 (40, 174)\n",
            "4138 (40, 174)\n",
            "4139 (40, 174)\n",
            "4140 (40, 174)\n",
            "4141 (40, 174)\n",
            "4142 (40, 174)\n",
            "4143 (40, 174)\n",
            "4144 (40, 174)\n",
            "4145 (40, 174)\n",
            "4146 (40, 174)\n",
            "4147 (40, 174)\n",
            "4148 (40, 174)\n",
            "4149 (40, 174)\n",
            "4150 (40, 174)\n",
            "4151 (40, 174)\n",
            "4152 (40, 174)\n",
            "4153 (40, 174)\n",
            "4154 (40, 174)\n",
            "4155 (40, 174)\n",
            "4156 (40, 174)\n",
            "4157 (40, 174)\n",
            "4158 (40, 174)\n",
            "4159 (40, 174)\n",
            "4160 (40, 174)\n",
            "4161 (40, 174)\n",
            "4162 (40, 174)\n",
            "4163 (40, 174)\n",
            "4164 (40, 174)\n",
            "4165 (40, 174)\n",
            "4166 (40, 174)\n",
            "4167 (40, 174)\n",
            "4168 (40, 174)\n",
            "4169 (40, 174)\n",
            "4170 (40, 174)\n",
            "4171 (40, 174)\n",
            "4172 (40, 174)\n",
            "4173 (40, 174)\n",
            "4174 (40, 174)\n",
            "4175 (40, 174)\n",
            "4176 (40, 174)\n",
            "4177 (40, 174)\n",
            "4178 (40, 174)\n",
            "4179 (40, 174)\n",
            "4180 (40, 174)\n",
            "4181 (40, 174)\n",
            "4182 (40, 174)\n",
            "4183 (40, 174)\n",
            "4184 (40, 174)\n",
            "4185 (40, 174)\n",
            "4186 (40, 174)\n",
            "4187 (40, 174)\n",
            "4188 (40, 174)\n",
            "4189 (40, 174)\n",
            "4190 (40, 174)\n",
            "4191 (40, 174)\n",
            "4192 (40, 174)\n",
            "4193 (40, 174)\n",
            "4194 (40, 174)\n",
            "4195 (40, 174)\n",
            "4196 (40, 174)\n",
            "4197 (40, 174)\n",
            "4198 (40, 174)\n",
            "4199 (40, 174)\n"
          ]
        }
      ],
      "source": [
        "for i in range(len(check5)):\n",
        "    #if (len(check2[i]) < 50000):\n",
        "            print(i, check5[i].shape)\n",
        "    #print(\"----------------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4ncxumBdzCa"
      },
      "source": [
        "### Convert the data and labels\n",
        "\n",
        "We will use `sklearn.preprocessing.LabelEncoder` to encode the categorical text data into model-understandable numerical data. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8BZL2K3dzCb",
        "outputId": "f2f2d60f-a66e-4eb8-964d-dcc2e3fc7aee"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "children_playing     1000\n",
              "street_music         1000\n",
              "jackhammer           1000\n",
              "drilling             1000\n",
              "dog_bark             1000\n",
              "air_conditioner      1000\n",
              "engine_idling        1000\n",
              "siren                 929\n",
              "car_horn              429\n",
              "gun_shot              374\n",
              "Applause              300\n",
              "Laughter              300\n",
              "Fireworks             300\n",
              "Tearing               300\n",
              "Cough                 243\n",
              "Microwave_oven        146\n",
              "Keys_jangling         139\n",
              "Telephone             120\n",
              "Computer_keyboard     119\n",
              "Bus                   109\n",
              "Scissors               95\n",
              "Name: class_name, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "df5.class_name.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F4Lbon9GdzCb"
      },
      "outputs": [],
      "source": [
        "# 0 --> Applause (300)\n",
        "# 1 --> Bus (109)\n",
        "# 2 --> Computer_keyboard (119)\n",
        "# 3 --> Cough (243)\n",
        "# 4 --> Fireworks (300)\n",
        "# 5 --> Keys_jangling (139)\n",
        "# 6 --> Laughter (300)\n",
        "# 7 --> Microwave_oven (146)\n",
        "# 8 --> Scissors (95)\n",
        "# 9 --> Tearing (300)\n",
        "# 10 --> Telephone (120)\n",
        "# 11 --> air_conditioner (1000)\n",
        "# 12 --> car_horn (429)\n",
        "# 13 --> children_playing (1000)\n",
        "# 14 --> dog_bark (1000)\n",
        "# 15 --> drilling (1000)\n",
        "# 16 --> engine_idling (1000)\n",
        "# 17 --> gun_shot (374)\n",
        "# 18 --> jackhammer (1000)\n",
        "# 19 --> siren (929)\n",
        "# 20 --> street_music (1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "SefRsdJedzCb"
      },
      "outputs": [],
      "source": [
        "df2 = df2.rename(columns={'MFCC': 'MFCC_Padded'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "z0b7vVyhdzCc",
        "outputId": "50ba8ef5-c4a5-4bb5-e09c-90df98842201"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-3784b226-9e88-4ec8-9b7d-0a35128959bb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MFCC_Padded</th>\n",
              "      <th>class_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[[-0.32703415, -0.30962744, -0.32634977, -0.33...</td>\n",
              "      <td>jackhammer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -0...</td>\n",
              "      <td>Laughter</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[[-0.55797315, -0.39460784, 0.32954752, 0.0515...</td>\n",
              "      <td>children_playing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1...</td>\n",
              "      <td>engine_idling</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[[-1.0, -1.0, -1.0, -1.0, -0.90335524, -0.7447...</td>\n",
              "      <td>dog_bark</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10898</th>\n",
              "      <td>[[-0.3960791, -0.36139658, -0.34552196, -0.330...</td>\n",
              "      <td>children_playing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10899</th>\n",
              "      <td>[[-0.27938482, -0.20506413, -0.21201873, -0.15...</td>\n",
              "      <td>children_playing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10900</th>\n",
              "      <td>[[-0.6639561, -0.6884442, -0.7704389, -0.85106...</td>\n",
              "      <td>dog_bark</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10901</th>\n",
              "      <td>[[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -0.97019...</td>\n",
              "      <td>Computer_keyboard</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10902</th>\n",
              "      <td>[[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1...</td>\n",
              "      <td>dog_bark</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10903 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3784b226-9e88-4ec8-9b7d-0a35128959bb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3784b226-9e88-4ec8-9b7d-0a35128959bb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3784b226-9e88-4ec8-9b7d-0a35128959bb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                             MFCC_Padded         class_name\n",
              "0      [[-0.32703415, -0.30962744, -0.32634977, -0.33...         jackhammer\n",
              "1      [[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -0...           Laughter\n",
              "2      [[-0.55797315, -0.39460784, 0.32954752, 0.0515...   children_playing\n",
              "3      [[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1...      engine_idling\n",
              "4      [[-1.0, -1.0, -1.0, -1.0, -0.90335524, -0.7447...           dog_bark\n",
              "...                                                  ...                ...\n",
              "10898  [[-0.3960791, -0.36139658, -0.34552196, -0.330...   children_playing\n",
              "10899  [[-0.27938482, -0.20506413, -0.21201873, -0.15...   children_playing\n",
              "10900  [[-0.6639561, -0.6884442, -0.7704389, -0.85106...           dog_bark\n",
              "10901  [[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -0.97019...  Computer_keyboard\n",
              "10902  [[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1...           dog_bark\n",
              "\n",
              "[10903 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "df2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "option=['Scissors','Bus','Computer_keyboard']\n",
        "df2 = df2[~df2.class_name.isin(option)]"
      ],
      "metadata": {
        "id": "_TOlVWqHUjMj"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.class_name.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eka22HziU5i7",
        "outputId": "91e3305a-7198-4657-8208-813986f0f57e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "children_playing    1000\n",
              "street_music        1000\n",
              "jackhammer          1000\n",
              "drilling            1000\n",
              "dog_bark            1000\n",
              "air_conditioner     1000\n",
              "engine_idling       1000\n",
              "siren                929\n",
              "car_horn             429\n",
              "gun_shot             374\n",
              "Applause             300\n",
              "Laughter             300\n",
              "Fireworks            300\n",
              "Tearing              300\n",
              "Cough                243\n",
              "Microwave_oven       146\n",
              "Keys_jangling        139\n",
              "Telephone            120\n",
              "Name: class_name, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xssw2LeudzCc"
      },
      "outputs": [],
      "source": [
        "# Convert features and corresponding classification labels into numpy arrays\n",
        "#X = np.array(df5.MFCC_Padded.tolist())\n",
        "#y = np.array(df5.class_name.tolist())\n",
        "\n",
        "# Encode the classification labels\n",
        "#le = LabelEncoder()\n",
        "#yy = to_categorical(le.fit_transform(y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "6UlvO_tQdzCd"
      },
      "outputs": [],
      "source": [
        "# Convert features and corresponding classification labels into numpy arrays\n",
        "X = np.array(df2.MFCC_Padded.tolist())\n",
        "y = np.array(df2.class_name.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhTtNNVcdzCd",
        "outputId": "8de49b3a-a2ff-4aab-8f17-c4fad5bb9e5d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10580, 40, 174)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMFpSaLbdzCd",
        "outputId": "f169534d-a9fe-4b63-9dfb-c22af7e2ddc1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10580,)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "HRAqBxUNdzCd",
        "outputId": "6d5507d6-2ed5-4efb-ee84-ee9c7cc5599b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-bd017d8c-6eb9-492c-8801-d4ffe5d05b40\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>jackhammer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Laughter</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>children_playing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>engine_idling</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>dog_bark</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10575</th>\n",
              "      <td>siren</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10576</th>\n",
              "      <td>children_playing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10577</th>\n",
              "      <td>children_playing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10578</th>\n",
              "      <td>dog_bark</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10579</th>\n",
              "      <td>dog_bark</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10580 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bd017d8c-6eb9-492c-8801-d4ffe5d05b40')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bd017d8c-6eb9-492c-8801-d4ffe5d05b40 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bd017d8c-6eb9-492c-8801-d4ffe5d05b40');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                      0\n",
              "0            jackhammer\n",
              "1              Laughter\n",
              "2      children_playing\n",
              "3         engine_idling\n",
              "4              dog_bark\n",
              "...                 ...\n",
              "10575             siren\n",
              "10576  children_playing\n",
              "10577  children_playing\n",
              "10578          dog_bark\n",
              "10579          dog_bark\n",
              "\n",
              "[10580 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "#y.head()\n",
        "aa = pd.DataFrame(y)\n",
        "aa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "e1TwoSiSweMH"
      },
      "outputs": [],
      "source": [
        "le = LabelEncoder()\n",
        "yy = to_categorical(le.fit_transform(y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3kuHwcgdzCd",
        "outputId": "a382790d-64bb-47c9-aafc-993e74e85ab7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 1., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "yy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#y.head()\n",
        "ax = pd.DataFrame(yy)\n",
        "ax"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "X4j592tzReF8",
        "outputId": "53b4da4a-3e26-4c36-aef6-f7d3aa29cc67"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-7c275c92-d476-4ec8-8abc-158ed7c5b2a0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10575</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10576</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10577</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10578</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10579</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10580 rows × 18 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7c275c92-d476-4ec8-8abc-158ed7c5b2a0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7c275c92-d476-4ec8-8abc-158ed7c5b2a0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7c275c92-d476-4ec8-8abc-158ed7c5b2a0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        0    1    2    3    4    5    6   ...   11   12   13   14   15   16   17\n",
              "0      0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  1.0  0.0  0.0\n",
              "1      0.0  0.0  0.0  0.0  1.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "2      0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "3      0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  1.0  0.0  0.0  0.0  0.0\n",
              "4      0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  1.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...\n",
              "10575  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  1.0  0.0\n",
              "10576  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "10577  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "10578  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  1.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "10579  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  1.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "\n",
              "[10580 rows x 18 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpIFEJlHdzCe",
        "outputId": "d6253a4a-fa6c-44a5-c1fa-eb41c37d0942"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "num_labels = 18\n",
        "num_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHu8HZi6dzCe"
      },
      "source": [
        "### Split the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "cV9D35yidzCe"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split \n",
        "X_train, X_test, y_train, y_test = train_test_split(X, yy, test_size=0.2, random_state = 42)\n",
        "X_train , X_val, y_train, y_val = train_test_split(X_train,y_train, test_size=.25, random_state= 42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "euwmgqdD57KY",
        "outputId": "f0591181-afc0-46db-9dc4-24ceddcf14cf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((6348, 40, 174),\n",
              " (2116, 40, 174),\n",
              " (6348, 18),\n",
              " (2116, 18),\n",
              " (2116, 40, 174),\n",
              " (2116, 18))"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "X_train.shape, X_val.shape, y_train.shape, y_val.shape, X_test.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eavw9DyExzv9",
        "outputId": "681058b7-f260-4c7f-95ed-59a8455a1856"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "LM5HPt4LdzCe"
      },
      "outputs": [],
      "source": [
        "#reshaping to shape required by CNN\n",
        "X_train2=np.reshape(X_train,(X_train.shape[0], 40,174,1))\n",
        "X_val2=np.reshape(X_val,(X_val.shape[0], 40,174,1))\n",
        "X_test2=np.reshape(X_test,(X_test.shape[0], 40,174,1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBjdHqhu2Jb4",
        "outputId": "1dc672ec-6a0e-4a0f-c9b9-b29fba50b3c8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((6348, 40, 174, 1), (2116, 40, 174, 1), (6348, 18), (2116, 18))"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "X_train2.shape, X_val2.shape, y_train.shape, y_val.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkUQcOZr1FeG",
        "outputId": "d37062ea-c951-4973-bc53-812a2a74ff00"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40, 174, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "X_train2.shape[1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-uDkxrT_KH3",
        "outputId": "8fd015ca-3d39-49dc-a425-42846b22acc6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6348, 40, 174, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "X_train2.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3aJyZnJn_ORy",
        "outputId": "1b9fec89-5505-4d92-fcba-caa8ef71cb54"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6348, 18)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxTEMoJr_EHP",
        "outputId": "90ffc3a9-5860-4123-86c1-5ae3483087a6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40, 174)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "X_train.shape[1:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HM7GYY0DdzCf"
      },
      "source": [
        "**Baseline:**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelc5 = Sequential()\n",
        "\n",
        "input_shape=X_train2.shape[1:]\n",
        "\n",
        "modelc5.add(Conv2D(64, (5, 5), input_shape=input_shape,activation='relu', padding='same'))\n",
        "\n",
        "modelc5.add(Flatten())\n",
        "\n",
        "modelc5.add(Dense(100))\n",
        "\n",
        "modelc5.add(Dense(units = num_labels, activation=\"softmax\"))\n",
        "\n",
        "modelc5.summary()\n",
        "modelc5.compile(loss = 'categorical_crossentropy', \n",
        "              metrics = ['accuracy'],\n",
        "              optimizer = 'adam')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JuqaRrOKDZKP",
        "outputId": "eb2bf904-fefc-4b6b-91ec-8df051ccaf8f"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_19 (Conv2D)          (None, 40, 174, 64)       1664      \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 445440)            0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 100)               44544100  \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 18)                1818      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 44,547,582\n",
            "Trainable params: 44,547,582\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "es = EarlyStopping(monitor='val_accuracy', min_delta= 0.01 , patience= 50, verbose= 1, mode='auto')\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath='(new2-base).hdf5', \n",
        "                               verbose=1, save_best_only=True)\n",
        "start = datetime.now()\n",
        "\n",
        "\n",
        "modelc5.fit(X_train2, y_train,\n",
        "          batch_size = 50, \n",
        "          epochs = 500,\n",
        "          validation_data = (X_val2, y_val), \n",
        "          callbacks=[checkpointer, es])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZDpQoBBDZMn",
        "outputId": "35f4e9e2-7296-47f1-d7dd-43c4ab3f9400"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.8916 - accuracy: 0.4860\n",
            "Epoch 00001: val_loss improved from inf to 1.35868, saving model to (new2-base).hdf5\n",
            "127/127 [==============================] - 3s 24ms/step - loss: 1.8916 - accuracy: 0.4860 - val_loss: 1.3587 - val_accuracy: 0.5865\n",
            "Epoch 2/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 1.0265 - accuracy: 0.6901\n",
            "Epoch 00002: val_loss improved from 1.35868 to 1.24968, saving model to (new2-base).hdf5\n",
            "127/127 [==============================] - 3s 25ms/step - loss: 1.0284 - accuracy: 0.6900 - val_loss: 1.2497 - val_accuracy: 0.6385\n",
            "Epoch 3/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 0.7668 - accuracy: 0.7736\n",
            "Epoch 00003: val_loss did not improve from 1.24968\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.7633 - accuracy: 0.7736 - val_loss: 1.3217 - val_accuracy: 0.6347\n",
            "Epoch 4/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 0.5935 - accuracy: 0.8314\n",
            "Epoch 00004: val_loss did not improve from 1.24968\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.5932 - accuracy: 0.8318 - val_loss: 1.3051 - val_accuracy: 0.6408\n",
            "Epoch 5/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 0.4848 - accuracy: 0.8618\n",
            "Epoch 00005: val_loss did not improve from 1.24968\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.4857 - accuracy: 0.8611 - val_loss: 1.3622 - val_accuracy: 0.6659\n",
            "Epoch 6/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 0.4156 - accuracy: 0.8798\n",
            "Epoch 00006: val_loss did not improve from 1.24968\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.4137 - accuracy: 0.8806 - val_loss: 1.3389 - val_accuracy: 0.6716\n",
            "Epoch 7/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 0.3721 - accuracy: 0.8872\n",
            "Epoch 00007: val_loss did not improve from 1.24968\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.3758 - accuracy: 0.8855 - val_loss: 1.6040 - val_accuracy: 0.6352\n",
            "Epoch 8/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 0.3480 - accuracy: 0.8891\n",
            "Epoch 00008: val_loss did not improve from 1.24968\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.3469 - accuracy: 0.8894 - val_loss: 1.4185 - val_accuracy: 0.6616\n",
            "Epoch 9/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 0.3395 - accuracy: 0.8934\n",
            "Epoch 00009: val_loss did not improve from 1.24968\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.3384 - accuracy: 0.8938 - val_loss: 1.6417 - val_accuracy: 0.6422\n",
            "Epoch 10/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 0.2781 - accuracy: 0.9102\n",
            "Epoch 00010: val_loss did not improve from 1.24968\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.2764 - accuracy: 0.9108 - val_loss: 1.3934 - val_accuracy: 0.6711\n",
            "Epoch 11/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 0.2443 - accuracy: 0.9162\n",
            "Epoch 00011: val_loss did not improve from 1.24968\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.2474 - accuracy: 0.9149 - val_loss: 1.4369 - val_accuracy: 0.6692\n",
            "Epoch 12/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 0.2479 - accuracy: 0.9154\n",
            "Epoch 00012: val_loss did not improve from 1.24968\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.2474 - accuracy: 0.9154 - val_loss: 1.4644 - val_accuracy: 0.6739\n",
            "Epoch 13/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 0.2406 - accuracy: 0.9138\n",
            "Epoch 00013: val_loss did not improve from 1.24968\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.2409 - accuracy: 0.9138 - val_loss: 1.4760 - val_accuracy: 0.6716\n",
            "Epoch 14/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 0.2309 - accuracy: 0.9162\n",
            "Epoch 00014: val_loss did not improve from 1.24968\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.2302 - accuracy: 0.9167 - val_loss: 1.4387 - val_accuracy: 0.6786\n",
            "Epoch 15/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 0.2294 - accuracy: 0.9149\n",
            "Epoch 00015: val_loss did not improve from 1.24968\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.2297 - accuracy: 0.9146 - val_loss: 1.4398 - val_accuracy: 0.6744\n",
            "Epoch 16/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 0.2271 - accuracy: 0.9173\n",
            "Epoch 00016: val_loss did not improve from 1.24968\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.2279 - accuracy: 0.9170 - val_loss: 1.4699 - val_accuracy: 0.6626\n",
            "Epoch 17/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 0.4302 - accuracy: 0.8685\n",
            "Epoch 00017: val_loss did not improve from 1.24968\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.4305 - accuracy: 0.8678 - val_loss: 2.0723 - val_accuracy: 0.5851\n",
            "Epoch 18/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 0.3725 - accuracy: 0.8742\n",
            "Epoch 00018: val_loss did not improve from 1.24968\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.3702 - accuracy: 0.8749 - val_loss: 1.7722 - val_accuracy: 0.6356\n",
            "Epoch 19/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 0.2944 - accuracy: 0.8968\n",
            "Epoch 00019: val_loss did not improve from 1.24968\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.2930 - accuracy: 0.8973 - val_loss: 2.0307 - val_accuracy: 0.6300\n",
            "Epoch 20/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 0.2573 - accuracy: 0.9078\n",
            "Epoch 00020: val_loss did not improve from 1.24968\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.2564 - accuracy: 0.9080 - val_loss: 1.6953 - val_accuracy: 0.6536\n",
            "Epoch 21/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 0.2189 - accuracy: 0.9142\n",
            "Epoch 00021: val_loss did not improve from 1.24968\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.2195 - accuracy: 0.9143 - val_loss: 1.6699 - val_accuracy: 0.6616\n",
            "Epoch 22/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 0.2094 - accuracy: 0.9155\n",
            "Epoch 00022: val_loss did not improve from 1.24968\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.2109 - accuracy: 0.9152 - val_loss: 1.6832 - val_accuracy: 0.6597\n",
            "Epoch 23/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 0.2093 - accuracy: 0.9192\n",
            "Epoch 00023: val_loss did not improve from 1.24968\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.2110 - accuracy: 0.9179 - val_loss: 1.6681 - val_accuracy: 0.6612\n",
            "Epoch 24/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 0.2058 - accuracy: 0.9168\n",
            "Epoch 00024: val_loss did not improve from 1.24968\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.2065 - accuracy: 0.9167 - val_loss: 1.8550 - val_accuracy: 0.6375\n",
            "Epoch 25/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 0.2146 - accuracy: 0.9165\n",
            "Epoch 00025: val_loss did not improve from 1.24968\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.2153 - accuracy: 0.9164 - val_loss: 1.6340 - val_accuracy: 0.6602\n",
            "Epoch 26/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 0.2080 - accuracy: 0.9186\n",
            "Epoch 00026: val_loss did not improve from 1.24968\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.2080 - accuracy: 0.9186 - val_loss: 1.7551 - val_accuracy: 0.6503\n",
            "Epoch 27/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 0.2111 - accuracy: 0.9181\n",
            "Epoch 00027: val_loss did not improve from 1.24968\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.2103 - accuracy: 0.9187 - val_loss: 1.6741 - val_accuracy: 0.6569\n",
            "Epoch 28/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 0.2112 - accuracy: 0.9186\n",
            "Epoch 00028: val_loss did not improve from 1.24968\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.2113 - accuracy: 0.9186 - val_loss: 1.7316 - val_accuracy: 0.6493\n",
            "Epoch 29/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 0.2115 - accuracy: 0.9162\n",
            "Epoch 00029: val_loss did not improve from 1.24968\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.2121 - accuracy: 0.9162 - val_loss: 1.6837 - val_accuracy: 0.6588\n",
            "Epoch 30/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 0.2054 - accuracy: 0.9152\n",
            "Epoch 00030: val_loss did not improve from 1.24968\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.2052 - accuracy: 0.9149 - val_loss: 1.6748 - val_accuracy: 0.6593\n",
            "Epoch 31/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 0.2078 - accuracy: 0.9168\n",
            "Epoch 00031: val_loss did not improve from 1.24968\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.2084 - accuracy: 0.9164 - val_loss: 1.6295 - val_accuracy: 0.6607\n",
            "Epoch 32/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 0.3061 - accuracy: 0.8934\n",
            "Epoch 00032: val_loss did not improve from 1.24968\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.3110 - accuracy: 0.8921 - val_loss: 2.8007 - val_accuracy: 0.5463\n",
            "Epoch 33/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 0.3938 - accuracy: 0.8640\n",
            "Epoch 00033: val_loss did not improve from 1.24968\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.3919 - accuracy: 0.8650 - val_loss: 1.9871 - val_accuracy: 0.6257\n",
            "Epoch 34/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 0.2595 - accuracy: 0.9040\n",
            "Epoch 00034: val_loss did not improve from 1.24968\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.2588 - accuracy: 0.9044 - val_loss: 2.1095 - val_accuracy: 0.6224\n",
            "Epoch 35/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 0.2139 - accuracy: 0.9182\n",
            "Epoch 00035: val_loss did not improve from 1.24968\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.2142 - accuracy: 0.9181 - val_loss: 2.1493 - val_accuracy: 0.6371\n",
            "Epoch 36/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 0.2037 - accuracy: 0.9165\n",
            "Epoch 00036: val_loss did not improve from 1.24968\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.2023 - accuracy: 0.9170 - val_loss: 1.9836 - val_accuracy: 0.6456\n",
            "Epoch 37/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 0.2007 - accuracy: 0.9160\n",
            "Epoch 00037: val_loss did not improve from 1.24968\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.2005 - accuracy: 0.9160 - val_loss: 1.9766 - val_accuracy: 0.6385\n",
            "Epoch 38/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 0.1949 - accuracy: 0.9187\n",
            "Epoch 00038: val_loss did not improve from 1.24968\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.1946 - accuracy: 0.9186 - val_loss: 1.9585 - val_accuracy: 0.6479\n",
            "Epoch 39/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 0.1976 - accuracy: 0.9178\n",
            "Epoch 00039: val_loss did not improve from 1.24968\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.1981 - accuracy: 0.9175 - val_loss: 1.9262 - val_accuracy: 0.6427\n",
            "Epoch 40/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 0.1984 - accuracy: 0.9152\n",
            "Epoch 00040: val_loss did not improve from 1.24968\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.1987 - accuracy: 0.9149 - val_loss: 1.9265 - val_accuracy: 0.6418\n",
            "Epoch 41/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 0.1930 - accuracy: 0.9179\n",
            "Epoch 00041: val_loss did not improve from 1.24968\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.1928 - accuracy: 0.9179 - val_loss: 1.9169 - val_accuracy: 0.6437\n",
            "Epoch 42/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 0.1965 - accuracy: 0.9147\n",
            "Epoch 00042: val_loss did not improve from 1.24968\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.1961 - accuracy: 0.9145 - val_loss: 1.9291 - val_accuracy: 0.6427\n",
            "Epoch 43/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 0.1987 - accuracy: 0.9162\n",
            "Epoch 00043: val_loss did not improve from 1.24968\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.1992 - accuracy: 0.9164 - val_loss: 1.9261 - val_accuracy: 0.6356\n",
            "Epoch 44/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 0.1927 - accuracy: 0.9187\n",
            "Epoch 00044: val_loss did not improve from 1.24968\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.1919 - accuracy: 0.9189 - val_loss: 1.9369 - val_accuracy: 0.6460\n",
            "Epoch 45/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 0.1975 - accuracy: 0.9136\n",
            "Epoch 00045: val_loss did not improve from 1.24968\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.1971 - accuracy: 0.9135 - val_loss: 1.9033 - val_accuracy: 0.6422\n",
            "Epoch 46/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 0.1906 - accuracy: 0.9139\n",
            "Epoch 00046: val_loss did not improve from 1.24968\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.1911 - accuracy: 0.9137 - val_loss: 1.9062 - val_accuracy: 0.6380\n",
            "Epoch 47/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 0.1930 - accuracy: 0.9187\n",
            "Epoch 00047: val_loss did not improve from 1.24968\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.1942 - accuracy: 0.9182 - val_loss: 1.9148 - val_accuracy: 0.6356\n",
            "Epoch 48/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 0.1941 - accuracy: 0.9194\n",
            "Epoch 00048: val_loss did not improve from 1.24968\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.1952 - accuracy: 0.9190 - val_loss: 2.0125 - val_accuracy: 0.6295\n",
            "Epoch 49/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 0.1890 - accuracy: 0.9203\n",
            "Epoch 00049: val_loss did not improve from 1.24968\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.1910 - accuracy: 0.9197 - val_loss: 2.0171 - val_accuracy: 0.6323\n",
            "Epoch 50/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 0.1955 - accuracy: 0.9186\n",
            "Epoch 00050: val_loss did not improve from 1.24968\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.1959 - accuracy: 0.9186 - val_loss: 1.9186 - val_accuracy: 0.6347\n",
            "Epoch 51/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 0.1945 - accuracy: 0.9190\n",
            "Epoch 00051: val_loss did not improve from 1.24968\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.1955 - accuracy: 0.9189 - val_loss: 1.9151 - val_accuracy: 0.6361\n",
            "Epoch 52/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 0.1906 - accuracy: 0.9181\n",
            "Epoch 00052: val_loss did not improve from 1.24968\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.1907 - accuracy: 0.9181 - val_loss: 1.8985 - val_accuracy: 0.6418\n",
            "Epoch 53/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 0.1925 - accuracy: 0.9173\n",
            "Epoch 00053: val_loss did not improve from 1.24968\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.1923 - accuracy: 0.9173 - val_loss: 1.9404 - val_accuracy: 0.6427\n",
            "Epoch 54/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 0.1918 - accuracy: 0.9198\n",
            "Epoch 00054: val_loss did not improve from 1.24968\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.1924 - accuracy: 0.9198 - val_loss: 1.8696 - val_accuracy: 0.6413\n",
            "Epoch 55/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 0.1962 - accuracy: 0.9195\n",
            "Epoch 00055: val_loss did not improve from 1.24968\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.1956 - accuracy: 0.9198 - val_loss: 1.8784 - val_accuracy: 0.6408\n",
            "Epoch 56/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 0.4613 - accuracy: 0.8626\n",
            "Epoch 00056: val_loss did not improve from 1.24968\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.4688 - accuracy: 0.8612 - val_loss: 3.3777 - val_accuracy: 0.5392\n",
            "Epoch 57/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 0.3623 - accuracy: 0.8798\n",
            "Epoch 00057: val_loss did not improve from 1.24968\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.3632 - accuracy: 0.8795 - val_loss: 2.7507 - val_accuracy: 0.6035\n",
            "Epoch 58/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 0.2137 - accuracy: 0.9101\n",
            "Epoch 00058: val_loss did not improve from 1.24968\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.2140 - accuracy: 0.9099 - val_loss: 2.2189 - val_accuracy: 0.6271\n",
            "Epoch 59/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 0.1780 - accuracy: 0.9200\n",
            "Epoch 00059: val_loss did not improve from 1.24968\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.1776 - accuracy: 0.9201 - val_loss: 2.2046 - val_accuracy: 0.6356\n",
            "Epoch 60/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 0.1853 - accuracy: 0.9203\n",
            "Epoch 00060: val_loss did not improve from 1.24968\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.1842 - accuracy: 0.9209 - val_loss: 2.1697 - val_accuracy: 0.6380\n",
            "Epoch 61/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 0.1819 - accuracy: 0.9162\n",
            "Epoch 00061: val_loss did not improve from 1.24968\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.1824 - accuracy: 0.9159 - val_loss: 2.1644 - val_accuracy: 0.6337\n",
            "Epoch 62/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 0.1819 - accuracy: 0.9157\n",
            "Epoch 00062: val_loss did not improve from 1.24968\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.1806 - accuracy: 0.9164 - val_loss: 2.1791 - val_accuracy: 0.6356\n",
            "Epoch 63/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 0.1792 - accuracy: 0.9165\n",
            "Epoch 00063: val_loss did not improve from 1.24968\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.1799 - accuracy: 0.9164 - val_loss: 2.1367 - val_accuracy: 0.6319\n",
            "Epoch 64/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 0.1794 - accuracy: 0.9176\n",
            "Epoch 00064: val_loss did not improve from 1.24968\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.1801 - accuracy: 0.9178 - val_loss: 2.1489 - val_accuracy: 0.6432\n",
            "Epoch 00064: early stopping\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4674084810>"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CNN Model**"
      ],
      "metadata": {
        "id": "ApT4SSadDdHC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN1D"
      ],
      "metadata": {
        "id": "8bxJ5qr8F6bk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Experment (1)"
      ],
      "metadata": {
        "id": "Pn5alCPvGC-i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelc9 = Sequential()\n",
        "\n",
        "input_shape=X_train.shape[1:]\n",
        "\n",
        "modelc9.add(Conv1D(filters=7, kernel_size=5, padding='same', activation='relu',\n",
        "                         input_shape=input_shape))\n",
        "modelc9.add(MaxPooling1D(pool_size=4))\n",
        "modelc9.add(Dropout(0.5))\n",
        "\n",
        "modelc9.add(Conv1D(filters=5, kernel_size=5, padding='same', activation='relu',))\n",
        "modelc9.add(MaxPooling1D(pool_size=4))\n",
        "modelc9.add(Dropout(0.5))\n",
        "\n",
        "modelc9.add(Dense(200))\n",
        "modelc9.add(Dropout(0.5))\n",
        "\n",
        "modelc9.add(LSTM(64))\n",
        "\n",
        "modelc9.add(Dense(units = num_labels, activation=\"softmax\"))\n",
        "\n",
        "modelc9.summary()\n",
        "\n",
        "modelc9.compile(loss = 'categorical_crossentropy', \n",
        "              metrics = ['accuracy'],\n",
        "              optimizer = 'adam')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5QdcQwzbzuXj",
        "outputId": "ca997998-c976-4a5e-d119-2f746775924f"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_5 (Conv1D)           (None, 40, 7)             6097      \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 10, 7)            0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " dropout_16 (Dropout)        (None, 10, 7)             0         \n",
            "                                                                 \n",
            " conv1d_6 (Conv1D)           (None, 10, 5)             180       \n",
            "                                                                 \n",
            " max_pooling1d_2 (MaxPooling  (None, 2, 5)             0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " dropout_17 (Dropout)        (None, 2, 5)              0         \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 2, 200)            1200      \n",
            "                                                                 \n",
            " dropout_18 (Dropout)        (None, 2, 200)            0         \n",
            "                                                                 \n",
            " lstm_7 (LSTM)               (None, 64)                67840     \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 18)                1170      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 76,487\n",
            "Trainable params: 76,487\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "es = EarlyStopping(monitor='val_accuracy', min_delta= 0.01 , patience= 50, verbose= 1, mode='auto')\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath='1D(2).hdf5', \n",
        "                               verbose=1, save_best_only=True)\n",
        "start = datetime.now()\n",
        "\n",
        "\n",
        "modelc9.fit(X_train, y_train,\n",
        "          batch_size = 50, \n",
        "          epochs = 500,\n",
        "          validation_data = (X_val, y_val), \n",
        "          callbacks=[checkpointer, es])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmm16R10zuji",
        "outputId": "dfeb0978-927f-47b7-8b92-b8491bb3486c"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "124/127 [============================>.] - ETA: 0s - loss: 2.5519 - accuracy: 0.1298\n",
            "Epoch 00001: val_loss improved from inf to 2.29789, saving model to 1D(2).hdf5\n",
            "127/127 [==============================] - 3s 10ms/step - loss: 2.5483 - accuracy: 0.1306 - val_loss: 2.2979 - val_accuracy: 0.1706\n",
            "Epoch 2/500\n",
            "122/127 [===========================>..] - ETA: 0s - loss: 2.3344 - accuracy: 0.1687\n",
            "Epoch 00002: val_loss improved from 2.29789 to 2.20832, saving model to 1D(2).hdf5\n",
            "127/127 [==============================] - 1s 7ms/step - loss: 2.3337 - accuracy: 0.1679 - val_loss: 2.2083 - val_accuracy: 0.1810\n",
            "Epoch 3/500\n",
            "122/127 [===========================>..] - ETA: 0s - loss: 2.2825 - accuracy: 0.1805\n",
            "Epoch 00003: val_loss improved from 2.20832 to 2.19005, saving model to 1D(2).hdf5\n",
            "127/127 [==============================] - 1s 7ms/step - loss: 2.2784 - accuracy: 0.1818 - val_loss: 2.1900 - val_accuracy: 0.2037\n",
            "Epoch 4/500\n",
            "118/127 [==========================>...] - ETA: 0s - loss: 2.2604 - accuracy: 0.1856\n",
            "Epoch 00004: val_loss improved from 2.19005 to 2.17039, saving model to 1D(2).hdf5\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.2633 - accuracy: 0.1843 - val_loss: 2.1704 - val_accuracy: 0.1994\n",
            "Epoch 5/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 2.2537 - accuracy: 0.1856\n",
            "Epoch 00005: val_loss improved from 2.17039 to 2.16834, saving model to 1D(2).hdf5\n",
            "127/127 [==============================] - 1s 7ms/step - loss: 2.2513 - accuracy: 0.1865 - val_loss: 2.1683 - val_accuracy: 0.2004\n",
            "Epoch 6/500\n",
            "123/127 [============================>.] - ETA: 0s - loss: 2.2419 - accuracy: 0.1818\n",
            "Epoch 00006: val_loss improved from 2.16834 to 2.14781, saving model to 1D(2).hdf5\n",
            "127/127 [==============================] - 1s 7ms/step - loss: 2.2415 - accuracy: 0.1812 - val_loss: 2.1478 - val_accuracy: 0.2070\n",
            "Epoch 7/500\n",
            "121/127 [===========================>..] - ETA: 0s - loss: 2.2348 - accuracy: 0.1884\n",
            "Epoch 00007: val_loss improved from 2.14781 to 2.14653, saving model to 1D(2).hdf5\n",
            "127/127 [==============================] - 1s 7ms/step - loss: 2.2365 - accuracy: 0.1900 - val_loss: 2.1465 - val_accuracy: 0.2089\n",
            "Epoch 8/500\n",
            "122/127 [===========================>..] - ETA: 0s - loss: 2.2367 - accuracy: 0.1948\n",
            "Epoch 00008: val_loss did not improve from 2.14653\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.2351 - accuracy: 0.1949 - val_loss: 2.1498 - val_accuracy: 0.2065\n",
            "Epoch 9/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 2.2109 - accuracy: 0.1978\n",
            "Epoch 00009: val_loss improved from 2.14653 to 2.12014, saving model to 1D(2).hdf5\n",
            "127/127 [==============================] - 1s 7ms/step - loss: 2.2128 - accuracy: 0.1977 - val_loss: 2.1201 - val_accuracy: 0.2335\n",
            "Epoch 10/500\n",
            "122/127 [===========================>..] - ETA: 0s - loss: 2.2173 - accuracy: 0.1946\n",
            "Epoch 00010: val_loss did not improve from 2.12014\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.2174 - accuracy: 0.1955 - val_loss: 2.1377 - val_accuracy: 0.2127\n",
            "Epoch 11/500\n",
            "122/127 [===========================>..] - ETA: 0s - loss: 2.2015 - accuracy: 0.1959\n",
            "Epoch 00011: val_loss did not improve from 2.12014\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.1971 - accuracy: 0.1953 - val_loss: 2.1235 - val_accuracy: 0.2212\n",
            "Epoch 12/500\n",
            "124/127 [============================>.] - ETA: 0s - loss: 2.1909 - accuracy: 0.1906\n",
            "Epoch 00012: val_loss improved from 2.12014 to 2.10683, saving model to 1D(2).hdf5\n",
            "127/127 [==============================] - 1s 7ms/step - loss: 2.1920 - accuracy: 0.1903 - val_loss: 2.1068 - val_accuracy: 0.2250\n",
            "Epoch 13/500\n",
            "118/127 [==========================>...] - ETA: 0s - loss: 2.1889 - accuracy: 0.2002\n",
            "Epoch 00013: val_loss did not improve from 2.10683\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.1872 - accuracy: 0.2024 - val_loss: 2.1201 - val_accuracy: 0.2103\n",
            "Epoch 14/500\n",
            "119/127 [===========================>..] - ETA: 0s - loss: 2.1886 - accuracy: 0.2045\n",
            "Epoch 00014: val_loss did not improve from 2.10683\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.1890 - accuracy: 0.2042 - val_loss: 2.1201 - val_accuracy: 0.2259\n",
            "Epoch 15/500\n",
            "124/127 [============================>.] - ETA: 0s - loss: 2.1795 - accuracy: 0.2010\n",
            "Epoch 00015: val_loss improved from 2.10683 to 2.09000, saving model to 1D(2).hdf5\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.1798 - accuracy: 0.2007 - val_loss: 2.0900 - val_accuracy: 0.2259\n",
            "Epoch 16/500\n",
            "123/127 [============================>.] - ETA: 0s - loss: 2.1648 - accuracy: 0.2067\n",
            "Epoch 00016: val_loss did not improve from 2.09000\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.1659 - accuracy: 0.2072 - val_loss: 2.0958 - val_accuracy: 0.2245\n",
            "Epoch 17/500\n",
            "122/127 [===========================>..] - ETA: 0s - loss: 2.1770 - accuracy: 0.2018\n",
            "Epoch 00017: val_loss did not improve from 2.09000\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.1734 - accuracy: 0.2032 - val_loss: 2.1084 - val_accuracy: 0.2235\n",
            "Epoch 18/500\n",
            "122/127 [===========================>..] - ETA: 0s - loss: 2.1659 - accuracy: 0.1982\n",
            "Epoch 00018: val_loss improved from 2.09000 to 2.06861, saving model to 1D(2).hdf5\n",
            "127/127 [==============================] - 1s 7ms/step - loss: 2.1654 - accuracy: 0.1994 - val_loss: 2.0686 - val_accuracy: 0.2453\n",
            "Epoch 19/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 2.1595 - accuracy: 0.2090\n",
            "Epoch 00019: val_loss improved from 2.06861 to 2.06647, saving model to 1D(2).hdf5\n",
            "127/127 [==============================] - 1s 7ms/step - loss: 2.1600 - accuracy: 0.2084 - val_loss: 2.0665 - val_accuracy: 0.2358\n",
            "Epoch 20/500\n",
            "122/127 [===========================>..] - ETA: 0s - loss: 2.1633 - accuracy: 0.2125\n",
            "Epoch 00020: val_loss improved from 2.06647 to 2.05730, saving model to 1D(2).hdf5\n",
            "127/127 [==============================] - 1s 7ms/step - loss: 2.1602 - accuracy: 0.2122 - val_loss: 2.0573 - val_accuracy: 0.2462\n",
            "Epoch 21/500\n",
            "119/127 [===========================>..] - ETA: 0s - loss: 2.1525 - accuracy: 0.2146\n",
            "Epoch 00021: val_loss did not improve from 2.05730\n",
            "127/127 [==============================] - 1s 7ms/step - loss: 2.1544 - accuracy: 0.2152 - val_loss: 2.0691 - val_accuracy: 0.2325\n",
            "Epoch 22/500\n",
            "120/127 [===========================>..] - ETA: 0s - loss: 2.1545 - accuracy: 0.2123\n",
            "Epoch 00022: val_loss did not improve from 2.05730\n",
            "127/127 [==============================] - 1s 7ms/step - loss: 2.1550 - accuracy: 0.2116 - val_loss: 2.0814 - val_accuracy: 0.2358\n",
            "Epoch 23/500\n",
            "126/127 [============================>.] - ETA: 0s - loss: 2.1512 - accuracy: 0.2197\n",
            "Epoch 00023: val_loss improved from 2.05730 to 2.05638, saving model to 1D(2).hdf5\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.1519 - accuracy: 0.2194 - val_loss: 2.0564 - val_accuracy: 0.2547\n",
            "Epoch 24/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 2.1411 - accuracy: 0.2266\n",
            "Epoch 00024: val_loss improved from 2.05638 to 2.04105, saving model to 1D(2).hdf5\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.1400 - accuracy: 0.2272 - val_loss: 2.0411 - val_accuracy: 0.2524\n",
            "Epoch 25/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 2.1398 - accuracy: 0.2202\n",
            "Epoch 00025: val_loss improved from 2.04105 to 2.02067, saving model to 1D(2).hdf5\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.1398 - accuracy: 0.2202 - val_loss: 2.0207 - val_accuracy: 0.2571\n",
            "Epoch 26/500\n",
            "122/127 [===========================>..] - ETA: 0s - loss: 2.1513 - accuracy: 0.2195\n",
            "Epoch 00026: val_loss did not improve from 2.02067\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.1525 - accuracy: 0.2207 - val_loss: 2.0315 - val_accuracy: 0.2623\n",
            "Epoch 27/500\n",
            "120/127 [===========================>..] - ETA: 0s - loss: 2.1200 - accuracy: 0.2198\n",
            "Epoch 00027: val_loss improved from 2.02067 to 2.00398, saving model to 1D(2).hdf5\n",
            "127/127 [==============================] - 1s 7ms/step - loss: 2.1209 - accuracy: 0.2216 - val_loss: 2.0040 - val_accuracy: 0.2831\n",
            "Epoch 28/500\n",
            "121/127 [===========================>..] - ETA: 0s - loss: 2.1205 - accuracy: 0.2359\n",
            "Epoch 00028: val_loss did not improve from 2.00398\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.1234 - accuracy: 0.2344 - val_loss: 2.0409 - val_accuracy: 0.2462\n",
            "Epoch 29/500\n",
            "123/127 [============================>.] - ETA: 0s - loss: 2.1191 - accuracy: 0.2293\n",
            "Epoch 00029: val_loss improved from 2.00398 to 1.99289, saving model to 1D(2).hdf5\n",
            "127/127 [==============================] - 1s 7ms/step - loss: 2.1175 - accuracy: 0.2298 - val_loss: 1.9929 - val_accuracy: 0.2892\n",
            "Epoch 30/500\n",
            "122/127 [===========================>..] - ETA: 0s - loss: 2.1168 - accuracy: 0.2328\n",
            "Epoch 00030: val_loss did not improve from 1.99289\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.1158 - accuracy: 0.2346 - val_loss: 1.9974 - val_accuracy: 0.2774\n",
            "Epoch 31/500\n",
            "123/127 [============================>.] - ETA: 0s - loss: 2.1023 - accuracy: 0.2281\n",
            "Epoch 00031: val_loss improved from 1.99289 to 1.98131, saving model to 1D(2).hdf5\n",
            "127/127 [==============================] - 1s 7ms/step - loss: 2.1029 - accuracy: 0.2281 - val_loss: 1.9813 - val_accuracy: 0.2765\n",
            "Epoch 32/500\n",
            "121/127 [===========================>..] - ETA: 0s - loss: 2.1213 - accuracy: 0.2255\n",
            "Epoch 00032: val_loss did not improve from 1.98131\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.1180 - accuracy: 0.2270 - val_loss: 1.9845 - val_accuracy: 0.2765\n",
            "Epoch 33/500\n",
            "120/127 [===========================>..] - ETA: 0s - loss: 2.1141 - accuracy: 0.2363\n",
            "Epoch 00033: val_loss improved from 1.98131 to 1.98081, saving model to 1D(2).hdf5\n",
            "127/127 [==============================] - 1s 7ms/step - loss: 2.1109 - accuracy: 0.2383 - val_loss: 1.9808 - val_accuracy: 0.2798\n",
            "Epoch 34/500\n",
            "120/127 [===========================>..] - ETA: 0s - loss: 2.1126 - accuracy: 0.2362\n",
            "Epoch 00034: val_loss did not improve from 1.98081\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.1091 - accuracy: 0.2353 - val_loss: 1.9828 - val_accuracy: 0.2750\n",
            "Epoch 35/500\n",
            "121/127 [===========================>..] - ETA: 0s - loss: 2.1024 - accuracy: 0.2423\n",
            "Epoch 00035: val_loss did not improve from 1.98081\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.1033 - accuracy: 0.2401 - val_loss: 1.9868 - val_accuracy: 0.2765\n",
            "Epoch 36/500\n",
            "121/127 [===========================>..] - ETA: 0s - loss: 2.0950 - accuracy: 0.2405\n",
            "Epoch 00036: val_loss did not improve from 1.98081\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.0971 - accuracy: 0.2401 - val_loss: 1.9983 - val_accuracy: 0.2878\n",
            "Epoch 37/500\n",
            "120/127 [===========================>..] - ETA: 0s - loss: 2.0917 - accuracy: 0.2438\n",
            "Epoch 00037: val_loss improved from 1.98081 to 1.97005, saving model to 1D(2).hdf5\n",
            "127/127 [==============================] - 1s 7ms/step - loss: 2.0907 - accuracy: 0.2429 - val_loss: 1.9700 - val_accuracy: 0.2873\n",
            "Epoch 38/500\n",
            "118/127 [==========================>...] - ETA: 0s - loss: 2.0930 - accuracy: 0.2334\n",
            "Epoch 00038: val_loss did not improve from 1.97005\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.0904 - accuracy: 0.2360 - val_loss: 1.9909 - val_accuracy: 0.2925\n",
            "Epoch 39/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 2.0865 - accuracy: 0.2453\n",
            "Epoch 00039: val_loss improved from 1.97005 to 1.96131, saving model to 1D(2).hdf5\n",
            "127/127 [==============================] - 1s 7ms/step - loss: 2.0874 - accuracy: 0.2450 - val_loss: 1.9613 - val_accuracy: 0.2944\n",
            "Epoch 40/500\n",
            "121/127 [===========================>..] - ETA: 0s - loss: 2.0787 - accuracy: 0.2461\n",
            "Epoch 00040: val_loss improved from 1.96131 to 1.95269, saving model to 1D(2).hdf5\n",
            "127/127 [==============================] - 1s 7ms/step - loss: 2.0776 - accuracy: 0.2470 - val_loss: 1.9527 - val_accuracy: 0.2954\n",
            "Epoch 41/500\n",
            "123/127 [============================>.] - ETA: 0s - loss: 2.0912 - accuracy: 0.2421\n",
            "Epoch 00041: val_loss did not improve from 1.95269\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.0944 - accuracy: 0.2405 - val_loss: 1.9672 - val_accuracy: 0.2921\n",
            "Epoch 42/500\n",
            "121/127 [===========================>..] - ETA: 0s - loss: 2.0738 - accuracy: 0.2446\n",
            "Epoch 00042: val_loss did not improve from 1.95269\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.0756 - accuracy: 0.2456 - val_loss: 1.9616 - val_accuracy: 0.2973\n",
            "Epoch 43/500\n",
            "122/127 [===========================>..] - ETA: 0s - loss: 2.0934 - accuracy: 0.2389\n",
            "Epoch 00043: val_loss did not improve from 1.95269\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.0909 - accuracy: 0.2391 - val_loss: 1.9710 - val_accuracy: 0.2788\n",
            "Epoch 44/500\n",
            "118/127 [==========================>...] - ETA: 0s - loss: 2.0736 - accuracy: 0.2466\n",
            "Epoch 00044: val_loss did not improve from 1.95269\n",
            "127/127 [==============================] - 1s 7ms/step - loss: 2.0718 - accuracy: 0.2478 - val_loss: 1.9890 - val_accuracy: 0.2888\n",
            "Epoch 45/500\n",
            "126/127 [============================>.] - ETA: 0s - loss: 2.0938 - accuracy: 0.2386\n",
            "Epoch 00045: val_loss did not improve from 1.95269\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.0942 - accuracy: 0.2396 - val_loss: 1.9612 - val_accuracy: 0.3029\n",
            "Epoch 46/500\n",
            "122/127 [===========================>..] - ETA: 0s - loss: 2.0863 - accuracy: 0.2441\n",
            "Epoch 00046: val_loss improved from 1.95269 to 1.92633, saving model to 1D(2).hdf5\n",
            "127/127 [==============================] - 1s 7ms/step - loss: 2.0862 - accuracy: 0.2454 - val_loss: 1.9263 - val_accuracy: 0.3015\n",
            "Epoch 47/500\n",
            "124/127 [============================>.] - ETA: 0s - loss: 2.0725 - accuracy: 0.2482\n",
            "Epoch 00047: val_loss did not improve from 1.92633\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.0737 - accuracy: 0.2484 - val_loss: 1.9345 - val_accuracy: 0.2930\n",
            "Epoch 48/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 2.0700 - accuracy: 0.2472\n",
            "Epoch 00048: val_loss did not improve from 1.92633\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.0713 - accuracy: 0.2484 - val_loss: 1.9784 - val_accuracy: 0.2897\n",
            "Epoch 49/500\n",
            "122/127 [===========================>..] - ETA: 0s - loss: 2.0710 - accuracy: 0.2507\n",
            "Epoch 00049: val_loss did not improve from 1.92633\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.0701 - accuracy: 0.2514 - val_loss: 1.9725 - val_accuracy: 0.2750\n",
            "Epoch 50/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 2.0870 - accuracy: 0.2405\n",
            "Epoch 00050: val_loss did not improve from 1.92633\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.0849 - accuracy: 0.2409 - val_loss: 1.9502 - val_accuracy: 0.2906\n",
            "Epoch 51/500\n",
            "126/127 [============================>.] - ETA: 0s - loss: 2.0714 - accuracy: 0.2513\n",
            "Epoch 00051: val_loss did not improve from 1.92633\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.0708 - accuracy: 0.2513 - val_loss: 1.9587 - val_accuracy: 0.2911\n",
            "Epoch 52/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 2.0718 - accuracy: 0.2488\n",
            "Epoch 00052: val_loss did not improve from 1.92633\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.0721 - accuracy: 0.2495 - val_loss: 1.9345 - val_accuracy: 0.3039\n",
            "Epoch 53/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 2.0692 - accuracy: 0.2563\n",
            "Epoch 00053: val_loss did not improve from 1.92633\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.0691 - accuracy: 0.2561 - val_loss: 1.9352 - val_accuracy: 0.2779\n",
            "Epoch 54/500\n",
            "124/127 [============================>.] - ETA: 0s - loss: 2.0611 - accuracy: 0.2553\n",
            "Epoch 00054: val_loss did not improve from 1.92633\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.0622 - accuracy: 0.2544 - val_loss: 1.9799 - val_accuracy: 0.2628\n",
            "Epoch 55/500\n",
            "118/127 [==========================>...] - ETA: 0s - loss: 2.0559 - accuracy: 0.2537\n",
            "Epoch 00055: val_loss did not improve from 1.92633\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.0573 - accuracy: 0.2517 - val_loss: 1.9409 - val_accuracy: 0.3015\n",
            "Epoch 56/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 2.0611 - accuracy: 0.2514\n",
            "Epoch 00056: val_loss did not improve from 1.92633\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.0623 - accuracy: 0.2517 - val_loss: 1.9486 - val_accuracy: 0.2873\n",
            "Epoch 57/500\n",
            "123/127 [============================>.] - ETA: 0s - loss: 2.0549 - accuracy: 0.2522\n",
            "Epoch 00057: val_loss did not improve from 1.92633\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.0560 - accuracy: 0.2517 - val_loss: 1.9354 - val_accuracy: 0.2883\n",
            "Epoch 58/500\n",
            "117/127 [==========================>...] - ETA: 0s - loss: 2.0584 - accuracy: 0.2552\n",
            "Epoch 00058: val_loss did not improve from 1.92633\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.0573 - accuracy: 0.2544 - val_loss: 1.9497 - val_accuracy: 0.2883\n",
            "Epoch 59/500\n",
            "126/127 [============================>.] - ETA: 0s - loss: 2.0580 - accuracy: 0.2583\n",
            "Epoch 00059: val_loss did not improve from 1.92633\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.0563 - accuracy: 0.2587 - val_loss: 1.9383 - val_accuracy: 0.2987\n",
            "Epoch 60/500\n",
            "117/127 [==========================>...] - ETA: 0s - loss: 2.0484 - accuracy: 0.2614\n",
            "Epoch 00060: val_loss did not improve from 1.92633\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.0489 - accuracy: 0.2617 - val_loss: 1.9868 - val_accuracy: 0.2836\n",
            "Epoch 61/500\n",
            "123/127 [============================>.] - ETA: 0s - loss: 2.0431 - accuracy: 0.2624\n",
            "Epoch 00061: val_loss did not improve from 1.92633\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.0424 - accuracy: 0.2617 - val_loss: 1.9342 - val_accuracy: 0.2949\n",
            "Epoch 62/500\n",
            "123/127 [============================>.] - ETA: 0s - loss: 2.0504 - accuracy: 0.2525\n",
            "Epoch 00062: val_loss did not improve from 1.92633\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.0473 - accuracy: 0.2541 - val_loss: 1.9463 - val_accuracy: 0.2906\n",
            "Epoch 63/500\n",
            "123/127 [============================>.] - ETA: 0s - loss: 2.0612 - accuracy: 0.2580\n",
            "Epoch 00063: val_loss did not improve from 1.92633\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.0569 - accuracy: 0.2587 - val_loss: 1.9332 - val_accuracy: 0.2954\n",
            "Epoch 64/500\n",
            "122/127 [===========================>..] - ETA: 0s - loss: 2.0416 - accuracy: 0.2679\n",
            "Epoch 00064: val_loss did not improve from 1.92633\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.0424 - accuracy: 0.2665 - val_loss: 1.9733 - val_accuracy: 0.2760\n",
            "Epoch 65/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 2.0541 - accuracy: 0.2555\n",
            "Epoch 00065: val_loss did not improve from 1.92633\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.0541 - accuracy: 0.2555 - val_loss: 1.9336 - val_accuracy: 0.3015\n",
            "Epoch 66/500\n",
            "120/127 [===========================>..] - ETA: 0s - loss: 2.0551 - accuracy: 0.2592\n",
            "Epoch 00066: val_loss did not improve from 1.92633\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.0548 - accuracy: 0.2604 - val_loss: 1.9620 - val_accuracy: 0.2788\n",
            "Epoch 67/500\n",
            "123/127 [============================>.] - ETA: 0s - loss: 2.0416 - accuracy: 0.2678\n",
            "Epoch 00067: val_loss improved from 1.92633 to 1.91161, saving model to 1D(2).hdf5\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.0417 - accuracy: 0.2687 - val_loss: 1.9116 - val_accuracy: 0.2996\n",
            "Epoch 68/500\n",
            "123/127 [============================>.] - ETA: 0s - loss: 2.0399 - accuracy: 0.2605\n",
            "Epoch 00068: val_loss did not improve from 1.91161\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.0412 - accuracy: 0.2598 - val_loss: 1.9209 - val_accuracy: 0.2859\n",
            "Epoch 69/500\n",
            "123/127 [============================>.] - ETA: 0s - loss: 2.0463 - accuracy: 0.2613\n",
            "Epoch 00069: val_loss did not improve from 1.91161\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.0441 - accuracy: 0.2617 - val_loss: 1.9457 - val_accuracy: 0.3025\n",
            "Epoch 70/500\n",
            "121/127 [===========================>..] - ETA: 0s - loss: 2.0403 - accuracy: 0.2615\n",
            "Epoch 00070: val_loss did not improve from 1.91161\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.0417 - accuracy: 0.2631 - val_loss: 1.9291 - val_accuracy: 0.2921\n",
            "Epoch 71/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 2.0477 - accuracy: 0.2646\n",
            "Epoch 00071: val_loss did not improve from 1.91161\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.0464 - accuracy: 0.2645 - val_loss: 1.9476 - val_accuracy: 0.2798\n",
            "Epoch 72/500\n",
            "123/127 [============================>.] - ETA: 0s - loss: 2.0431 - accuracy: 0.2528\n",
            "Epoch 00072: val_loss did not improve from 1.91161\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.0402 - accuracy: 0.2541 - val_loss: 1.9541 - val_accuracy: 0.2864\n",
            "Epoch 73/500\n",
            "121/127 [===========================>..] - ETA: 0s - loss: 2.0219 - accuracy: 0.2729\n",
            "Epoch 00073: val_loss did not improve from 1.91161\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.0242 - accuracy: 0.2727 - val_loss: 1.9379 - val_accuracy: 0.2935\n",
            "Epoch 74/500\n",
            "126/127 [============================>.] - ETA: 0s - loss: 2.0470 - accuracy: 0.2579\n",
            "Epoch 00074: val_loss did not improve from 1.91161\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.0467 - accuracy: 0.2580 - val_loss: 1.9636 - val_accuracy: 0.2741\n",
            "Epoch 75/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 2.0352 - accuracy: 0.2656\n",
            "Epoch 00075: val_loss did not improve from 1.91161\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.0355 - accuracy: 0.2662 - val_loss: 1.9227 - val_accuracy: 0.2883\n",
            "Epoch 76/500\n",
            "119/127 [===========================>..] - ETA: 0s - loss: 2.0388 - accuracy: 0.2666\n",
            "Epoch 00076: val_loss did not improve from 1.91161\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.0403 - accuracy: 0.2639 - val_loss: 1.9208 - val_accuracy: 0.2973\n",
            "Epoch 77/500\n",
            "118/127 [==========================>...] - ETA: 0s - loss: 2.0367 - accuracy: 0.2627\n",
            "Epoch 00077: val_loss improved from 1.91161 to 1.90000, saving model to 1D(2).hdf5\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.0301 - accuracy: 0.2623 - val_loss: 1.9000 - val_accuracy: 0.3010\n",
            "Epoch 78/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 2.0243 - accuracy: 0.2700\n",
            "Epoch 00078: val_loss did not improve from 1.90000\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.0243 - accuracy: 0.2700 - val_loss: 1.9275 - val_accuracy: 0.2869\n",
            "Epoch 79/500\n",
            "123/127 [============================>.] - ETA: 0s - loss: 2.0475 - accuracy: 0.2626\n",
            "Epoch 00079: val_loss did not improve from 1.90000\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.0488 - accuracy: 0.2632 - val_loss: 1.9145 - val_accuracy: 0.2987\n",
            "Epoch 80/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 2.0306 - accuracy: 0.2664\n",
            "Epoch 00080: val_loss did not improve from 1.90000\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.0325 - accuracy: 0.2656 - val_loss: 1.9338 - val_accuracy: 0.2888\n",
            "Epoch 81/500\n",
            "122/127 [===========================>..] - ETA: 0s - loss: 2.0208 - accuracy: 0.2641\n",
            "Epoch 00081: val_loss did not improve from 1.90000\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.0231 - accuracy: 0.2634 - val_loss: 1.9287 - val_accuracy: 0.2968\n",
            "Epoch 82/500\n",
            "121/127 [===========================>..] - ETA: 0s - loss: 2.0433 - accuracy: 0.2617\n",
            "Epoch 00082: val_loss did not improve from 1.90000\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.0423 - accuracy: 0.2601 - val_loss: 1.9566 - val_accuracy: 0.2925\n",
            "Epoch 83/500\n",
            "119/127 [===========================>..] - ETA: 0s - loss: 2.0340 - accuracy: 0.2686\n",
            "Epoch 00083: val_loss did not improve from 1.90000\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.0354 - accuracy: 0.2689 - val_loss: 1.9522 - val_accuracy: 0.2921\n",
            "Epoch 84/500\n",
            "124/127 [============================>.] - ETA: 0s - loss: 2.0100 - accuracy: 0.2750\n",
            "Epoch 00084: val_loss did not improve from 1.90000\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.0082 - accuracy: 0.2744 - val_loss: 1.9504 - val_accuracy: 0.2798\n",
            "Epoch 85/500\n",
            "126/127 [============================>.] - ETA: 0s - loss: 2.0314 - accuracy: 0.2759\n",
            "Epoch 00085: val_loss did not improve from 1.90000\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.0300 - accuracy: 0.2760 - val_loss: 1.9290 - val_accuracy: 0.2954\n",
            "Epoch 86/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 2.0239 - accuracy: 0.2648\n",
            "Epoch 00086: val_loss did not improve from 1.90000\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.0223 - accuracy: 0.2650 - val_loss: 1.9318 - val_accuracy: 0.3006\n",
            "Epoch 87/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 2.0249 - accuracy: 0.2698\n",
            "Epoch 00087: val_loss did not improve from 1.90000\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.0223 - accuracy: 0.2711 - val_loss: 1.9416 - val_accuracy: 0.2859\n",
            "Epoch 88/500\n",
            "122/127 [===========================>..] - ETA: 0s - loss: 2.0289 - accuracy: 0.2762\n",
            "Epoch 00088: val_loss improved from 1.90000 to 1.89472, saving model to 1D(2).hdf5\n",
            "127/127 [==============================] - 1s 7ms/step - loss: 2.0276 - accuracy: 0.2791 - val_loss: 1.8947 - val_accuracy: 0.3124\n",
            "Epoch 89/500\n",
            "121/127 [===========================>..] - ETA: 0s - loss: 2.0055 - accuracy: 0.2702\n",
            "Epoch 00089: val_loss did not improve from 1.89472\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.0068 - accuracy: 0.2700 - val_loss: 1.9018 - val_accuracy: 0.2968\n",
            "Epoch 90/500\n",
            "124/127 [============================>.] - ETA: 0s - loss: 2.0348 - accuracy: 0.2598\n",
            "Epoch 00090: val_loss did not improve from 1.89472\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.0355 - accuracy: 0.2599 - val_loss: 1.9108 - val_accuracy: 0.2958\n",
            "Epoch 91/500\n",
            "123/127 [============================>.] - ETA: 0s - loss: 2.0252 - accuracy: 0.2777\n",
            "Epoch 00091: val_loss did not improve from 1.89472\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.0212 - accuracy: 0.2782 - val_loss: 1.9496 - val_accuracy: 0.2788\n",
            "Epoch 92/500\n",
            "119/127 [===========================>..] - ETA: 0s - loss: 2.0127 - accuracy: 0.2728\n",
            "Epoch 00092: val_loss did not improve from 1.89472\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.0150 - accuracy: 0.2736 - val_loss: 1.9542 - val_accuracy: 0.2812\n",
            "Epoch 93/500\n",
            "124/127 [============================>.] - ETA: 0s - loss: 2.0122 - accuracy: 0.2782\n",
            "Epoch 00093: val_loss improved from 1.89472 to 1.88082, saving model to 1D(2).hdf5\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.0125 - accuracy: 0.2777 - val_loss: 1.8808 - val_accuracy: 0.3015\n",
            "Epoch 94/500\n",
            "124/127 [============================>.] - ETA: 0s - loss: 2.0053 - accuracy: 0.2806\n",
            "Epoch 00094: val_loss did not improve from 1.88082\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.0025 - accuracy: 0.2817 - val_loss: 1.9109 - val_accuracy: 0.2850\n",
            "Epoch 95/500\n",
            "123/127 [============================>.] - ETA: 0s - loss: 2.0112 - accuracy: 0.2694\n",
            "Epoch 00095: val_loss did not improve from 1.88082\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.0109 - accuracy: 0.2703 - val_loss: 1.9089 - val_accuracy: 0.2935\n",
            "Epoch 96/500\n",
            "121/127 [===========================>..] - ETA: 0s - loss: 2.0256 - accuracy: 0.2722\n",
            "Epoch 00096: val_loss did not improve from 1.88082\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.0252 - accuracy: 0.2722 - val_loss: 1.9273 - val_accuracy: 0.2892\n",
            "Epoch 97/500\n",
            "123/127 [============================>.] - ETA: 0s - loss: 2.0138 - accuracy: 0.2733\n",
            "Epoch 00097: val_loss did not improve from 1.88082\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.0122 - accuracy: 0.2730 - val_loss: 1.9328 - val_accuracy: 0.2958\n",
            "Epoch 98/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 2.0010 - accuracy: 0.2853\n",
            "Epoch 00098: val_loss did not improve from 1.88082\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.0027 - accuracy: 0.2843 - val_loss: 1.9339 - val_accuracy: 0.2793\n",
            "Epoch 99/500\n",
            "124/127 [============================>.] - ETA: 0s - loss: 2.0197 - accuracy: 0.2729\n",
            "Epoch 00099: val_loss did not improve from 1.88082\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.0198 - accuracy: 0.2721 - val_loss: 1.9554 - val_accuracy: 0.2788\n",
            "Epoch 100/500\n",
            "124/127 [============================>.] - ETA: 0s - loss: 2.0073 - accuracy: 0.2718\n",
            "Epoch 00100: val_loss did not improve from 1.88082\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.0081 - accuracy: 0.2706 - val_loss: 1.9291 - val_accuracy: 0.2850\n",
            "Epoch 101/500\n",
            "124/127 [============================>.] - ETA: 0s - loss: 1.9950 - accuracy: 0.2863\n",
            "Epoch 00101: val_loss did not improve from 1.88082\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 1.9938 - accuracy: 0.2850 - val_loss: 1.9093 - val_accuracy: 0.3043\n",
            "Epoch 102/500\n",
            "122/127 [===========================>..] - ETA: 0s - loss: 2.0105 - accuracy: 0.2789\n",
            "Epoch 00102: val_loss did not improve from 1.88082\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.0090 - accuracy: 0.2785 - val_loss: 1.9324 - val_accuracy: 0.3006\n",
            "Epoch 103/500\n",
            "121/127 [===========================>..] - ETA: 0s - loss: 2.0113 - accuracy: 0.2750\n",
            "Epoch 00103: val_loss did not improve from 1.88082\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.0101 - accuracy: 0.2730 - val_loss: 1.9259 - val_accuracy: 0.2892\n",
            "Epoch 104/500\n",
            "126/127 [============================>.] - ETA: 0s - loss: 2.0007 - accuracy: 0.2784\n",
            "Epoch 00104: val_loss did not improve from 1.88082\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 1.9989 - accuracy: 0.2787 - val_loss: 1.9408 - val_accuracy: 0.2826\n",
            "Epoch 105/500\n",
            "124/127 [============================>.] - ETA: 0s - loss: 2.0053 - accuracy: 0.2826\n",
            "Epoch 00105: val_loss did not improve from 1.88082\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.0027 - accuracy: 0.2826 - val_loss: 1.9084 - val_accuracy: 0.2916\n",
            "Epoch 106/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 2.0098 - accuracy: 0.2832\n",
            "Epoch 00106: val_loss did not improve from 1.88082\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.0107 - accuracy: 0.2826 - val_loss: 1.9543 - val_accuracy: 0.2940\n",
            "Epoch 107/500\n",
            "123/127 [============================>.] - ETA: 0s - loss: 2.0000 - accuracy: 0.2772\n",
            "Epoch 00107: val_loss did not improve from 1.88082\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.0036 - accuracy: 0.2757 - val_loss: 1.9478 - val_accuracy: 0.2911\n",
            "Epoch 108/500\n",
            "121/127 [===========================>..] - ETA: 0s - loss: 1.9972 - accuracy: 0.2798\n",
            "Epoch 00108: val_loss did not improve from 1.88082\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 1.9980 - accuracy: 0.2801 - val_loss: 1.9887 - val_accuracy: 0.2727\n",
            "Epoch 109/500\n",
            "122/127 [===========================>..] - ETA: 0s - loss: 2.0128 - accuracy: 0.2693\n",
            "Epoch 00109: val_loss did not improve from 1.88082\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.0106 - accuracy: 0.2695 - val_loss: 1.9131 - val_accuracy: 0.2888\n",
            "Epoch 110/500\n",
            "126/127 [============================>.] - ETA: 0s - loss: 2.0055 - accuracy: 0.2748\n",
            "Epoch 00110: val_loss did not improve from 1.88082\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.0028 - accuracy: 0.2760 - val_loss: 1.9087 - val_accuracy: 0.2807\n",
            "Epoch 111/500\n",
            "119/127 [===========================>..] - ETA: 0s - loss: 1.9889 - accuracy: 0.2886\n",
            "Epoch 00111: val_loss did not improve from 1.88082\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 1.9846 - accuracy: 0.2902 - val_loss: 1.9186 - val_accuracy: 0.2821\n",
            "Epoch 112/500\n",
            "122/127 [===========================>..] - ETA: 0s - loss: 1.9941 - accuracy: 0.2784\n",
            "Epoch 00112: val_loss did not improve from 1.88082\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 1.9936 - accuracy: 0.2779 - val_loss: 1.9420 - val_accuracy: 0.2703\n",
            "Epoch 113/500\n",
            "122/127 [===========================>..] - ETA: 0s - loss: 2.0014 - accuracy: 0.2844\n",
            "Epoch 00113: val_loss did not improve from 1.88082\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.0006 - accuracy: 0.2843 - val_loss: 1.9121 - val_accuracy: 0.2949\n",
            "Epoch 114/500\n",
            "121/127 [===========================>..] - ETA: 0s - loss: 2.0023 - accuracy: 0.2858\n",
            "Epoch 00114: val_loss did not improve from 1.88082\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.0051 - accuracy: 0.2850 - val_loss: 1.9596 - val_accuracy: 0.2722\n",
            "Epoch 115/500\n",
            "122/127 [===========================>..] - ETA: 0s - loss: 1.9764 - accuracy: 0.2893\n",
            "Epoch 00115: val_loss did not improve from 1.88082\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 1.9776 - accuracy: 0.2891 - val_loss: 1.9444 - val_accuracy: 0.2930\n",
            "Epoch 116/500\n",
            "120/127 [===========================>..] - ETA: 0s - loss: 2.0111 - accuracy: 0.2800\n",
            "Epoch 00116: val_loss did not improve from 1.88082\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.0114 - accuracy: 0.2795 - val_loss: 1.9458 - val_accuracy: 0.2769\n",
            "Epoch 117/500\n",
            "118/127 [==========================>...] - ETA: 0s - loss: 2.0003 - accuracy: 0.2808\n",
            "Epoch 00117: val_loss did not improve from 1.88082\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 1.9936 - accuracy: 0.2840 - val_loss: 1.9186 - val_accuracy: 0.3025\n",
            "Epoch 118/500\n",
            "118/127 [==========================>...] - ETA: 0s - loss: 1.9974 - accuracy: 0.2844\n",
            "Epoch 00118: val_loss did not improve from 1.88082\n",
            "127/127 [==============================] - 1s 7ms/step - loss: 1.9978 - accuracy: 0.2826 - val_loss: 1.9681 - val_accuracy: 0.2741\n",
            "Epoch 119/500\n",
            "121/127 [===========================>..] - ETA: 0s - loss: 1.9933 - accuracy: 0.2861\n",
            "Epoch 00119: val_loss did not improve from 1.88082\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 1.9941 - accuracy: 0.2878 - val_loss: 1.9234 - val_accuracy: 0.2873\n",
            "Epoch 120/500\n",
            "123/127 [============================>.] - ETA: 0s - loss: 1.9870 - accuracy: 0.2798\n",
            "Epoch 00120: val_loss did not improve from 1.88082\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 1.9880 - accuracy: 0.2802 - val_loss: 1.9006 - val_accuracy: 0.2973\n",
            "Epoch 121/500\n",
            "121/127 [===========================>..] - ETA: 0s - loss: 1.9937 - accuracy: 0.2747\n",
            "Epoch 00121: val_loss did not improve from 1.88082\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 1.9925 - accuracy: 0.2741 - val_loss: 1.9145 - val_accuracy: 0.3114\n",
            "Epoch 122/500\n",
            "122/127 [===========================>..] - ETA: 0s - loss: 2.0011 - accuracy: 0.2810\n",
            "Epoch 00122: val_loss did not improve from 1.88082\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.0015 - accuracy: 0.2791 - val_loss: 1.9122 - val_accuracy: 0.2916\n",
            "Epoch 123/500\n",
            "123/127 [============================>.] - ETA: 0s - loss: 2.0006 - accuracy: 0.2831\n",
            "Epoch 00123: val_loss did not improve from 1.88082\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.0008 - accuracy: 0.2834 - val_loss: 1.9268 - val_accuracy: 0.2836\n",
            "Epoch 124/500\n",
            "121/127 [===========================>..] - ETA: 0s - loss: 2.0017 - accuracy: 0.2752\n",
            "Epoch 00124: val_loss did not improve from 1.88082\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 1.9982 - accuracy: 0.2755 - val_loss: 1.9257 - val_accuracy: 0.3010\n",
            "Epoch 125/500\n",
            "124/127 [============================>.] - ETA: 0s - loss: 1.9865 - accuracy: 0.2805\n",
            "Epoch 00125: val_loss did not improve from 1.88082\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 1.9861 - accuracy: 0.2806 - val_loss: 1.9250 - val_accuracy: 0.3062\n",
            "Epoch 126/500\n",
            "122/127 [===========================>..] - ETA: 0s - loss: 1.9773 - accuracy: 0.2844\n",
            "Epoch 00126: val_loss did not improve from 1.88082\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 1.9807 - accuracy: 0.2828 - val_loss: 1.9455 - val_accuracy: 0.3053\n",
            "Epoch 127/500\n",
            "121/127 [===========================>..] - ETA: 0s - loss: 1.9998 - accuracy: 0.2860\n",
            "Epoch 00127: val_loss did not improve from 1.88082\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 1.9951 - accuracy: 0.2873 - val_loss: 1.9015 - val_accuracy: 0.3119\n",
            "Epoch 128/500\n",
            "120/127 [===========================>..] - ETA: 0s - loss: 1.9676 - accuracy: 0.2970\n",
            "Epoch 00128: val_loss did not improve from 1.88082\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 1.9687 - accuracy: 0.2955 - val_loss: 1.9064 - val_accuracy: 0.3247\n",
            "Epoch 129/500\n",
            "123/127 [============================>.] - ETA: 0s - loss: 1.9934 - accuracy: 0.2873\n",
            "Epoch 00129: val_loss did not improve from 1.88082\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 1.9939 - accuracy: 0.2875 - val_loss: 1.9534 - val_accuracy: 0.2817\n",
            "Epoch 130/500\n",
            "124/127 [============================>.] - ETA: 0s - loss: 1.9919 - accuracy: 0.2842\n",
            "Epoch 00130: val_loss did not improve from 1.88082\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 1.9891 - accuracy: 0.2851 - val_loss: 1.9530 - val_accuracy: 0.2854\n",
            "Epoch 131/500\n",
            "122/127 [===========================>..] - ETA: 0s - loss: 1.9774 - accuracy: 0.2846\n",
            "Epoch 00131: val_loss did not improve from 1.88082\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 1.9755 - accuracy: 0.2837 - val_loss: 1.9594 - val_accuracy: 0.2694\n",
            "Epoch 132/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.9829 - accuracy: 0.2897\n",
            "Epoch 00132: val_loss did not improve from 1.88082\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 1.9829 - accuracy: 0.2897 - val_loss: 1.9457 - val_accuracy: 0.2826\n",
            "Epoch 133/500\n",
            "119/127 [===========================>..] - ETA: 0s - loss: 1.9920 - accuracy: 0.2892\n",
            "Epoch 00133: val_loss did not improve from 1.88082\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 1.9874 - accuracy: 0.2910 - val_loss: 1.9323 - val_accuracy: 0.3015\n",
            "Epoch 134/500\n",
            "118/127 [==========================>...] - ETA: 0s - loss: 1.9809 - accuracy: 0.2834\n",
            "Epoch 00134: val_loss did not improve from 1.88082\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 1.9802 - accuracy: 0.2845 - val_loss: 1.8965 - val_accuracy: 0.3072\n",
            "Epoch 135/500\n",
            "119/127 [===========================>..] - ETA: 0s - loss: 1.9770 - accuracy: 0.2894\n",
            "Epoch 00135: val_loss did not improve from 1.88082\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 1.9715 - accuracy: 0.2911 - val_loss: 1.9491 - val_accuracy: 0.2869\n",
            "Epoch 136/500\n",
            "122/127 [===========================>..] - ETA: 0s - loss: 1.9788 - accuracy: 0.2821\n",
            "Epoch 00136: val_loss did not improve from 1.88082\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 1.9773 - accuracy: 0.2832 - val_loss: 1.9845 - val_accuracy: 0.2949\n",
            "Epoch 137/500\n",
            "122/127 [===========================>..] - ETA: 0s - loss: 1.9863 - accuracy: 0.2831\n",
            "Epoch 00137: val_loss did not improve from 1.88082\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 1.9854 - accuracy: 0.2818 - val_loss: 1.8931 - val_accuracy: 0.2958\n",
            "Epoch 138/500\n",
            "122/127 [===========================>..] - ETA: 0s - loss: 1.9814 - accuracy: 0.2852\n",
            "Epoch 00138: val_loss did not improve from 1.88082\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 1.9830 - accuracy: 0.2843 - val_loss: 1.9198 - val_accuracy: 0.2930\n",
            "Epoch 139/500\n",
            "119/127 [===========================>..] - ETA: 0s - loss: 1.9813 - accuracy: 0.2834\n",
            "Epoch 00139: val_loss did not improve from 1.88082\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 1.9804 - accuracy: 0.2865 - val_loss: 1.9088 - val_accuracy: 0.3001\n",
            "Epoch 140/500\n",
            "121/127 [===========================>..] - ETA: 0s - loss: 1.9718 - accuracy: 0.2922\n",
            "Epoch 00140: val_loss did not improve from 1.88082\n",
            "127/127 [==============================] - 1s 7ms/step - loss: 1.9704 - accuracy: 0.2921 - val_loss: 1.9608 - val_accuracy: 0.3006\n",
            "Epoch 141/500\n",
            "123/127 [============================>.] - ETA: 0s - loss: 1.9780 - accuracy: 0.2909\n",
            "Epoch 00141: val_loss did not improve from 1.88082\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 1.9800 - accuracy: 0.2894 - val_loss: 1.9781 - val_accuracy: 0.2779\n",
            "Epoch 142/500\n",
            "122/127 [===========================>..] - ETA: 0s - loss: 1.9689 - accuracy: 0.2992\n",
            "Epoch 00142: val_loss did not improve from 1.88082\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 1.9758 - accuracy: 0.2962 - val_loss: 1.9688 - val_accuracy: 0.2840\n",
            "Epoch 143/500\n",
            "119/127 [===========================>..] - ETA: 0s - loss: 1.9746 - accuracy: 0.2924\n",
            "Epoch 00143: val_loss did not improve from 1.88082\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 1.9732 - accuracy: 0.2924 - val_loss: 1.9300 - val_accuracy: 0.2991\n",
            "Epoch 144/500\n",
            "122/127 [===========================>..] - ETA: 0s - loss: 1.9777 - accuracy: 0.2931\n",
            "Epoch 00144: val_loss did not improve from 1.88082\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 1.9763 - accuracy: 0.2930 - val_loss: 1.9850 - val_accuracy: 0.2793\n",
            "Epoch 145/500\n",
            "121/127 [===========================>..] - ETA: 0s - loss: 1.9846 - accuracy: 0.2893\n",
            "Epoch 00145: val_loss did not improve from 1.88082\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 1.9835 - accuracy: 0.2884 - val_loss: 1.9386 - val_accuracy: 0.2973\n",
            "Epoch 146/500\n",
            "121/127 [===========================>..] - ETA: 0s - loss: 1.9557 - accuracy: 0.2939\n",
            "Epoch 00146: val_loss did not improve from 1.88082\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 1.9589 - accuracy: 0.2932 - val_loss: 1.9735 - val_accuracy: 0.2850\n",
            "Epoch 147/500\n",
            "122/127 [===========================>..] - ETA: 0s - loss: 1.9819 - accuracy: 0.2931\n",
            "Epoch 00147: val_loss did not improve from 1.88082\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 1.9820 - accuracy: 0.2930 - val_loss: 1.9926 - val_accuracy: 0.2902\n",
            "Epoch 148/500\n",
            "122/127 [===========================>..] - ETA: 0s - loss: 1.9721 - accuracy: 0.2952\n",
            "Epoch 00148: val_loss did not improve from 1.88082\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 1.9723 - accuracy: 0.2938 - val_loss: 1.9585 - val_accuracy: 0.2892\n",
            "Epoch 149/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.9659 - accuracy: 0.2932\n",
            "Epoch 00149: val_loss did not improve from 1.88082\n",
            "127/127 [==============================] - 1s 7ms/step - loss: 1.9659 - accuracy: 0.2932 - val_loss: 1.9511 - val_accuracy: 0.2996\n",
            "Epoch 150/500\n",
            "121/127 [===========================>..] - ETA: 0s - loss: 1.9792 - accuracy: 0.2964\n",
            "Epoch 00150: val_loss did not improve from 1.88082\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 1.9779 - accuracy: 0.2947 - val_loss: 1.9430 - val_accuracy: 0.2840\n",
            "Epoch 151/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 1.9750 - accuracy: 0.2832\n",
            "Epoch 00151: val_loss did not improve from 1.88082\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 1.9729 - accuracy: 0.2832 - val_loss: 1.9536 - val_accuracy: 0.2991\n",
            "Epoch 152/500\n",
            "124/127 [============================>.] - ETA: 0s - loss: 1.9684 - accuracy: 0.2948\n",
            "Epoch 00152: val_loss did not improve from 1.88082\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 1.9666 - accuracy: 0.2941 - val_loss: 1.9080 - val_accuracy: 0.3110\n",
            "Epoch 153/500\n",
            "122/127 [===========================>..] - ETA: 0s - loss: 1.9834 - accuracy: 0.2874\n",
            "Epoch 00153: val_loss did not improve from 1.88082\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 1.9851 - accuracy: 0.2878 - val_loss: 1.9104 - val_accuracy: 0.3119\n",
            "Epoch 154/500\n",
            "121/127 [===========================>..] - ETA: 0s - loss: 1.9684 - accuracy: 0.2896\n",
            "Epoch 00154: val_loss did not improve from 1.88082\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 1.9678 - accuracy: 0.2913 - val_loss: 1.9458 - val_accuracy: 0.2930\n",
            "Epoch 155/500\n",
            "123/127 [============================>.] - ETA: 0s - loss: 1.9682 - accuracy: 0.2972\n",
            "Epoch 00155: val_loss did not improve from 1.88082\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 1.9679 - accuracy: 0.2971 - val_loss: 1.9520 - val_accuracy: 0.2930\n",
            "Epoch 156/500\n",
            "120/127 [===========================>..] - ETA: 0s - loss: 1.9658 - accuracy: 0.3033\n",
            "Epoch 00156: val_loss did not improve from 1.88082\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 1.9663 - accuracy: 0.3023 - val_loss: 1.9473 - val_accuracy: 0.3048\n",
            "Epoch 157/500\n",
            "124/127 [============================>.] - ETA: 0s - loss: 1.9758 - accuracy: 0.2937\n",
            "Epoch 00157: val_loss did not improve from 1.88082\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 1.9768 - accuracy: 0.2924 - val_loss: 1.9822 - val_accuracy: 0.2769\n",
            "Epoch 158/500\n",
            "121/127 [===========================>..] - ETA: 0s - loss: 1.9753 - accuracy: 0.2800\n",
            "Epoch 00158: val_loss did not improve from 1.88082\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 1.9757 - accuracy: 0.2826 - val_loss: 1.9438 - val_accuracy: 0.3020\n",
            "Epoch 159/500\n",
            "124/127 [============================>.] - ETA: 0s - loss: 1.9720 - accuracy: 0.2868\n",
            "Epoch 00159: val_loss did not improve from 1.88082\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 1.9736 - accuracy: 0.2870 - val_loss: 1.9107 - val_accuracy: 0.3176\n",
            "Epoch 160/500\n",
            "123/127 [============================>.] - ETA: 0s - loss: 1.9713 - accuracy: 0.2946\n",
            "Epoch 00160: val_loss did not improve from 1.88082\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 1.9723 - accuracy: 0.2947 - val_loss: 1.9615 - val_accuracy: 0.2717\n",
            "Epoch 161/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.9590 - accuracy: 0.2962\n",
            "Epoch 00161: val_loss did not improve from 1.88082\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 1.9590 - accuracy: 0.2962 - val_loss: 1.9962 - val_accuracy: 0.2840\n",
            "Epoch 162/500\n",
            "122/127 [===========================>..] - ETA: 0s - loss: 1.9779 - accuracy: 0.2923\n",
            "Epoch 00162: val_loss did not improve from 1.88082\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 1.9779 - accuracy: 0.2917 - val_loss: 1.9430 - val_accuracy: 0.2859\n",
            "Epoch 163/500\n",
            "121/127 [===========================>..] - ETA: 0s - loss: 1.9626 - accuracy: 0.2851\n",
            "Epoch 00163: val_loss did not improve from 1.88082\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 1.9622 - accuracy: 0.2858 - val_loss: 1.8996 - val_accuracy: 0.3001\n",
            "Epoch 164/500\n",
            "121/127 [===========================>..] - ETA: 0s - loss: 1.9572 - accuracy: 0.2911\n",
            "Epoch 00164: val_loss did not improve from 1.88082\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 1.9582 - accuracy: 0.2921 - val_loss: 1.9460 - val_accuracy: 0.2930\n",
            "Epoch 165/500\n",
            "123/127 [============================>.] - ETA: 0s - loss: 1.9843 - accuracy: 0.2867\n",
            "Epoch 00165: val_loss did not improve from 1.88082\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 1.9835 - accuracy: 0.2873 - val_loss: 1.9571 - val_accuracy: 0.3105\n",
            "Epoch 166/500\n",
            "121/127 [===========================>..] - ETA: 0s - loss: 1.9874 - accuracy: 0.2909\n",
            "Epoch 00166: val_loss did not improve from 1.88082\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 1.9861 - accuracy: 0.2921 - val_loss: 1.9453 - val_accuracy: 0.2916\n",
            "Epoch 167/500\n",
            "120/127 [===========================>..] - ETA: 0s - loss: 1.9540 - accuracy: 0.2928\n",
            "Epoch 00167: val_loss did not improve from 1.88082\n",
            "127/127 [==============================] - 1s 7ms/step - loss: 1.9554 - accuracy: 0.2930 - val_loss: 1.9244 - val_accuracy: 0.3053\n",
            "Epoch 168/500\n",
            "120/127 [===========================>..] - ETA: 0s - loss: 1.9547 - accuracy: 0.2905\n",
            "Epoch 00168: val_loss did not improve from 1.88082\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 1.9558 - accuracy: 0.2892 - val_loss: 1.9613 - val_accuracy: 0.3110\n",
            "Epoch 169/500\n",
            "121/127 [===========================>..] - ETA: 0s - loss: 1.9554 - accuracy: 0.2954\n",
            "Epoch 00169: val_loss did not improve from 1.88082\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 1.9564 - accuracy: 0.2958 - val_loss: 1.9574 - val_accuracy: 0.2935\n",
            "Epoch 170/500\n",
            "124/127 [============================>.] - ETA: 0s - loss: 1.9646 - accuracy: 0.2855\n",
            "Epoch 00170: val_loss did not improve from 1.88082\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 1.9646 - accuracy: 0.2847 - val_loss: 1.9288 - val_accuracy: 0.3147\n",
            "Epoch 171/500\n",
            "122/127 [===========================>..] - ETA: 0s - loss: 1.9575 - accuracy: 0.2921\n",
            "Epoch 00171: val_loss did not improve from 1.88082\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 1.9564 - accuracy: 0.2924 - val_loss: 1.9188 - val_accuracy: 0.2930\n",
            "Epoch 172/500\n",
            "120/127 [===========================>..] - ETA: 0s - loss: 1.9611 - accuracy: 0.3005\n",
            "Epoch 00172: val_loss did not improve from 1.88082\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 1.9628 - accuracy: 0.2987 - val_loss: 1.9490 - val_accuracy: 0.2944\n",
            "Epoch 173/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.9576 - accuracy: 0.2941\n",
            "Epoch 00173: val_loss did not improve from 1.88082\n",
            "127/127 [==============================] - 1s 7ms/step - loss: 1.9576 - accuracy: 0.2941 - val_loss: 1.9456 - val_accuracy: 0.3058\n",
            "Epoch 174/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.9584 - accuracy: 0.3015\n",
            "Epoch 00174: val_loss did not improve from 1.88082\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 1.9584 - accuracy: 0.3015 - val_loss: 1.8992 - val_accuracy: 0.3067\n",
            "Epoch 175/500\n",
            "122/127 [===========================>..] - ETA: 0s - loss: 2.0018 - accuracy: 0.2833\n",
            "Epoch 00175: val_loss did not improve from 1.88082\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 2.0047 - accuracy: 0.2815 - val_loss: 1.9643 - val_accuracy: 0.3010\n",
            "Epoch 176/500\n",
            "120/127 [===========================>..] - ETA: 0s - loss: 1.9730 - accuracy: 0.2812\n",
            "Epoch 00176: val_loss did not improve from 1.88082\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 1.9718 - accuracy: 0.2823 - val_loss: 1.9470 - val_accuracy: 0.2991\n",
            "Epoch 177/500\n",
            "119/127 [===========================>..] - ETA: 0s - loss: 1.9744 - accuracy: 0.2936\n",
            "Epoch 00177: val_loss did not improve from 1.88082\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 1.9738 - accuracy: 0.2947 - val_loss: 1.9001 - val_accuracy: 0.2991\n",
            "Epoch 178/500\n",
            "120/127 [===========================>..] - ETA: 0s - loss: 1.9659 - accuracy: 0.2923\n",
            "Epoch 00178: val_loss did not improve from 1.88082\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 1.9639 - accuracy: 0.2933 - val_loss: 1.9307 - val_accuracy: 0.3043\n",
            "Epoch 00178: early stopping\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f442c81c950>"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Experment (2)"
      ],
      "metadata": {
        "id": "GJ2n5em_GOVz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelc10 = Sequential()\n",
        "\n",
        "input_shape=X_train.shape[1:]\n",
        "\n",
        "modelc10.add(Conv1D(filters=7, kernel_size=5, padding='same', activation='relu',\n",
        "                         input_shape=input_shape))\n",
        "modelc10.add(MaxPooling1D(pool_size=4))\n",
        "modelc10.add(Dropout(0.5))\n",
        "\n",
        "modelc10.add(Conv1D(filters=5, kernel_size=5, padding='same', activation='relu',))\n",
        "modelc10.add(MaxPooling1D(pool_size=4))\n",
        "modelc10.add(Dropout(0.5))\n",
        "\n",
        "modelc10.add(Dense(200))\n",
        "modelc10.add(Dropout(0.5))\n",
        "\n",
        "modelc10.add(Flatten())\n",
        "\n",
        "\n",
        "modelc10.add(Dense(units = num_labels, activation=\"softmax\"))\n",
        "\n",
        "modelc10.summary()\n",
        "\n",
        "modelc10.compile(loss = 'categorical_crossentropy', \n",
        "              metrics = ['accuracy'],\n",
        "              optimizer = 'adam')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-jtxudj4XM5",
        "outputId": "f4f3ccd2-bea1-48a5-983a-573fd0d1d55a"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_9 (Conv1D)           (None, 40, 7)             6097      \n",
            "                                                                 \n",
            " max_pooling1d_5 (MaxPooling  (None, 10, 7)            0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " dropout_22 (Dropout)        (None, 10, 7)             0         \n",
            "                                                                 \n",
            " conv1d_10 (Conv1D)          (None, 10, 5)             180       \n",
            "                                                                 \n",
            " max_pooling1d_6 (MaxPooling  (None, 2, 5)             0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " dropout_23 (Dropout)        (None, 2, 5)              0         \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 2, 200)            1200      \n",
            "                                                                 \n",
            " dropout_24 (Dropout)        (None, 2, 200)            0         \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (None, 400)               0         \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 18)                7218      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,695\n",
            "Trainable params: 14,695\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "es = EarlyStopping(monitor='val_accuracy', min_delta= 0.01 , patience= 50, verbose= 1, mode='auto')\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath='1D(3).hdf5', \n",
        "                               verbose=1, save_best_only=True)\n",
        "start = datetime.now()\n",
        "\n",
        "\n",
        "modelc10.fit(X_train, y_train,\n",
        "          batch_size = 50, \n",
        "          epochs = 500,\n",
        "          validation_data = (X_val, y_val), \n",
        "          callbacks=[checkpointer, es])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQD0VIT_4vgz",
        "outputId": "b9b581cd-4ab6-4bd6-b9ed-5b0f3c50fff9"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "120/127 [===========================>..] - ETA: 0s - loss: 2.6159 - accuracy: 0.1253\n",
            "Epoch 00001: val_loss improved from inf to 2.44239, saving model to 1D(3).hdf5\n",
            "127/127 [==============================] - 1s 7ms/step - loss: 2.6071 - accuracy: 0.1279 - val_loss: 2.4424 - val_accuracy: 0.2457\n",
            "Epoch 2/500\n",
            "119/127 [===========================>..] - ETA: 0s - loss: 2.4690 - accuracy: 0.1503\n",
            "Epoch 00002: val_loss improved from 2.44239 to 2.30698, saving model to 1D(3).hdf5\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.4651 - accuracy: 0.1508 - val_loss: 2.3070 - val_accuracy: 0.2221\n",
            "Epoch 3/500\n",
            "119/127 [===========================>..] - ETA: 0s - loss: 2.4039 - accuracy: 0.1671\n",
            "Epoch 00003: val_loss improved from 2.30698 to 2.28142, saving model to 1D(3).hdf5\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.4020 - accuracy: 0.1670 - val_loss: 2.2814 - val_accuracy: 0.2335\n",
            "Epoch 4/500\n",
            "124/127 [============================>.] - ETA: 0s - loss: 2.3809 - accuracy: 0.1750\n",
            "Epoch 00004: val_loss improved from 2.28142 to 2.26486, saving model to 1D(3).hdf5\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.3795 - accuracy: 0.1741 - val_loss: 2.2649 - val_accuracy: 0.2316\n",
            "Epoch 5/500\n",
            "119/127 [===========================>..] - ETA: 0s - loss: 2.3504 - accuracy: 0.1807\n",
            "Epoch 00005: val_loss improved from 2.26486 to 2.22020, saving model to 1D(3).hdf5\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.3498 - accuracy: 0.1812 - val_loss: 2.2202 - val_accuracy: 0.2382\n",
            "Epoch 6/500\n",
            "123/127 [============================>.] - ETA: 0s - loss: 2.3153 - accuracy: 0.1880\n",
            "Epoch 00006: val_loss improved from 2.22020 to 2.19243, saving model to 1D(3).hdf5\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.3204 - accuracy: 0.1865 - val_loss: 2.1924 - val_accuracy: 0.2311\n",
            "Epoch 7/500\n",
            "119/127 [===========================>..] - ETA: 0s - loss: 2.3238 - accuracy: 0.1850\n",
            "Epoch 00007: val_loss improved from 2.19243 to 2.17629, saving model to 1D(3).hdf5\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.3234 - accuracy: 0.1837 - val_loss: 2.1763 - val_accuracy: 0.2439\n",
            "Epoch 8/500\n",
            "119/127 [===========================>..] - ETA: 0s - loss: 2.3003 - accuracy: 0.1938\n",
            "Epoch 00008: val_loss improved from 2.17629 to 2.16245, saving model to 1D(3).hdf5\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.2995 - accuracy: 0.1941 - val_loss: 2.1624 - val_accuracy: 0.2514\n",
            "Epoch 9/500\n",
            "122/127 [===========================>..] - ETA: 0s - loss: 2.2936 - accuracy: 0.2005\n",
            "Epoch 00009: val_loss improved from 2.16245 to 2.14534, saving model to 1D(3).hdf5\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.2952 - accuracy: 0.1996 - val_loss: 2.1453 - val_accuracy: 0.2661\n",
            "Epoch 10/500\n",
            "121/127 [===========================>..] - ETA: 0s - loss: 2.2936 - accuracy: 0.1952\n",
            "Epoch 00010: val_loss improved from 2.14534 to 2.13798, saving model to 1D(3).hdf5\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.2954 - accuracy: 0.1949 - val_loss: 2.1380 - val_accuracy: 0.2656\n",
            "Epoch 11/500\n",
            "120/127 [===========================>..] - ETA: 0s - loss: 2.2615 - accuracy: 0.2125\n",
            "Epoch 00011: val_loss improved from 2.13798 to 2.11988, saving model to 1D(3).hdf5\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.2635 - accuracy: 0.2105 - val_loss: 2.1199 - val_accuracy: 0.2708\n",
            "Epoch 12/500\n",
            "122/127 [===========================>..] - ETA: 0s - loss: 2.2665 - accuracy: 0.2103\n",
            "Epoch 00012: val_loss improved from 2.11988 to 2.11607, saving model to 1D(3).hdf5\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.2658 - accuracy: 0.2108 - val_loss: 2.1161 - val_accuracy: 0.3029\n",
            "Epoch 13/500\n",
            "124/127 [============================>.] - ETA: 0s - loss: 2.2708 - accuracy: 0.2047\n",
            "Epoch 00013: val_loss improved from 2.11607 to 2.09915, saving model to 1D(3).hdf5\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.2720 - accuracy: 0.2042 - val_loss: 2.0991 - val_accuracy: 0.2878\n",
            "Epoch 14/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 2.2452 - accuracy: 0.2235\n",
            "Epoch 00014: val_loss did not improve from 2.09915\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.2483 - accuracy: 0.2223 - val_loss: 2.1301 - val_accuracy: 0.2684\n",
            "Epoch 15/500\n",
            "122/127 [===========================>..] - ETA: 0s - loss: 2.2426 - accuracy: 0.2141\n",
            "Epoch 00015: val_loss improved from 2.09915 to 2.08753, saving model to 1D(3).hdf5\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.2419 - accuracy: 0.2144 - val_loss: 2.0875 - val_accuracy: 0.2821\n",
            "Epoch 16/500\n",
            "117/127 [==========================>...] - ETA: 0s - loss: 2.2306 - accuracy: 0.2181\n",
            "Epoch 00016: val_loss improved from 2.08753 to 2.07684, saving model to 1D(3).hdf5\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.2328 - accuracy: 0.2187 - val_loss: 2.0768 - val_accuracy: 0.2722\n",
            "Epoch 17/500\n",
            "120/127 [===========================>..] - ETA: 0s - loss: 2.2132 - accuracy: 0.2247\n",
            "Epoch 00017: val_loss improved from 2.07684 to 2.07451, saving model to 1D(3).hdf5\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.2109 - accuracy: 0.2250 - val_loss: 2.0745 - val_accuracy: 0.2774\n",
            "Epoch 18/500\n",
            "119/127 [===========================>..] - ETA: 0s - loss: 2.2116 - accuracy: 0.2297\n",
            "Epoch 00018: val_loss improved from 2.07451 to 2.05607, saving model to 1D(3).hdf5\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.2093 - accuracy: 0.2298 - val_loss: 2.0561 - val_accuracy: 0.2925\n",
            "Epoch 19/500\n",
            "122/127 [===========================>..] - ETA: 0s - loss: 2.2232 - accuracy: 0.2261\n",
            "Epoch 00019: val_loss did not improve from 2.05607\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.2248 - accuracy: 0.2272 - val_loss: 2.0637 - val_accuracy: 0.2963\n",
            "Epoch 20/500\n",
            "120/127 [===========================>..] - ETA: 0s - loss: 2.2117 - accuracy: 0.2250\n",
            "Epoch 00020: val_loss improved from 2.05607 to 2.04992, saving model to 1D(3).hdf5\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.2077 - accuracy: 0.2256 - val_loss: 2.0499 - val_accuracy: 0.2911\n",
            "Epoch 21/500\n",
            "120/127 [===========================>..] - ETA: 0s - loss: 2.1851 - accuracy: 0.2267\n",
            "Epoch 00021: val_loss improved from 2.04992 to 2.04910, saving model to 1D(3).hdf5\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.1861 - accuracy: 0.2270 - val_loss: 2.0491 - val_accuracy: 0.2888\n",
            "Epoch 22/500\n",
            "121/127 [===========================>..] - ETA: 0s - loss: 2.1991 - accuracy: 0.2337\n",
            "Epoch 00022: val_loss improved from 2.04910 to 2.04692, saving model to 1D(3).hdf5\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.2012 - accuracy: 0.2330 - val_loss: 2.0469 - val_accuracy: 0.3001\n",
            "Epoch 23/500\n",
            "122/127 [===========================>..] - ETA: 0s - loss: 2.1855 - accuracy: 0.2330\n",
            "Epoch 00023: val_loss improved from 2.04692 to 2.02359, saving model to 1D(3).hdf5\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.1839 - accuracy: 0.2319 - val_loss: 2.0236 - val_accuracy: 0.3133\n",
            "Epoch 24/500\n",
            "123/127 [============================>.] - ETA: 0s - loss: 2.1767 - accuracy: 0.2311\n",
            "Epoch 00024: val_loss improved from 2.02359 to 2.01331, saving model to 1D(3).hdf5\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.1756 - accuracy: 0.2324 - val_loss: 2.0133 - val_accuracy: 0.3086\n",
            "Epoch 25/500\n",
            "121/127 [===========================>..] - ETA: 0s - loss: 2.1847 - accuracy: 0.2372\n",
            "Epoch 00025: val_loss did not improve from 2.01331\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.1885 - accuracy: 0.2372 - val_loss: 2.0667 - val_accuracy: 0.2944\n",
            "Epoch 26/500\n",
            "119/127 [===========================>..] - ETA: 0s - loss: 2.1848 - accuracy: 0.2338\n",
            "Epoch 00026: val_loss did not improve from 2.01331\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.1866 - accuracy: 0.2331 - val_loss: 2.0269 - val_accuracy: 0.3086\n",
            "Epoch 27/500\n",
            "119/127 [===========================>..] - ETA: 0s - loss: 2.1758 - accuracy: 0.2388\n",
            "Epoch 00027: val_loss did not improve from 2.01331\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.1763 - accuracy: 0.2390 - val_loss: 2.0264 - val_accuracy: 0.2944\n",
            "Epoch 28/500\n",
            "120/127 [===========================>..] - ETA: 0s - loss: 2.1828 - accuracy: 0.2345\n",
            "Epoch 00028: val_loss did not improve from 2.01331\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.1826 - accuracy: 0.2346 - val_loss: 2.0281 - val_accuracy: 0.3048\n",
            "Epoch 29/500\n",
            "117/127 [==========================>...] - ETA: 0s - loss: 2.1652 - accuracy: 0.2434\n",
            "Epoch 00029: val_loss did not improve from 2.01331\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.1624 - accuracy: 0.2457 - val_loss: 2.0217 - val_accuracy: 0.3152\n",
            "Epoch 30/500\n",
            "124/127 [============================>.] - ETA: 0s - loss: 2.1769 - accuracy: 0.2408\n",
            "Epoch 00030: val_loss did not improve from 2.01331\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.1788 - accuracy: 0.2407 - val_loss: 2.0282 - val_accuracy: 0.3086\n",
            "Epoch 31/500\n",
            "123/127 [============================>.] - ETA: 0s - loss: 2.1733 - accuracy: 0.2311\n",
            "Epoch 00031: val_loss did not improve from 2.01331\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.1731 - accuracy: 0.2309 - val_loss: 2.0312 - val_accuracy: 0.2802\n",
            "Epoch 32/500\n",
            "123/127 [============================>.] - ETA: 0s - loss: 2.1707 - accuracy: 0.2333\n",
            "Epoch 00032: val_loss did not improve from 2.01331\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.1765 - accuracy: 0.2325 - val_loss: 2.0199 - val_accuracy: 0.2949\n",
            "Epoch 33/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 2.1800 - accuracy: 0.2366\n",
            "Epoch 00033: val_loss did not improve from 2.01331\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.1786 - accuracy: 0.2365 - val_loss: 2.0298 - val_accuracy: 0.2864\n",
            "Epoch 34/500\n",
            "123/127 [============================>.] - ETA: 0s - loss: 2.1639 - accuracy: 0.2384\n",
            "Epoch 00034: val_loss did not improve from 2.01331\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.1631 - accuracy: 0.2382 - val_loss: 2.0196 - val_accuracy: 0.3062\n",
            "Epoch 35/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 2.1757 - accuracy: 0.2376\n",
            "Epoch 00035: val_loss did not improve from 2.01331\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.1756 - accuracy: 0.2368 - val_loss: 2.0282 - val_accuracy: 0.2821\n",
            "Epoch 36/500\n",
            "122/127 [===========================>..] - ETA: 0s - loss: 2.1575 - accuracy: 0.2389\n",
            "Epoch 00036: val_loss did not improve from 2.01331\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.1613 - accuracy: 0.2376 - val_loss: 2.0393 - val_accuracy: 0.2836\n",
            "Epoch 37/500\n",
            "123/127 [============================>.] - ETA: 0s - loss: 2.1573 - accuracy: 0.2460\n",
            "Epoch 00037: val_loss improved from 2.01331 to 2.00293, saving model to 1D(3).hdf5\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.1560 - accuracy: 0.2472 - val_loss: 2.0029 - val_accuracy: 0.3062\n",
            "Epoch 38/500\n",
            "123/127 [============================>.] - ETA: 0s - loss: 2.1439 - accuracy: 0.2428\n",
            "Epoch 00038: val_loss improved from 2.00293 to 2.00279, saving model to 1D(3).hdf5\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.1429 - accuracy: 0.2437 - val_loss: 2.0028 - val_accuracy: 0.3001\n",
            "Epoch 39/500\n",
            "120/127 [===========================>..] - ETA: 0s - loss: 2.1593 - accuracy: 0.2398\n",
            "Epoch 00039: val_loss did not improve from 2.00279\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.1607 - accuracy: 0.2401 - val_loss: 2.0234 - val_accuracy: 0.2869\n",
            "Epoch 40/500\n",
            "120/127 [===========================>..] - ETA: 0s - loss: 2.1526 - accuracy: 0.2415\n",
            "Epoch 00040: val_loss did not improve from 2.00279\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.1577 - accuracy: 0.2418 - val_loss: 2.0216 - val_accuracy: 0.3110\n",
            "Epoch 41/500\n",
            "124/127 [============================>.] - ETA: 0s - loss: 2.1400 - accuracy: 0.2455\n",
            "Epoch 00041: val_loss improved from 2.00279 to 1.98533, saving model to 1D(3).hdf5\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.1411 - accuracy: 0.2448 - val_loss: 1.9853 - val_accuracy: 0.3138\n",
            "Epoch 42/500\n",
            "120/127 [===========================>..] - ETA: 0s - loss: 2.1585 - accuracy: 0.2380\n",
            "Epoch 00042: val_loss did not improve from 1.98533\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.1632 - accuracy: 0.2368 - val_loss: 2.0127 - val_accuracy: 0.3157\n",
            "Epoch 43/500\n",
            "123/127 [============================>.] - ETA: 0s - loss: 2.1530 - accuracy: 0.2506\n",
            "Epoch 00043: val_loss did not improve from 1.98533\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.1568 - accuracy: 0.2486 - val_loss: 1.9961 - val_accuracy: 0.2996\n",
            "Epoch 44/500\n",
            "120/127 [===========================>..] - ETA: 0s - loss: 2.1449 - accuracy: 0.2453\n",
            "Epoch 00044: val_loss did not improve from 1.98533\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.1508 - accuracy: 0.2445 - val_loss: 2.0062 - val_accuracy: 0.3001\n",
            "Epoch 45/500\n",
            "121/127 [===========================>..] - ETA: 0s - loss: 2.1453 - accuracy: 0.2390\n",
            "Epoch 00045: val_loss did not improve from 1.98533\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.1479 - accuracy: 0.2393 - val_loss: 2.0055 - val_accuracy: 0.3072\n",
            "Epoch 46/500\n",
            "115/127 [==========================>...] - ETA: 0s - loss: 2.1432 - accuracy: 0.2407\n",
            "Epoch 00046: val_loss did not improve from 1.98533\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.1411 - accuracy: 0.2424 - val_loss: 2.0127 - val_accuracy: 0.3129\n",
            "Epoch 47/500\n",
            "120/127 [===========================>..] - ETA: 0s - loss: 2.1499 - accuracy: 0.2480\n",
            "Epoch 00047: val_loss did not improve from 1.98533\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.1464 - accuracy: 0.2486 - val_loss: 2.0193 - val_accuracy: 0.2873\n",
            "Epoch 48/500\n",
            "120/127 [===========================>..] - ETA: 0s - loss: 2.1481 - accuracy: 0.2445\n",
            "Epoch 00048: val_loss did not improve from 1.98533\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.1487 - accuracy: 0.2442 - val_loss: 2.0058 - val_accuracy: 0.2977\n",
            "Epoch 49/500\n",
            "121/127 [===========================>..] - ETA: 0s - loss: 2.1415 - accuracy: 0.2504\n",
            "Epoch 00049: val_loss did not improve from 1.98533\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.1403 - accuracy: 0.2514 - val_loss: 2.0132 - val_accuracy: 0.3228\n",
            "Epoch 50/500\n",
            "123/127 [============================>.] - ETA: 0s - loss: 2.1347 - accuracy: 0.2395\n",
            "Epoch 00050: val_loss did not improve from 1.98533\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.1368 - accuracy: 0.2387 - val_loss: 1.9934 - val_accuracy: 0.3072\n",
            "Epoch 51/500\n",
            "119/127 [===========================>..] - ETA: 0s - loss: 2.1404 - accuracy: 0.2494\n",
            "Epoch 00051: val_loss did not improve from 1.98533\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.1398 - accuracy: 0.2480 - val_loss: 2.0083 - val_accuracy: 0.3247\n",
            "Epoch 52/500\n",
            "117/127 [==========================>...] - ETA: 0s - loss: 2.1431 - accuracy: 0.2407\n",
            "Epoch 00052: val_loss did not improve from 1.98533\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.1423 - accuracy: 0.2415 - val_loss: 2.0018 - val_accuracy: 0.2963\n",
            "Epoch 53/500\n",
            "119/127 [===========================>..] - ETA: 0s - loss: 2.1429 - accuracy: 0.2442\n",
            "Epoch 00053: val_loss did not improve from 1.98533\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.1438 - accuracy: 0.2429 - val_loss: 2.0049 - val_accuracy: 0.2935\n",
            "Epoch 54/500\n",
            "118/127 [==========================>...] - ETA: 0s - loss: 2.1427 - accuracy: 0.2402\n",
            "Epoch 00054: val_loss did not improve from 1.98533\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.1396 - accuracy: 0.2404 - val_loss: 2.0048 - val_accuracy: 0.3110\n",
            "Epoch 55/500\n",
            "121/127 [===========================>..] - ETA: 0s - loss: 2.1375 - accuracy: 0.2476\n",
            "Epoch 00055: val_loss did not improve from 1.98533\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.1380 - accuracy: 0.2459 - val_loss: 1.9945 - val_accuracy: 0.3062\n",
            "Epoch 56/500\n",
            "122/127 [===========================>..] - ETA: 0s - loss: 2.1359 - accuracy: 0.2420\n",
            "Epoch 00056: val_loss did not improve from 1.98533\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.1370 - accuracy: 0.2429 - val_loss: 2.0056 - val_accuracy: 0.3001\n",
            "Epoch 57/500\n",
            "121/127 [===========================>..] - ETA: 0s - loss: 2.1356 - accuracy: 0.2395\n",
            "Epoch 00057: val_loss did not improve from 1.98533\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.1393 - accuracy: 0.2374 - val_loss: 2.0198 - val_accuracy: 0.2845\n",
            "Epoch 58/500\n",
            "122/127 [===========================>..] - ETA: 0s - loss: 2.1320 - accuracy: 0.2520\n",
            "Epoch 00058: val_loss did not improve from 1.98533\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.1320 - accuracy: 0.2513 - val_loss: 1.9918 - val_accuracy: 0.3105\n",
            "Epoch 59/500\n",
            "123/127 [============================>.] - ETA: 0s - loss: 2.1248 - accuracy: 0.2462\n",
            "Epoch 00059: val_loss did not improve from 1.98533\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.1270 - accuracy: 0.2457 - val_loss: 1.9898 - val_accuracy: 0.2996\n",
            "Epoch 60/500\n",
            "118/127 [==========================>...] - ETA: 0s - loss: 2.1426 - accuracy: 0.2412\n",
            "Epoch 00060: val_loss did not improve from 1.98533\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.1455 - accuracy: 0.2402 - val_loss: 1.9940 - val_accuracy: 0.3256\n",
            "Epoch 61/500\n",
            "119/127 [===========================>..] - ETA: 0s - loss: 2.1208 - accuracy: 0.2434\n",
            "Epoch 00061: val_loss did not improve from 1.98533\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.1219 - accuracy: 0.2428 - val_loss: 1.9906 - val_accuracy: 0.2859\n",
            "Epoch 62/500\n",
            "120/127 [===========================>..] - ETA: 0s - loss: 2.1263 - accuracy: 0.2503\n",
            "Epoch 00062: val_loss did not improve from 1.98533\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.1306 - accuracy: 0.2498 - val_loss: 2.0023 - val_accuracy: 0.3209\n",
            "Epoch 63/500\n",
            "120/127 [===========================>..] - ETA: 0s - loss: 2.1413 - accuracy: 0.2365\n",
            "Epoch 00063: val_loss did not improve from 1.98533\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.1409 - accuracy: 0.2361 - val_loss: 2.0017 - val_accuracy: 0.3351\n",
            "Epoch 64/500\n",
            "126/127 [============================>.] - ETA: 0s - loss: 2.1305 - accuracy: 0.2465\n",
            "Epoch 00064: val_loss did not improve from 1.98533\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.1304 - accuracy: 0.2468 - val_loss: 1.9914 - val_accuracy: 0.3228\n",
            "Epoch 65/500\n",
            "120/127 [===========================>..] - ETA: 0s - loss: 2.1272 - accuracy: 0.2455\n",
            "Epoch 00065: val_loss improved from 1.98533 to 1.97921, saving model to 1D(3).hdf5\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.1265 - accuracy: 0.2465 - val_loss: 1.9792 - val_accuracy: 0.2873\n",
            "Epoch 66/500\n",
            "119/127 [===========================>..] - ETA: 0s - loss: 2.1183 - accuracy: 0.2407\n",
            "Epoch 00066: val_loss improved from 1.97921 to 1.97722, saving model to 1D(3).hdf5\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.1206 - accuracy: 0.2401 - val_loss: 1.9772 - val_accuracy: 0.3143\n",
            "Epoch 67/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 2.1269 - accuracy: 0.2487\n",
            "Epoch 00067: val_loss did not improve from 1.97722\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.1269 - accuracy: 0.2487 - val_loss: 1.9952 - val_accuracy: 0.2930\n",
            "Epoch 68/500\n",
            "118/127 [==========================>...] - ETA: 0s - loss: 2.1353 - accuracy: 0.2366\n",
            "Epoch 00068: val_loss did not improve from 1.97722\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.1331 - accuracy: 0.2376 - val_loss: 1.9776 - val_accuracy: 0.3062\n",
            "Epoch 69/500\n",
            "121/127 [===========================>..] - ETA: 0s - loss: 2.1197 - accuracy: 0.2481\n",
            "Epoch 00069: val_loss did not improve from 1.97722\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.1170 - accuracy: 0.2495 - val_loss: 1.9870 - val_accuracy: 0.2968\n",
            "Epoch 70/500\n",
            "118/127 [==========================>...] - ETA: 0s - loss: 2.1216 - accuracy: 0.2442\n",
            "Epoch 00070: val_loss did not improve from 1.97722\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.1219 - accuracy: 0.2448 - val_loss: 1.9973 - val_accuracy: 0.3294\n",
            "Epoch 71/500\n",
            "120/127 [===========================>..] - ETA: 0s - loss: 2.1248 - accuracy: 0.2423\n",
            "Epoch 00071: val_loss did not improve from 1.97722\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.1251 - accuracy: 0.2421 - val_loss: 1.9946 - val_accuracy: 0.3001\n",
            "Epoch 72/500\n",
            "116/127 [==========================>...] - ETA: 0s - loss: 2.1258 - accuracy: 0.2405\n",
            "Epoch 00072: val_loss did not improve from 1.97722\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.1195 - accuracy: 0.2393 - val_loss: 1.9948 - val_accuracy: 0.3034\n",
            "Epoch 73/500\n",
            "120/127 [===========================>..] - ETA: 0s - loss: 2.1322 - accuracy: 0.2387\n",
            "Epoch 00073: val_loss did not improve from 1.97722\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.1281 - accuracy: 0.2374 - val_loss: 1.9808 - val_accuracy: 0.3162\n",
            "Epoch 74/500\n",
            "121/127 [===========================>..] - ETA: 0s - loss: 2.1261 - accuracy: 0.2491\n",
            "Epoch 00074: val_loss improved from 1.97722 to 1.97572, saving model to 1D(3).hdf5\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.1258 - accuracy: 0.2480 - val_loss: 1.9757 - val_accuracy: 0.3110\n",
            "Epoch 75/500\n",
            "123/127 [============================>.] - ETA: 0s - loss: 2.1234 - accuracy: 0.2501\n",
            "Epoch 00075: val_loss did not improve from 1.97572\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.1252 - accuracy: 0.2489 - val_loss: 1.9832 - val_accuracy: 0.3067\n",
            "Epoch 76/500\n",
            "124/127 [============================>.] - ETA: 0s - loss: 2.1175 - accuracy: 0.2523\n",
            "Epoch 00076: val_loss improved from 1.97572 to 1.96927, saving model to 1D(3).hdf5\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.1191 - accuracy: 0.2516 - val_loss: 1.9693 - val_accuracy: 0.2991\n",
            "Epoch 77/500\n",
            "119/127 [===========================>..] - ETA: 0s - loss: 2.1152 - accuracy: 0.2461\n",
            "Epoch 00077: val_loss did not improve from 1.96927\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.1143 - accuracy: 0.2453 - val_loss: 1.9909 - val_accuracy: 0.2892\n",
            "Epoch 78/500\n",
            "123/127 [============================>.] - ETA: 0s - loss: 2.1112 - accuracy: 0.2442\n",
            "Epoch 00078: val_loss did not improve from 1.96927\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.1093 - accuracy: 0.2440 - val_loss: 1.9700 - val_accuracy: 0.3095\n",
            "Epoch 79/500\n",
            "120/127 [===========================>..] - ETA: 0s - loss: 2.1296 - accuracy: 0.2457\n",
            "Epoch 00079: val_loss did not improve from 1.96927\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.1275 - accuracy: 0.2467 - val_loss: 1.9970 - val_accuracy: 0.2798\n",
            "Epoch 80/500\n",
            "120/127 [===========================>..] - ETA: 0s - loss: 2.1231 - accuracy: 0.2490\n",
            "Epoch 00080: val_loss did not improve from 1.96927\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.1254 - accuracy: 0.2478 - val_loss: 1.9977 - val_accuracy: 0.2925\n",
            "Epoch 81/500\n",
            "119/127 [===========================>..] - ETA: 0s - loss: 2.0989 - accuracy: 0.2575\n",
            "Epoch 00081: val_loss did not improve from 1.96927\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.0998 - accuracy: 0.2552 - val_loss: 1.9761 - val_accuracy: 0.2878\n",
            "Epoch 82/500\n",
            "123/127 [============================>.] - ETA: 0s - loss: 2.1108 - accuracy: 0.2460\n",
            "Epoch 00082: val_loss did not improve from 1.96927\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.1122 - accuracy: 0.2456 - val_loss: 1.9846 - val_accuracy: 0.2996\n",
            "Epoch 83/500\n",
            "122/127 [===========================>..] - ETA: 0s - loss: 2.1163 - accuracy: 0.2492\n",
            "Epoch 00083: val_loss did not improve from 1.96927\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.1098 - accuracy: 0.2503 - val_loss: 1.9695 - val_accuracy: 0.2991\n",
            "Epoch 84/500\n",
            "119/127 [===========================>..] - ETA: 0s - loss: 2.1119 - accuracy: 0.2461\n",
            "Epoch 00084: val_loss improved from 1.96927 to 1.96614, saving model to 1D(3).hdf5\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.1156 - accuracy: 0.2462 - val_loss: 1.9661 - val_accuracy: 0.3053\n",
            "Epoch 85/500\n",
            "119/127 [===========================>..] - ETA: 0s - loss: 2.1106 - accuracy: 0.2497\n",
            "Epoch 00085: val_loss did not improve from 1.96614\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.1082 - accuracy: 0.2495 - val_loss: 1.9816 - val_accuracy: 0.3010\n",
            "Epoch 86/500\n",
            "118/127 [==========================>...] - ETA: 0s - loss: 2.1087 - accuracy: 0.2461\n",
            "Epoch 00086: val_loss did not improve from 1.96614\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.1060 - accuracy: 0.2480 - val_loss: 1.9834 - val_accuracy: 0.2906\n",
            "Epoch 87/500\n",
            "119/127 [===========================>..] - ETA: 0s - loss: 2.1146 - accuracy: 0.2496\n",
            "Epoch 00087: val_loss did not improve from 1.96614\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.1220 - accuracy: 0.2489 - val_loss: 2.0013 - val_accuracy: 0.2925\n",
            "Epoch 88/500\n",
            "120/127 [===========================>..] - ETA: 0s - loss: 2.1227 - accuracy: 0.2502\n",
            "Epoch 00088: val_loss did not improve from 1.96614\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.1219 - accuracy: 0.2508 - val_loss: 1.9753 - val_accuracy: 0.3119\n",
            "Epoch 89/500\n",
            "117/127 [==========================>...] - ETA: 0s - loss: 2.1060 - accuracy: 0.2540\n",
            "Epoch 00089: val_loss did not improve from 1.96614\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.1069 - accuracy: 0.2549 - val_loss: 1.9794 - val_accuracy: 0.3067\n",
            "Epoch 90/500\n",
            "119/127 [===========================>..] - ETA: 0s - loss: 2.1029 - accuracy: 0.2405\n",
            "Epoch 00090: val_loss did not improve from 1.96614\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.0988 - accuracy: 0.2418 - val_loss: 1.9747 - val_accuracy: 0.3053\n",
            "Epoch 91/500\n",
            "122/127 [===========================>..] - ETA: 0s - loss: 2.1096 - accuracy: 0.2449\n",
            "Epoch 00091: val_loss did not improve from 1.96614\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.1076 - accuracy: 0.2443 - val_loss: 1.9854 - val_accuracy: 0.2850\n",
            "Epoch 92/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 2.1137 - accuracy: 0.2467\n",
            "Epoch 00092: val_loss did not improve from 1.96614\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.1137 - accuracy: 0.2467 - val_loss: 1.9883 - val_accuracy: 0.3199\n",
            "Epoch 93/500\n",
            "118/127 [==========================>...] - ETA: 0s - loss: 2.1062 - accuracy: 0.2547\n",
            "Epoch 00093: val_loss did not improve from 1.96614\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.1073 - accuracy: 0.2560 - val_loss: 1.9987 - val_accuracy: 0.3020\n",
            "Epoch 94/500\n",
            "117/127 [==========================>...] - ETA: 0s - loss: 2.1097 - accuracy: 0.2460\n",
            "Epoch 00094: val_loss did not improve from 1.96614\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.1080 - accuracy: 0.2489 - val_loss: 1.9788 - val_accuracy: 0.3152\n",
            "Epoch 95/500\n",
            "117/127 [==========================>...] - ETA: 0s - loss: 2.1158 - accuracy: 0.2448\n",
            "Epoch 00095: val_loss did not improve from 1.96614\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.1122 - accuracy: 0.2465 - val_loss: 1.9854 - val_accuracy: 0.2991\n",
            "Epoch 96/500\n",
            "120/127 [===========================>..] - ETA: 0s - loss: 2.1058 - accuracy: 0.2442\n",
            "Epoch 00096: val_loss did not improve from 1.96614\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.1047 - accuracy: 0.2437 - val_loss: 1.9731 - val_accuracy: 0.3006\n",
            "Epoch 97/500\n",
            "119/127 [===========================>..] - ETA: 0s - loss: 2.1009 - accuracy: 0.2447\n",
            "Epoch 00097: val_loss did not improve from 1.96614\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.1048 - accuracy: 0.2434 - val_loss: 1.9859 - val_accuracy: 0.2930\n",
            "Epoch 98/500\n",
            "118/127 [==========================>...] - ETA: 0s - loss: 2.1054 - accuracy: 0.2436\n",
            "Epoch 00098: val_loss did not improve from 1.96614\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.1033 - accuracy: 0.2454 - val_loss: 1.9818 - val_accuracy: 0.3110\n",
            "Epoch 99/500\n",
            "121/127 [===========================>..] - ETA: 0s - loss: 2.1069 - accuracy: 0.2554\n",
            "Epoch 00099: val_loss did not improve from 1.96614\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.1032 - accuracy: 0.2541 - val_loss: 1.9718 - val_accuracy: 0.3001\n",
            "Epoch 100/500\n",
            "118/127 [==========================>...] - ETA: 0s - loss: 2.0986 - accuracy: 0.2486\n",
            "Epoch 00100: val_loss did not improve from 1.96614\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.0996 - accuracy: 0.2473 - val_loss: 1.9869 - val_accuracy: 0.3100\n",
            "Epoch 101/500\n",
            "124/127 [============================>.] - ETA: 0s - loss: 2.0951 - accuracy: 0.2510\n",
            "Epoch 00101: val_loss did not improve from 1.96614\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.0962 - accuracy: 0.2506 - val_loss: 1.9790 - val_accuracy: 0.3001\n",
            "Epoch 102/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 2.1141 - accuracy: 0.2472\n",
            "Epoch 00102: val_loss did not improve from 1.96614\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.1141 - accuracy: 0.2472 - val_loss: 1.9726 - val_accuracy: 0.3114\n",
            "Epoch 103/500\n",
            "117/127 [==========================>...] - ETA: 0s - loss: 2.1017 - accuracy: 0.2533\n",
            "Epoch 00103: val_loss did not improve from 1.96614\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.1010 - accuracy: 0.2519 - val_loss: 1.9715 - val_accuracy: 0.3086\n",
            "Epoch 104/500\n",
            "122/127 [===========================>..] - ETA: 0s - loss: 2.0989 - accuracy: 0.2410\n",
            "Epoch 00104: val_loss did not improve from 1.96614\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.1008 - accuracy: 0.2412 - val_loss: 1.9891 - val_accuracy: 0.3143\n",
            "Epoch 105/500\n",
            "120/127 [===========================>..] - ETA: 0s - loss: 2.0960 - accuracy: 0.2518\n",
            "Epoch 00105: val_loss did not improve from 1.96614\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.0982 - accuracy: 0.2491 - val_loss: 1.9814 - val_accuracy: 0.3010\n",
            "Epoch 106/500\n",
            "118/127 [==========================>...] - ETA: 0s - loss: 2.0980 - accuracy: 0.2581\n",
            "Epoch 00106: val_loss did not improve from 1.96614\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.0975 - accuracy: 0.2588 - val_loss: 1.9732 - val_accuracy: 0.3001\n",
            "Epoch 107/500\n",
            "118/127 [==========================>...] - ETA: 0s - loss: 2.0927 - accuracy: 0.2420\n",
            "Epoch 00107: val_loss did not improve from 1.96614\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.0956 - accuracy: 0.2402 - val_loss: 1.9789 - val_accuracy: 0.2921\n",
            "Epoch 108/500\n",
            "121/127 [===========================>..] - ETA: 0s - loss: 2.0821 - accuracy: 0.2559\n",
            "Epoch 00108: val_loss improved from 1.96614 to 1.96520, saving model to 1D(3).hdf5\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.0895 - accuracy: 0.2532 - val_loss: 1.9652 - val_accuracy: 0.2958\n",
            "Epoch 109/500\n",
            "118/127 [==========================>...] - ETA: 0s - loss: 2.1022 - accuracy: 0.2444\n",
            "Epoch 00109: val_loss did not improve from 1.96520\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.1022 - accuracy: 0.2461 - val_loss: 1.9806 - val_accuracy: 0.2963\n",
            "Epoch 110/500\n",
            "120/127 [===========================>..] - ETA: 0s - loss: 2.0949 - accuracy: 0.2447\n",
            "Epoch 00110: val_loss did not improve from 1.96520\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.0915 - accuracy: 0.2465 - val_loss: 1.9823 - val_accuracy: 0.2736\n",
            "Epoch 111/500\n",
            "119/127 [===========================>..] - ETA: 0s - loss: 2.0901 - accuracy: 0.2506\n",
            "Epoch 00111: val_loss did not improve from 1.96520\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.0862 - accuracy: 0.2511 - val_loss: 1.9675 - val_accuracy: 0.3100\n",
            "Epoch 112/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 2.1111 - accuracy: 0.2409\n",
            "Epoch 00112: val_loss did not improve from 1.96520\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.1111 - accuracy: 0.2409 - val_loss: 1.9888 - val_accuracy: 0.3006\n",
            "Epoch 113/500\n",
            "121/127 [===========================>..] - ETA: 0s - loss: 2.0913 - accuracy: 0.2493\n",
            "Epoch 00113: val_loss improved from 1.96520 to 1.95856, saving model to 1D(3).hdf5\n",
            "127/127 [==============================] - 1s 5ms/step - loss: 2.0923 - accuracy: 0.2487 - val_loss: 1.9586 - val_accuracy: 0.3166\n",
            "Epoch 00113: early stopping\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f442b159ad0>"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN2D"
      ],
      "metadata": {
        "id": "sCGtS6HaF-S1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Experment (1)"
      ],
      "metadata": {
        "id": "nNiqTy5gEpOV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lY7o0NSt0_d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "outputId": "4236a292-3c9e-4731-91fe-7c439e1ea8ca"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-18c4bc6eea7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodelc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodelc1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Sequential' is not defined"
          ]
        }
      ],
      "source": [
        "modelc1 = Sequential()\n",
        "\n",
        "input_shape=X_train2.shape[1:]\n",
        "\n",
        "modelc1.add(Conv2D(64, (10, 10), input_shape=input_shape,activation='relu', padding='same'))\n",
        "modelc1.add(Conv2D(64, (10, 10), activation='relu', padding='same'))\n",
        "modelc1.add(BatchNormalization())\n",
        "modelc1.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "modelc1.add(Conv2D(128, (5, 5),activation='relu',padding='same'))\n",
        "modelc1.add(Conv2D(128, (5, 5),activation='relu',padding='same'))\n",
        "modelc1.add(BatchNormalization())\n",
        "modelc1.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "modelc1.add(Flatten())\n",
        "\n",
        "modelc1.add(Dense(200))\n",
        "modelc1.add(Activation('relu'))\n",
        "modelc1.add(BatchNormalization())\n",
        "modelc1.add(Dropout(0.5))\n",
        "\n",
        "\n",
        "modelc1.add(Dense(100))\n",
        "modelc1.add(Activation('relu'))\n",
        "modelc1.add(BatchNormalization())\n",
        "modelc1.add(Dropout(0.5))\n",
        "\n",
        "\n",
        "modelc1.add(Dense(50))\n",
        "modelc1.add(BatchNormalization())\n",
        "modelc1.add(Activation('relu'))\n",
        "modelc1.add(Dropout(0.3))\n",
        "\n",
        "\n",
        "modelc1.add(Dense(units = num_labels, activation=\"softmax\"))\n",
        "\n",
        "modelc1.summary()\n",
        "\n",
        "modelc1.compile(loss = 'categorical_crossentropy', \n",
        "              metrics = ['accuracy'],\n",
        "              optimizer = 'adam')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZUjinUBendt",
        "outputId": "cf5b46c2-36a8-42ea-f564-78a7dcfeae0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "127/127 [==============================] - ETA: 0s - loss: 2.6386 - accuracy: 0.1681\n",
            "Epoch 00001: val_loss improved from inf to 2.64355, saving model to new2(1-1).hdf5\n",
            "127/127 [==============================] - 25s 108ms/step - loss: 2.6386 - accuracy: 0.1681 - val_loss: 2.6436 - val_accuracy: 0.1399\n",
            "Epoch 2/200\n",
            "127/127 [==============================] - ETA: 0s - loss: 2.1560 - accuracy: 0.2804\n",
            "Epoch 00002: val_loss improved from 2.64355 to 2.60841, saving model to new2(1-1).hdf5\n",
            "127/127 [==============================] - 12s 93ms/step - loss: 2.1560 - accuracy: 0.2804 - val_loss: 2.6084 - val_accuracy: 0.1957\n",
            "Epoch 3/200\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.9475 - accuracy: 0.3503\n",
            "Epoch 00003: val_loss did not improve from 2.60841\n",
            "127/127 [==============================] - 11s 90ms/step - loss: 1.9475 - accuracy: 0.3503 - val_loss: 2.7206 - val_accuracy: 0.2164\n",
            "Epoch 4/200\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.7375 - accuracy: 0.4220\n",
            "Epoch 00004: val_loss improved from 2.60841 to 1.65634, saving model to new2(1-1).hdf5\n",
            "127/127 [==============================] - 12s 93ms/step - loss: 1.7375 - accuracy: 0.4220 - val_loss: 1.6563 - val_accuracy: 0.4277\n",
            "Epoch 5/200\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.5649 - accuracy: 0.4891\n",
            "Epoch 00005: val_loss improved from 1.65634 to 1.38617, saving model to new2(1-1).hdf5\n",
            "127/127 [==============================] - 12s 93ms/step - loss: 1.5649 - accuracy: 0.4891 - val_loss: 1.3862 - val_accuracy: 0.5383\n",
            "Epoch 6/200\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.4318 - accuracy: 0.5343\n",
            "Epoch 00006: val_loss did not improve from 1.38617\n",
            "127/127 [==============================] - 11s 90ms/step - loss: 1.4318 - accuracy: 0.5343 - val_loss: 1.4917 - val_accuracy: 0.5009\n",
            "Epoch 7/200\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.3904 - accuracy: 0.5539\n",
            "Epoch 00007: val_loss did not improve from 1.38617\n",
            "127/127 [==============================] - 11s 90ms/step - loss: 1.3904 - accuracy: 0.5539 - val_loss: 1.4518 - val_accuracy: 0.5288\n",
            "Epoch 8/200\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.2693 - accuracy: 0.5947\n",
            "Epoch 00008: val_loss improved from 1.38617 to 1.16348, saving model to new2(1-1).hdf5\n",
            "127/127 [==============================] - 12s 93ms/step - loss: 1.2693 - accuracy: 0.5947 - val_loss: 1.1635 - val_accuracy: 0.6196\n",
            "Epoch 9/200\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.1511 - accuracy: 0.6378\n",
            "Epoch 00009: val_loss did not improve from 1.16348\n",
            "127/127 [==============================] - 11s 90ms/step - loss: 1.1511 - accuracy: 0.6378 - val_loss: 1.1857 - val_accuracy: 0.6285\n",
            "Epoch 10/200\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.1889 - accuracy: 0.6243\n",
            "Epoch 00010: val_loss did not improve from 1.16348\n",
            "127/127 [==============================] - 11s 90ms/step - loss: 1.1889 - accuracy: 0.6243 - val_loss: 2.4049 - val_accuracy: 0.4400\n",
            "Epoch 11/200\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.0410 - accuracy: 0.6736\n",
            "Epoch 00011: val_loss improved from 1.16348 to 1.00910, saving model to new2(1-1).hdf5\n",
            "127/127 [==============================] - 12s 93ms/step - loss: 1.0410 - accuracy: 0.6736 - val_loss: 1.0091 - val_accuracy: 0.6687\n",
            "Epoch 12/200\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.9555 - accuracy: 0.6972\n",
            "Epoch 00012: val_loss did not improve from 1.00910\n",
            "127/127 [==============================] - 11s 90ms/step - loss: 0.9555 - accuracy: 0.6972 - val_loss: 1.3599 - val_accuracy: 0.5922\n",
            "Epoch 13/200\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.8509 - accuracy: 0.7290\n",
            "Epoch 00013: val_loss improved from 1.00910 to 0.87195, saving model to new2(1-1).hdf5\n",
            "127/127 [==============================] - 12s 93ms/step - loss: 0.8509 - accuracy: 0.7290 - val_loss: 0.8720 - val_accuracy: 0.7216\n",
            "Epoch 14/200\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.7633 - accuracy: 0.7497\n",
            "Epoch 00014: val_loss improved from 0.87195 to 0.83402, saving model to new2(1-1).hdf5\n",
            "127/127 [==============================] - 12s 93ms/step - loss: 0.7633 - accuracy: 0.7497 - val_loss: 0.8340 - val_accuracy: 0.7226\n",
            "Epoch 15/200\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.7031 - accuracy: 0.7698\n",
            "Epoch 00015: val_loss did not improve from 0.83402\n",
            "127/127 [==============================] - 11s 90ms/step - loss: 0.7031 - accuracy: 0.7698 - val_loss: 0.8541 - val_accuracy: 0.7136\n",
            "Epoch 16/200\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.6605 - accuracy: 0.7809\n",
            "Epoch 00016: val_loss improved from 0.83402 to 0.79587, saving model to new2(1-1).hdf5\n",
            "127/127 [==============================] - 12s 93ms/step - loss: 0.6605 - accuracy: 0.7809 - val_loss: 0.7959 - val_accuracy: 0.7283\n",
            "Epoch 17/200\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.6153 - accuracy: 0.7919\n",
            "Epoch 00017: val_loss did not improve from 0.79587\n",
            "127/127 [==============================] - 11s 90ms/step - loss: 0.6153 - accuracy: 0.7919 - val_loss: 0.8030 - val_accuracy: 0.7292\n",
            "Epoch 18/200\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.5904 - accuracy: 0.8025\n",
            "Epoch 00018: val_loss improved from 0.79587 to 0.77986, saving model to new2(1-1).hdf5\n",
            "127/127 [==============================] - 12s 93ms/step - loss: 0.5904 - accuracy: 0.8025 - val_loss: 0.7799 - val_accuracy: 0.7387\n",
            "Epoch 19/200\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.5579 - accuracy: 0.8114\n",
            "Epoch 00019: val_loss did not improve from 0.77986\n",
            "127/127 [==============================] - 11s 90ms/step - loss: 0.5579 - accuracy: 0.8114 - val_loss: 0.8806 - val_accuracy: 0.7198\n",
            "Epoch 20/200\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.5451 - accuracy: 0.8114\n",
            "Epoch 00020: val_loss did not improve from 0.77986\n",
            "127/127 [==============================] - 11s 90ms/step - loss: 0.5451 - accuracy: 0.8114 - val_loss: 0.8083 - val_accuracy: 0.7486\n",
            "Epoch 21/200\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.5003 - accuracy: 0.8231\n",
            "Epoch 00021: val_loss did not improve from 0.77986\n",
            "127/127 [==============================] - 11s 90ms/step - loss: 0.5003 - accuracy: 0.8231 - val_loss: 0.8379 - val_accuracy: 0.7306\n",
            "Epoch 22/200\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.5333 - accuracy: 0.8182\n",
            "Epoch 00022: val_loss did not improve from 0.77986\n",
            "127/127 [==============================] - 11s 90ms/step - loss: 0.5333 - accuracy: 0.8182 - val_loss: 0.8112 - val_accuracy: 0.7439\n",
            "Epoch 23/200\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.4958 - accuracy: 0.8288\n",
            "Epoch 00023: val_loss did not improve from 0.77986\n",
            "127/127 [==============================] - 11s 90ms/step - loss: 0.4958 - accuracy: 0.8288 - val_loss: 0.8967 - val_accuracy: 0.7264\n",
            "Epoch 24/200\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.4770 - accuracy: 0.8289\n",
            "Epoch 00024: val_loss did not improve from 0.77986\n",
            "127/127 [==============================] - 11s 90ms/step - loss: 0.4770 - accuracy: 0.8289 - val_loss: 0.8752 - val_accuracy: 0.7160\n",
            "Epoch 25/200\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.4448 - accuracy: 0.8428\n",
            "Epoch 00025: val_loss did not improve from 0.77986\n",
            "127/127 [==============================] - 11s 90ms/step - loss: 0.4448 - accuracy: 0.8428 - val_loss: 0.7905 - val_accuracy: 0.7476\n",
            "Epoch 26/200\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.4288 - accuracy: 0.8450\n",
            "Epoch 00026: val_loss did not improve from 0.77986\n",
            "127/127 [==============================] - 11s 90ms/step - loss: 0.4288 - accuracy: 0.8450 - val_loss: 0.8197 - val_accuracy: 0.7543\n",
            "Epoch 27/200\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.4221 - accuracy: 0.8467\n",
            "Epoch 00027: val_loss did not improve from 0.77986\n",
            "127/127 [==============================] - 11s 90ms/step - loss: 0.4221 - accuracy: 0.8467 - val_loss: 0.8534 - val_accuracy: 0.7462\n",
            "Epoch 28/200\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.4190 - accuracy: 0.8485\n",
            "Epoch 00028: val_loss did not improve from 0.77986\n",
            "127/127 [==============================] - 11s 90ms/step - loss: 0.4190 - accuracy: 0.8485 - val_loss: 0.8927 - val_accuracy: 0.7387\n",
            "Epoch 29/200\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.4115 - accuracy: 0.8519\n",
            "Epoch 00029: val_loss did not improve from 0.77986\n",
            "127/127 [==============================] - 11s 90ms/step - loss: 0.4115 - accuracy: 0.8519 - val_loss: 0.8034 - val_accuracy: 0.7547\n",
            "Epoch 30/200\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.4018 - accuracy: 0.8540\n",
            "Epoch 00030: val_loss did not improve from 0.77986\n",
            "127/127 [==============================] - 11s 90ms/step - loss: 0.4018 - accuracy: 0.8540 - val_loss: 0.8308 - val_accuracy: 0.7538\n",
            "Epoch 31/200\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.4216 - accuracy: 0.8494\n",
            "Epoch 00031: val_loss did not improve from 0.77986\n",
            "127/127 [==============================] - 11s 90ms/step - loss: 0.4216 - accuracy: 0.8494 - val_loss: 0.8691 - val_accuracy: 0.7396\n",
            "Epoch 32/200\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.4396 - accuracy: 0.8418\n",
            "Epoch 00032: val_loss did not improve from 0.77986\n",
            "127/127 [==============================] - 11s 90ms/step - loss: 0.4396 - accuracy: 0.8418 - val_loss: 0.9213 - val_accuracy: 0.7387\n",
            "Epoch 33/200\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.4173 - accuracy: 0.8505\n",
            "Epoch 00033: val_loss did not improve from 0.77986\n",
            "127/127 [==============================] - 11s 90ms/step - loss: 0.4173 - accuracy: 0.8505 - val_loss: 0.9317 - val_accuracy: 0.7391\n",
            "Epoch 34/200\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.3949 - accuracy: 0.8573\n",
            "Epoch 00034: val_loss did not improve from 0.77986\n",
            "127/127 [==============================] - 11s 90ms/step - loss: 0.3949 - accuracy: 0.8573 - val_loss: 0.8872 - val_accuracy: 0.7472\n",
            "Epoch 35/200\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.3867 - accuracy: 0.8595\n",
            "Epoch 00035: val_loss did not improve from 0.77986\n",
            "127/127 [==============================] - 11s 90ms/step - loss: 0.3867 - accuracy: 0.8595 - val_loss: 0.8818 - val_accuracy: 0.7481\n",
            "Epoch 36/200\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.3861 - accuracy: 0.8612\n",
            "Epoch 00036: val_loss did not improve from 0.77986\n",
            "127/127 [==============================] - 11s 90ms/step - loss: 0.3861 - accuracy: 0.8612 - val_loss: 0.8477 - val_accuracy: 0.7585\n",
            "Epoch 37/200\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.3820 - accuracy: 0.8628\n",
            "Epoch 00037: val_loss did not improve from 0.77986\n",
            "127/127 [==============================] - 11s 90ms/step - loss: 0.3820 - accuracy: 0.8628 - val_loss: 0.8629 - val_accuracy: 0.7543\n",
            "Epoch 38/200\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.3860 - accuracy: 0.8631\n",
            "Epoch 00038: val_loss did not improve from 0.77986\n",
            "127/127 [==============================] - 11s 90ms/step - loss: 0.3860 - accuracy: 0.8631 - val_loss: 0.8720 - val_accuracy: 0.7509\n",
            "Epoch 39/200\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.3663 - accuracy: 0.8677\n",
            "Epoch 00039: val_loss did not improve from 0.77986\n",
            "127/127 [==============================] - 11s 90ms/step - loss: 0.3663 - accuracy: 0.8677 - val_loss: 0.9682 - val_accuracy: 0.7368\n",
            "Epoch 40/200\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.4242 - accuracy: 0.8507\n",
            "Epoch 00040: val_loss did not improve from 0.77986\n",
            "127/127 [==============================] - 11s 90ms/step - loss: 0.4242 - accuracy: 0.8507 - val_loss: 0.9109 - val_accuracy: 0.7439\n",
            "Epoch 41/200\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.4170 - accuracy: 0.8526\n",
            "Epoch 00041: val_loss did not improve from 0.77986\n",
            "127/127 [==============================] - 11s 90ms/step - loss: 0.4170 - accuracy: 0.8526 - val_loss: 0.8765 - val_accuracy: 0.7595\n",
            "Epoch 42/200\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.3917 - accuracy: 0.8625\n",
            "Epoch 00042: val_loss did not improve from 0.77986\n",
            "127/127 [==============================] - 11s 90ms/step - loss: 0.3917 - accuracy: 0.8625 - val_loss: 0.8789 - val_accuracy: 0.7538\n",
            "Epoch 43/200\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.3636 - accuracy: 0.8713\n",
            "Epoch 00043: val_loss did not improve from 0.77986\n",
            "127/127 [==============================] - 11s 90ms/step - loss: 0.3636 - accuracy: 0.8713 - val_loss: 0.9157 - val_accuracy: 0.7410\n",
            "Epoch 44/200\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.3553 - accuracy: 0.8741\n",
            "Epoch 00044: val_loss did not improve from 0.77986\n",
            "127/127 [==============================] - 11s 90ms/step - loss: 0.3553 - accuracy: 0.8741 - val_loss: 0.8838 - val_accuracy: 0.7552\n",
            "Epoch 45/200\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.3560 - accuracy: 0.8691\n",
            "Epoch 00045: val_loss did not improve from 0.77986\n",
            "127/127 [==============================] - 11s 90ms/step - loss: 0.3560 - accuracy: 0.8691 - val_loss: 1.0002 - val_accuracy: 0.7439\n",
            "Epoch 46/200\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.3912 - accuracy: 0.8645\n",
            "Epoch 00046: val_loss did not improve from 0.77986\n",
            "127/127 [==============================] - 11s 90ms/step - loss: 0.3912 - accuracy: 0.8645 - val_loss: 1.0995 - val_accuracy: 0.7108\n",
            "Epoch 47/200\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.3502 - accuracy: 0.8752\n",
            "Epoch 00047: val_loss did not improve from 0.77986\n",
            "127/127 [==============================] - 11s 90ms/step - loss: 0.3502 - accuracy: 0.8752 - val_loss: 0.8936 - val_accuracy: 0.7533\n",
            "Epoch 48/200\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.3357 - accuracy: 0.8822\n",
            "Epoch 00048: val_loss did not improve from 0.77986\n",
            "127/127 [==============================] - 11s 90ms/step - loss: 0.3357 - accuracy: 0.8822 - val_loss: 0.9027 - val_accuracy: 0.7543\n",
            "Epoch 49/200\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.3392 - accuracy: 0.8784\n",
            "Epoch 00049: val_loss did not improve from 0.77986\n",
            "127/127 [==============================] - 11s 90ms/step - loss: 0.3392 - accuracy: 0.8784 - val_loss: 0.8476 - val_accuracy: 0.7613\n",
            "Epoch 50/200\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.3257 - accuracy: 0.8852\n",
            "Epoch 00050: val_loss did not improve from 0.77986\n",
            "127/127 [==============================] - 11s 90ms/step - loss: 0.3257 - accuracy: 0.8852 - val_loss: 0.8907 - val_accuracy: 0.7571\n",
            "Epoch 51/200\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.3232 - accuracy: 0.8866\n",
            "Epoch 00051: val_loss did not improve from 0.77986\n",
            "127/127 [==============================] - 11s 90ms/step - loss: 0.3232 - accuracy: 0.8866 - val_loss: 0.9057 - val_accuracy: 0.7533\n",
            "Epoch 52/200\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.3813 - accuracy: 0.8691\n",
            "Epoch 00052: val_loss did not improve from 0.77986\n",
            "127/127 [==============================] - 11s 90ms/step - loss: 0.3813 - accuracy: 0.8691 - val_loss: 1.0645 - val_accuracy: 0.7306\n",
            "Epoch 53/200\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.3495 - accuracy: 0.8792\n",
            "Epoch 00053: val_loss did not improve from 0.77986\n",
            "127/127 [==============================] - 11s 90ms/step - loss: 0.3495 - accuracy: 0.8792 - val_loss: 0.9478 - val_accuracy: 0.7443\n",
            "Epoch 54/200\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.3343 - accuracy: 0.8839\n",
            "Epoch 00054: val_loss did not improve from 0.77986\n",
            "127/127 [==============================] - 11s 90ms/step - loss: 0.3343 - accuracy: 0.8839 - val_loss: 0.9352 - val_accuracy: 0.7519\n",
            "Epoch 55/200\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.3151 - accuracy: 0.8880\n",
            "Epoch 00055: val_loss did not improve from 0.77986\n",
            "127/127 [==============================] - 11s 90ms/step - loss: 0.3151 - accuracy: 0.8880 - val_loss: 0.8740 - val_accuracy: 0.7628\n",
            "Epoch 56/200\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.3170 - accuracy: 0.8877\n",
            "Epoch 00056: val_loss did not improve from 0.77986\n",
            "127/127 [==============================] - 11s 90ms/step - loss: 0.3170 - accuracy: 0.8877 - val_loss: 0.9787 - val_accuracy: 0.7486\n",
            "Epoch 57/200\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.3009 - accuracy: 0.8946\n",
            "Epoch 00057: val_loss did not improve from 0.77986\n",
            "127/127 [==============================] - 11s 90ms/step - loss: 0.3009 - accuracy: 0.8946 - val_loss: 0.8596 - val_accuracy: 0.7632\n",
            "Epoch 58/200\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.2996 - accuracy: 0.9012\n",
            "Epoch 00058: val_loss did not improve from 0.77986\n",
            "127/127 [==============================] - 11s 90ms/step - loss: 0.2996 - accuracy: 0.9012 - val_loss: 0.9484 - val_accuracy: 0.7538\n",
            "Epoch 59/200\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.3048 - accuracy: 0.8967\n",
            "Epoch 00059: val_loss did not improve from 0.77986\n",
            "127/127 [==============================] - 11s 90ms/step - loss: 0.3048 - accuracy: 0.8967 - val_loss: 1.0127 - val_accuracy: 0.7462\n",
            "Epoch 60/200\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.3060 - accuracy: 0.8932\n",
            "Epoch 00060: val_loss did not improve from 0.77986\n",
            "127/127 [==============================] - 11s 90ms/step - loss: 0.3060 - accuracy: 0.8932 - val_loss: 1.0054 - val_accuracy: 0.7491\n",
            "Epoch 61/200\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.2898 - accuracy: 0.9011\n",
            "Epoch 00061: val_loss did not improve from 0.77986\n",
            "127/127 [==============================] - 11s 90ms/step - loss: 0.2898 - accuracy: 0.9011 - val_loss: 1.0302 - val_accuracy: 0.7410\n",
            "Epoch 62/200\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.3027 - accuracy: 0.8963\n",
            "Epoch 00062: val_loss did not improve from 0.77986\n",
            "127/127 [==============================] - 11s 90ms/step - loss: 0.3027 - accuracy: 0.8963 - val_loss: 0.9934 - val_accuracy: 0.7500\n",
            "Epoch 63/200\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.2832 - accuracy: 0.9015\n",
            "Epoch 00063: val_loss did not improve from 0.77986\n",
            "127/127 [==============================] - 11s 90ms/step - loss: 0.2832 - accuracy: 0.9015 - val_loss: 0.9616 - val_accuracy: 0.7595\n",
            "Epoch 64/200\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.2954 - accuracy: 0.8993\n",
            "Epoch 00064: val_loss did not improve from 0.77986\n",
            "127/127 [==============================] - 11s 90ms/step - loss: 0.2954 - accuracy: 0.8993 - val_loss: 0.9872 - val_accuracy: 0.7528\n",
            "Epoch 65/200\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.3176 - accuracy: 0.8916\n",
            "Epoch 00065: val_loss did not improve from 0.77986\n",
            "127/127 [==============================] - 11s 90ms/step - loss: 0.3176 - accuracy: 0.8916 - val_loss: 1.0828 - val_accuracy: 0.7349\n",
            "Epoch 66/200\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.2909 - accuracy: 0.8973\n",
            "Epoch 00066: val_loss did not improve from 0.77986\n",
            "127/127 [==============================] - 11s 90ms/step - loss: 0.2909 - accuracy: 0.8973 - val_loss: 1.0011 - val_accuracy: 0.7500\n",
            "Epoch 67/200\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.2822 - accuracy: 0.9006\n",
            "Epoch 00067: val_loss did not improve from 0.77986\n",
            "127/127 [==============================] - 11s 90ms/step - loss: 0.2822 - accuracy: 0.9006 - val_loss: 1.0692 - val_accuracy: 0.7434\n",
            "Epoch 68/200\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.2835 - accuracy: 0.8992\n",
            "Epoch 00068: val_loss did not improve from 0.77986\n",
            "127/127 [==============================] - 11s 90ms/step - loss: 0.2835 - accuracy: 0.8992 - val_loss: 1.0260 - val_accuracy: 0.7453\n",
            "Epoch 69/200\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.2747 - accuracy: 0.9041\n",
            "Epoch 00069: val_loss did not improve from 0.77986\n",
            "127/127 [==============================] - 11s 90ms/step - loss: 0.2747 - accuracy: 0.9041 - val_loss: 1.1235 - val_accuracy: 0.7377\n",
            "Epoch 70/200\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.2745 - accuracy: 0.9008\n",
            "Epoch 00070: val_loss did not improve from 0.77986\n",
            "127/127 [==============================] - 11s 90ms/step - loss: 0.2745 - accuracy: 0.9008 - val_loss: 1.0950 - val_accuracy: 0.7476\n",
            "Epoch 71/200\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.2731 - accuracy: 0.9011\n",
            "Epoch 00071: val_loss did not improve from 0.77986\n",
            "127/127 [==============================] - 11s 90ms/step - loss: 0.2731 - accuracy: 0.9011 - val_loss: 1.0135 - val_accuracy: 0.7585\n",
            "Epoch 72/200\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.2687 - accuracy: 0.9031\n",
            "Epoch 00072: val_loss did not improve from 0.77986\n",
            "127/127 [==============================] - 11s 90ms/step - loss: 0.2687 - accuracy: 0.9031 - val_loss: 1.0435 - val_accuracy: 0.7420\n",
            "Epoch 73/200\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.2629 - accuracy: 0.9060\n",
            "Epoch 00073: val_loss did not improve from 0.77986\n",
            "127/127 [==============================] - 11s 90ms/step - loss: 0.2629 - accuracy: 0.9060 - val_loss: 1.0481 - val_accuracy: 0.7543\n",
            "Epoch 74/200\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.2567 - accuracy: 0.9107\n",
            "Epoch 00074: val_loss did not improve from 0.77986\n",
            "127/127 [==============================] - 11s 90ms/step - loss: 0.2567 - accuracy: 0.9107 - val_loss: 1.0417 - val_accuracy: 0.7585\n",
            "Epoch 75/200\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.2605 - accuracy: 0.9101\n",
            "Epoch 00075: val_loss did not improve from 0.77986\n",
            "127/127 [==============================] - 11s 90ms/step - loss: 0.2605 - accuracy: 0.9101 - val_loss: 0.9747 - val_accuracy: 0.7533\n",
            "Epoch 76/200\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.2628 - accuracy: 0.9074\n",
            "Epoch 00076: val_loss did not improve from 0.77986\n",
            "127/127 [==============================] - 11s 90ms/step - loss: 0.2628 - accuracy: 0.9074 - val_loss: 1.0823 - val_accuracy: 0.7462\n",
            "Epoch 00076: early stopping\n",
            "Training completed in time:  0:14:46.338089\n"
          ]
        }
      ],
      "source": [
        "es = EarlyStopping(monitor='val_accuracy', min_delta= 0.01 , patience= 50, verbose= 1, mode='auto')\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath='new2(1-1).hdf5', \n",
        "                               verbose=1, save_best_only=True)\n",
        "start = datetime.now()\n",
        "\n",
        "modelc1.fit(X_train2, y_train,\n",
        "          batch_size = 50, \n",
        "          epochs = 200,\n",
        "          validation_data = (X_val2, y_val), \n",
        "          callbacks=[checkpointer, es])\n",
        "\n",
        "duration = datetime.now() - start\n",
        "print(\"Training completed in time: \", duration)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#saving the model history\n",
        "loss = pd.DataFrame(modelc1.history.history)\n",
        "\n",
        "\n",
        "#plotting the loss and accuracy \n",
        "plt.figure(figsize=(10,10))\n",
        "\n",
        "plt.subplot(2,2,1)\n",
        "plt.plot(loss[\"loss\"], label =\"Loss\")\n",
        "plt.plot(loss[\"val_loss\"], label = \"Validation_loss\")\n",
        "plt.legend()\n",
        "plt.title(\"Training and Validation Loss\")\n",
        "\n",
        "plt.subplot(2,2,2)\n",
        "plt.plot(loss['accuracy'],label = \"Training Accuracy\")\n",
        "plt.plot(loss['val_accuracy'], label =\"Validation_ Accuracy \")\n",
        "plt.legend()\n",
        "plt.title(\"Training-Validation Accuracy\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "li22CtciUdIm",
        "outputId": "9a78b3fc-b8d4-42c6-afd4-a020cbecb5a0"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Training-Validation Accuracy')"
            ]
          },
          "metadata": {},
          "execution_count": 36
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = modelc1.predict(X_val2)\n",
        "\n",
        "# finding class with larget predicted probability using argmax of numpy \n",
        "y_pred = np.argmax(prediction, axis = 1)  # prediction using model \n",
        "y_val_orig = np.argmax(y_val, axis = 1) # original y_val\n",
        "#print(y_pred)"
      ],
      "metadata": {
        "id": "PdiPjNbWUdNN"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_val_orig, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQOrkDrdUdRk",
        "outputId": "f98547ae-9bc0-4e1b-fd16-9d8c993048ec"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.16      0.28      0.20        53\n",
            "           1       0.24      0.20      0.22        51\n",
            "           2       0.16      0.27      0.20        51\n",
            "           3       0.21      0.13      0.16        31\n",
            "           4       0.21      0.19      0.20        64\n",
            "           5       0.15      0.13      0.14        30\n",
            "           6       0.19      0.13      0.15        71\n",
            "           7       0.20      0.30      0.24        20\n",
            "           8       0.85      0.94      0.89       214\n",
            "           9       0.98      0.95      0.96        84\n",
            "          10       0.74      0.81      0.78       199\n",
            "          11       0.86      0.79      0.83       227\n",
            "          12       0.95      0.79      0.86       209\n",
            "          13       0.91      0.96      0.93       180\n",
            "          14       0.95      0.90      0.92        67\n",
            "          15       0.95      0.85      0.90       198\n",
            "          16       0.89      0.92      0.90       168\n",
            "          17       0.87      0.81      0.84       199\n",
            "\n",
            "    accuracy                           0.75      2116\n",
            "   macro avg       0.58      0.58      0.57      2116\n",
            "weighted avg       0.76      0.75      0.75      2116\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "cnf_matrix = metrics.confusion_matrix(y_val_orig, y_pred)\n",
        "plt.figure(figsize=(10,8))\n",
        "ax= plt.subplot()\n",
        "sns.heatmap(cnf_matrix,annot=True, fmt='.5g', ax=ax,cmap=\"YlGnBu\");\n",
        "plt.rcParams.update({'font.size': 30});\n",
        "ax.set_xlabel('Predicted Values', fontsize=17, color='Black');\n",
        "ax.set_ylabel('Actual Values',fontsize=17, color='Black'); \n",
        "ax.set_title('Confusion Matrix \\n', color='Black', fontsize=23);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        },
        "id": "f_0yzGC6wVzX",
        "outputId": "f8f99d8f-010d-43e5-fdd0-f7f1670057bc"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Experment (2)"
      ],
      "metadata": {
        "id": "3ZebtuD1zQ1I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "HDfn3uQhdzCf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aef4abce-b9f6-4bde-ea01-63abc672ac36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_4 (Conv2D)           (None, 40, 174, 10)       100       \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 40, 174, 16)       1456      \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 20, 87, 16)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 20, 87, 16)        0         \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 20, 87, 20)        2900      \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 20, 87, 16)        2896      \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 10, 43, 16)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 10, 43, 16)        0         \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 10, 43, 30)        4350      \n",
            "                                                                 \n",
            " global_average_pooling2d (G  (None, 30)               0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 30)                0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 30)                930       \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 18)                558       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,190\n",
            "Trainable params: 13,190\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "modelc2 = Sequential()\n",
        "\n",
        "modelc2.add(InputLayer(input_shape=X_train2.shape[1:]))\n",
        "\n",
        "modelc2.add(Conv2D(filters=10, kernel_size=3, activation='relu', padding='same'))\n",
        "modelc2.add(Conv2D(filters=16, kernel_size=3, activation='relu', padding='same'))\n",
        "modelc2.add(MaxPooling2D())\n",
        "modelc2.add(Dropout(0.5))\n",
        "\n",
        "modelc2.add(Conv2D(filters=20, kernel_size=3, activation='relu', padding='same'))\n",
        "modelc2.add(Conv2D(filters=16, kernel_size=3, activation='relu', padding='same'))\n",
        "modelc2.add(MaxPooling2D())\n",
        "modelc2.add(Dropout(0.5))\n",
        "\n",
        "modelc2.add(Conv2D(filters=30, kernel_size=3, activation='relu', padding='same'))\n",
        "modelc2.add(GlobalAveragePooling2D())\n",
        "\n",
        "# Fully connected block - flattening followed by dense and output layers\n",
        "modelc2.add(Flatten())\n",
        "modelc2.add(Dense(30, activation='relu'))\n",
        "\n",
        "#final layer\n",
        "# add neural network so flatten the output comming from last layer of cnn model \n",
        "modelc2.add(Dense(units = num_labels, activation=\"softmax\"))\n",
        "\n",
        "modelc2.summary()\n",
        "\n",
        "modelc2.compile(loss = 'categorical_crossentropy', \n",
        "              metrics = ['accuracy'],\n",
        "              optimizer = 'adam')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "es = EarlyStopping(monitor='val_accuracy', min_delta= 0.01 , patience= 50, verbose= 1, mode='auto')\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath='new2(2).hdf5', \n",
        "                               verbose=1, save_best_only=True)\n",
        "start = datetime.now()\n",
        "\n",
        "modelc2.fit(X_train2, y_train,\n",
        "          batch_size = 50, \n",
        "          epochs = 1000,\n",
        "          validation_data = (X_val2, y_val), \n",
        "          callbacks=[checkpointer, es])\n",
        "\n",
        "duration = datetime.now() - start\n",
        "print(\"Training completed in time: \", duration)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xiF7g-5C0d1U",
        "outputId": "21da7555-345d-4410-e406-e586a1f2b162"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 2.5910 - accuracy: 0.1374\n",
            "Epoch 00001: val_loss improved from inf to 2.39289, saving model to new2(2).hdf5\n",
            "127/127 [==============================] - 2s 11ms/step - loss: 2.5910 - accuracy: 0.1374 - val_loss: 2.3929 - val_accuracy: 0.1583\n",
            "Epoch 2/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 2.3099 - accuracy: 0.2109\n",
            "Epoch 00002: val_loss improved from 2.39289 to 2.19697, saving model to new2(2).hdf5\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 2.3099 - accuracy: 0.2109 - val_loss: 2.1970 - val_accuracy: 0.2651\n",
            "Epoch 3/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 2.0818 - accuracy: 0.2711\n",
            "Epoch 00003: val_loss improved from 2.19697 to 1.99485, saving model to new2(2).hdf5\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 2.0818 - accuracy: 0.2711 - val_loss: 1.9948 - val_accuracy: 0.2760\n",
            "Epoch 4/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.9707 - accuracy: 0.3004\n",
            "Epoch 00004: val_loss improved from 1.99485 to 1.94676, saving model to new2(2).hdf5\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 1.9707 - accuracy: 0.3004 - val_loss: 1.9468 - val_accuracy: 0.3185\n",
            "Epoch 5/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.9161 - accuracy: 0.3234\n",
            "Epoch 00005: val_loss improved from 1.94676 to 1.92135, saving model to new2(2).hdf5\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 1.9161 - accuracy: 0.3234 - val_loss: 1.9213 - val_accuracy: 0.3450\n",
            "Epoch 6/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.8519 - accuracy: 0.3499\n",
            "Epoch 00006: val_loss improved from 1.92135 to 1.81891, saving model to new2(2).hdf5\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 1.8519 - accuracy: 0.3499 - val_loss: 1.8189 - val_accuracy: 0.3653\n",
            "Epoch 7/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.8013 - accuracy: 0.3741\n",
            "Epoch 00007: val_loss improved from 1.81891 to 1.79283, saving model to new2(2).hdf5\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 1.8013 - accuracy: 0.3741 - val_loss: 1.7928 - val_accuracy: 0.3738\n",
            "Epoch 8/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.7446 - accuracy: 0.4063\n",
            "Epoch 00008: val_loss improved from 1.79283 to 1.72910, saving model to new2(2).hdf5\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 1.7446 - accuracy: 0.4063 - val_loss: 1.7291 - val_accuracy: 0.4154\n",
            "Epoch 9/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.7010 - accuracy: 0.4135\n",
            "Epoch 00009: val_loss improved from 1.72910 to 1.68433, saving model to new2(2).hdf5\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 1.7010 - accuracy: 0.4135 - val_loss: 1.6843 - val_accuracy: 0.4282\n",
            "Epoch 10/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.6453 - accuracy: 0.4434\n",
            "Epoch 00010: val_loss improved from 1.68433 to 1.62174, saving model to new2(2).hdf5\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 1.6453 - accuracy: 0.4434 - val_loss: 1.6217 - val_accuracy: 0.4579\n",
            "Epoch 11/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.6001 - accuracy: 0.4630\n",
            "Epoch 00011: val_loss improved from 1.62174 to 1.59839, saving model to new2(2).hdf5\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 1.6001 - accuracy: 0.4630 - val_loss: 1.5984 - val_accuracy: 0.4787\n",
            "Epoch 12/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.5445 - accuracy: 0.4891\n",
            "Epoch 00012: val_loss improved from 1.59839 to 1.55595, saving model to new2(2).hdf5\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 1.5445 - accuracy: 0.4891 - val_loss: 1.5560 - val_accuracy: 0.4660\n",
            "Epoch 13/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.5189 - accuracy: 0.4961\n",
            "Epoch 00013: val_loss improved from 1.55595 to 1.50443, saving model to new2(2).hdf5\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 1.5189 - accuracy: 0.4961 - val_loss: 1.5044 - val_accuracy: 0.5137\n",
            "Epoch 14/1000\n",
            "126/127 [============================>.] - ETA: 0s - loss: 1.4738 - accuracy: 0.5137\n",
            "Epoch 00014: val_loss improved from 1.50443 to 1.47574, saving model to new2(2).hdf5\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 1.4757 - accuracy: 0.5135 - val_loss: 1.4757 - val_accuracy: 0.5269\n",
            "Epoch 15/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.4519 - accuracy: 0.5271\n",
            "Epoch 00015: val_loss improved from 1.47574 to 1.46045, saving model to new2(2).hdf5\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 1.4519 - accuracy: 0.5271 - val_loss: 1.4604 - val_accuracy: 0.5165\n",
            "Epoch 16/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.4208 - accuracy: 0.5378\n",
            "Epoch 00016: val_loss improved from 1.46045 to 1.43830, saving model to new2(2).hdf5\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 1.4208 - accuracy: 0.5378 - val_loss: 1.4383 - val_accuracy: 0.5293\n",
            "Epoch 17/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.3835 - accuracy: 0.5514\n",
            "Epoch 00017: val_loss improved from 1.43830 to 1.41057, saving model to new2(2).hdf5\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 1.3835 - accuracy: 0.5514 - val_loss: 1.4106 - val_accuracy: 0.5444\n",
            "Epoch 18/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.3753 - accuracy: 0.5507\n",
            "Epoch 00018: val_loss improved from 1.41057 to 1.39293, saving model to new2(2).hdf5\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 1.3753 - accuracy: 0.5507 - val_loss: 1.3929 - val_accuracy: 0.5449\n",
            "Epoch 19/1000\n",
            "126/127 [============================>.] - ETA: 0s - loss: 1.3431 - accuracy: 0.5616\n",
            "Epoch 00019: val_loss did not improve from 1.39293\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 1.3428 - accuracy: 0.5614 - val_loss: 1.4271 - val_accuracy: 0.5468\n",
            "Epoch 20/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.3235 - accuracy: 0.5712\n",
            "Epoch 00020: val_loss did not improve from 1.39293\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 1.3235 - accuracy: 0.5712 - val_loss: 1.4140 - val_accuracy: 0.5577\n",
            "Epoch 21/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.3025 - accuracy: 0.5740\n",
            "Epoch 00021: val_loss improved from 1.39293 to 1.37963, saving model to new2(2).hdf5\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 1.3025 - accuracy: 0.5740 - val_loss: 1.3796 - val_accuracy: 0.5619\n",
            "Epoch 22/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.2789 - accuracy: 0.5824\n",
            "Epoch 00022: val_loss improved from 1.37963 to 1.28248, saving model to new2(2).hdf5\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 1.2789 - accuracy: 0.5824 - val_loss: 1.2825 - val_accuracy: 0.5964\n",
            "Epoch 23/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.2575 - accuracy: 0.5898\n",
            "Epoch 00023: val_loss did not improve from 1.28248\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 1.2575 - accuracy: 0.5898 - val_loss: 1.3113 - val_accuracy: 0.5803\n",
            "Epoch 24/1000\n",
            "121/127 [===========================>..] - ETA: 0s - loss: 1.2348 - accuracy: 0.5909\n",
            "Epoch 00024: val_loss did not improve from 1.28248\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 1.2381 - accuracy: 0.5904 - val_loss: 1.2914 - val_accuracy: 0.5794\n",
            "Epoch 25/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.2089 - accuracy: 0.6117\n",
            "Epoch 00025: val_loss improved from 1.28248 to 1.23501, saving model to new2(2).hdf5\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 1.2089 - accuracy: 0.6117 - val_loss: 1.2350 - val_accuracy: 0.6101\n",
            "Epoch 26/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.2056 - accuracy: 0.6106\n",
            "Epoch 00026: val_loss did not improve from 1.23501\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 1.2056 - accuracy: 0.6106 - val_loss: 1.2953 - val_accuracy: 0.5870\n",
            "Epoch 27/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.2098 - accuracy: 0.6046\n",
            "Epoch 00027: val_loss improved from 1.23501 to 1.21563, saving model to new2(2).hdf5\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 1.2098 - accuracy: 0.6046 - val_loss: 1.2156 - val_accuracy: 0.6078\n",
            "Epoch 28/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.1705 - accuracy: 0.6174\n",
            "Epoch 00028: val_loss improved from 1.21563 to 1.20972, saving model to new2(2).hdf5\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 1.1705 - accuracy: 0.6174 - val_loss: 1.2097 - val_accuracy: 0.6106\n",
            "Epoch 29/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.1554 - accuracy: 0.6254\n",
            "Epoch 00029: val_loss did not improve from 1.20972\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 1.1554 - accuracy: 0.6254 - val_loss: 1.2293 - val_accuracy: 0.5978\n",
            "Epoch 30/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.1482 - accuracy: 0.6276\n",
            "Epoch 00030: val_loss improved from 1.20972 to 1.17772, saving model to new2(2).hdf5\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 1.1482 - accuracy: 0.6276 - val_loss: 1.1777 - val_accuracy: 0.6200\n",
            "Epoch 31/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.1342 - accuracy: 0.6359\n",
            "Epoch 00031: val_loss did not improve from 1.17772\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 1.1342 - accuracy: 0.6359 - val_loss: 1.1884 - val_accuracy: 0.6177\n",
            "Epoch 32/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.1257 - accuracy: 0.6339\n",
            "Epoch 00032: val_loss improved from 1.17772 to 1.17433, saving model to new2(2).hdf5\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 1.1257 - accuracy: 0.6339 - val_loss: 1.1743 - val_accuracy: 0.6238\n",
            "Epoch 33/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.1012 - accuracy: 0.6421\n",
            "Epoch 00033: val_loss improved from 1.17433 to 1.15001, saving model to new2(2).hdf5\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 1.1012 - accuracy: 0.6421 - val_loss: 1.1500 - val_accuracy: 0.6290\n",
            "Epoch 34/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.0925 - accuracy: 0.6468\n",
            "Epoch 00034: val_loss improved from 1.15001 to 1.14515, saving model to new2(2).hdf5\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 1.0925 - accuracy: 0.6468 - val_loss: 1.1451 - val_accuracy: 0.6271\n",
            "Epoch 35/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.0750 - accuracy: 0.6509\n",
            "Epoch 00035: val_loss improved from 1.14515 to 1.13712, saving model to new2(2).hdf5\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 1.0750 - accuracy: 0.6509 - val_loss: 1.1371 - val_accuracy: 0.6262\n",
            "Epoch 36/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.0767 - accuracy: 0.6533\n",
            "Epoch 00036: val_loss did not improve from 1.13712\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 1.0767 - accuracy: 0.6533 - val_loss: 1.1649 - val_accuracy: 0.6219\n",
            "Epoch 37/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.0601 - accuracy: 0.6545\n",
            "Epoch 00037: val_loss did not improve from 1.13712\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 1.0601 - accuracy: 0.6545 - val_loss: 1.1392 - val_accuracy: 0.6295\n",
            "Epoch 38/1000\n",
            "126/127 [============================>.] - ETA: 0s - loss: 1.0461 - accuracy: 0.6610\n",
            "Epoch 00038: val_loss improved from 1.13712 to 1.12012, saving model to new2(2).hdf5\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 1.0459 - accuracy: 0.6615 - val_loss: 1.1201 - val_accuracy: 0.6418\n",
            "Epoch 39/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.0440 - accuracy: 0.6605\n",
            "Epoch 00039: val_loss did not improve from 1.12012\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 1.0440 - accuracy: 0.6605 - val_loss: 1.1292 - val_accuracy: 0.6300\n",
            "Epoch 40/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.0380 - accuracy: 0.6602\n",
            "Epoch 00040: val_loss improved from 1.12012 to 1.10836, saving model to new2(2).hdf5\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 1.0380 - accuracy: 0.6602 - val_loss: 1.1084 - val_accuracy: 0.6465\n",
            "Epoch 41/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.0240 - accuracy: 0.6665\n",
            "Epoch 00041: val_loss improved from 1.10836 to 1.07007, saving model to new2(2).hdf5\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 1.0240 - accuracy: 0.6665 - val_loss: 1.0701 - val_accuracy: 0.6630\n",
            "Epoch 42/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.9976 - accuracy: 0.6760\n",
            "Epoch 00042: val_loss did not improve from 1.07007\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.9976 - accuracy: 0.6760 - val_loss: 1.0921 - val_accuracy: 0.6474\n",
            "Epoch 43/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.0064 - accuracy: 0.6706\n",
            "Epoch 00043: val_loss did not improve from 1.07007\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 1.0064 - accuracy: 0.6706 - val_loss: 1.1454 - val_accuracy: 0.6347\n",
            "Epoch 44/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.0038 - accuracy: 0.6701\n",
            "Epoch 00044: val_loss did not improve from 1.07007\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 1.0038 - accuracy: 0.6701 - val_loss: 1.0951 - val_accuracy: 0.6470\n",
            "Epoch 45/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.9792 - accuracy: 0.6804\n",
            "Epoch 00045: val_loss did not improve from 1.07007\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.9792 - accuracy: 0.6804 - val_loss: 1.0874 - val_accuracy: 0.6484\n",
            "Epoch 46/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.9704 - accuracy: 0.6807\n",
            "Epoch 00046: val_loss improved from 1.07007 to 1.06816, saving model to new2(2).hdf5\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.9704 - accuracy: 0.6807 - val_loss: 1.0682 - val_accuracy: 0.6531\n",
            "Epoch 47/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.9774 - accuracy: 0.6816\n",
            "Epoch 00047: val_loss improved from 1.06816 to 1.06228, saving model to new2(2).hdf5\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.9774 - accuracy: 0.6816 - val_loss: 1.0623 - val_accuracy: 0.6569\n",
            "Epoch 48/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.9570 - accuracy: 0.6819\n",
            "Epoch 00048: val_loss improved from 1.06228 to 1.03410, saving model to new2(2).hdf5\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.9570 - accuracy: 0.6819 - val_loss: 1.0341 - val_accuracy: 0.6720\n",
            "Epoch 49/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.9553 - accuracy: 0.6859\n",
            "Epoch 00049: val_loss did not improve from 1.03410\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.9553 - accuracy: 0.6859 - val_loss: 1.0972 - val_accuracy: 0.6578\n",
            "Epoch 50/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.9514 - accuracy: 0.6895\n",
            "Epoch 00050: val_loss did not improve from 1.03410\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.9514 - accuracy: 0.6895 - val_loss: 1.0813 - val_accuracy: 0.6668\n",
            "Epoch 51/1000\n",
            "126/127 [============================>.] - ETA: 0s - loss: 0.9401 - accuracy: 0.6846\n",
            "Epoch 00051: val_loss did not improve from 1.03410\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.9403 - accuracy: 0.6845 - val_loss: 1.0465 - val_accuracy: 0.6725\n",
            "Epoch 52/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.9355 - accuracy: 0.6889\n",
            "Epoch 00052: val_loss did not improve from 1.03410\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.9355 - accuracy: 0.6889 - val_loss: 1.0601 - val_accuracy: 0.6720\n",
            "Epoch 53/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.9220 - accuracy: 0.6947\n",
            "Epoch 00053: val_loss did not improve from 1.03410\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.9220 - accuracy: 0.6947 - val_loss: 1.0784 - val_accuracy: 0.6649\n",
            "Epoch 54/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.9116 - accuracy: 0.6975\n",
            "Epoch 00054: val_loss did not improve from 1.03410\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.9116 - accuracy: 0.6975 - val_loss: 1.0490 - val_accuracy: 0.6725\n",
            "Epoch 55/1000\n",
            "126/127 [============================>.] - ETA: 0s - loss: 0.9101 - accuracy: 0.6978\n",
            "Epoch 00055: val_loss did not improve from 1.03410\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.9093 - accuracy: 0.6983 - val_loss: 1.0393 - val_accuracy: 0.6692\n",
            "Epoch 56/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.9149 - accuracy: 0.6950\n",
            "Epoch 00056: val_loss improved from 1.03410 to 1.01779, saving model to new2(2).hdf5\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.9149 - accuracy: 0.6950 - val_loss: 1.0178 - val_accuracy: 0.6777\n",
            "Epoch 57/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.9125 - accuracy: 0.6971\n",
            "Epoch 00057: val_loss did not improve from 1.01779\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.9125 - accuracy: 0.6971 - val_loss: 1.0311 - val_accuracy: 0.6682\n",
            "Epoch 58/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.9118 - accuracy: 0.6999\n",
            "Epoch 00058: val_loss did not improve from 1.01779\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.9118 - accuracy: 0.6999 - val_loss: 1.0188 - val_accuracy: 0.6772\n",
            "Epoch 59/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.8943 - accuracy: 0.7060\n",
            "Epoch 00059: val_loss improved from 1.01779 to 1.00500, saving model to new2(2).hdf5\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.8943 - accuracy: 0.7060 - val_loss: 1.0050 - val_accuracy: 0.6796\n",
            "Epoch 60/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.8899 - accuracy: 0.7070\n",
            "Epoch 00060: val_loss improved from 1.00500 to 0.99874, saving model to new2(2).hdf5\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.8899 - accuracy: 0.7070 - val_loss: 0.9987 - val_accuracy: 0.6810\n",
            "Epoch 61/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.8879 - accuracy: 0.7037\n",
            "Epoch 00061: val_loss did not improve from 0.99874\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.8879 - accuracy: 0.7037 - val_loss: 1.0226 - val_accuracy: 0.6824\n",
            "Epoch 62/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.8803 - accuracy: 0.7042\n",
            "Epoch 00062: val_loss did not improve from 0.99874\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.8803 - accuracy: 0.7042 - val_loss: 1.0296 - val_accuracy: 0.6791\n",
            "Epoch 63/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.8886 - accuracy: 0.7043\n",
            "Epoch 00063: val_loss did not improve from 0.99874\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.8886 - accuracy: 0.7043 - val_loss: 1.0034 - val_accuracy: 0.6777\n",
            "Epoch 64/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.8778 - accuracy: 0.7122\n",
            "Epoch 00064: val_loss improved from 0.99874 to 0.98720, saving model to new2(2).hdf5\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.8778 - accuracy: 0.7122 - val_loss: 0.9872 - val_accuracy: 0.6881\n",
            "Epoch 65/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.8651 - accuracy: 0.7097\n",
            "Epoch 00065: val_loss did not improve from 0.98720\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.8651 - accuracy: 0.7097 - val_loss: 1.0249 - val_accuracy: 0.6734\n",
            "Epoch 66/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.8584 - accuracy: 0.7168\n",
            "Epoch 00066: val_loss did not improve from 0.98720\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.8584 - accuracy: 0.7168 - val_loss: 0.9957 - val_accuracy: 0.6843\n",
            "Epoch 67/1000\n",
            "126/127 [============================>.] - ETA: 0s - loss: 0.8727 - accuracy: 0.7071\n",
            "Epoch 00067: val_loss did not improve from 0.98720\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.8721 - accuracy: 0.7073 - val_loss: 1.0983 - val_accuracy: 0.6574\n",
            "Epoch 68/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.8604 - accuracy: 0.7130\n",
            "Epoch 00068: val_loss did not improve from 0.98720\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.8604 - accuracy: 0.7130 - val_loss: 0.9993 - val_accuracy: 0.6744\n",
            "Epoch 69/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.8427 - accuracy: 0.7172\n",
            "Epoch 00069: val_loss did not improve from 0.98720\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.8427 - accuracy: 0.7172 - val_loss: 1.0056 - val_accuracy: 0.6796\n",
            "Epoch 70/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.8531 - accuracy: 0.7158\n",
            "Epoch 00070: val_loss improved from 0.98720 to 0.96637, saving model to new2(2).hdf5\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.8531 - accuracy: 0.7158 - val_loss: 0.9664 - val_accuracy: 0.6942\n",
            "Epoch 71/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.8443 - accuracy: 0.7166\n",
            "Epoch 00071: val_loss did not improve from 0.96637\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.8443 - accuracy: 0.7166 - val_loss: 1.0120 - val_accuracy: 0.6853\n",
            "Epoch 72/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.8430 - accuracy: 0.7185\n",
            "Epoch 00072: val_loss did not improve from 0.96637\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.8430 - accuracy: 0.7185 - val_loss: 0.9996 - val_accuracy: 0.6938\n",
            "Epoch 73/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.8338 - accuracy: 0.7207\n",
            "Epoch 00073: val_loss did not improve from 0.96637\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.8338 - accuracy: 0.7207 - val_loss: 0.9785 - val_accuracy: 0.6980\n",
            "Epoch 74/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.8259 - accuracy: 0.7207\n",
            "Epoch 00074: val_loss did not improve from 0.96637\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.8259 - accuracy: 0.7207 - val_loss: 1.0167 - val_accuracy: 0.6881\n",
            "Epoch 75/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.8414 - accuracy: 0.7180\n",
            "Epoch 00075: val_loss improved from 0.96637 to 0.93256, saving model to new2(2).hdf5\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.8414 - accuracy: 0.7180 - val_loss: 0.9326 - val_accuracy: 0.7112\n",
            "Epoch 76/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.8207 - accuracy: 0.7220\n",
            "Epoch 00076: val_loss did not improve from 0.93256\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.8207 - accuracy: 0.7220 - val_loss: 1.0407 - val_accuracy: 0.6843\n",
            "Epoch 77/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.8342 - accuracy: 0.7168\n",
            "Epoch 00077: val_loss did not improve from 0.93256\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.8342 - accuracy: 0.7168 - val_loss: 0.9681 - val_accuracy: 0.6900\n",
            "Epoch 78/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.8140 - accuracy: 0.7237\n",
            "Epoch 00078: val_loss did not improve from 0.93256\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.8140 - accuracy: 0.7237 - val_loss: 0.9663 - val_accuracy: 0.6966\n",
            "Epoch 79/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.8178 - accuracy: 0.7264\n",
            "Epoch 00079: val_loss did not improve from 0.93256\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.8178 - accuracy: 0.7264 - val_loss: 0.9716 - val_accuracy: 0.7013\n",
            "Epoch 80/1000\n",
            "126/127 [============================>.] - ETA: 0s - loss: 0.8153 - accuracy: 0.7279\n",
            "Epoch 00080: val_loss did not improve from 0.93256\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.8168 - accuracy: 0.7273 - val_loss: 0.9443 - val_accuracy: 0.7004\n",
            "Epoch 81/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.8129 - accuracy: 0.7317\n",
            "Epoch 00081: val_loss did not improve from 0.93256\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.8129 - accuracy: 0.7317 - val_loss: 0.9560 - val_accuracy: 0.7051\n",
            "Epoch 82/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.8034 - accuracy: 0.7302\n",
            "Epoch 00082: val_loss did not improve from 0.93256\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.8034 - accuracy: 0.7302 - val_loss: 0.9800 - val_accuracy: 0.6994\n",
            "Epoch 83/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.8109 - accuracy: 0.7286\n",
            "Epoch 00083: val_loss did not improve from 0.93256\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.8109 - accuracy: 0.7286 - val_loss: 0.9629 - val_accuracy: 0.7056\n",
            "Epoch 84/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.8117 - accuracy: 0.7275\n",
            "Epoch 00084: val_loss did not improve from 0.93256\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.8117 - accuracy: 0.7275 - val_loss: 0.9553 - val_accuracy: 0.6942\n",
            "Epoch 85/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.7841 - accuracy: 0.7398\n",
            "Epoch 00085: val_loss did not improve from 0.93256\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.7841 - accuracy: 0.7398 - val_loss: 1.0054 - val_accuracy: 0.6819\n",
            "Epoch 86/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.8064 - accuracy: 0.7309\n",
            "Epoch 00086: val_loss did not improve from 0.93256\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.8064 - accuracy: 0.7309 - val_loss: 0.9616 - val_accuracy: 0.6923\n",
            "Epoch 87/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.7951 - accuracy: 0.7339\n",
            "Epoch 00087: val_loss did not improve from 0.93256\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.7951 - accuracy: 0.7339 - val_loss: 0.9706 - val_accuracy: 0.7089\n",
            "Epoch 88/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.8014 - accuracy: 0.7272\n",
            "Epoch 00088: val_loss did not improve from 0.93256\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.8014 - accuracy: 0.7272 - val_loss: 0.9832 - val_accuracy: 0.6994\n",
            "Epoch 89/1000\n",
            "126/127 [============================>.] - ETA: 0s - loss: 0.8000 - accuracy: 0.7246\n",
            "Epoch 00089: val_loss did not improve from 0.93256\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.8000 - accuracy: 0.7245 - val_loss: 0.9482 - val_accuracy: 0.7018\n",
            "Epoch 90/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.7978 - accuracy: 0.7319\n",
            "Epoch 00090: val_loss did not improve from 0.93256\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.7978 - accuracy: 0.7319 - val_loss: 0.9729 - val_accuracy: 0.6994\n",
            "Epoch 91/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.7973 - accuracy: 0.7313\n",
            "Epoch 00091: val_loss did not improve from 0.93256\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.7973 - accuracy: 0.7313 - val_loss: 0.9689 - val_accuracy: 0.6905\n",
            "Epoch 92/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.7903 - accuracy: 0.7294\n",
            "Epoch 00092: val_loss improved from 0.93256 to 0.93033, saving model to new2(2).hdf5\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.7903 - accuracy: 0.7294 - val_loss: 0.9303 - val_accuracy: 0.7127\n",
            "Epoch 93/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.7621 - accuracy: 0.7399\n",
            "Epoch 00093: val_loss did not improve from 0.93033\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.7621 - accuracy: 0.7399 - val_loss: 1.0146 - val_accuracy: 0.6919\n",
            "Epoch 94/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.7769 - accuracy: 0.7358\n",
            "Epoch 00094: val_loss did not improve from 0.93033\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.7769 - accuracy: 0.7358 - val_loss: 0.9826 - val_accuracy: 0.6933\n",
            "Epoch 95/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.7732 - accuracy: 0.7365\n",
            "Epoch 00095: val_loss did not improve from 0.93033\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.7732 - accuracy: 0.7365 - val_loss: 0.9322 - val_accuracy: 0.7112\n",
            "Epoch 96/1000\n",
            "126/127 [============================>.] - ETA: 0s - loss: 0.7753 - accuracy: 0.7394\n",
            "Epoch 00096: val_loss improved from 0.93033 to 0.91486, saving model to new2(2).hdf5\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.7749 - accuracy: 0.7396 - val_loss: 0.9149 - val_accuracy: 0.7146\n",
            "Epoch 97/1000\n",
            "126/127 [============================>.] - ETA: 0s - loss: 0.7552 - accuracy: 0.7486\n",
            "Epoch 00097: val_loss did not improve from 0.91486\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.7559 - accuracy: 0.7483 - val_loss: 0.9295 - val_accuracy: 0.7146\n",
            "Epoch 98/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.7529 - accuracy: 0.7465\n",
            "Epoch 00098: val_loss improved from 0.91486 to 0.90827, saving model to new2(2).hdf5\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.7529 - accuracy: 0.7465 - val_loss: 0.9083 - val_accuracy: 0.7155\n",
            "Epoch 99/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.7507 - accuracy: 0.7428\n",
            "Epoch 00099: val_loss improved from 0.90827 to 0.90114, saving model to new2(2).hdf5\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.7507 - accuracy: 0.7428 - val_loss: 0.9011 - val_accuracy: 0.7216\n",
            "Epoch 100/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.7676 - accuracy: 0.7398\n",
            "Epoch 00100: val_loss did not improve from 0.90114\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.7676 - accuracy: 0.7398 - val_loss: 0.9428 - val_accuracy: 0.7108\n",
            "Epoch 101/1000\n",
            "126/127 [============================>.] - ETA: 0s - loss: 0.7460 - accuracy: 0.7476\n",
            "Epoch 00101: val_loss did not improve from 0.90114\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.7479 - accuracy: 0.7470 - val_loss: 0.9529 - val_accuracy: 0.7032\n",
            "Epoch 102/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.7525 - accuracy: 0.7489\n",
            "Epoch 00102: val_loss did not improve from 0.90114\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.7525 - accuracy: 0.7489 - val_loss: 0.9392 - val_accuracy: 0.7117\n",
            "Epoch 103/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.7429 - accuracy: 0.7535\n",
            "Epoch 00103: val_loss did not improve from 0.90114\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.7429 - accuracy: 0.7535 - val_loss: 0.9362 - val_accuracy: 0.7103\n",
            "Epoch 104/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.7355 - accuracy: 0.7437\n",
            "Epoch 00104: val_loss did not improve from 0.90114\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.7355 - accuracy: 0.7437 - val_loss: 0.9305 - val_accuracy: 0.7051\n",
            "Epoch 105/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.7439 - accuracy: 0.7467\n",
            "Epoch 00105: val_loss did not improve from 0.90114\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.7439 - accuracy: 0.7467 - val_loss: 0.9315 - val_accuracy: 0.7089\n",
            "Epoch 106/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.7452 - accuracy: 0.7468\n",
            "Epoch 00106: val_loss did not improve from 0.90114\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.7452 - accuracy: 0.7468 - val_loss: 0.9105 - val_accuracy: 0.7098\n",
            "Epoch 107/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.7447 - accuracy: 0.7472\n",
            "Epoch 00107: val_loss improved from 0.90114 to 0.89752, saving model to new2(2).hdf5\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.7447 - accuracy: 0.7472 - val_loss: 0.8975 - val_accuracy: 0.7188\n",
            "Epoch 108/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.7374 - accuracy: 0.7500\n",
            "Epoch 00108: val_loss did not improve from 0.89752\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.7374 - accuracy: 0.7500 - val_loss: 0.9664 - val_accuracy: 0.6975\n",
            "Epoch 109/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.7419 - accuracy: 0.7478\n",
            "Epoch 00109: val_loss did not improve from 0.89752\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.7419 - accuracy: 0.7478 - val_loss: 0.9256 - val_accuracy: 0.7037\n",
            "Epoch 110/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.7403 - accuracy: 0.7524\n",
            "Epoch 00110: val_loss improved from 0.89752 to 0.88202, saving model to new2(2).hdf5\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.7403 - accuracy: 0.7524 - val_loss: 0.8820 - val_accuracy: 0.7179\n",
            "Epoch 111/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.7291 - accuracy: 0.7508\n",
            "Epoch 00111: val_loss did not improve from 0.88202\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.7291 - accuracy: 0.7508 - val_loss: 0.9767 - val_accuracy: 0.7160\n",
            "Epoch 112/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.7240 - accuracy: 0.7532\n",
            "Epoch 00112: val_loss did not improve from 0.88202\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.7240 - accuracy: 0.7532 - val_loss: 0.9552 - val_accuracy: 0.7032\n",
            "Epoch 113/1000\n",
            "126/127 [============================>.] - ETA: 0s - loss: 0.7307 - accuracy: 0.7498\n",
            "Epoch 00113: val_loss improved from 0.88202 to 0.87991, saving model to new2(2).hdf5\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.7302 - accuracy: 0.7497 - val_loss: 0.8799 - val_accuracy: 0.7268\n",
            "Epoch 114/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.7241 - accuracy: 0.7509\n",
            "Epoch 00114: val_loss did not improve from 0.87991\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.7241 - accuracy: 0.7509 - val_loss: 0.9526 - val_accuracy: 0.7023\n",
            "Epoch 115/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.7240 - accuracy: 0.7532\n",
            "Epoch 00115: val_loss did not improve from 0.87991\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.7240 - accuracy: 0.7532 - val_loss: 0.8817 - val_accuracy: 0.7193\n",
            "Epoch 116/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.7279 - accuracy: 0.7554\n",
            "Epoch 00116: val_loss did not improve from 0.87991\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.7279 - accuracy: 0.7554 - val_loss: 0.8898 - val_accuracy: 0.7254\n",
            "Epoch 117/1000\n",
            "126/127 [============================>.] - ETA: 0s - loss: 0.7147 - accuracy: 0.7560\n",
            "Epoch 00117: val_loss did not improve from 0.87991\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.7140 - accuracy: 0.7566 - val_loss: 0.8931 - val_accuracy: 0.7268\n",
            "Epoch 118/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.7153 - accuracy: 0.7544\n",
            "Epoch 00118: val_loss did not improve from 0.87991\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.7153 - accuracy: 0.7544 - val_loss: 0.8830 - val_accuracy: 0.7212\n",
            "Epoch 119/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.7280 - accuracy: 0.7550\n",
            "Epoch 00119: val_loss did not improve from 0.87991\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.7280 - accuracy: 0.7550 - val_loss: 0.9565 - val_accuracy: 0.7070\n",
            "Epoch 120/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.7178 - accuracy: 0.7577\n",
            "Epoch 00120: val_loss did not improve from 0.87991\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.7178 - accuracy: 0.7577 - val_loss: 0.9301 - val_accuracy: 0.7075\n",
            "Epoch 121/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.7030 - accuracy: 0.7602\n",
            "Epoch 00121: val_loss did not improve from 0.87991\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.7030 - accuracy: 0.7602 - val_loss: 0.9507 - val_accuracy: 0.7051\n",
            "Epoch 122/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.7078 - accuracy: 0.7580\n",
            "Epoch 00122: val_loss did not improve from 0.87991\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.7078 - accuracy: 0.7580 - val_loss: 0.9599 - val_accuracy: 0.7013\n",
            "Epoch 123/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.7145 - accuracy: 0.7571\n",
            "Epoch 00123: val_loss did not improve from 0.87991\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.7145 - accuracy: 0.7571 - val_loss: 0.9003 - val_accuracy: 0.7226\n",
            "Epoch 124/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.7195 - accuracy: 0.7525\n",
            "Epoch 00124: val_loss did not improve from 0.87991\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.7195 - accuracy: 0.7525 - val_loss: 0.9214 - val_accuracy: 0.7136\n",
            "Epoch 125/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.7051 - accuracy: 0.7566\n",
            "Epoch 00125: val_loss did not improve from 0.87991\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.7051 - accuracy: 0.7566 - val_loss: 0.9296 - val_accuracy: 0.7098\n",
            "Epoch 126/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.7086 - accuracy: 0.7574\n",
            "Epoch 00126: val_loss did not improve from 0.87991\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.7086 - accuracy: 0.7574 - val_loss: 0.9024 - val_accuracy: 0.7169\n",
            "Epoch 127/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.6872 - accuracy: 0.7654\n",
            "Epoch 00127: val_loss did not improve from 0.87991\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.6872 - accuracy: 0.7654 - val_loss: 0.9333 - val_accuracy: 0.7131\n",
            "Epoch 128/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.6933 - accuracy: 0.7601\n",
            "Epoch 00128: val_loss improved from 0.87991 to 0.87616, saving model to new2(2).hdf5\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.6933 - accuracy: 0.7601 - val_loss: 0.8762 - val_accuracy: 0.7202\n",
            "Epoch 129/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.6888 - accuracy: 0.7617\n",
            "Epoch 00129: val_loss did not improve from 0.87616\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.6888 - accuracy: 0.7617 - val_loss: 0.9360 - val_accuracy: 0.7183\n",
            "Epoch 130/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.6939 - accuracy: 0.7662\n",
            "Epoch 00130: val_loss did not improve from 0.87616\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.6939 - accuracy: 0.7662 - val_loss: 0.9660 - val_accuracy: 0.7103\n",
            "Epoch 131/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.7065 - accuracy: 0.7607\n",
            "Epoch 00131: val_loss did not improve from 0.87616\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.7065 - accuracy: 0.7607 - val_loss: 0.9007 - val_accuracy: 0.7231\n",
            "Epoch 132/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.6899 - accuracy: 0.7634\n",
            "Epoch 00132: val_loss did not improve from 0.87616\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.6899 - accuracy: 0.7634 - val_loss: 0.8801 - val_accuracy: 0.7278\n",
            "Epoch 133/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.6900 - accuracy: 0.7675\n",
            "Epoch 00133: val_loss did not improve from 0.87616\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.6900 - accuracy: 0.7675 - val_loss: 0.9053 - val_accuracy: 0.7155\n",
            "Epoch 134/1000\n",
            "126/127 [============================>.] - ETA: 0s - loss: 0.6815 - accuracy: 0.7608\n",
            "Epoch 00134: val_loss did not improve from 0.87616\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.6839 - accuracy: 0.7601 - val_loss: 0.9032 - val_accuracy: 0.7160\n",
            "Epoch 135/1000\n",
            "126/127 [============================>.] - ETA: 0s - loss: 0.6892 - accuracy: 0.7668\n",
            "Epoch 00135: val_loss improved from 0.87616 to 0.86031, saving model to new2(2).hdf5\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.6893 - accuracy: 0.7670 - val_loss: 0.8603 - val_accuracy: 0.7268\n",
            "Epoch 136/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.7000 - accuracy: 0.7628\n",
            "Epoch 00136: val_loss did not improve from 0.86031\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.7000 - accuracy: 0.7628 - val_loss: 0.9113 - val_accuracy: 0.7231\n",
            "Epoch 137/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.6866 - accuracy: 0.7678\n",
            "Epoch 00137: val_loss did not improve from 0.86031\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.6866 - accuracy: 0.7678 - val_loss: 0.8856 - val_accuracy: 0.7150\n",
            "Epoch 138/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.6930 - accuracy: 0.7675\n",
            "Epoch 00138: val_loss did not improve from 0.86031\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.6930 - accuracy: 0.7675 - val_loss: 0.9036 - val_accuracy: 0.7160\n",
            "Epoch 139/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.6815 - accuracy: 0.7664\n",
            "Epoch 00139: val_loss did not improve from 0.86031\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.6815 - accuracy: 0.7664 - val_loss: 0.9286 - val_accuracy: 0.7160\n",
            "Epoch 140/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.6870 - accuracy: 0.7628\n",
            "Epoch 00140: val_loss did not improve from 0.86031\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.6870 - accuracy: 0.7628 - val_loss: 0.9081 - val_accuracy: 0.7207\n",
            "Epoch 141/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.6711 - accuracy: 0.7692\n",
            "Epoch 00141: val_loss did not improve from 0.86031\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.6711 - accuracy: 0.7692 - val_loss: 0.9181 - val_accuracy: 0.7198\n",
            "Epoch 142/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.6833 - accuracy: 0.7626\n",
            "Epoch 00142: val_loss did not improve from 0.86031\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.6833 - accuracy: 0.7626 - val_loss: 0.8841 - val_accuracy: 0.7250\n",
            "Epoch 143/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.6853 - accuracy: 0.7643\n",
            "Epoch 00143: val_loss did not improve from 0.86031\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.6853 - accuracy: 0.7643 - val_loss: 0.9200 - val_accuracy: 0.7075\n",
            "Epoch 144/1000\n",
            "126/127 [============================>.] - ETA: 0s - loss: 0.6797 - accuracy: 0.7711\n",
            "Epoch 00144: val_loss did not improve from 0.86031\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.6809 - accuracy: 0.7703 - val_loss: 0.9209 - val_accuracy: 0.7179\n",
            "Epoch 145/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.6809 - accuracy: 0.7650\n",
            "Epoch 00145: val_loss did not improve from 0.86031\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.6809 - accuracy: 0.7650 - val_loss: 0.8818 - val_accuracy: 0.7283\n",
            "Epoch 146/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.6701 - accuracy: 0.7684\n",
            "Epoch 00146: val_loss did not improve from 0.86031\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.6701 - accuracy: 0.7684 - val_loss: 0.8914 - val_accuracy: 0.7235\n",
            "Epoch 147/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.6572 - accuracy: 0.7722\n",
            "Epoch 00147: val_loss did not improve from 0.86031\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.6572 - accuracy: 0.7722 - val_loss: 0.8917 - val_accuracy: 0.7268\n",
            "Epoch 148/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.6652 - accuracy: 0.7687\n",
            "Epoch 00148: val_loss did not improve from 0.86031\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.6652 - accuracy: 0.7687 - val_loss: 0.8838 - val_accuracy: 0.7235\n",
            "Epoch 149/1000\n",
            "127/127 [==============================] - ETA: 0s - loss: 0.6742 - accuracy: 0.7672\n",
            "Epoch 00149: val_loss did not improve from 0.86031\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.6742 - accuracy: 0.7672 - val_loss: 0.8898 - val_accuracy: 0.7221\n",
            "Epoch 00149: early stopping\n",
            "Training completed in time:  0:02:47.997222\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = modelc2.predict(X_val2)\n",
        "\n",
        "# finding class with larget predicted probability using argmax of numpy \n",
        "y_pred = np.argmax(prediction, axis = 1)  # prediction using model \n",
        "y_val_orig = np.argmax(y_val, axis = 1) # original y_val\n",
        "#print(y_pred)"
      ],
      "metadata": {
        "id": "OOR_XDVz0d9e"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_val_orig, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yiFqS65E5iL3",
        "outputId": "a6c8b7ba-6904-457a-e37b-733386ca275c"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.14      0.09      0.11        53\n",
            "           1       0.29      0.33      0.31        51\n",
            "           2       0.12      0.16      0.13        51\n",
            "           3       0.28      0.42      0.34        31\n",
            "           4       0.25      0.19      0.21        64\n",
            "           5       0.00      0.00      0.00        30\n",
            "           6       0.31      0.15      0.21        71\n",
            "           7       1.00      0.05      0.10        20\n",
            "           8       0.93      0.82      0.87       214\n",
            "           9       0.71      0.90      0.80        84\n",
            "          10       0.63      0.85      0.72       199\n",
            "          11       0.85      0.67      0.75       227\n",
            "          12       0.81      0.80      0.80       209\n",
            "          13       0.89      0.89      0.89       180\n",
            "          14       0.59      0.96      0.73        67\n",
            "          15       0.88      0.90      0.89       198\n",
            "          16       0.83      0.93      0.88       168\n",
            "          17       0.83      0.81      0.82       199\n",
            "\n",
            "    accuracy                           0.72      2116\n",
            "   macro avg       0.57      0.55      0.53      2116\n",
            "weighted avg       0.72      0.72      0.71      2116\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "cnf_matrix = metrics.confusion_matrix(y_val_orig, y_pred)\n",
        "plt.figure(figsize=(10,8))\n",
        "ax= plt.subplot()\n",
        "\n",
        "sns.heatmap(cnf_matrix,annot=True, fmt='.5g', ax=ax,cmap=\"YlGnBu\");\n",
        "plt.rcParams.update({'font.size': 30});\n",
        "ax.set_xlabel('Predicted Values', fontsize=10, color='Black');\n",
        "ax.set_ylabel('Actual Values',fontsize=10, color='Black'); \n",
        "plt.xticks(fontsize=14, rotation=90);\n",
        "plt.yticks(fontsize=14, rotation=90);\n",
        "\n",
        "ax.set_title('Confusion Matrix \\n', color='Black', fontsize=23);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        },
        "id": "8En0NDsf5iOh",
        "outputId": "a81645a5-0392-4756-9360-cc832f7e8079"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmEAAAIaCAYAAABoEJpJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydd3gUxfvAP5OiQICETmiBEGooSofQFFS+gFIsIKjYQEQRO4oFkCL6LTZQARX8iSJKEQsoXUBq6EkgkEBCRyAkJIQAuczvj71cLsnV5HbvEufzPPvcltmZeWdm996deecdIaVEoVAoFAqFQmEsft7OgEKhUCgUCsU/EaWEKRQKhUKhUHgBpYQpFAqFQqFQeAGlhCkUCoVCoVB4AaWEKRQKhUKhUHgBpYQpFAqFQqFQeAGlhCkUHkYI0VUIsUoIkSqEkOatp8F5mGROd76R6SpACDHfXPaTvJ0XhULh2yglTFEiEEJECiH+J4TYLYS4IIS4IYS4KITYKoR4VwjRxNt5BBBCNAfWAHcAGcAW4C8gzZv58mWsFFUphPi3k7BdC4Qf6KE81Dcrrs97Ij6FQqFwBaWEKXwaIUSgEGIWsB94AWgNpAC7gYtAe+A1IE4IMdVrGc3jCeBmYDlQT0oZJaXsKqXcY3A+LgDxwBmD0y0uw4UQ/g6uj9Ap3frARMATStgZtLK/4IG4FApFKUYpYQqfRQjhBywDxgBZwASgmpSysZSyo5SyMVAdGA2cArp6LbN5NDP//iGlzPFWJqSUM6WUTaWUr3srD0XgEBCK1otYCCFEWeABIBU4a2C+3EJK+bq57Gd6Oy8KhcK3UUqYwpd5FegHXAN6SynflVKmWAeQUqZIKWcDzYElXshjQcqaf696NRclk/8z/z5i5/ogoCKwCK1NKBQKRYlGKWEKn0QIUR5NCQOYJqXc6ii8lDJDSvmJjXgqCCHeEkLsFUJkCCGuCCEOCCHeEUIE20l7g9ne6FEhRA0hxGdCiJNCiGtCiKNCiOlCiDK27gF6mk/Ns7Jb2mAOUz/3nAO5LWnbuDZUCLGmgE1cnBDiSyFEtwJhHRrmm/PymRAiUQiRZZ5EsEkI8aS94UAreeoLIdoKIZab83JVCLFHCPGYPblcZBVaD9dAIURFG9dzhyK/theBEOImIcS9ZuP4GCHEJbN8iUKIOUKICBv3bADWmw/DCticSSFEfXO4nubjJPPxCCHEFqsJGLnhChnmCyGChRBJjgz2hRD/MV+PF0IE2S8mhUJRWgjwdgYUCjv0BSoBJuCzokQghKiDZiTfBJBALJADtDBvDwkhekspj9qJoi6a7VlV870moAHwOtASuNsq7AG056klWm/NEeBvq2vFQgjxLprtG8A5YB8QBNRDGwKVwCYX47odzWatPFqPXQwQgjac2xW4VwgxSEqZZSeKfwEfAplAIpo91S3AV0KIKlLK/7grnxkTsAB4GW3Y8QurPNcGegOHpZRbhRD24mgMLEar53PAUbTeyTBgJDBUCHGnlHKb1T0HgCpobeIaEF0gzkLlIIT4BHgWOA0cRisDu0gp04QQw4E/gTeFEGuklJut4rsTeBG4DjwopbziKD6FQlFKkFKqTW0+twEfoykW+4oRx5/mOA4AjazON0BTriTaH65fgfs2mK9dR7NJq2J1bRCasiCBO2ykmXvvozau1Tdfkw7yXOh+NCUwG7gB3AsIq2sC6AHcWyCeSeZ45hc4Xw3NYFyiDesFW127DW3SgwT+ZyNv0qpc3gICzef9gP+ar10BKrpZT7nx3oKmCElgY4Ewr5nPv2E+TjIfDywQrgYwHKhU4Hx5qzI5ZF2G5us9zdeSHOQzN0w2mgJ6n9W1ACDAvD/fHG6SjTgmmq8lAyFWdXLGfP5lbz97alOb2ozb1HCkwlepbf6110vlECFEd6A72h/bg1LKI7nXpJTHgPvRlKm2aL1utkgBHpZSXrS6dxnws/mwX1HyVgQiAH8gRkq5REppGc6UGn9KKV21h3sardfnFJpsFtcZUsr1aL0xAGOEEFXtxLFaSjlFSnnDfF8OWu/gOaAccLsbsuVDShmDpiB3FUKEW10agVaX3zi5/5yU8lsp5aUC5zOklJPQ3IU0AToUNY9odfG2lHKxVfzZUspsF+6dCmxG68Gcaz43D6gJrEZTZhUKxT8EpYQpfJVcm6CMIt6fq1itMf+x50NKmYg2JGcdtiALpZS20t9u/m1YxLy5y3Hzb2MhRJtixpUr66dSyus2ri9AU6Zuxr4yNafgCXNce82HxS2Xr9F6+B4BEEJ0BJoC66WUxx3daA4vhBB3CiE+FEL8KoTYKITYLITYDDQyB7vVA3l0GymlCXgIbYbnfUKIlWjK/AVghLWCrVAoSj9KCVP4KpfNv+WLeH+u89ZCCpgVubZaTe1cT7BzPtfWq6h5cwsp5WngO7RepmizMfg0IURfIUQFN6NzWC7m3pxD5kNvlct3aEOvDwvN+MupQX4u5vJYA/wBjENTcLoBUeatujlolWLk74KU8nxRb5ZSJgNPmQ/7mH8fk1KWNJ9uCoWimCglTOGrnDL/Niji/bnKyTkHYXJ9TdlTZOwZR+f6/7JrHa4Dj6H5STsGdDbv/wb8LYT4SgjhqlLh8+UipbyAJls40AsYitYj6sqQ63/RevDOAY+a4ygrpRRSSkHecGZgMbLoCaP5LWh2ZaD1dP7hgTgVCkUJQylhCl8ld+ZYCwe2SY5IN//WcBCmZoGwemMZahL2p/fZdE0gpbwuNT9pDdEU04fR/GqZ0BS0pUJzbusMXywXW+T2en2BNkt2sXQyY1AIEQA8aD58TEr5tZTymMw/y7M4PWAewVxPC9B6NnPQ7MOmeTVTCoXCKyglTOGrrESzm/FHMyZ3l3jzbwsHYXKvHXIQxpNYKxHV7YQp5MeqIFLKJCnlAinlCKAjmnLXHc1hrTMclotZkckdhjSqXGzxG5qdVJj52BUbrGrkDYVuLnjR7P+snZ17jbTFeh1tRusJ4E60odeXhRC9DMyDQqHwAZQSpvBJpJTpQO5izm8IITo7Ci+EKC+EeNbq1Arzb28hRKSN8OFA7uLPvxU3v65gHmZLNR8Wmp0nhHgAzV+XO3HGkrc4eC0Xbsktl6eFEDfZuD4MrZcsC1jnTl48iXnm5XvAWmApmrsRZ2Ra7de0cf0h7Cu/uSsclLVz3SMIITqhucrIAR6SUq4F3kAbwv0/N4aVFQpFKUApYQpfZgbwO9pMvTVCiPFCiMrWAcyeyJ9AMzS/L/e8lHIjsBHtz22hEKKR1T1hwA9ovWy70HrdjCJXCZoqhLAoTWYl82O0XpF8CCF6CyH+J4RoXeB8gBDiRTTFLRvNgaszPkNb+LwO2p++ZdUAIUQP4H+54cxKo9eQUv5HStlbSnmvK7MGze429psP/2ftdV8IMQCYhQ3Hq2ZyXaFUt6W0ewJzfr5F8yk23dxGAf6DpmzWAr7UI22FQuGbKCVM4bOY/U8NQHOJUBZNKTtvXtZluxAiHm3I6gs0paJgb8lwNG/mLYFDQoj9Qoi9aF7e26IZuT8gjV1oeyJaz1Ur4JgQYp8Q4giaofYf5t+ClAdeAPYKIVKEELuEELvQZiPm+pV6RUrpyNgeAPOsvgfQDN2HAGeEEDvNediAZjP1B5rhf0lkPJqdXH/glLmsjgM/oZXtYls3mRXOXOP4Xeb7Npg3W71qReFTtIkC24DJVmlLNHccF4EBQojRHkpPoVD4OEoJU/g0ZoP0p9CUlg/R3EpUA9qYf6OB6UAzKeXEAveeRLMBmojWU9YQbVmbQ8AUoI20v2SRLkgpE9BcJSxHGz5rbP59Bm02ny02oS2Rswztj7oRmmJ5BfgR6C6l/NCNPKxDK8/ZaDMhW6EN0/0FjAL6SftLFvk0UsrfgTvQ1oIUaPZtqWh2WP3QFDR7PERembREs9vqAZRxcI9LCCEeQvsouAwMK+jY1eyG5Enz4f+EEM2Km6ZCofB9hPINqFAoFAqFQmE8qidMoVAoFAqFwgsoJUyhUCgUCoXCCyglTKFQKBQKhcILKCVMoVAoFAqFwgsoJUyhUCgUCoXCCyglTKFQKBQKhcILKCVMoVAoFAqFwgsoJUyhUCgUCoXCCyglTKFQKBQKhcILKCVMoVAoFAqFwgsoJUyhUCgUCoXCCyglTKFQKBQKhcILKCVMoVAoFAqFwgsoJUyhUCgUCoXCCyglTKFQKBQKhcILKCVMoVAoFAqFwgsoJUyhUCgUCoXCCyglTKFQKBQKhcILKCVMoVAoFAqFwgsoJUyhUCgUCoXCCyglTKFQKBQKhcILKCVMoVAoFAqFwgsoJUyhUCgUCoXCCyglTKFQKBQKhcILKCVMoVAoFAqFwgsoJUyhUCgUCoXCCyglTKFQKBQKhcILKCVMoVAoFAqFwgsoJUyhUCgUCoXCCyglTKFQKBQKhcILBHg7A8WlSZMmG4AeLgZPjo+Pr1/gfn+gGdAOaGv+bQ2UNQeZHB8fP8mFfAigkVU8bYE2QAVzkK/j4+MfdTGfNGnSJAp4EOgJ1DLn52/gBLARWBEfH7/Z1fjMcW6gGGVVXJo0afIHcKfVqcfi4+PnuxmHR+qrqHhChgLxCeAB4GHgFqAakALEAQuB+fHx8dm+Gr+eaZjj7QK0N2/NzHFXBaQ5jQPAb8CC+Pj41CLmPxi4C7gN7ZmNACoCGcBx4C9gXnx8/M4ixm+UHIY+G3q8o6zi1q3d6l3fBdLS/flTlGxKjBKWnbNP2jrfvn1zdu6McymOWrWqhRWMp/cdHVizeofde0aPGTAxy7R1orO4Hx5xF998/Yfd6/cMjBpxI2fvCGfxXLp0mSmTv7B3uZ55i2rSNOz1Gzl7CwUQCLtxF7esLGkIf5fisOanZesLnZs2/Zl5Jhkzz1Z4PxFoM5477uzM6lVb7abzzLNDJ0rindYXQI684UowC+7K4C9uchhfWloGnTq1Ytu2/QUv1TRvt0dGNpx7+vRmatWq7lZejYjfk2nYqou9+77nltZDHSVf27z1qVy54ier18yjV68OdgMLUbjj/4u5S7nppkCuX7fZFkLMWyvg6VdeGcXkd8ZQtuzNNuOXMsfmeU/KIYT9V7anno3snKsOrxf3HQUQ6FfObvyealMSU6FznqxvgeP3oOeev8b2X+o6ULbegzbf+8Xh6vGFhspQkigxSpgrfPzJyw6vl7HxMOXk5H9xBgcHERxSnuPJ59xKu2A8QUFlqFGzMkcTT7scx4ULqTz52BQSEk4CEN6wNrf3ak/9+qGUK1eG1NR0Eo6cYNMm2y82dyhKWRWVixfTeG/GfADKlivD1cysIseVYypQXyEVCAmpQHKS6+VcFDwpA8D16zcYM2Yq0dGxAISGVuWBB/oQFhbK2bMXWLJkDYmJJ4iNTWTkyEksWvQfype3/8dldPxGpQFQo0ZlWrVqTJMmYdSqVY2goLJczbrGsaOn+P33LSQnnyEl5TLjnnuf2XPeJCrqFpfjTko6bflDrlu3Bp27tKZZ0wZUqlSRtMsZbNu6n1WrtmIy5fDzz39yMSWNuXPfxs/PfUsOPeUAY54Nvd9Rercpo+rbqGdDUfIpVUpYr972v4Lt0bJlBOHhdWgeGU6T5qHUqVON5cs28fYbX7oVT3jD2jw04i4iI+vTPLI+YfVrEr3zEE8++p5L90spefmFD0lIOIm/vx/jXx/B0AfvtPvwnzlzwa38FaQoZVVUpk39grS0DJo1b0BERF1++XljkeNq2aoR4Q3rEBkZQYvIhtSpW5OlS9cy4fWPPJjjwnhSBoCFC1daXtCRkQ2ZN28qwcHlLdcfeqg/Y8ZMY/Pm3SQknGDWrO8ZP/5xn4nfiDQCAwP45dePiIioazfM2OeGMnXqF3y/8A9MphymT/uS31Z84nIaQgh69GzHE08MpEOHFoWuDxlyF9HRsYwaOYXMzCz+2ryXZcvWc++9vXxKDtD/2TDiHaV3mzKivo2QQ09s9Rgr9OMfX9qjnhrMCy8O4667OlGnTrUix3PfAz15ZfyD9O3fmfoNQhHCvd7XHxatITr6IAAvv/IQw4b3cfj1FRpatch5NZJ163by+8ot+Pn5MXnyaPyL0INgzejRD/DSSyPo0yeKOnVreiiXjvG0DNnZJj7//AdA+1N4770X8r2gAW6++Sbef/8FypUrA8CCBb9y6dJln4jfqDT8/PwcKi4A/v7+TJjwBCEhmunl0aOnOHHirMtpvPzKCGbPftPmH3Iu7dpF8uJLD1uOly1b53L8YIwcoP+zofc7yog2ZUR9GyGHovTwj1fCfAEpJV/P+xWAuvVqMPzhf3k5R54hIyOTKZPnADBseB9atIzwco7cRw8Ztm3bR0pKGgCdO7emUaMwm+GqVAmhb99ugDa8sXbtdp+I36g0XCUwMICwsFDL8YXzrtu1F/xztEefPlGW/SOHk13PnBsURw69MeIdZUSbMqK+fenZKAoCP49vCvuo0vEBdkUf5Phx7au3X7+uRbI38UX+8+9vOHcuhZo1qzBu3DBvZ6dI6CHDX3/tsex369bGYdhu3dpa9jdt2uUT8RuVhqvk5ORw6vTfluOq1UI8nkZQUFnLflbWdY/HD8bIUVSMeEf5UpsqTn37khwK36dU2YQ9/dS7xMUdIzUtnaByZakZWoW2bZsx+N7badasvrezZ5dd5i5+gBYtG5KTk8Pyn/5k+bI/SUg4SWZmFlWqBHPLrY0ZOLgnUVGti52m3mUVvTOWH39YDcAbbz1JUPmyTu7wPfSS4fDh45b9yEjHPWstWuRdP3LkuIOQxsVvVBquIKXkow+/s/QaNWvWgLo6DMUdOZLXG1KrVtHNFuxhlBxFxYh3lK+0KS3Oote3L8lRFJRNmLGUKiVs48a8L5C0tAzS0jKIP5TMd9/+zqDBPXnzrScpU8ax2wBvEBt71LJfLqgMjz4ymd27DuULc+bMBc6cucDKFVu4866OTHv3GbtTp11Bz7K6du06b7/1OVJKet/R0aHbAF9FTxmSkk5Z9mvXduwaombNqvj7+2Ey5ZCcfBoppVN7Q73jNyqNgmzatJtr17SZbVlXr5F8/CxrVm/j0KEkAEJCKjBl6hi343WFHxatsuz36NnWQUjneFOOomLEO8obbcoexalvX5KjKCglzFhKhRIWElKBqK6taR4ZTvVqlZBITp86z4YNu9m7Jx6AZUs3cOb0RWbPnUBAgPt+rvTE2vbjnYlzSUo6Q8WKQQy+T+uVys42Eb3zIL/8spHsGyZW/bGdGzdMfDLrFbfTMqKsZs38gaSk0wQFleWNN59w+35fQE8Z0tOvWPYrVaroMGxAgD/ly5cjLS2D7GwTmZlZ+YZKvBG/UWkUZMLrM7lwobCdVGBgALff3p6XX3mEOnVquB2vM3bvPsTSpZpx9s0338Sjj95TrPi8JUdxMOId5Y02ZYvi1revyKEoGZR4Jez5F4YR2SKcwMDCoowcNYg1q3fw2vhPuHr1Gtu2HeDLL5bz1OjBXsipfdLTMy37SUlnqFevJl99/TY1a1axnB8wsAcPDOnNyCemkpFxlfXrolm5Ygv/6tvF5XSMKKuDB48xf97PAIx7fhg1alRxcofvobcMmVY+xm6+2Xlvo3WYK1euOn1J6x2/UWm4Snh4bTp3bkXlysEeizOX8+cv8cLz/7b4AXxu3DBq1tRnZrKechQXI95RvtCmPFHfviBHcfB2T9w/DV37HYUQdYQQ04QQ64UQB83beiHEVCGE4znbLnLLrY1tKhW59L6jA5PeecpyPO+rn+15S/YaOTn5HRRPfffpfC+3XFq2iuC55/M8by/4ZqVb6ehdViaTibfe+JTsbBMtW0YwbHgft/LnC5QGGUormzZ/xcFDS4k7uISd0Qv47rvpDH3wLhISTjBp0myGDBlvMR73BJmZWTwzZjrnzl0EoEfPdjz++IBix2u0HJ7AqHeUN9GrvhUKR+imhAkhugIHgfuBWOA78xabe04IEWU/Bs/Rv39XGjSoBWhfdLt3xxuRrMsEBZWx7DdsWIc2bZraDTtwUE8CArUhwpgDCWReKZ7n9oIUp6zmz/uFuLijBAT4M3nK0yVylqcRMuT6BgLN9swZ1mFc+UrWO36j0rCHEILy5ctxa5umTJz4FJ9//gb+/n4kHDnBE49PztcTUVSuXbvOmKensX//EQDatGnGBx+87NFeAiPk8BRGvKO82aY8Wd/elMMz+OmwKeyhZ+l8CMyTUjaWUj4rpZxi3p6VUjYB5pnD2EUIMUoIES2EiJ47Z3GxMtO+Q3PL/rGjpxyENJ4KFYMs+80jGzgMW65cGRrU15QkkymHU6f+dhi+KBSlrJKTzzBr5iIAHhnRn6ZN63s8X3pjlAwVKuTVtzMHjdnZJjIytKGgwMCAfC94b8VvVBqu0rXbrQwcdBsAJ0+eY/nyDcWK7/r1G4x9dgbbth0AoFWrRsyZ+5bH810QT8vhSYx4R3mrTXm6vn3p2VD4PnrahEUCwx1c/wwY5SgCKeUcYA7YX8DbVXI9UUN+w0lfoH79ULZviwGgQgXn64eVtwqTnpHpIGTRKEpZ/frLJrKyriOEwN/fn88/s600x1s5PtywPppz51IA6BLVmlatGhUj18XHKBnq16/NyZPa2qSnTv3t0Aj77NkLmMxrAtar59pKDHrHb1Qa7tCt660sWbwWgB07YnjwwaINI9+4kc3z4/7Nxo27AWjePJy5X0w0bF0/T8nhaYx4R3mjTelR3772bLiLmh1pLHoqYWeAKMDeeFaUOYwhpKamW/atv1R8gcZN8jwqWxvA2iPDKkwFHf4cilJWUkrL79w5S126Z/Xq7axerXmJLleujNeVMKNkaNy4Hps3ay/92NgEOnZsaTdsTEyCZb9Ro3ou5Unv+I1Kwx2sh3HSLxftwyQ728RLL/2Xdet2ANC4cRhffjXJZS/rnsATcuiBEe8oo9uUXvXta8+GuyglzFj0LO3/AJ8LIT4XQtwrhOhq3u4VQnwOzALe1zH9fETvzHM2WL9+qIOQxtOt2y2W/bjYYw7DZmZmcSzpNAABgf7UruPYD01R8OWyKg107ZrnRTv3ZW0Pay/a1t61vRm/UWm4Q7KVIXulShUchLSNyWTi1Vc+YNUfWwGIiKjLvPmTnboY8DTFlUMvjHhHGdmm9KxvX3s2FL6Nbj1hUspPhRAXgReAJ4Bch1MmYBfwiJTyB73St+a33zZz1GzbFBRUljZt7RuVeoNatavR+pbG7Nt7mMTEk+zefciu4etPyzaQfcMEQJs2TT1uQ1DUsnp27BCeHTvEabgJr33CTz9tAGDa9GcYNPj2IufV0xglQ8eOmhuClJQ0tmzZx5EjyTbXl7t4MZUVKzYB2jT2Xr06+kT8RqXhKjk5OSxZssZyfMut7j3fOTk5TJgwkxUrNgPQoEFt5s1/hypVjF02qLhy6IkR7yij2pTe9e1Lz0ZRUGs9GouupS2lXCSl7ASUA2qbt3JSyk6eUMAWfLOC/fuOOAyzds0OJr4123L86GP9XfLdYjTPjcv783/z9c8sdkbWHDiQwMcffm85fuzxu12OvzSVVUknIMCf0aMfALShz/HjPyAtLSNfmGvXrjN+/AeWGXLDh/dz+Std7/iNSuPrr39h717Hs3OvZFxl/KsfcTBO650JDi5P375dXU5DSsnEtz9j+U/rAQgLC2X+11OoVq2Sy3E4wwg5jEDvd5QRbcqI+jZCDkXpwRBnrVLKG+hg/7V9ewzvTp9Pgwa16NipBRERdQkJqYCUklOnz7Nh/S6LF3iADh0jeXLkoHxxnDz5N0sWa96RJZpPrMOHT1iu79h+0GI4mUuvO9rRrHn+L5vLl6/wf/N+z3fu9OkLlv1DB4/nezkBdOzUgo6dWlj2hwy9g0Xfr+b48bMMuudl7r3vdpo1b8CNG9nsij7Izz9vtHxh3nd/L7p1v9XQsvIFTp44y+LFa/Kdi49Psuxv37YfU3b++rrzrs40b97QiOy5zIMP/otVq7YQHR1LbGwiAwaMZciQPoSF1eLs2QssXryaxEStHUZE1GXMGOc9dEbGb0QaO3fEMuPdeYSFhdKpU0saNapHSKWK+Pv7kZKSRlzcUdas3m75gwsI8GfK1DFuDeN98MECfvxRWx80MDCAhx/pz4EDhzlwwPF9UVG3urwkjxFygP7Pht7vKNC/TRlR30bIoSfKJsxYSrzHfIBjx05z7Nhpu9eFENx3fy/GvzaCm27KL/Lp0+eZM9u+EfbuXYfZvetwvnN161UvpISlp2cyd/YvduM5HH+Cw/En8p3zD/C3KGEAb7z1OP7+fiz8bhWXL19h3le24xv2UB/GvzbCblqOKE5Z+QKnTp/n88/td6JGR8cRHR2X71y9sFCfU8JuuimQTz99k+eee5dt2/Zz5swFPvxwQaFwkZENmTlzgtuTSfSO36g0QHMdkpzs+Buubt0aTJo8mi5d3Fs4es+evPUPb9zIZuqUuS7dt2btbLeXFtJTDjDm2dD7HaV3mzKqvo16NvRAKWHG4nv/sm7wyquP0KNHW/bvO8Kh+GRSLqaRmppOdraJihWDCKsfSps2TRk0qCf1zQ5IfRk/Pz8mvPk4/fp3ZemS9ezcEcf585cAqF69Mu3aN2PI0DtoHhnudtylraxKA8HB5Zk/fyorV25m+fJ1xMUd5dKlywQHlycioh79+nVn8ODeRV7rVO/49U5j2vRn6bdlH9E74zh06BgnTpwjNTUdKSVBQWWpWbMKzZqFc9vt7enZsy033RRYZDn0pLTIAfq+o3Ixot0aQWmRQ6EvIndavq9TXD9hLqUh9Z0S7i/094Ys0N/PjBD6vzT8hP5/RDlS3+Wr/IWyp3MVvesC9P/ClzLHeaBiIoT+383ZOVd1TyPQT3+/axKTrvELjFKeGhvqPKxqk+c9/l97If5D7ztA81FUv6NCoVAoFAqFFyjRw5EKhUKhUCg8hxGjKYo8SrwS9ugjk9i5M855QKBWrWqsXjsr3zmTKYejiSeJiT3K/phYDsYe53D8Sa5lacMjI5/uy6hn+jmM95eftvLOm4WNLp3Rrn0z5v3fW3w6czGfzXLNQ7s19wzszrR3R+c7F+Bn39uzyWQiMfEkMTEJxMYmEPKVCNEAACAASURBVBOTQPyhY2RlaQvIPvPsUMaOHeY03Rs56Q6vHzqYxNIlf7JndzynTp4nMzOLcuXKUDO0Cq1aR3DPgG60advEYRzOhvKklBZbi4MHj5GSkkZISAUaNqxL//7dGTRIH1uLkU+8w19/7bMcF9fXmd5yGFFOnkjD3jCbp9osOP9zKa4cOUUc/nKnTfnpLAOAvx1TACkle/Yc4sCBBGIOJJB49CSXUi5z6VI6Qmg2UI0bh9GjR1vuvqcHFSsW3djcM+3W9kCPJ9uUMXIYizLMN5YSr4QVlxdf+B9rVu/wStp16hbP230dN73lP//8+6xetbVYaToiJyeH92cs4LsFqyhoa5ienkl6eiZHDp9gyY/r+VffzkyZPqpIfsjS0jIss46sOX/+EufPX2Lbtv0sXLiSmTMnUKuW51YU+GnZ+nx/lsVFbzmMKCe909C7zeZSGtqU3jJcv36D4cPesHs9KyuFc+dS2LRpD59++gPvTBlDr14dfE6O0t6mFCWLUqWEffzJyw6vl7Hh5yUnJ78xbXBwEMEhQRxP/tvldNt3bMK/P3K4FjkAAZTj9fGfWr64Bg7qAUCfvp1p0rSwR+WCZGRc5c3XPwfAz08wYGA3l/MIkFPA31lwSAVCQiqQnGTfZYU7/HvGt3z7zR+W4563taFdh2ZUr1aJlJQ09u1NYNUf2zGZcli5YiumnBz++8FzbqVx/foNxoyZSnR0LAChoVV54IE+hIWFcvbsBZYsWUNi4gliYxMZOXISixb9xyOLL1+8mMZ7M+YDULZcGa6anSwWFb3lMKKcjEhD7zZrlBy28GSbMlKGGjUq06pVY5o0CaNWrWoEBZXlatY1jh09xe+/byE5+QwpKZcZ99z7zJ7zJlFRtziP1EA5SnOb8gSqJ8xYSpUS1qu3+19dLVtGEB5eh+aR4YQ3DaZ2napuDy/WDK1MzdDKTsNFbzluUcDCwmrStp227Ed4eG3Cw2s7vf+H7/McMXboGEmt2tVcziNAy1aNCG9Yh8jICFpENqRO3ZosXbqWCa9/5FY8tjh16jzffaspYP7+fnw6+xW6RLXKF2b4w/Do4/147JGpZGZmser37RwalUTTZvVdTmfhwpWWF1tkZEPmzZuab8Hdhx7qz5gx09i8eTcJCSeYNet7xo9/vNjyTZv6BWlpGTRr3oCIiLr88vPGYsWntxxGlJMRaejZZo2UwxaebFNGyBAYGMAvv35ERERdu2HGPjeUqVO/4PuFf2Ay5TB92pf8tuITn5KjNLcpRcnjH6/yjnpqMC+8OIy77upE7TpVdU1r2dINlv0Bg7oX6/6Bg3u4ff/o0Q/w0ksj6NMnijp1a7p9vyO2bYkhJ0cbgux1R/tCClguzSMbcP+QPHuXXbscL+diTXa2yeKMUgjBe++9kO/FBtoabO+//4JlvboFC37l0qXLbslSkHXrdvL7yi34+fkxefJo/P2K99joLYcR5WRUXejZZqF0tCmjZPDz83OogAH4+/szYcIThIRo3v6PHj3FiRNnHd5jtByltU15CiH8PL4p7KNKxyDS0q6wYd1uQOspumege0pYwpGTxBw4CkCFiuXofUd7j+exOKSk5L1AwsIcv9jC6oda9q9eveZyGtu27SMlJQ2Azp1b21wUF6BKlRD69tWGaq9fv8HatdtdTqMgGRmZTJk8B4Bhw/vQomVEkePKRW85jCgnb9SFHpSGNuVrdREYGEBYWN4zfuF8qkv3+ZocRaW0yKEwBqWEGcTvv+7k+nVtxmXnLi2pUcP58KU11r1gfft28bmFtatUCbbsJyc7/vI9bnU9PNx17/x//bXHst+tWxuHYbt1a2vZ37Rpl8tpFOQ///6Gc+dSqFmzCuPGeWbGlN5yGFFO3qgLPSgNbcrX6iInJ4dTp/NsaqtWC3HpPl+To6iUfDn8dNgU9ihVNmFPP/UucXHHSE1LJ6hcWWqGVqFt22YMvvd2mrlhd6QHv/y0zbI/6N6ebt2bnW3i1182F/l+I+javTWBgQHcuJHN2tU72fLXAbpEtSwULi72GD8uWgtoPWbdurtutHv48HHLfmSk496DFi3yrh85ctxBSPtE74zlxx+0xX7feOtJgsp7ZsUDveUwopyMrgu9KA1typfqQkrJRx9+Z+n9atasAXVdHPLzJTmKQ0mXQw0fGkupUsI2bsz7AklLyyAtLYP4Q8l89+3vDBrckzffepIyZYzvQTp86CTxB7XFuytVqsBtt7V1ckd+/tywm5SL2nBf4yb1iGxR9HXZ9KJ69Uq88NJQ3p+xAJMph6eenEHP29rQvkNzqlcP4WLKZfbtOWKZHdmwYW0+mvkigYGuN8GkpFOW/dq1HU/prlmzKv7+fphMOSQnn0ZKiRCuOyG8du06b7/1OVJKet/RsUhT7e2htxxGlJORdaEnpaFNeasuNm3azbVrWu9+1tVrJB8/y5rV2zh0KAmAkJAKTJk6xuX4VJvyLTkUxlAqlLCQkApEdW1N88hwqlerhERy+tR5NmzYzd49muH3sqUbOHP6IrPnTjDcOd7Py/J80vTrH0XgTe4V+0/L8mZN5bq18EUeHvEvqlYN4YP/LuTMmYtsWL+bDet35wtTuXJFxo67n353R1HWhssQR6SnX7HsV6pU0WHYgAB/ypcvR1paBtnZJjIzswgKcr3XYdbMH0hKOk1QUFneePMJt/LpDL3lMKKcjKwLPSkNbcpbdTHh9ZlcuFDY3iswMIDbb2/Py688Qp06NVyOT7Up35BD9YQZS4lXwp5/YRiRLcJt9qiMHDWINat38Nr4T7h69Rrbth3gyy+W89TowYbl78aNbH7/bafleKCbQ4kXLqSxeeNeQHu59b8nypPZ8zi972xPQKA/M6b/H3+fu1ToekrKZeZ9+Sv+Af4McnOGZ6aVHyVXbOKsw1y5ctXll9vBg8eYP+9nAMY9P4waNaq4lU9n6C2HEeVkVF3oTWloU75WF+HhtencuRWVKwc7D2yFr8lRVEqLHApjKPFK2C23NnZ4vfcdHZh07SnGv/IxAPO++pnHHr+bm26yvTSHp9m4fj9pqdqXUfPIBjRpUs+t+3/9eRPZ2dpyKD1va+P0y8qbnDh+jrFj/kti4ilq16nG9Bmj6dylJcEh5UlLzWDrlgPMmrmE48fP8fYbc0hOOsPzLw71drbzYTKZeOuNT8nONtGyZQTDhvfxdpYUJZzS2qY2bf4K0OzArly5ypHDx/n5lz/58YfVTJo0mwXfrmDWrNepV8/zbiAU+iGUIb2h/CNKu3//rjRooM3CS0/PZPdu131TFRfrochBg3u6ff9PS/+07BfFN5hR/P33JYYPnUhi4inq1avBoh+ncveAblStFkJgYABVq4Vw94BuLPpxKnXraUMUX879hY0b9jiJOY9cnzqg2dc4wzqMq1+X8+f9QlzcUQIC/Jk85Wn8iukTzBZ6y2FEORmRhhGUhjbl7boQQlC+fDlubdOUiROf4vPP38Df34+EIyd44vHJ+XqGHOFtOTxFSZdD+Qkzln9M6bTv0Nyyf+zoKQchPcf5v1PZvuUQADffHEjf/l3cun//vgQSE7W8Vq9RmaiurT2eR08x57OfuHRJW9h77Lj7CQ6xvZB4cEh5xj53v+X4u29XuZxGhQp5CwI7c2yYnW0iIyMT0IZxrV+M9khOPsOsmYsAeGREf5o2re9y3txBbzn0jt+oNIygNLQpX6uLrt1uZeCg2wA4efIcy5dvcOk+X5OjqJQWORTGUOKHI10l14Mz5Dec1JNfl2szAQF69mpNxYpBTu7Ij7VvsHsGdMXf33d15o1/5vVodercwmHYTl3yrh84kOhyGvXr1+bkyXMAnDr1t0Oj37NnL1jKvl69UJdmHP36yyaysq4jhMDf35/PP1tsM1z84WTL/ob10Zw7lwJAl6jWtGrVyOty6B2/UWkYQWloU75YF9263sqSxZormh07YnjwQedDsL4oR1Eo6XL4Qh7+SfxjlLDU1HTLvvWXip78ujzPN9jdgzq7dW9W1nX+WJl3vy/PigQ4b+UV25nvo/JW169muu4xv3HjemzerM22jI1NoGPHwn7IcomJSbDsN2rkmh2elNLyO3fOUpfuWb16O6tXa56uy5Ur45ISprccesdvVBpGUBralC/WhfWwWvrlTJfu8UU5ikJpkUNhDL7bteJhoncetOzXt1o2Ry/27k7geJLmNTq0VmU6dGri1v2rV+0gPV17ebVp2zTfUj++iPVL9+zZFIdhz5y+YNkPsTNsaYuuXfO8T+e+5Oxh7X3a2iu1L6C3HEaUk6oL35HDF2VIPp63KkalShUchMzDF+UoCiVdDmUTZiz/iJ6w337bzFGzHVhQUFnatG2qe5q/LMvrxeo/oJPbXbzLl+UZ5A+617d7wQAiGtVhV7Rm//b7iq2MfGqA3bArV+RNVnDH8WzHjtq095SUNLZs2ceRI8k212W7eDGVFSs2Adr07169OroU/7Njh/Ds2CFOw0147RN++mkDANOmP8Ogwbc7vqEAesuhd/xGpWEEpaFN+Vpd5OTksGTJGsvxLbe69r71NTmKSkmXQ82ONJYSXdoLvlnB/n1HHIZZu2YHE9+abTl+9LH+uq+7eDXzGmv+0L6AhBDcPaiTW/efOnWeHdvjAE1pvPMu33g4HdG3X95w6+zPlrFta4zNcNu2xjB39nLLcf97urqcRkCAP6NHPwBowzvjx39AWlpGvjDXrl1n/PgPLDOyhg/v53NuPfSWw4hyUnXhO3IYJcPXX//C3r2OZ5ZfybjK+Fc/4mDcMQCCg8vTt69rz3hpqAsoPXIojKFE94Rt3x7Du9Pn06BBLTp2akFERF1CQiogpeTU6fNsWL/L4jEfoEPHSJ4cOShfHCdP/s2SxesAyJba8N+Rw3mzJ6N3xFsMJ3O5/Y5baNKsrt18rVm1m0yzrVO7jo0JreWeY8bly/602JLc1aejx2bMnDxxlsWL1+Q7Fx+fZNnfvm0/puz8st55V2eaN2/oNO5B9/Zk2dI/iTlwlGvXbvDUkzO4vVc7Oke1JCSkPKmpGWz96wDr1kaTk6PJFtWtFXfe5d7SLQ8++C9WrdpCdHQssbGJDBgwliFD+hAWVouzZy+wePFqEhO1JaIiIuoyZozzXghvoLccRpSTEWno2WaNlENvjJBh545YZrw7j7CwUDp1akmjRvUIqVQRf38/UlLSiIs7yprV2y0KR0CAP1OmjnF5ONIoOVSbcowaPjQWkftn7+tk5+wrlNGxz77PurXRTu8VQnDf/b0Y/9qIQkvl7NgRy2MjJruVl7enPsTdA+0b2o8a8T/27NJm/U1571H69GsPQBn/Sk7jllLSp/c4Tpvtpr75bpJTh7TWBPrZt7Havv0AIx55w+W4AKa/O47Bg3vlO3cjJ91m2NRL6bz26qf8tXm/03jv7NORKVNHUS7ItoJ5k5/9r8K0tAyee+5dtm2zn05kZENmzpxArVr2124zSec+fGzh6tCRv3Dc4+opObwVvyfTkNh+D3mqzQII7JsEeEKOorYn8Eyb8lRd5MgbNs8/+8wM1q7dYfc+a+rWrcGkyaPp0sW2Wx0/Yd9ZdklpU47aE3jy+Wts6HTF+rfM8LhSkLT3NTXl0g4luifslVcfoUePtuzfd4RD8cmkXEwjNTWd7GwTFSsGEVY/lDZtmjJoUE/qm5216s2J439bFLAKFctyW+9b3Lp/+7ZYiwJWv0GoWwqYtwmpVIHP545n65YYVvy2hQP7Ejh3LoWrV69RtuzN1AytQutbGjFgYDdubePeRAVrgoPLM3/+VFau3Mzy5euIizvKpUuXCQ4uT0REPfr1687gwb0NXyPUXfSWw4hyUnXhO+gtw7Tpz9Jvyz6id8Zx6NAxTpw4R2pqOlJKgoLKUrNmFZo1C+e229vTs2fbIq9KUhrqAkquHKonzFhKdE+Yp8k0ndc1fld6woqLo54wT2GvJ8yTOOoJ8xTF6blwBWc9YYo87PVaeBJnPRfFRe/2BMa0KXs9YZ7EUU+Yp9C7TendnvIwtieswa3ve7zgju15VfWE2aFE94QpFAqFQqHwHGp2pLGUGCUsh+xC5z6duZjPZrnmANGaewZ2Z9q7owudL+dfzWb4Rx+ZxM6dcS7FXatWNVavnWXzWg7OvzAPHUxi6ZI/2bM7nlMnz5OZmUW5cmWoGVqFVq0juGdAN9q0tT+U50ovVXHT8MP+V6ynysoZUkpLN//Bg8dISUkjJKQCDRvWpX//7gwa5Lyb3yQLO4r1ZJtypdfCE3J4M3690zCZTCQmniQmJoHY2ARiYhKIP3SMrCyt1+mZZ4cyduww1/Jpp2fEU2n4CfsypqdfYfOmPWzfHkNcXCLJx89yJSOTcuXKEBpajTZtmjJ4cC9auuDs1xGeeS5c6wnbvfsQK3/bws4dsfx9/hLXsq5TuXIwNUOr0LZdM7p3v9WuOyAhbP/1eLK+nfVUlfRnQzfUcKShlBglzJPUqVM0I2Q9ycnJ4f0ZC/huwSoKDhGnp2eSnp7JkcMnWPLjev7VtzNTpo9y29WGEWkYgT2D1/PnL3H+/CW2bdvPwoUri2Vw7i5FaVN6y2FEOemdxvPPv8/qVVudBywGeqfxxdylfPzxQq5fL6zcXL58hcuXrxAfn8TChb9zzz09mPzOmEITiFzBqOfi0qXLTJn8Bav+2F7o2pkzFzhz5gJ7dsezaeMelix73624jahvKB3PhqJ0UKKVsD59O9OkaWEneAXJyLjKm69/DoCfn2DAwG5FTvPjT152eL1MEV6eAP+e8S3ffvOH5bjnbW1o16EZ1atVIiUljX17E1j1h7YW5coVWzHl5PDfD57zuTSs0aOsrl+/wZgxU4mOjgUgNLQqDzzQh7CwUM6evcCSJWtITDxBbGwiI0dOYtGi/1C+fDmX4zeqTekth97xG5VGTgH3MMEhFQgJqUBy0mm34vFmGklJpy0KWN26NejcpTXNmjagUqWKpF3OYNvW/axatRWTKYeff/6TiylpzJ37Nn5+rvdIGFEXABcupPLkY1NISDgJQHjD2tzeqz3164dSrlwZUlPTSThygk2b9rodNxhT36Xl2dALZZhvLCVaCQsPr014eG2n4X74Ps8nTIeOkdSqbXvY0RV69XbPr5UrnDp1nu++1ZQjf38/Pp39Cl2iWuULM/xhePTxfjz2yFQyM7NY9ft2Do1Kommz+j6TRkH0KKuFC1daXmyRkQ2ZN28qwcF5kxEeeqg/Y8ZMY/Pm3SQknGDWrO8ZP/5xl+M3qk3pLYfe8RuVRstWjQhvWIfIyAhaRDakTt2aLF26lgmvf+RWPN5MQwhBj57teOKJgXToUHhx+yFD7iI6OpZRI6eQmZnFX5v3smzZeu69t7CbDXsYURdSSl5+4UMSEk7i7+/H+NdHMPTBO+0qi2fOXLB53hFG1HdpeTYUpYN/hMq7bOkGy/7Awb63BNC2LTEWB6a97mhfSDnKpXlkA+4fkuc/aNcux96rjU5Db7KzTXz++Q+A9sf23nsv5Huxgbb8x/vvv2BxcLtgwa9cunTZ43kpTpvSWw4jysmouhg9+gFeemkEffpEUaduTbfu9ZU0Xn5lBLNnv2lTAculXbtIXnzpYcvxsmXrXI7fqLr4YdEaoqO1NXhffuUhhg3v47C3LjS0qlvxg/51UZqeDb0QQnh8U9in1CthCUdOEnPgKAAVKpaj9x3tvZyjwqSk5D18YWGOXzzWC3lfvVrYsNybaejNtm37SElJA6Bz59Y212MDqFIlhL59teHB69dvsHZtYduV4lDcNqW3HEaUk6/URUmg4B+wPfr0ibLsHzmc7HL8RtSFlJKv5/0KQN16NRj+8L9cvteXUM+GcwR+Ht8U9in1pWPdY9G3bxefNDSvUiXYsp+cfNZh2ONW18PDXXdAa0QaevPXX3ss+926tXEYtlu3tpb9TZt2eTQfxW1TesthRDn5Sl2UJoKCylr2c2cDuoIRdbEr+iDHj2vvhX79urplr+ZLqGdD4WuUaJswZ2Rnm/j1l82W40H39ix2nE8/9S5xccdITUsnqFxZbTp222YMvvd2mhXRdqpr99YEBgZw40Y2a1fvZMtfB+gS1bJQuLjYY/y4aC2g9WZ16+66N34j0iiIp8vq8OHjlv3IyAiHYVu0yLt+5MhxByHdwxNtSm85jCgnX6iL0saRI3m9X7VquW5jaERd7DIPQwK0aNmQnJwclv/0J8uX/UlCwkkyM7OoUiWYW25tzMDBPYmKsr1ckbdRz4ZzlGG+sZRqJezPDbtJuagNwzVuUo/IFuHFjnPjxryvnLS0DNLSMog/lMx33/7OoME9efOtJylTxr2ekerVK/HCS0N5f8YCTKYcnnpyBj1va0P7Ds2pXj2EiymX2bfniGXmYsOGtflo5osEBrpefUakURBPl1VSUt7C6rVrO57SXbNmVfz9/TCZckhOPo2U0iO2CZ5oU3rLYUQ5+UJdlDZ+WLTKst+jZ1sHIfNjRF3Exh617JcLKsOjj0xm965D+cLkuqdYuWILd97VkWnvPlMkVxt6op4Nha9RqpWwn5ZttOwPHFQ8g/yQkApEdW1N88hwqlerhERy+tR5NmzYzd49mvH6sqUbOHP6IrPnTnDbAd/DI/5F1aohfPDfhZw5c5EN63ezYf3ufGEqV67I2HH30+/uqCK93IxIA/Qrq/T0K5b9SpUcL2sUEOBP+fLlSEvLIDvbRGZmVr7hnqLiiTaltxxGlJMv1EVpYvfuQyxdqhnj33zzTTz66D0u32tEXVw4n2rZf2fiXJKSzlCxYhCD79N6tbOzTUTvPMgvv2wk+4aJVX9s58YNE5/MesVlOYxAPRsuoJRAQym1StiFC2ls3qj5qgkMDKD/PVFO7rDP8y8MI7JFuM1eoZGjBrFm9Q5eG/8JV69eY9u2A3z5xXKeGj3Y7XR639megEB/Zkz/P/4+d6nQ9ZSUy8z78lf8A/wZVMRZnnqnoWdZZWZmWfZdscOyDnPlytViv9w81ab0lsOIcvJ2XZQmzp+/xAvP/5ucHM1H1nPjhlGzpuszC42oi/T0TMt+UtIZ6tWryVdfv03NmlUs5wcM7MEDQ3oz8ompZGRcZf26aFau2MK/+nZxVRTdUc+GC6jRSEMptcX968+byM42AZpTUmdfJI645dbGDoflet/RgUnvPGU5nvfVzza9YzvixPFz3D9oAi+O+4jAwACmzxjN+o2z2L3/a9ZvnMX0GaOpXacax4+f4+035vDh/753Ww4j0jCirLyFJ9uUQgHaH/YzY6Zz7txFAHr0bMfjjw/wcq4Kk+veJpep7z6dTwHLpWWrCJ57fqjleME3K3XPm6J0IYTwF0K0EEI8KoT4RAixVQiRKYSQ5m2Si/HMt7rH6eZG/joLIb4SQiSa85UihNglhHhTCOG2XxZdlTAhRIgQop8QoosoMNAthAgSQrytV9o/Lf3Tsm+Eb7D+/bvSoIE2kzA9PZPdu133r/X335cYPnQiiYmnqFevBot+nMrdA7pRtVoIgYEBVK0Wwt0DurHox6nUrVcDgC/n/sLGDXucxGxsGq5S1LLK9akDcO2a89lj1mE8MhTpoTaltxxGlJO366I0cO3adcY8PY39+48A0KZNMz744GW3bYKMqIugoLw0GjasQ5s2tteEBBg4qCcBgZqJQcyBBDKvZNkNazTq2XABITy/uccPwAFgHvAs0AnwesEIjf8BfwGPAeFo+aoEtAGmADFCiNvtx1IY3ZQwIUQkcBBYDmwGdgohrB2mlAcmOoljlBAiWggR/cUc1xdV3r8vgcREzTiyeo3KRHU1ZqZO+w7NLfvHjp5yEDI/cz77iUuXtIW3x467n+AQ236FgkPKM/a5+y3H3327ymY4b6XhDkUpqwoVgiz7zhwbZmebyMjQhlACAwPyvRiLgifblN5yGFFO3qyL0sD16zcY++wMtm07AECrVo2YM/etIpWNIfVdMS+N5pENHIYtV64MDeprH1kmUw6nTv3tUhpGoJ6NEkFBI+EU4Egx43wKGORkc8a7wAuAAK4AHwMPAaOB1eYwNYDlQgiX3Qro2RP2LrAVCAZqA0eBv4QQjVyNQEo5R0rZTkrZ7slRrttYWftxumdAV/z9jRl1DQmpYNm3Ns50xsY/83qbOnW271UboFOXvOsHDiT6VBruUJSyql8/bzkhZy/2s2cvYDKvQ1evXmixZxx5sk3pLYcR5eTNuijp3LiRzfPj/s3GjdqkmObNw5n7xcQirx1oTH3nOXCuUMF5PstbhUnPyHQQ0ljUs+EC3u8J2wHMAO4HwqWUVYDpxZRqlZTyJ0ebo5uFELcCr5oP04AuUspxUspvpZSzpZR3ApPN18sDcwqO/tlDT+2kE/CWlPKKlPKMlPIBtG7GDUKIxnolmpV1nT9WbrMcF3dWpDukpqZb9q2/hpxx3mrmUVB5x72u5a2uX8103Zu9EWm4Q1HKqnHjepb92NgEh2FjYvKuN2pUz0FI53i6TekthxHl5K26KOlkZ5t46aX/sm7dDgAaNw7jy68muexV3xaG1HeTvEEMayN9e2RYhangIwtTg3o2SgJSyulSytellIullMe8nR8zb6P1gAFMkFLutxFmMpoCCdAe6OtKxHoqYTcD+YzdpJQvYlbEgGZ6JLp61Q7LS6JN26b5luDRm+ideQ4N67uRrrUdwNmzKQ7DnjmdtyhuiJ0hRW+l4Q5FKauuXfO8T2/evNtByPzep629UhcFT7cpveUwopy8VRclGZPJxKuvfMCqP7YCEBFRl3nzJxd7gocRddGtW97oSlys4//FzMwsjiWdBiAg0J/adRz7yjIS9Wy4gJ8OWwlGCFEByF2n6zIw31Y4KaUEPrE6NcSV+PUsnnigXcGTUsoXgB/RbMU8zvJlecbTg+41rhfst982c9Rs2xQUVJY2be0brhYkolEdy/7vK7Y6DLvS6ro7jkKNbwgXOwAAIABJREFUSMNVilpWHTu2onJlbfmlLVv25fMwbs3Fi6msWLEJ0KZ/9+rVsVj59XSb0lsOI8rJW3VRUsnJyWHChJmsWKGtttCgQW3mzX+HKlVCih23EXVRq3Y1Wt+iDWAkJp5k9+5DdsP+tGwD2Te0WcRt2jT1KTsn9Ww4Rwrh8a2E0wOtUwlgo5TSUVfwH1b7fVyJXE8lbBnwoK0LUspxwALyuvc8wqlT59mxPQ7Q/tzvvKv4jXrBNyvYv8+xTeDaNTuY+NZsy/Gjj/V3az3Bvv06W/Znf7aMbVtjbIbbtjWGubPzdNf+93T1qTT0LquAAH9Gj34A0BYUHj/+A9LSMvKFuXbtOuPHf2Dx1TN8eL9i9TTo0ab0lsOIcvJGXZRUpJRMfPszlv+0HoCwsFDmfz2FatUqeSR+o+riuXF5H/Zvvv4Z584V7lE/cCCBjz/Mc23z2ON3u5WG3qhn4x/LXCHEcSHENSFEqhAiTggxVwjR3YV7rY2oHS7wKaU8D+Rq3dWEEE67gYXWg+b7XM/Z5TSjn85czGeztFmUg+/tyeSpo9xKw8+G79qxz77PurXRNGhQi46dWhARUZeQkApIKTl1+jwb1u+yeIEH6NAxktlz3uCmmwrHlYNtf1g3bmTzyPDJxBzQlgbx8xPc3qsdnaNaEhJSntTUDLb+dYB1a6Mt/nqiurXis9mvumzI6ck0/Ai0mYYnyyrAz7bd2vXrN3jssbeIjo4FIDS0KkOG9CEsrBZnz15g8eLVJCaeALThnu+//7ddm7PrOek2z1tTnDZ1k18Fu9c8KYc34vd0GhLbj/fJE2dZvHhNvnPx8UmsX6+ZXrRr15x27fJPNLnzrs40b97QZTk8l0aOzfj/979vmDN7CaDNgBv/2mM2fWwVJCrq1kKrVohCE8c0PFkXN3Lsf+hPmfwFi77XJoJVrBjEvffdTrPmDbhxI5td0Qf5+eeNll6w++7vxaR3bD8v9p5vT9a3sPONX9KeDWhsaFdSo+6zPa4UHNn4VLFkEEI8iuayAmCylHKSC/fMB0a4EP1vwCNSSpt2OkKIr9BcUgA8JqWc7yTdP4Fc5a6blHKzw/ClRQmTUtKn9zhOm+2ZvvluErfc6p79vyMlzBlCCO67vxfjXxthd7kfe0oYQOqldF579VP+2mzL3i8/d/bpyJSpoygX5F43v6fScKaEOcOVsrL3kgZtHcrnnnuXbdvsyxEZ2ZCZMydQq5b9DxFnSlhx25QjJQw8J4e34vdkGvaUsO3bDzDikTfcytP0d8cxeHAvl8N7Lg3bStjDD7/Bzh2xbsUPsGbtbOrUqZHvnD0lDDxXF46UsJycHGZMn8/C71bh6L9j2EN9GP/aCLuziO09356sb3tKGJSsZ0MpYcVSwgajuY/YAZwATEAd4E7zlksMECWlLORTRAixlDwXFndLKX91kq5b4UvNskXbt8Va/izrNwh1WwGzxyuvPkKPHm3Zv+8Ih+KTSbmYRmpqOtnZJipWDCKsfiht2jRl0KCe1Dc7IC0KIZUq8Pnc8WzdEsOK37ZwYF8C586lcPXqNcqWvZmaoVVofUsjBgzsxq1tmvhkGkaVVXBweebPn8rKlZtZvnwdcXFHuXTpMsHB5YmIqEe/ft0ZPLi32+t3FkSvNpWL3nIYUU5G1YXCOUbUhZ+fHxPefJx+/buydMl6du6I4/x5bfmz6tUr0659M4YMvYPmkZ63JfUk6tlwgJ/ndT4hxCjAult0jpRyjscTys8nwDNSSls+kP4rhOgGLAaqow05/hcYaSOs9ew0VzwPX7Xad/wlTinqCfMEtnrCPImjnrCShL2eME/iqCfMU7gyHFkcnPWEKfKw1xNWsrDdE+ZJHPWEeQpHPWGewojn21FPWMnC4J6w2+Z6vids/UjDe8JcjDcK2IRmn24CwqSUpwqEWQXcYT68Q0qZf7y8cJzfAsPMh8OklAsdhS/hk0cVCoVCoVAo3EdK+ReQuyyMP3CXjWDWsypcsQGy/sJw+qVfYoYjA/1s+6symUwkJp4kJiaB2NgEYmISiD90jKwsbT2uZ54dytixw2zeW5DsnKvOAwG7dx9i5W9b2Lkjlr/PX+Ja1nUqVw6mZmgV2rZrRvfut9p0uxAgbH/9SSnZs+cQBw4kEHMggcSjJ7mUcplLl9IRQuvWbtw4jB492nL3PT2oWDG/AWduGcTGJLIvJo642CSOxJ+0lMFTY+5m9DPOFwU+GJfMgX1HtfsPn+LSpXRSL2VgMmnDieENQ+nYuTlD7hvocGaXlNLSBX/w4DFSUtIICalAw4Z16d+/O4MGFb8L3hNpBIjCz1Nx68Ibcugdv6NeKk8+f96I35NpuNJLVRLqO8DPtp1mevoVNm/aw/btMcTFJZJ8/CxXMjIpV64MoaHVaNOmKYMH96JlK+eLojjrpSop7xBfSMPjlJYORNfZQJ7yZctfUqrVvisLdFvPukm1G8pMiRmOlMTbzOjYse+yepV9v1eeVMIuXbrMlMlfsOqP7Q7DNWkaxpJl7xc67y9sD+Ndu3adW1oPdSmPlStX5J0pY+jVq4Pl3HNj32f16m1273FVCevd/UUuXnS81hlAuXJlee21xxkypLAblJJk8JojCw8PF7curPGzU9+5lBTDfEdKmCefP2/E78k0nCkWJae+TYXOfTF3KR9/vJDr152bVNxzTw8mvzPG7qQbMGaCgSNKVhoGD0fersNw5DrfHI40xz0SyLVPmyulHFXg+mtoyzC6lLYQIgnIXWKihpTS4dpVJaYnzB45pvx2GMEhFQgJqUCy2WOzp7hwIZUnH5tCQsJJAMIb1ub2Xu2pXz+UcuXKkJqaTsKRE2zatLfIadSoUZlWrRrTpEkYtWpVIyioLFezrnHs6Cl+/30LyclnSEm5zLjn3mf2nDeJitK8WOfkFCiD4CCCQ8pzPPmc23kIqVSeVq3CadykLrXqVKV8+bJk3zBx/PjfbFi3h0MHj5OZeZW3356Fv78/9913h+Xe69dvMGbM1HzTsh94oA9hYaGcPXuBJUvWkJh4gtjYREaOnMSiRf9xe708I9KAoteFr8hhVDnp/fwZ8XwbkUZJr++kpNMWBaxu3Rp07tKaZk0bUKlSRdIuZ7Bt635WrdqKyZTDzz//ycWUNObOfRs/P/csXkrLO8So508XdDDM93Gc9VxZO9V0uKyBEKIaeQrYeWcKGJQCJaxlq0aEN6xDZGQELSIbUqduTZYuXcuE1z/yWBpSSl5+4UMSEk7i7+/H+NdHMPTBO+2+YM6cuWDzvD0CAwP45dePiIioazfM2OeGMnXqF3y/8A9MphymT/uS31ZoKyS0bBlBeHgdIiPDiWhWhdp1qvHzsr+Y+OY8u/HZYvZXLxHesJZd32NPjbmbL+euYOaHmt+s9977knvu6clNN2k9PgsXrrS8dCIjGzJv3tR8a+I99FB/xoyZxubNu0lIOMGsWd8zfvzjbuVR7zSKWxe+IocRdQH6P39GPN9GpFHS61sIQY+e7XjiiYF06NCi0PUhQ+4iOjqWUSOnkJmZxV+b97Js2Xruvdd1VyFGyFGa0tCNku/h3l2sl0E5bOP6BuAamtf87kKIslJKe8Nm1jZlv7uSeIk3zB89+gFeemkEffpEUaduTV3S+GHRGqKjtbUOX37lIYYN7+PwCy801JVh4zz8/Pwc/ukD+Pv7M2HCE4T8P3vnHRbF9fXx77BgoSuiFOmIAlbsImpEo1Gjgokak9gSo8GexBBb1Fhj8v5M0cSSqEmMLSqWRI1dUQOKWCiCFAFBUBBY6bC78/4xMrsr23dm2F3n47OPszt37plzzszlzJ17z7WnZtxlZubh0aMCAMDMWW/hk0/fw7Dh/eDa1lEr2bL4+LqqTf76wYwRaN/eEwDw/HkFbt2issmLRGJs3XoQANVgf/31wgaLEjdt2gQbNy6klzHZs+dvlJSof/1ZDxcy9PWFIejBhZ3qYfv+4+L+ZluGKfj7s0VTsG3bMoUBWD09egTik0/fp79HRV3QuH7AdNoQLu8/Hv14MTuyPnCSQH7ZIQAASZLlAE6++GoLYKqSuggAc2R+OqDJORh9EMY2JEnit11UrjU39zZ49/031BzBHhYW5vDwkC4eXVSodswfK/j6ukvPoYjKERQTcxfFxUIAQN++XdCunYfCYx0c7DFiRAgAqsv+/HnV4+tk4UKGpujjC7b1MCQ78ZiGv18OIpQxfHgwvZ32QPGaicowlTbE6O8/goUPxxAEMZkgiKGEil4FgiD6AzgC6Rn+TpLkIyXFVwP04Nj1BEF0VlDmSwD169rdJEnyH03OlQ/C1HAr7j5ycqhejpEj+2s9xoFJJBIJ8h5LXzG3ctR/8V9dyMnJl55DK2qW5LVrt+nfQkKCVB4fEiJ9rR4drXIpLjm4kKEp+viCbT0MyU48r5a/raykM8DrZ5dqiqm0IYbkD2OEIAgvgiDWyH5AZb6vZ/DL+wmC6PZSNUGgUk9kv1gjch5BEO8QBDGeIIhPCII4DeAKqEStAJAEYKGycyJJ8jaA+tl2dgCuEwTxHUEQkwiC+IggiH8BrHyxvxzyiWlVYvRjwtjm1ovXkADQsZMPJBIJjh29jGNRl5GenovKymo4ONihazc/jA0fhODgLqycB0mS+P67vXSPi7+/F9xYej2jir8OXEJCArVId6tW9ujePQAA8OBBDl0mMNBXZR0dO0r3p6XlqCgpDxcyNEFfX7Cth6HYiYfiVfJ3Wpq098vFRbuhEabShhiSP3Si8QfmewBQtXZVyIuPLOkAbiso6wbgQzXyogDMIElS3euMxaDGhc0HYPXi/5d5CuAdkiQ1nqHHB2FqSErKpLctrZph6uRViL+VIlcmP78I+flFOHXyOl4f1htr189WOT1bHdHR8aipoWYiVVfVIDunAOfOxiAlJQsAYG9vg9VrInSuXxNuxT3AcyG12kNtbR0e5z1D9OV7uB1PBWDNmjXBunXz6UH5WVnSJMOurqqndDs5tYJAYAaxWILs7McgSVKjhci5kPEybPiCbT0aw048ynmV/H3wwBl6e+AglRPJGmAqbYgh+eMV5hsAcQD6guoVawMqx1czAEIADwFcB/UKMl6TCkkqn9dCgiAOgurpGgDABdRSRpkAjgL4mSRJrWbm8UGYGmTH+ny1YgeysvJha2uF8LcGw9/fEyKRGHE37+PEiSsQ1Ylx5t9Y1NWJ8eOWRTrLXLJ4M4qKGgblFhbmGDy4Jz5bNLnBwr5M8/3/HULCvcwGvwsEZujbtys+/XQyAgJ86N/LyqTLc7VoYauybnNzAaytLSEUlkMkEqOyslruNYYyuJDxMmz4gm09GsNOPMp5VfwdH5+CI0eowfhNmzbB1KmjtTreVNoQQ/GHzjRyDEiS5CV9z+LF0kN7XnwYhSTJ/wAoTyyoJXwQpoayMuk6allZ+XB3d8LO376Ek5M0tciYsQMxfsIQzPhgDcrLq3DxQhxOnbyON0b0Y/RcvL1d0bdvZ7Rsacdovdrg7OKA/v27wdlZ/lVDZaV0XdOmTZuorUe2TEVFlUYNDxcyNEUfX7CthyHZiefV8HdhYQkWLviGzlk4b/4kODlpN0vcVNoQQ/CHPpB8Txyn8EGYGiQS+eTBa9Z/LBeA1dOpsy/mLZiIdWuo3Fx7/jilcxAWfXUnAGrsUUVFFdIe5OD4icv46+BZrFy5DXv+PIktWxbD3Z29MWG/71tCb1dV1iArqwBn/43Dvj3nsWHDr9i9+xi2bFkqN6bBFDEEX/DwGDKVldWYHbEOT548AwAMHNQD06erX6GDh4eHnx2pFisr6fqCPj5tERSkaGkpirFhg2BuQS3HkZiQjsqKaqVlNYEgCFhbW6JbUAesWDETW7cuhUBghvS0R/hg+iq5Jy42aW7ZFP4BHpi3cBx27fkCVlbNUVBQhGnTltENb32+G4Ba+kcdsmU0ffLjQoYymPQF23o0pp14GmLK/q6pqUXEx2tx7x41VjQoyB+bNn2m07gmU2lDjP7+MyOY//AohQ/C1GAjs0BzQKCXyrKWls3g5ekCABCLJcjLU7tigVb0D+mGsWGvAQByc5/g2LFLjNavCR383fHhh+MAUMlaf//9BADAxkZqJ3VJB0UiMcrLqde8Fhbmco2WKriQoSn6+IJtPQzJTjym6+/a2jrMnbMBMTEJAIDOndth+47lOtdpKm0If//xaAMfhKnB01OakNPGRv3aXtYyZcrKK1WU1I2Q/tJ0KDduJKooyR6yuW9u3KAaYE9PV/o3dcFnQUERxC/W63N3d9b4qZkLGdqgqy/Y1sPQ7PSqY4r+rqsTYcH8b3DlCjWxLCDAGzt+WaHX+oem0oYY/f1nAslajQk+CFODX3tptmPZQfrKKJcpY8PCgqyy3dVlz5kP8rQ9h+fPqZlAfn7SLPpJSekqj09MlO5v185dRUl5uJChDbr6gm09DM1Orzqm5m+RSIxPP/0/XLhw44V8D/y6c6XGWfWVYSptiNHffwTB/IdHKXwQpoaQkK70dnLSQ5VlKyur8TDrMQDA3EIA17aqc8ToQnaOdI3CFi1sGK9fE2Qz5tdPwe7fX9o7dvWq6rQrspmhZTNGq4MLGdqgqy/Y1sPQ7PSqY0r+FovF+HzRJpz5l5qh7+vrhl27V6lNxaAJptKG8PcfjzbwQZgaXFwd0aWrHwAgIyMX8fEpSssejboEUZ0YABAU1IHx9/sSiQSHD5+jv3ftpnySAJscOCBd47Tbi3Po3VuaruH69btymbNlefasFCdPRgOgpmaHhvZWWE4RXMjQFH18wbYehmQnHtPxt0QiwZIlm3Hy5FUAgJeXK3bt/goODswsn2YqbYjR33/8wHxO4YMwDZg3fwK9vWzxz3jypLhBmYSEdPzw3X76+7Tpb2pc/2+/ncCdO6kqy1SUVyHy8+9xP5nqjbOzs8aIEf01lqGO41HX8N+1JFBJgRVTVyvC/745iAsXqIVmLSzM8fbbrwOgkg7OmjUeAJXOITJyE4TCcrnja2pqERm5iZ5J+O67I7V6guZCBhe+YFsPLuzEozmm4G+SJLHiy59x7OhFAICHhzN2/7Yajo4tNK5DHabShvD3H482EKr+6BoSJFIVnmjuowIcOnRO7rfU1CxcvEiNV+jRIwA9enSU2//6sL5y2d7rEUmqlMpfveoXHNh/FgBga2uFcW8Nhn+AF+rqRLgVdx/Hj1+he8HeejsUK79quH6ngLBQWPec2Rtw/vwNeHg4o0+fTmjXzh32LWwhEJihuFiI5ORMnDsbS9/I5uYC/G/Tpxg6tA9lg9wnOHToPABA/EKHBw9yceXSXQBAt+7t0L27n5zM0Ne7o4O/dAzCN+v3Y++ec2jj1AJ9+gagnV9btGxpC3MLAZ4LK5D2IBcXzt9G4VNp9vhlyz7C++9Lg83a2jpMm7YccXFJAABn51aYMGE4PDxcUFBQhEOHziIjg1qk3tfXDfv3fyM3k0gTmJQhIesa/KavL2QxU+JvpvVgu34SytsIJu+/xqifSRmEihHIxuVvcYPf/ve/P7B922EA1MNX5BfTFOZLfJng4G4Kl3AjIGBdD2UYnww/TruSfMN+ZzwoSI+azHeHKcHog7DY2ARMmaxqrc+GrFs/H+HhoQ1+VxWESSQSbFi3G/v2nlHZWzTpveGI/GIKBIKGnYzqgjBNcHNrg5WrZqFfP+lC4TdiEzFlypcaHV/PqjXTMDosmP5eH4RpgoODPZYunYGRIwc02CcUlmPevPWIibmn9PjAQB9s3rwELi66jZljSoaqIEwTFPlCFlVBGMC+rZiqX1UQxuT91xj1MylDVRAGGJO/GwZh77+/FDdvJGl9TufOb1O4rJeyIAwwrjaEGxkcB2HhfzAfhB15nw/ClMBnzNcQMzMzLFk2HSNH9ceRwxdx80YyCgtLAACtW7dEj57+mDBxKAICvbWue+26ORh5/S7ibiYjJeUhHj16gtLSMpAkCSur5nBycoC/vzdeG9wTgwZ1pxfNZpI588PQq08HxN1MRUpyDh49eorSEmo9s+aWTeHoaAe/9u4IDumIN994Q+l4Nzs7a+zevQanTl3FsWMXkJyciZKS57Czs4avrztGjhyA8PAhMDdX3girg00ZXPqCbVtx4QsezeH9rRnG3oZwKYPH+DH6njAmUdUTxgTKesKYpFrccLwa01ias7t4OFco6gljEnU9YcaCqp4wHinqesKMBUU9YUyjqieM52U47gkbt4f5nrDD75nGzcEC/MB8Hh4eHh4eHp5GwGheR2raSxUfn4JT/1zHzRtJeFpYgprqWrRsaQcnZwd07+GPAQO6Iai7fqkdtJEhFkuQmZGLpKRMJCSmIDkpG2mpj1BdTfXCfBQxCrNmj9brfFav+ANRh6Lp7xGz38LsOeMblJs6eSVu3kzWqE4XF0ecPb+F/l6vR2JSJhISU5GclPVCD2rds5kRozFr9li19VZX1yL2v2TcjL2PpMSHyM5+grLnlWja1AKt27RAp87eGPFmX7zWf6DKekiSpLv5799/iOJiIeztbeDj44ZRowYgLEx9Nz9BKH4GKSurwNXo24iNTURycgaycwpQUV4JS8tmcHZ2RFBQB4SHh6JT53Zq9VUHE3o0Zv1isRgZGblITExHUlI6EhPTkZrykL4uZs+ZiLlzJ6mtR9deyRkffIVr1+7S39eum42w8MEKy5oRivVkyt9iUrceJG10EBBNVNbFhL/rJIoTD/+0+RB+3nJEjTYNGT12ANaunyX3WxMz1Xn1mNBDWQ8uU9esJj2fbN9/rMB3zXCK0QRh6igpeY7Vq37BmX9jG+zLzy9Cfn4RbsenIvrKbRyO2siZjE8XbsK5s5oN9NaFuBupOHr4Kmv11/PJwv/prcfJv//D2lW/o7KypsE+kUiMh5n5eJiZj+NHryEk5AI2bvyEzrcji7IBr4WFJSgsLEFMzD3s23dKp0G1v+w4gh9+2Ifa2oZBwfPnFXj+vAKpqVnYt+80Ro8eiFVfRSic/aUJbOrBRf0AsGDBRpw9859Ox+rL0aiLcsGLLnDpb0UwoUM9XPhbF9pqmbSabT24umYN1R9q4TPcc4pJBGFFRaX4cNpqpKfnAgC8fVwxOLQnPD2dYWnZDKWlZUhPe4To6Ducy5BIJHLf7eysYGdvhZxs/Rf3rq6uxeoVf4AkSTRv3hRVVQ2DG2X88ONnKvc3e+kPjWI9rJGT/URjmXm5RXQA1srRDn36BiKwoxdaOtigqqoGt2+l4fTJWNTU1CE6Oh5Tpy7DgQPfoHlz6SSA2to6RESskZv6PX78cHh4OKOgoAiHD59DRsYjJCVlYMaMlThw4Fut1rPLynpM/0F2c2uDvv26wL+DF1q0sIXweTli/ruHM2f+g1gswfHjl/GsWIgdO76EmZl2j49s68F2/fVIxC9dF/Y2sLe3QfaLlSPY4tkzIb7esBsA0NyyGape5FvSFq78zaYOADf+Hj6iL9p38FBbrry8CssWbwUAmJkRGDM2xKD04OKa5er+4zF+jD4II0kSny38DunpuRAIzBC5eAomvvO60kYyP7+IUxkdO/nCy9sVgYHeaOfvCNe2rXA86jpWLtut9Xm8zLYtJ/Ao5ylat7HH0GE98OfvmqWYAIDQIb20ktWpky+8vdsiINAbfv5t4NrWEcejrmLFsp1a1dO1my+mfTgCwSGdG6TxGBMWgvenDsOsD79FUaEQqalZ2LHjMObNe5cus2/fKbphCwz0wa5da+TWrHvvvVGIiFiLq1fjkZ7+CFu27Edk5HSNz48gCAwc1AMffDAWvXp1bLB/woRhiItLwkczVqOyshrXrt5BVNRFjBuneUoELvRgu/56OnVuB2+ftggM9EXHQB+0dXPCkSPnsWTx91rXpQ1r1/wCobAc/gFe8PV1w4njV3Sqhyt/K4IpHQBu/O3t7Qpvb1e15Q7ul7ZDvXoHwsXVUWMZXOjBxTXL1f3HCnxHGKcY/dvfgwfOIS7uPgDgs0XvYdK7w1U+pTo7t+JUxkczw7Dwk0l4fVgfuLbVXrYy7idnY89vVPLYRYsnwsqa2SWSXuajmeFY+MkkDBvWB65tNW9UZZnwzmDs2rMEAwZ1VZhHDQB8fF2xfOUU+ntU1Hl6WyQSY+vWgwCoP55ff72wwaLBTZs2wcaNC+kUGnv2/I2Skucan+Nni6Zg27ZlCv8g19OjRyA++fR9mXO8oHH9APt6cGGnembNGo9PP52C4cOD0dbNSevjdeHChZs4feo6zMzMsGrVLAj06JXiwt+KYFIHLv2tCVFHLtHbY8NVj+2UhSs92L5mDc0fPIaNUQdhJEnit11/AwDc3Nvg3fffMEoZ2iISibH6y98hFksw8LUuCB0apP4gA8DWTrOs08EhnenG6fHjQpSXUwOFY2LuorhYCADo27cL2rVT/GrEwcEeI0ZQr0Bqa+tw/nzDMXzKeLmxVMbw4dJEt2kPFK8Npwy29eDCTo1FeXklVq/aDgCY9O5wdOzkq1d9XPj7ZZjWwZD8nZ6Wi8SETACAja0lhgztqfGxhqSHPhi7HqQZwfiHRzlGHYTdiruPnJwCAMDIkf0ZGafRGDK05Y9dZ5By/xEsLZsicuk7jX06jCMQmKFZM+mYtOpqahzZtWu36d9CQlQHniEh3ent6OhbDJ8hYGXVnN6un1WlKWzrYUh2Yppvv/kDT54Uw8nJAfPnq5/BxhT6+PtlmNbBkPwt2ws2YkQ/NG2qejanLIakhz6Yih483GDUY8JuvXhFCAAdO/lAIpHg2NHLOBZ1GenpuaisrIaDgx26dvPD2PBBCA5WvLxMY8vQhpzsJ9j+M9UzFzFvLJycW+pUz8cz1yM5+SFKhWWwsmxOpdfo7o/wcYPh7+/J4BlrT/Gz5/STZPPmTekZkg8e5NBlAgNV9x507Cjdn5aWo6KkbqSlSXtDXFy0ez3Lth6GZCcmibuZhL8OUq/gly5rWhucAAAgAElEQVT/EFbWzdUcwRz6+FsWNnQwFH+LRGL8fUI6Uzts3CCtjjcUPfTF6PXgZ0dyilEHYUlJmfS2pVUzTJ28CvG3UuTK1KeOOHXyOl4f1htr18/Waoo5FzI0hSRJfPXl76ipqUNAoAcmTHpN57quXJE+rQmF5RAKy5Gako29f55GWPggLFv+IZo10/wplkkO/3WZ3g4JCaJ7H7Oy8ujfXV1VT+l2cmoFgcAMYrEE2dmPQZIkCAYbl4MHztDbAwd1V1GyIWzrYUh2Yoqamlp8uXwrSJLEkKG9ERqq3cQSfdHH3/WwpYOh+PvypXgUP6PGNfm1d0dgR+2WcDMUPfTF6PUwDDO+Mhh1EFZUWEpvf7ViB7Ky8mFra4Xwt6jeHJFIjLib93HixBWI6sQ4828s6urE+HHLIoOSoSmH/7qC+Lg0CARmWLbqfaWD21Vhb2+D4P5dEBDojdaOLUCCxOO8Qly6FI87t1MBUK8U8h8/w7YdSzhPJJj76Cl2/vIPAGpQ64wZb9H7ysoq6O0WLWxV1mNuLoC1tSWEQmr9y8rKarlXSvoQH5+CI0eowdlNmzbB1KnaJdtlWw9DsROTbNl8EFlZj2Fl1RxLl33AqWx9/V0PWzoYir+PRklnd44N03xAfj2Gooe+mIoePNzAeRBGEIQFSTKzaF9ZmTSzc1ZWPtzdnbDzty/h5ORA/z5m7ECMnzAEMz5Yg/LyKly8EIdTJ6/jjRH9DEaGJjx9UoIf/u8wAOCd90LRwd9d6zoWLJyEwI7esLBo6PYZH4Xh3Nkb+CLyR1RV1SAmJgG//nIMM2eF633umlJVWYNP5m1GdRU15mbSpBHo3NmP3l8pk0dJk7EmsmUqKqoYadwKC0uwcME3dN60efMnwclJu1mvbOthCHZikvv3H2L3ruMAgPkLJqFNGwc1RzAHE/4G2NXBEPxdVCTE1StUjkQLC3OMGh2s5oiGGIIeTGD0evAD6TmlMUaZVxAE4c9ERRKJ/LIUa9Z/LBcc1dOpsy/mLZhIf9/zxymDkqEJ61fvRXl5NZxdHPDxHN2exLt281MYgNUzZGgvrPxqJv19187jCjOJs4FYLMHiz7ch7QGVDDcw0Mdw8ua8oLKyGrMj1uHJk2cAgIGDemD69DGNfFamjVgsxvKlP0EkEqNTJ19Menc4Z7KZ8ndj6sAVfx+PhkhELds06LUgtT1APDw8FKwFYQRB/KDoA0AAYKnMd52xspLmxvLxaYugIOVrQo4NGwRzC+rVWmJCOiorNMtOzYUMdZw5HYfLF6mlTb5Y9g6aWzI/3qyeUaP6w8vLBQDVCxgfn8qarHokEglWLP0Vly9ST9KeXk7YsWNlg6fI+rQVADW+Rh2yZfR9uqypqUXEx2tx714aACAoyB+bNn2m0/gNtvVoTDsxze5dJ5CcnAlzcwFWrf6Ys9nJTPqbbR0Mwd9Hj0jHcWqTG0wWQ9CDCYxeD4Jg/sOjFDZbtDkAQgB0eulDAPB7sa08QyIAgiA+IggijiCIuF+2H26w38ZWmncqINBL5clYWjaDlycVXIjFEuTlabZsEBcyVCEsrcDGdfsAAEOHdUfIwM5616mOnr0C6O2HmXkqSuoPSZJYs/J3/HOCWsvNza01tv26CA4O9g3K2thIfaEusaFIJKbzi1lYmMs1jNpSW1uHuXM2ICYmAQDQuXM7bN+xXOc62dajsezENNnZ+diy+QAAYPKUUejQwZMTuUz6mwsdGtvf9+6mIyODaidat2mJ4P66zRBvbD2Ywuj1IFj48CiFzTFhSwHMALCAJEn6MYkgiDoAU0mSTFZXAUmS2wFsB4A6yR3y5f2ens6IjUkEANjYqF93y1qmTFl5pYqS3MpQxZVLd1H8rAwAYN/CBr9s/Udhufi4NHo7Lu4+tv5MBa2dO7dDv2DtAjd7ext6W3aQKRtsWLMHUYepAb3OLg7YtnMRWrdpobCsp6crcnOptSrz8p6ibds2SustKCiC+MUace7uzjrPOKqrE2HB/G9w5Uo8ACAgwBs7flmh1zpvbOvRGHZig79PRKO6uhYEQUAgEGDrz4cUlkuVSZ566WIcnjwpBgD0C+6Czp3baSWTaX9zoUNj+1s2N9joMf11mjAENL4eTGEqevBwA2tBGEmS6wmCuAhgD0EQBwEsI0lSou44bfBrL81ELDuAXhnlMmVsNGxUuZChClIm9Pxr/yWNjrkRm4QbsdS6Ze+9P0LrIKy0tIzeln2qY5pv1u/Fwf0XAQBtnFpg+85FcHZRPmDZz88dV69SfxyTktLRu3cnpWUTE9Pp7XbttJ/EAFBPqZ9++n+4cOHGC/ke+HXnSo2zrCuDbT24thNbkC8ufpIksWP7EY2OOXs2FmfPUpnHLS2baRWEseFvLnRoTH9XV9fi31Mx9HddZkXWYyrXrdHrwQ/M5xRWB1iQJBkDoDsAHwCxBEFo91iqhpCQrvR2ctJDlWUrK6vxMOsxAMDcQgDXtqrzt3Apw9CIuylNUOvp6cyKjE3fHsTePdRCv60c7bBt5+do66baXv37S7NP1zdyypDNPi2blVpTxGIxPl+0CWf+pV6T+vq6YdfuVYwMOGZbDy7tZCqw6W+2aUx/nz1zg344DereAR56tBemct2aih483MB6igqSJIUAJhAEMQPANTAY+Lm4OqJLVz/cvfMAGRm5iI9PUTpw/mjUJYjqqNk7QUEdNH73zoUMVYwO64fRYepTXWzdchzbf3qRSX/2W5g9Z7xO8v755yoyX4wDs7JqjqDuyici6MqW74/g912nAQAODrbYvvNzeHgo77Kvp3fvzmjZ0g7FxUJcv34XaWnZCtdle/asFCdPRgOgpn+HhvbW6vwkEgmWLNmMkyep7N9eXq7YtfsrhePUdIFtPbiyE9vMmTsBc+ZOUFtuyRc/4ujRSwCAtetmIyx8sFZy2PQ3Fzo0pr+PRUkH5IeN070XDDCd69bo9eB7wjiFsxQVJEnuANAfwHQAuUzVO2++tIFbtvhneiyFLAkJ6fjhu/3092nT3zQ4GWyz54+TuHc3TWWZ8+duYMXybfT3qdNGabX2mybs2HoCv2yngsUWLW2wbecieHlr9vRsbi7ArFlUcEmSJCIjN0EoLJcrU1NTi8jITXSunnffHalVbwZJkljx5c84dpR6Terh4Yzdv62Go6PicWq6wLYeXNjJVODC32zTWP7OyyvEjVhqaK+VVXO8Pky/IMJUrltj14MkmP/wKIfTZK0kST4A8IDJOnv36YgJE4fiwP6zyMkpQNjozzDurcHwD/BCXZ0It+Lu4/jxK3QP1VtvhyJkQDfOZOTmPsWRQ1S2bTFJLURdnwsLAG7GpkIsOionL/T1IJ2SsaoiNjYR69fthpeXC3r36QhfXzfY29uAJEnkPS7EpYu36Iz5ANCrdyA+nBFGf8/NfYrDL/SQkNSU6gcyetyITYFYJD/mJfT17ujgL30CPHzwEn76MYr+PuGdUORkP0FO9pMG59tUIG2QgoIC6PUj33nnDZw5cx1xcUlISsrAmDFzMWHCcHh4uKCgoAiHDp1FRsYjANQrpYgI9b0QsmzatAd//UWt7WdhYY73J49CQsIDJCSoPi44uJtWS1WxrQfb9deT+6gAhw6dk/stNTWL3o6NuQexSH4o6OvD+iIgwEcneUzDlb/Zhit/y3Is6jI95m3Y8N6M9PxzoQcX12xj+IPHODHqZYvqWbp8OgQCM+zbewbPn1dg184TCstNem84Ir+YwqmMx48LsX1blMKyAHD7Vhpu35LvoXJzb814EFbPw4eP8fDhY6X7CYLAW2+HIvKLKWjSRHp5UHooH1h8+9YD3L4lH19TekiDsLt3MuT2b90iH3wq4/ff19GDW5s0scBPPy3DvHnrERNzD/n5Rfjuuz0NjgkM9MHmzUu0nlhw+7Z0XdC6OhHWrN6h0XHnzm9TOQvqZdjWg+3668l7XIitWw8q3R8Xl4y4OPmJ0O4ezgYThHHlb7bhyt/1kCSJYzLLFGm7WLcyuNCDi2uWa38wCv86klNMIggzMzPDkmXTMXJUfxw5fBE3bySjsLAEANC6dUv06OmPCROHIiBQuwVluZbBJos+n4yBA7vj3t00pKRmo/iZEKWlZRCJxLC1tYKHpzOCgjogLGwQPF8kazVU7OyssXv3Gpw6dRXHjl1AcnImSkqew87OGr6+7hg5cgDCw4dwvu6ltrCth6nYiUczuPR3bEwSHj8uAgB4ejmjazc/NUdojqlct6aiBw+7ECTZIP2WQaIoT5ixUSsRsi6jqRkzg8dVUSspV19ITyzNHVmXQULMav0ETKNxJcH+rSdhZjlZlZgR7PpDQrJ7PQGAgGB2jKYiaiVl6gvpSRMzG/WF9ITt65bgLAupH6ddU94zDzNuuMxt4/juNSU0xtqRPDw8PDw8PDyvPEbzOlJAWDT4jSRJ3L6dgoSEdCQmpCMjMxclxc9RUlIGgqC6g/38PDBwYHe8OXogbG1Vv3cXa/g0Hh+fglP/XMfNG0l4WliCmupatGxpBydnB3Tv4Y8BA7opTO2gqpdq6uSVuHlT7SICAAAXF0ecPb9Fo7JsyGgqsNNaNgDM+OArXLt2l/6uSzqBekiSpLv5799/iOJiIeztbeDj44ZRowYgLEx9N7+6niomZLCth6qnfbFYjIyMXCQmpiMpKR2JielITXmI6mpqYsXsORMxd+4kteeo7omfCTup6+FhQoYyWzFlJ4EGPW1sX1NM1G+m4s8CF+0UwNT9zf51y4UenMOPCeMUo3kdKSGTGpxoTU0tunaZqNHxLVva4qvVEQgN7aW0jLogrKTkOVav+gVn/o1VWa59Bw8cjtrY4HdVjYIxBWGEDq91jkZdxJLFm+V+UxWEqfqjLBSW0wNelVE/4NXFRbeEucYiQ1UQNnfuepw985/S/UwEYcZiJ0C5rbiwE8C+rZiqXySpUrqPqTbE3Ez5QtXGdE1xI4Pj15GzjzD/OnJLOB/ZKcFoesJU0aZNS3Tu7If27T3g4uIIK6vmqKquwcPMPJw+fR3Z2fkoLn6O+fM2Ytv2ZQgO7qq+0pcoKirFh9NWIz2dSsvg7eOKwaE94enpDEvLZigtLUN62iNER9/RW58ffvxM5f5mDEyN50JGPc+eCfH1ht0AgOaWzVD1IjeOLtTW1iEiYg3i4qhlmZydW2H8+OHw8HBGQUERDh8+h4yMR0hKysCMGStx4MC3Wq/7ZyoyJGL5afZ29jawt7dBdpby2bGGpoMp2IkLPbiw08uw0YaYyjXVGP7gMU6MOgizsDDHib+/h6+vm9Iyc+dNxJo1v2D/vn8hFkuwbu2v+Ofkj1rJIUkSny38DunpuRAIzBC5eAomvvM6zMwUD6nLzy/Sqv6XCR2ivLeOKbiQUc/aNb9AKCyHf4AXfH3dcOL4FfUHKWHfvlN0wxYY6INdu9bIre333nujEBGxFlevxiM9/RG2bNmPyMjpr6SMTp3bwdunLQIDfdEx0Adt3Zxw5Mh5LFn8vVb1NKYOpmAnLvTgwk4vw0YbYirXVGP4gzH4RcQ5xagH5puZmakMwABAIBBgyZIPYG9PzcbJzMzDo0cFWsk5eOAc4uKo9RQ/W/QeJr07XGkABlBPPTwUFy7cxOlT12FmZoZVq2ZBoMJu6hCJxHR+H4Ig8PXXCxssrty0aRNs3LiQThy5Z8/fKCl5/srJAIBZs8bj00+nYPjwYLR1c9LqWHXwdtIctvXgyk5sYyrXlKn4g4cbjDoI0xQLC3N4eEiXxikqLNX4WJIk8dsuapkdN/c2ePf9Nxg/P1OlvLwSq1dtBwBMenc4Onby1au+mJi7KC6m0nz07dtF4XpsAODgYI8RI0IAUK8Fzp9XPYbPFGWwDW8nzWFbD95OhnVNGb0/zAjmPzxKeSWCMIlEgrzHT+nvrRw1z6V1K+4+cnKonrORI/ur7AHjkefbb/7AkyfFcHJywPz56gc2q+Patdv0dkhIkMqyISHd6e3o6FuvnAy24e2kOWzrwdvJsK4pY/cHSRCMf3iUY9RjwjSBJEl8/91euvfL398Lblq8crj14jUkAHTs5AOJRIJjRy/jWNRlpKfnorKyGg4OdujazQ9jwwchOLiL3uf88cz1SE5+iFJhGawsm1OpL7r7I3zcYPj7e+pdPxcy4m4m4a+D1Jp8S5d/CCtr5bOhNOXBgxx6OzBQda9ax47S/WlpOSpKmqYMtuHtpDls69FYdmK6DTGVa8pUrlsebjCpICw6Oh41NVSaieqqGmTnFODc2RikpGQBAOztbbB6TYRWdSYlZdLbllbNMHXyKsTfSpErk59fhPz8Ipw6eR2vD+uNtetn67W475Ur0icpobAcQmE5UlOysffP0wgLH4Rlyz9Es2b6Zc5mU0ZNTS2+XL4VJEliyNDeKtOCaENWVh697eqqetq4k1MrCARmEIslyM5+DJIkQWjwRGYqMtiGt5PmsK1HY9mJ6TbEVK4po79u+Zc9nGJSQdiSxZtRVNRwvJeFhTkGD+6JzxZN1nrRXdnxY1+t2IGsrHzY2loh/C3qaU8kEiPu5n2cOHEFojoxzvwbi7o6MX7cskjr87e3t0Fw/y4ICPRGa8cWIEHicV4hLl2Kx53bqQCAqCOXkP/4GbbtWKJTkj8uZGzZfBBZWY9hZdUcS5d9oPXxyigrq6C3W7SwVVnW3FwAa2tLCIXlEInEqKyshpWV+t44U5HBNrydNIdtPbi2E1ttiKlcU6Zy3fJwg0kFYcrw9nZF376d0bKl9pney8oq6e2srHy4uzth529fwsnJgf59zNiBGD9hCGZ8sAbl5VW4eCEOp05exxsj+mksZ8HCSQjs6A0Li4YumfFRGM6dvYEvIn9EVVUNYmIS8OsvxzBzVrhWunAh4/79h9i96zgAYP6CSWjTxkHNEZpTKZNfrGlT9U/YsmUqKqo0atxMRQbb8HbSHLb14NJObLYhpnJNGf11yw+k5xST6niMvroT91OOIPn+YdyM24O9e9dh4jvDkJ7+CCtXbsOECZH0IHtNkUjkkwevWf+xXABWT6fOvpi3QJq9f88fp7SS07Wbn8KGrZ4hQ3th5Vcz6e+7dh5Hba12ix6zLUMsFmP50p8gEonRqZMvJr07XKvz4+HhMWy4aKd4GhmCYP7DoxSTCsLqIQgC1taW6BbUAStWzMTWrUshEJghPe0RPpi+Su5JRR1WVs3obR+ftggKargmZD1jwwbB3ILqek9MSEdlhe6Z4RUxalR/eHm5AKB66OLjUxmtX18Zu3edQHJyJszNBVi1+mPGZ5LW59QBqHFn6pAto+nTpanIYBveTprDth6GZidd2xBTuaYMzR88ho1JBmEv0z+kG8aGvQYAyM19gmPHLml8rI3Mot8BgV4qy1paNoOXJ9X4iMUS5OU9VVleF3r2CqC3H2bmqSjJrYzs7Hxs2XwAADB5yih06ODJ+HnZ2Eh9oS6xoUgkRnk59SrZwsJcrmF8FWSwDW8nzWFbD0O0ky5tiKlcU4boD63g84RxyisRhAFASP9u9PaNG4kaH+fpKU3yamOjfm0va5kyZeWVKkrqRn3mf0B+AGhjy/j7RDSqq2tBEAQEAgG2/nxI4Sf1QTZ9zKWLcfTv9+6lqZXh6elKb6sLcAsKiiB+sSagu7uzxjOOTEUG2/B20hy29TBEO+nShpjKNWWI/uAxXF6ZIEy2m7fsuebBkV97abZj2UH6yiiXKWPDwoKspaVl0vplnrgaWwZJkvT/O7YfwQ/f71P4uZ/8kD7m7NlY+vf6WVWq8PNzp7eTktJVlk1MlO5v185dRUnTlME2vJ00h209DNFOurQhpnJNGaI/tIJg4cOjlFcmCMuWGZDfooWNipLyhIR0pbeTkx6qKEnNinmY9RgAYG4hgGtb1TlidCHupjR5rGwvnbHJ0IX+/aXZp69ejVdZVjb7tGxW6ldFBtvwdtIctvUwRDvp0oaYyjVliP7gMVxeiSBMIpHg8OFz9Peu3ZQPrn8ZF1dHdOnqBwDIyMhFfHyK0rJHoy5BVCcGAAQFdWD8/f4//1xF5ovxFVZWzRHUXXM92JYxZ+4EJKccVvsZO3YQfczadbPp3ydPGaVWRu/e0jQj16/fRVpatsJyz56V4uTJaADU9O/Q0N4a6WBKMtiGt5PmsK2HodlJ1zbEVK4pQ/OHtpBmBOMfHuUYdRD2228ncOeO6tdYFeVViPz8e/o1mJ2dNUaM6K+VnHnzJ9Dbyxb/jCdPihuUSUhIxw/f7ae/T5v+psb17/njJO7dVT0m6vy5G1ixfBv9feq0URrloOFSBtuYmwswa9Z4ANRrz8jITRAKy+XK1NTUIjJyEz0D9t13R6pNmGiKMtiGt5PmsK0HV3Ziuw0xlWvK6K9bfmA+pxD1Y3kMHQmZ1OBE58zegPPnb8DDwxl9+nRCu3busG9hC4HADMXFQiQnZ+Lc2Vj6BjA3F+B/mz7F0KF9FMoQk8rz2axe9QsO7KfWQrS1tcK4twbDP8ALdXUi3Iq7j+PHr9C9YG+9HYqVX33UoA5CycvxuXM24sL5OHh5uaB3n47w9XWDvb0NSJJE3uNCXLp4S27MVK/egdi2fSmaNNE81y6TMghC+yz69Sz54kccPXoJANUTFhY+WGE5AaG44a6trcO0acsRF5cEAHB2boUJE4bDw8MFBQVFOHToLDIyHgEAfH3dsH//N1qPnTMmGSSU37+5jwpw6NA5ud9SU7Nw8eINAECPHgHo0aOj3P7Xh/VFQICP3G/KrltjshOg3FZs24lpPdiuXySpUvg7k22IuZniVAzGdk1xI8OP0yjGc+lJxoOCrLUj+EhMCSYRhGmCm1sbrFw1C/36KV9gW1UQJpFIsGHdbuzbewaqbDbpveGI/GIKBIKGnYzqgjB1EASBt94OReQXU7Rem5JJGY0ZhAHUOnXz5q1HTMw9pWUCA32wefMSuLjoNi7PWGSoCsJiYxMwZfJSrc5p3fr5CA8PlftNVXBhLHYClNuKCzsB7NuKqfrVBWHq0KQNURaEAcZ1TXEjg+MgbNkp5oOwNW/wQZgSjDoIEwrLcf36XcTdTEZKykM8evQEpaVlIEkSVlbN4eTkAH9/b7w2uCcGDeqOJk0sVMpQFYTVc/fOAxw5fBE3bySjsLAEANC6dUv06OmPCROHIiDQW+mxyhrpnJwC3IhNwr27aUhJzUbxMyFKS8sgEolha2sFD09nBAV1QFjYIHi+SIKoLUzKaOwgDKC6+U+duopjxy4gOTkTJSXPYWdnDV9fd4wcOQDh4UN0WvfS2GQ0dhDGhA6awISMxg7CAPZtxUT9yoIwJtsQVUEYU3qow3hk8EGYKWPUQRjTaBKE6YMmjbQxoE8QpinqgjAeClVBGFOYynXLtq1MxU7KgjAmUReE8cjCcRD2JQtB2Fd8EKaMV2IBbx4eHh4eHh4N4BPGcorRB2GT31+OmzeTNCrr4uKI8xe2qS8oA0mSuH07FUkJGUhMzEBmRh6KS8pQWvIcBEHAzs4a7fzcMWBgN4x6MwS2tvKDK8ViCTIzcpGUlInkpIdISsxAamo2qqup9cIiZr+F2XPGqzyHqKhLWLbkJ63OGwB69gzA7t9XAgC2bD6In7Yc0rqOMWMHYt362RqV3fzjAfy05aDWMsaOHYR1G+ZqdYxsN//9+w9RXCyEvb0NfHzcMGrUAISFKe7mF4vFyMjIRWJiGpKSMpCYmIaUlIe0P+bMeQdz507SSH5W1mO6nqSkdCQlZaCigupFCAsbjA0bFrKmh6ZI67+IlJfqHzlqAMLCQvWqnyl7Nlb9srBtq3pSUh5i//5TuHkzEfn5RRCJxHB0bIGuXTsgLGywXJ4p3XVg53oCgPv3s3Dk8AXEx6cgL/cpKiurYWnZDM7OrdC5SzuMHjMQ3XVMn8OFvxvnmmLPHzzGjdEEYRJSpGSPdj2nyusBBETDMWM1tbWY/O4KpcdUVxfjyZNiXI2+g60/HcZXqyMQGtqL3r9w4UacPRuj9Pg6SSUqxYUqz7lWonr9MWW4ujlCAkpfEhLd6mgrrYNGiQ3Jl8tpiEvbVhCTNXK/6TIwv7CwBIWFJYiJuYd9+04pHPC6YMHXOHPmP6V1iySVqBY/U3vO3369D3/89q/S/S/rowh99KhHl0HzsvXvV1M/oPo13vwFX+OsCnuSL/7pCpP1s22rGrFQpXyRSIz/fbsPe34/3WBfbu4T5OY+wd9/X8bwN/pg9bqPFKZ2aCqw00sHddcTAEigeFiGRCLBxg17sHdPw8lJZWWVKCvLwYMHOTj013m8MaKvUh0AgITiHIpsX09MytB1Ioa2/uAcPqUEpxhNEKYJP/z4mcr9zbScUShLmzYt0bmzH9q394CLiyOsrJqjqroGDzPzcPr0dWRn56O4+Dnmz9uIbduXITiYyrQvkcgHP3Z2VrCzt0JOtuaLe/fs3R7ffN8w5cXLSCQkViz+jX6iGxs2kN43fERftO/goexQmvLyKixbvBUAYGZGYMzYEI3PkwsZtbV1iIhYIzf1e/z44fDwcEZBQREOHz6HjIxHSErKwIwZK3HgwLewllk+qn6dtnoof1gjJ/uJxucANPSrlVUztHFqicyMx5zo0dj11yN52Z72NrC3t0F2lmZ2aOz6Ae5stXrVTkQdvgyASpcz6s1gdO/RAU2aWiAz4zGijlzC0yclOH0qBrW1ddj0wwKN1xLkQodvNvyJP/+QPngMei0IPXr5o7VjCxQXC3H3TjrO/BsLsViCUyf/g1giwf9tmqeVDC78bUrXFI/xY1JBWOiQXuoLaYmFhTlO/P09fH3dlJaZO28i1qz5Bfv3/QuxWIJ1a3/FPyd/BAB06uQLb++2CAz0hmcHG7i2bYUTR//DV8v2aHwOTs4t4eTcUm2561eT6ADMw8MJ3XtIXwl4e7vC29tV2aE0B/dL8yX16h0IF1dHjc+TCxn79p2iG7bAQB/s2rUGdnbW9GEir9EAACAASURBVP733huFiIi1uHo1Hunpj7Bly35ERk6n93fu7AcfHzcEBvrC198Bbds64lhUNL5c+qvG5wAA3j6ueG/KMAQGeiIg0BMenk6Iu5mCD6d+zYkejV1/PZ06t4O3T1sEBvqiY6AP2ro54ciR81iy+Hut62qM+gFubBV95S4dgFlZNcOOnYvRsZN8nrGp00dg9qxvEX8rFRfO38KJ41cxeoxmDyhs65CXV4i9f1IBmEBghp+2LUK/4M5yZd59H5g6fSSmTV6DyspqnDkdi5SPstDB31NjOVz421SuKdbge8I4xagz5nOBmZmZygAMAAQCAZYs+QD29tSalJmZeXj0iFqrcuast/DJp+9h2PB+cG3bitVzPREl7WIfEzZApzqijlyit8eGD1ReUA90lSESibF1KzXmjCAIfP31QrmGDaCW/9i4cSG9ZNSePX+jpET6OnfWrPH49NMpGD48GG3bah78vcxb4wdhUeQ7GDGqLzy9nDXusWBKj8asXxY5e7o5aX18Y9fPla327pH2IM1bML5BAAZQS/xs+CYCFhbUs/GWHw6pzEnIpQ4x1xMhkVDnEjq0Z4MArJ6AQC+8PUGadubWLdUrmrwM2/7mQgaX9x8bkATB+IdHOXwQxhAWFubw8JAuVFtUWMqpfKGwAlcuJgCgnlRHj9U+CEtPy0ViQiYAwMbWEkOG9mT0HPWVERNzF8XF1Libvn27oF07xa8+HRzsMWIE1YNQW1uH8+dj9TxrZmFbD1OxExdwYSuJRIJbcdSaswRBYOSoYKVlnZwc0Kt3AAAgP/8Z4jUIYrjQobhYGiB4eKgOXDxkFuyuqlI/NtLU4O8/Hm3ggzCGkEgkyHssHefVytGeU/mn/76J2lpqYHzffp3Qpo3615cvI9tDNWJEP1bWjdRHxrVrt+ntkBDVM8hCQrrT29HRtzQ/QQ5gWw9TsRMXcGGr0tJyephAy5a2sLVTvQSOh6c0yLl65a7a+rnQwcFBOiEgO7tAZdkcmf3e3rollzZmjP7+M2Phw6MUkxoT9vHM9UhOfohSYRmsLJvDydkB3bv7I3zcYPhrMS5BW0iSxPff7aV7v/z9veDGUle6Mk4clc7ADBs3SOvjRSIx/j5xVa862Jbx4EEOvR0Y6KuybMeO0v1paTkqSnIP23qYip24gAtb6ZMQOy3tkdoyXOjQf0AXWFiYo65OhPNnb+L6tQT0C+7UoFxy0kP8deA8AKrHLGRAV41lmAr8/cejDSYVhF25In0CEQrLIRSWIzUlG3v/PI2w8EFYtvxDNGumX+9OdHQ8amqoKdzVVTXIzinAubMxSEnJAgDY29tg9ZoIvWRoy4OUXKTepxrrFi1s8Npr3dUc0ZDLl+JR/Ix65eDX3h2BHZUvv6Qr+srIysqjt11dVU/pdnJqBYHADGKxBNnZj0GSpFbjttiEbT1MxU5cwIWt7OysYW4ugEgkRknJczx/XtEgn6As2VnSnqSsh/kGoUPr1i2w8NOJ2LhhD8RiCWZ+uAGDXgtCz14BaN3aHs+Kn+Pu7TR6dqSPjyu+3/wJPb7tVcLo77/Glv+KYRJ3iL29DYL7d0FAoDdaO7YACRKP8wpx6VI87tymxlREHbmE/MfPsG3HEr2S4y1ZvBlFRQ3He1lYmGPw4J74bNFktG3bRuf6deG4zID8kaOCYdFEe7cejbpCb8umtmASfWWUlVXQ2y1a2Kosa24ugLW1JYTCcohEYlRWVsPKyjCWSmFbD1OxExdwYStzcwE6dfbB7fgHkEhInPz7OiZOGqqw7JMnxbgRmyxzfpUGoQMAvD/lDbRqZY9N/7cP+fnPcOliPC5djJcr07KlLebOfxsj3wxWuni3qcPffzzaYPRB2IKFkxDY0VvhE9eMj8Jw7uwNfBH5I6qqahATk4BffzmGmbPCGT8Pb29X9O3bGS1bKk+myAZ1dSKc/ucm/X2sDq8Ri4qEuHrlDgAqmBw1WvnAYV1hQkZlZTW9rclYMtkyFRVVBtO4sa2HqdiJC7iy1bi3X8Pt+AcAgB++O4jOXXwREOglfy4V1Vj8+U+oq5MmPS4vV7+OI5f+HvJ6T5hbCLBh3e94+qSkwf7i4ufY9evfEJgLEMbS7GpDx+jvPz5FBacYfRDWtZufyv1DhvbCypqZiFz0AwBg187jmDb9TTRp0jA7viZEX90JgBrnUVFRhbQHOTh+4jL+OngWK1duw54/T2LLlsVwd+dmTNiVi/cgLKWevPwD3NG+vbvWdfx9PBoikRgAlYBR3dObLnAhg4fHUBk5KhjHj0bjRmwyysur8P6kVRj1ZjCCerRH06ZNkJmRh6NHrqCg4BnaurVG7iNqko+ZAf1BfJTzBHMj/g8ZGXlwbeuIdRtmoW+/TrCzt4awtBz/XU/Als2HkZPzBF8u3Y7srHws+GRiY582j7YY0DX3KsDavAWCIEIIgmgv8z2CIIgkgiDKCIJIJAhiFluyX2bUqP7w8qJm6ZSVVSI+XrvcNYogCALW1pboFtQBK1bMxNatSyEQmCE97RE+mL5K7mmITWRfRb4Z3lenOo4euUxvs5UbjAkZ9Tl1AKCmplZtedkyjf50KQPbepiKnbiAK1sJBGb43/fz0T+kCwCqBzvqyGUsX7Idn3+6GVt/ikJBwTMEdvTClyulSTtVjR3jUoenT0vw7sQVyMjIg7t7Gxz4aw3eHBOCVo72sLAwRytHe7w5JgQH/loDN3dqOMavO07gyqXbamo2Pfj7j0cb2Jw8+jMAFwAgCGI2gK8BHAXwMYAoABte/K4UgiA+IggijiCIuB3btV98WpaevQLo7YeZeSpK6kb/kG4YG/YaAGoduGPHLjEu42UKn5Yi9jqVf6hpUwsMH9FD6zru3U1HRgZlj9ZtWiK4fxdGz5FJGTY20j9I6hIbikRilJdT42ksLMzlGsbGhm09TMVOXMClrWxtrfDTtkX48adPMfT1Xmjj1BJNmljAxtYSXbq2w5JlU/DH3pUwM5M2yw6t1A9v4EKH7T8fRUlJGQBg7vy3YWdvrbCcnb015s57m/6+988zGtVvShj9/Uew8OFRCpuvI30AZL7Y/hDAHJIkf6vfSRDEPQCrAWxRVgFJktsBbAcAkeSuXqu21mezB+QHTjJJSP9uOHyImp5940Yi3nlnOCty6vn7WCy9FuKg0C6wsdV+7THZvF2jx/SHQMB8XM6UDE9PV+TmUms85uU9VTkBoqCgiLaNu7t2Ge3Zhm09TMVOXNAYtho4qBsGDuqmdH9mhvQhsaMGM4i50OHKZWmPVp++HVWW7dNPuj8hIUOj+k0J/v7j0QY2e8LKANSv0+MC4M5L++MBaD+ASUdKS8vobdknFSaR7Uoue65+VpO+/H1MmhvszTDtX0VWV9fi31PSOtiYFcmkDD8/6eWSlJSusmxionR/u3acXWYawbYepmInLjBEW8XdvE9vB3Vvr6IkBRc6FMqsAGJlrfqVmbXM/qrKVy9jviFeU9pAmhGMf3iUw2YQdhLAnBfbFwGMf2n/BAAPWJQvh2zD5imzrAaTZOdI8/u0aGGjoqT+3IlPR04WNXjX2aUlevVR31i/zNkzN+gp8EHdO8gtN8IUTMro31+affrq1XgVJeWzT8tmpTYE2NbDVOzEBYZmq5KSMly5TD2v2thaIlSDZb240EH2AbOgoFhl2fzHRfS2vZLXlqaMoV1TWkMQzH94lMJmEPYFgAEEQUQDyAWwkCCIaIIgthMEcRnACgCLWZRP888/V5H5YhyYlVVzBHXvwLgMiUSCw4fP0d+7dmNehiwnoqS9S6PG9NGpG/tYlHSwfNg4dgbkMymjd29pCpDr1+8iLS1bYblnz0px8mQ0AGr6d2hob73kMg3bepiKnbjA0Gz17cY/6SWOJr4zVKNcW1zo4NuuLb19+uR/KkoCp2T2s5H02dAxtGuKx7BhLQgjSbIAQBCAaABvgBqe1wvA66CCsmCSJE/pI2PPHydx726ayjLnz93AiuXb6O9Tp43Sar3C3347gTt3VM+mrCivQuTn3+N+8kMAVIbsESP6ayxDW6oqa3DuX+oJiyAIvBnWR+s68vIK6aSQVlbN8fow5hsApmWYmwswaxbVoUqSJCIjN0EoLJcrU1NTi8jITfTs1HffHWlw6TDY1sNU7MQFXNrq7t101NbWKdxXW1uHb77egxPHqGW9vLxd8NGsMQajw4iR0uEO236OQsx/iQrLxfyXiB3bjtHfR41mrx00VIz+/jMjmP/wKIXVPGEkSQoBLHnxYZzY2ESsX7cbXl4u6N2nI3x93WBvbwOSJJH3uBCXLt6iM+YDQK/egfhwRphWMm7eSMKG9bvg4eGMPn06oV07d9i3sIVAYIbiYiGSkzNx7mwsfZOZmwuwek0E/ToyN/cJDr0YrF8nocqkPZAOvI27kUoPzKxn8NCuaO/vpvSczp2JR+WLsRY9evvB2cVBK50Aqoeqfk27YcN7szIrhw0Z77zzBs6cuY64uCQkJWVgzJi5mDBhODw8XFBQUIRDh84iI4NawsnX1w0RERPkjn/0qACHDp0FAIhJKhHmgwfS9fluxN5v4I/QoT3gH+Ah99vz5xX4fddpud8ey7yGSbmfg02b/pDb36dPZ/Tt24URPdi2k6bkPirAoUPn5H5LTc2it2Nj7kEskrfn68P6IiDAxyDqB7iz1Y6tR3HndhpCBnRBx04+cHS0R1V1DTIzHuPf07F4nFcIAGjdpgV+2PyJVg+LbOsQNm4Qoo5cRmJCJmpq6jDzww0YHNoDfYM7wd7eGqWl5fjvWgIunI+DRELd88EhnfH6sF5ayeHC36Z0TfEYP4Q+i8tyiaLZkXPnbMSF83FqjyUIAm+9HYrIL6ao7N43IxrGpHNmb8D58zc0Okc3tzZYuWoW+vWTpmC4EZuIKVO+1Oj4er5c8x7eHKt8oP1HU/6H27eoWUerv56K4SOl40aaCVqorZ8kSQwfMp8OGv7Yu1Jt0ltt0VdGEzPlY+qEwnLMm7ceMTH3lJYJDPTB5s1L4OIiv3ZbbGwCJk/W7pngq7UfYExYiNxveXmFGDF0kVb1zJnzDubOnUR/10cPTWCqfhLK24jY2ARMmbxUq/Nat34+wsNDNSrLZP2EirnyTNiqRixUeV5zPv6WHu+ljJ69A7Bq9Ydo21axjKYC5SkrmPJ3rURxWoXSkjJ88flPuHZVef31vD68N1av+QiWVoofvCyU3N9sX09MylB1PQFM3t9+nHYluf9wmfGgIGfeQL47TAlGnTF/0eeTMXBgd9y7m4aU1GwUPxOitLQMIpEYtrZW8PB0RlBQB4SFDYLni2St2rJ23RyMvH4XcTeTkZLyEI8ePUFpaRlIkoSVVXM4OTnA398brw3uiUGDuuuciV9THuU8pQMwG9vmeG1IV63riI1JooMjTy9nxgMwtmXY2Vlj9+41OHXqKo4du4Dk5EyUlDyHnZ01fH3dMXLkAISHD9FrjVAuYFsPU7ETF3Bhq4i54xDY0RtxcSnIyy1E8TMhzMzM4Ohojy7d2mHY8D4IGaB7nj62dbBvYYOtOyLx3/VEnPznOhLupuPJk2JUVdWgefOmcHJ2QJeu7TBmbAi6BWk/UcjUMNb7z4zNkeI8DTDqnjCmUdQTxiTlonxW6wc06wkzBlT1hDFFtfgZq/U3E2j/mtgQUdUTZkyo67nQF3U9YUygqieMKZT1hDGJsp4wY4Lt60kKtz1hnpuZ7wnLmsP3hCnDqHvCeHh4eHh4eJiDzyjBLXzHIw8PDw8PDw9PI2A0PWGKXhWSJInbt1OQkJCOxIR0ZGTmoqT4OUpKykAQ1Dt5Pz8PDBzYHW+OHqh2MVyCUByTlpVV4Gr0bcTGJiI5OQPZOQWoKK+EpWUzODs7IiioA8LDQ9GpczuV9VsKHJXumzp5JW7eTFZ5fD0uLo44e17xak8CM+UzqpjSgyQlSn5n1h+qz4Gkx1rcv/8QxcVC2NvbwMfHDaNGDUBYmPqxFk0F9gp/Z8xOKl7jicViZGTkIjExHUlJ6UhMTEdqykM6R9TsORPlBvErQ90rESbsxIUMdTAhg4RY4e9M+VuTV4Vs24qJ+puYqU6VYCz+flVkMA3fE8YtRjMmTEImNTjRmppadO0yUaPjW7a0xVerIxAaqnzKtKIg7JcdR/DDD/uU5veRZfTogVj1VYTSGZhiSa3SY9kOwpjUQ1kQxqQ/zAjlExyYm/XX8I8yk3ZS1dE8d+56nD2jPOklE0EY27MvjU0G2/4moPqPqbHMhuVlGJoMbseEef/E/JiwzAh+TJgyTCIIa9OmJTp39kP79h5wcXGElVVzVFXX4GFmHk6fvo7sbGpAvEBghm3blyE4WPGMQkVB2LKlm+mcMm5ubdC3Xxf4d/BCixa2ED4vR8x/93DmzH90bqng/l2xY8eXMFMwxUTTIOyHHz9TaYtmzZsiOFjxLCplQRiTeqgLwpjwh7IgrLa2DtOmLUdcXBIAwNm5FcaPHw4PD2cUFBTh8OFzcvl3Dhz4FtbWihc2V/RHmUk7qQrCZkesxfnzsfR3O3sb2NvbIDvrMbVfzyCMSTspw9hksO1vVUEY27YyNl/wMrSRwW0Q5vPzFcaDgoyPB/BBmBKMOgiTSCTIzMyDr6/yxKZisRhr1vyC/fv+BQB4e7vin5M/KiyrKAhbvmwLnhaW4IMPxqJXr44Kj4uLS8JHM1bT2Y/XrpuLceMa5q3RNAhLun9QaTl1KAvCmNRDWRDGpD+UBWG//XYc69btAEA9Re7atQZ2dtL16WpqahERsZZes2369DBERk5XWJeiP8pM2klVELZ160FUVFQhMNAXHQN90NbNCUeOnMeSxd8D0D8IY9JOyjA2GWz7W1UQxratjM0XvAxtZHAbhPluZT4IS5/FB2HKMOogTFPq6kQYEPIBSkvLAABnzv4ENzenBuUUBWFCYbnczaOMPXv+wZrV1E3Xo2cg9uxZ26BMYwZhTOqhLAjTFE38oSgIE4nECAmZguJiIQiCwIkTP6JdO48G5Z49K8WQITNQWVmNJk0scOXKboVLgij6o8yknbSd98JUEMa0nRRhjDLY9reyIIxtWxmjL3gZ2sjggzBT5pWYHWlhYQ4PD2f6e1FhqcbHatJAA8Dw4cH0dtoDxQu2NiaGpIeu/oiJuYviYioXU9++XRQ2bADg4GCPESOoDPe1tXVyr/3UYUh20hUu7GQqMrjwN9t6mIoveBmay2ATgmD+w6OcVyIIk0gkyHv8lP7eylHxrDh9sLJqTm/Xz3AzRrjQQ1d/XLt2m94OCQlSWTYkpDu9HR19S8szVI8h+5sLO5mKDE3Rx99s62EqvuBlMH/d8hg+RpOiQldIksT33+2le1v8/b0UvorUl7Q06dOxi4vyVBSa8PHM9UhOfohSYRmsLJvDydkB3bv7I3zcYPj7e+p5pqphUg9F6OOPBw9y6O3AQF+VZTt2lO5PS8tRUVI32LaTPnBhJ1ORoSn6+JttPUzFF7wM5q9bXVCSqYmHJUwqCIuOjkdNDTXVvLqqBtk5BTh3NgYpKVkAAHt7G6xeE8GK7IMHztDbAwd1V1FSPVeuSJ+khMJyCIXlSE3Jxt4/TyMsfBCWLf8QzZopzwemD0zqwbQ/srLy6G1XV9XTxp2cWkEgMINYLEF29mOQJAmCwX5xJu3ENFzYyVRkaIo+/mZbD1PxBS+D+etWF/jXh9xiUkHYksWbUVTUcHyRhYU5Bg/uic8WTUbbtm0Ylxsfn4IjRy4AAJo2bYKpU0frVI+9vQ2C+3dBQKA3Wju2AAkSj/MKcelSPO7cTgUARB25hPzHz7BtxxLGk/wxpUc9TPujrKyC3lY3SNbcXABra0sIheUQicSorKyWe6WkD0zbiWm4sJOpyNAEff3Nth6m4gteBrPXLY9xYFJBmDK8vV3Rt29ntGzJ/OK3hYUlWLjgG0gk1IzBefMnwcmpldb1LFg4CYEdvWFh0dAlMz4Kw7mzN/BF5I+oqqpBTEwCfv3lGGbOCtf7/OthSg9N0NUf9SkCAOqPoTpky1RUVDHSuHFpJ13hwk6mIkMdTPibbT1MxRe8DOauW30w43vCOMWkgrDoqzsBUOOOKiqqkPYgB8dPXMZfB89i5cpt2PPnSWzZshju7syMCausrMbsiHV48uQZAGDgoB6YPn2MTnV17eancv+Qob2wsmYmIhf9AADYtfM4pk1/E02aKM8srylM6iEL1/5gG7bsxGOY8P7m4eFhG5McgkcQBKytLdEtqANWrJiJrVuXQiAwQ3raI3wwfZXck4qu1NTUIuLjtbh3Lw0AEBTkj02bPmP1ff6oUf3h5eUCACgrq0R8fKredXKhB1P+sLRsJnfe6pAto+/TZWP4W1e4sJOpyFBVF1P+ZlsPU/EFL0P/65YJGjtFBUEQAoIgOhIEMZUgiB8JgviPIIhKgiDIF5+V2utEDCcI4gBBENkEQVQTBPGUIIhrBEEsJAhCq0WMCYLo+//snWd4VNXWgN+dQktCQpMECAESauhVOoIKigVQgWtD8KqIgPpZoihXkGK9eikWQAWuSvFSRBSkidKbIJAEAgkkhBIEElIIaTP7+3EmU5KpyZxDGOZ9nvPklH322uusOZk1u6wlhPhGCJFkaFe6EOJPIcTbQgiXh0U80gkrSa/eHRgy9A4Azp69yJo1v5ervoKCQiaMf589e44C0LZtU+YvmGzx8qlFl66tjPunT52zU9IxN0qPstojKMj0rmRkZNktW1SkIycnF1DmoJVHpxtp77KgxXPyFBnWcLe91dbDU2zhlVG+z627uNFOGPADcBRYCIwHbgfK5J0KISoLIZYC64HhQEOgMlAH6AF8AhwWQrR1oi4hhPgE2AmMBpoY2lUD6AhMA2KFEP1daeMt4YQB9O7Vwbi/b19smespLCzipRc/Yts2Jd1Eq1ZNWPDVOy7nFisrISFBxn3zCaCucqP1KIs9GjWqb9w/d+5vOyUhLe2yMd9fw4ZhZe6xutHPqSxo8Zw8RUZJ1LC32np4ii28Msr+ufUwSq44SwdOlrGuxcBIw/4V4D3gUWAisM9wPhL4VQhhO9+ewnvAy4AArgGzgceBscAmQ5m6wBohhPUE1Va4ZZww827e7KzcMtVRVKTjlVf+zW+/KbZr1iyCr7+Z4nTUbXdQnOoHLH9xuUJF0KMs9mjWrKFxPy4u0W7Z2FjT9aZNG9opaZuK8JzKghbPyVNkmKOWvdXWw1Ns4ZVRts+tuxFCuH1zkX3A+8AjQBMpZS1gZhn0eBAYYTg8A3SUUk6SUi6VUs4BuqP0tgGEofSK2aqrA/C64TAT6CGlfFFK+b2Ucp6U8m5gquF6IDBfOKn4LeOEpZxJM+7XqBFkp6R1dDodr7/2KRs37AYgKiqchYumOp1PzF0c2H/MuN+oUZidktapKHqUxR69epmiTxcnvrWFefRp86jUzlJRnlNZ0OI5eYqMYtS0t9p6eIotvDIqVrzBG4WUcqaU8k0p5Qop5elyVDXFbP95KaVFNFypJEF+AcVBA3hYCNHaRl3/AmOi3klSyiNWykzF1LvWBbjXmUY6dMKEEB8KIaoLIfyFEFuEEJeEEI87U3lFQa/Xs3LlZuNx+w4tXL5/0qS5rFu3A4DGjeuzcNG71Krl/vRH9vjllx2cMswDCwioSsdON6ceZbVHt26msBa7dh22iGJuzpUrV1m3bjugLP8eMKCby+2rCM+prGjxnDxFBqhvb7X18BRbeGW49rlVC+Hj/k1zHYRoChQPCZ6UUq6zVk5KeR1YYHZquJW6goB7DIdZwCIbdUlgjtmpEdbKlcSZx3O3lDILuA9IBqKA15ypXG0WL17LX3/ZXyF4Lec6Ma/P4li84lAHBwdy7729nJYhpeSdf33Bmh+3AhAREcaixdOoU6dG2Rtegu++XceRw/aHvLds3sc7k+cZj58afZ9TMWiK0UIPte3h5+fL2LHKOyKlJCbmUzIzcyzK5OcXEBPzqXHF5WOPDXapN0OL56Q2WjwnT5Ghhb3V1sNTbOGVUfF72W8iBprtb3BQ9lez/UFWrvdFmcwPsE1KaW/+jLksa3WVQijOm50CQsRKKVsLIb4CVkgpfxVCHJZStnNGgLvQy7hSDR3/wvts2bKPiIgwbr+9DU2bNiSkRnV8fX1IT88kPv4UmzftNb4Afn6+fPLpK9x11+1WZQgrLvsnn3zL/HkrAWX1SswbowkNreWwvT17dqBq1coW53R668uVJ4z/kN+2HKBx43p0u701UVHhhIQEIaXk3PlL/L71T2PEfICu3aKZN/8tKlUqHebN18e6Y+ZOPZRe3NK40x4+wnr8s4KCQkaPnsyBA3EAhIXVZsSIQURE1CMt7TIrVmwiKSkVUIaUli37yObcOYmu1Dl3Pid7v3HOpqaxYsVmi3MJCcls3ar0Znfu3IrOnS17xu8e2J1WrSItzgmsTztw53Oyxc0mQ217i1LzidXR40bU75VxI2U003S2fttvt9t3CsrAkSd6l0sHIcRTmOZvTZVSTnFQ/kvgOcPhaCnlIjtl/YA8lAUB14AgaeYYCSHeQJmU76zsZCDCcFhXSml3dYYzTtj7wBDgOtAVCAF+llJq2ndqzwlzhvDwukyZOpYePWz7jtacsCeeeIv9++JcaKnC5i3zSqXkceSEOUIIwcOPDCDmjVFWvvAVbDlh7tTDkRPmDI7sYcsJAyWf5sSJ77Fnj7VheYXo6Ejmzp1EvXq2c7dZ+1J253Oy54Tt3XuUUU++5ZKMme+9yLBhAyzO2XLCwH3PyR43kwy17W3PCQP1n9XNZAuvDFdkaOuEtfvO/U7Y4cc1d8J+A+4wHN4hpfzdQfkUlPAVAOFSyrNm175BCUkBDhw6Q/k/gD6Gw95Syh32yjuMmC+lfEMI8SGQKaXUCSFygQoRNnrGzPEM3nWYA/vjOX78NKmpF7l6NRspJQEBVQkNrUXLlk24o38X+vXraS0TngAAIABJREFU5Jbo8mrw2utP0rdvJ44cPsnxhBTSr2Ry9Wo2RUU6qlcPIKJRGB07tmDo0H40MgRrrYhoZY/g4EAWLZrO+vU7WLPmN+LjT5GRkUVwcCBRUQ0ZPLgPw4bd6fbcmjcbWjwnT5GhBWrr4Sm28Mrw4gbMJ3RedqL8FUxOWAhw1uxaWeqydq9VnOkJqwb8H9BQSvmsYcJbcynlz040xm1Y6wlzN9Z6wtyJrZ4wd2KrJ8yd2OoJcyf2esLchbWeEfei/oxUez1hXixR296OesK8eCkb2vaEtf9ejZ6wPs8Bz5qdmi+lnO/s/WXoCTsBNDUcNpVS2o0VIoTYiRK8FZTwE7vNrm0E7jIc3iWl3Fzy/hJ1fY8SiwzgUSnlUnvlnckduRD406yB54D/AZo6YV68ePHixYuXmw+Dw+W003Ur4YwTFimlHCGE+AeAlDLX2SBk7sRRz4iU0tjte+zYadLTMwkJCSIyMpz77uvD0KHl7/Ytrww/H8eZF9TWwx31C2H/+s1gC3Dcc3Ej9Lh6NZt27drQp09P+vXrRVRUU4SogqlX7Qrmvd0BEdNK1fn4w72Z9+9nS513xLbdx7hnZOmYiFnJMSXO+CEIQRAEVEKZz6oHipBcB64hyeSZp6eyc+dh410zZr7A0GGmjB46nY5TSeeIjU3kcOxRjsWd4UTCOfLzCgF45vl7ePaFwU63P/XMJX5csZM/958kNeUS13LzqFK5ErVvC6ZVdEOGPnAvfft2tnl/ee0tsd2BoNPpSEo6S2xsInFxicTGJpJw/DR5eUrv+AvjRzJhwqM27y+mSH/dYZliDh48zvpfdrF/Xxx/X8ogP6+AmjWDCQ2rRafOLenTp4PVMDf+PvazA9ws77deFlqt99Ch4xw9mkjs0USSTp0lIz2LjIxshFCGEJs1i6Bv307c/0Bfqle3PSFfZ6V+W5TVFgD+God48PGMznXz5ajO5IIy/3LOLnHNnXWVwpnhyF3AAGCnlLKjECISWCql7OpEY9zICZsNvbkmWd44GZ6gg6fLmD17NgMHDrRzl3pO2H9/+IPnX/uq1HlzJ0xQE0Fdh474ylVfMunNTy3OlXTCXpzwIZs27bVZhytO2KKvNjJv7i8UFdkfcrz99rbMmvWGRfovcI+97TlhEya8x6aNu21ed6cTlpGRxbSpX7Fxg+1nC9C8RQQrV39Y6rw9J+xmevesOWH5+QW0bzfSSunS1KxZnXenjWPAAOtfdc44YeW1BYC/T3tN3aJOS90/HPnnP7wT823hTE/YOyhxNMINY509gaecuE8TCgoKGTduusVS4OHDBxEREUZa2mVWrtxMUlIqcXFJPPPMFJYv/9jlPHCeIMMTdLgVZLRr19yiXEZGBrm516hfv4HTdf++K54Rz/zHYTkfH8HX/xlLNcNK229/2Ga3vCAUH1EbACl1SLKAXCQ6BD6AP4IArlzJ44P3FWeuarUqXDfEQiqJTm85tzA4uBrBIQGcSbnksO3mLPl2K5/95yfjcYfOUfTqE03d0BpkZeWScOws69fuo6CgiD17jvDcc1NZsuQDfH0VR1ILe+t1JXQNCSIkJIiU5PMu1eOIy5ev8s/R00hMVL5DmkTWp/+ALjRqFEa1alW4ejWbxJOpbN/+l8t1e8q7B1C3bk3atm1G8+YR1KtXh4CAqlzPy+f0qXP8+usuUlIukJ6exYsTP2Te/Lfp2dPpVIBG1LSFF4ecwOSENbJX0BCiojjh5zWUKVcl6yrGbl0GIsz2T9gsZcCZ1ZGbhBAHUTKZC+BFKaUzKwQ0YenS9cYXNjo6koULp1vkenv88fsYN24GO3YcJDExlc8+W0ZMzJhbToYn6HBryAgE0ikszOHttz/mxx83MHToUN5//32n6z57/gpnz19xWO6uvm2MDtjJUxfYtd/2/wtBDTMHLBs9Z8Fsors0/r3EtOmfkJmZTctWjYmKCmftT9aduzZtmtKkSQOioyNp3CKQ+g1qs/bHPbz79nfOKQrkXS9g3hzT9NTJ7z7GA8O6lyo3+pm7eW7UHC5evMJffyWwdes+7rxTKaeFvdu0bUqTyAZER0fROjqSBuGhrFq1hUlvznKpHntIKXn15f+QmHgWX18fYt4cxch/3I2Pj/XxrAsXXPs37gnvnr+/H2t/nkVUlO1czRMmjmT69K9YtnQDOp2emTO+5pd1c2yWt4batlATD8khHmu23wkbUe4NtMeUNDxelh4eLFmXTYQQdTA5YZccxQgD59IW9QGiUcY2s4BWhnM3nKIiHV9++QOgxND64IOXSyXbrVy5Eh9++DLVqilDud999zMZGVm3lAxP0OHWkZEOXMbfP4/XX3/cKEMNnhje17j/3Yrtdkr6IggFQMpc9KSAjZWGv/22n1/X78THx4epU8fia+NLB+C5sQ/xf688zsBB3anfoHZZVODwX6fIzc0HoFXrCKsOGED9BrV59tmHjccHDsQD2tgbYOzY4bzyyigGDepJg/BQl+51lh+Wb+bAASW37KuvPc6jjw2y+aUPSi+Ts9z498I9Mnx8fOw6YAC+vr5MmvS0ccj61KlzpKam2b2nJGrawotTmEeutze/Aywj2/9q5frvQL5hv48Qwt7kbnNZ1uoqhTNT/l4z2yYDa7FMjHnD2LPnMOnpmQB0796Opk0jrJarVSuEe+/tDSjd3Vu22B+f9zQZnqDDrS7D3dQIDmDwnR0A5cvv+xW2py0IahrngOmx/WWUk5PLtKnKAqhHHxtE6zZRbmyxdTLSTfNewyPq2C3bqJEpxl5xuhgt7K0FUkoWL1R6BMMb1uWxJ+5xcIdrVNT3Qi1b+Pv7ERERZjy+fOmq0/eqbQu1ET7C7ZvWSClPAocMh02FEFaNIJRVT8+YnfrBSl05QHHuyerYmI5lWLA43uzUcmfa6tAJk1Leb7bdBbQGMpypXG127jxk3O/du6OdkpYZ6s0z198KMjxBB68M9zJiaA+qVFFiym3ZHsuFi7ZfaYGSR1HKAsB22rSPP/qWixfTCQ2txYsvOp5k7g5q1jLl20t1MJcsJeWCcT8yUukN0cLeWvDngWOcOaM4yIMH97Lb61IWKvJ7oYYt9Ho9586bRpJq13E+mbvatlAbIdy/3SCmmu1/IYRoaH5RKIFBP8M0IX+FlNJ86NGcaZhmXbwnhGhrpcy/gOJMQvullL8400hnJuaX5CzQsgz3uZ0TJ84Y96Oj7f/qbt3adP3kyTN2SnqeDE/Q4VaW8fvv9pOil4UnHjHNKPjvD3/YLFcvtAZCFAcALl6ZVwVBLQQBKP9C9Ozfv4v//bAJgLcm/5OAQMfhWNxBuw5NCKkRyNWMHOJjU/hp9W4eGFp6SPL8uSvMm/c/AEJCgnjggX6ANvbWgj8NQ18ArdtEotfrWfPjH6xZ/QeJiWfJzc2jVq1g2ndoxpBh/ejZ07XUvxXxvSiLDGeQUjLrP0uMvV8tWzYm3IUhZLVt4ekIIRoDT5c4be709DdMpjdnpZTykPkJKeUaIcRyYATKPK2DQoh5wFGgFvAkSipGgAsoQemtIqU8ZMgcFAMEA7sM+bT3oUzkfQi421A8B8vAtHZx6IQJIeZg8gB9UCaxHXRWgJokJ5sWMdSvb385dGhobXx9fdDp9KSknEdKiTPhzjxBhifocCvL8DHrzldkOBRhlzYtG9K+dSMALl3J4pdNtl/njm2bmGRTiKC2IUSFqRH5+YVMnjwDKSV33TWAAQP6oOTDVZ/Klf15Y/II3np9IboiPdMmf8/Pa/bSu09r6oaGkJV1nePHUo2rI+vWrcXcuZOoUUPpQdPC3loQF3fKuF8toApPPTmVg38etyhz4cJlLly4zPp1u7h7YDdmvPeCzRy0JamI74U7bLF9+0Hy85VQE3nX80k5k8bmTXs4fjwZUBz2adPHuVSn2rZQmwrwkY4A7CXW7W3YzEnENPxozigU/2UkiuM1yUqZJGCYlDLVQbveBCoDLwIBhr8l+Rv4h5TS6SWvzvSEmWeWLkKJEbbTWQFqkp19zbhf/E/VFn5+vgQGViMzM4eiIh25uXkEBDj+te4JMjxBh1tZRuXKpn/OhYVFVCpnZqonh5t6wX74cReFhbZja9WtE2zcFwQhhNIWKbOQZAM65sxZRHJyMgEBAUye/A4+1EZPIuB8MMvyMODuDgRVr8bHM//H6VNpHDqQyKEDlllKqlatREzMGIYNu9MiRpgW9tYC8zlL776zgOTkC1SvHsCwh/vTsmUjiop0HNh/jLVrt1FUqGPjhr0UFuqY89lrTtVfEd8Ld9hi0ptzuXy59Hwvf38/+vfvwquvPVkqUbsj1LaFF+eRUuYD/xBCLAbGoER5uA1loeFJlOw/86WU12zXYqxLAi8LIX5A6enqA9RD+cV5CvgR+MLV6BHOhKhY7EqFWpJrFn+ocmXH30zmZa5du+7US+sJMjxBh1tZhr+/KTBqeZ0wf39fhg/pYTz+r4PYYCHVTTGYhKiMlBLJWSTKBOpjx06zcOEyAF56aRx16ypfWD6ynmEVpTZ07tqUV954iH9/sJLTSaUXD1y/XsDChT+i0+n55z+HGXtNtLC3FmRnm+bqJSdfoGHDUL5Z/C9CQ2sZzz84pC/DR9zJM09PJyfnOlt/O8D6dbu4594e1qq0oCK+F2raokmT+nTv3paaNYMdFy6B2rZQmxvdE2YIrOrWVkgpf8XJ1YpO1LUbsB152UVszhgUQhwVQhyxsh0VQtgOZezFi5cKy+C7OlK7ptITdPDIKWKP2++BL7mySZJhdMB0Oh2T3/qcoiIdbdpE8Y/HuhuTuwtRnNJIfdKvZDN29CzGP/sZVzNyeP3t4azd9C67D81i0/b3+eDTf9K0eX3+/judjz9exGuvfYJer34Sei3R6y1DG01/73mLL/1i2rSNYuJLpojx3327XvW2VWS27/iGY8dXEX9sJfsPfMeSJTMZ+Y+BJCamMmXKPEaMiDFOsncWry28uIK9ZRv3Afdb2YrP20UI4SOEeEsI8ZMQ4jnDudFCiBNCiEQhxIfCNOO3TJjHUMrPL3BY3ryMs7+aPEGGJ+hwK8swHy709y/LWhoTT5rFBnPUCwaQc81ybpc0Wxi9aOFa4uNP4efny9Rpz+PjIw1R9BUEljGe1OB6bj7PjPqUQ38mERwSwMIlr/LIyD6EhtXEz9+XkBqB9L+rPQuXvEqHDkpuvrVrf2fpUuULTwt7a0FAgEmPyMgGdOxoPQ8hwJCh/fAz9K7GHk0k95rj+XsV8b1wpy2EEAQGVqNDxxa8885zfPnlW/j6+pB4MpWnx0y16KVzhNq2UBsf4f7Ni21sOmFSyhR7mxN1TwVeQYk++ZYQ4l3gY2Ax8DVKrI3J9ioQQjwrhDgghDgwf37pkBtBQabkqo4C9hUV6cjJUbqJ/f39nA6C6QkyPEGHW1lGfn6+8bg8TljobSEM6N0agOt5BfywxnGPemamaWhFmRKhrJBMSbnAZ3OVd/LJUffRokUjQynz3Ibq94T9b9k2ziQroQSeGH2nzaCvlSv788YbpgVX3367FtDG3loQZJZoulV0Y7tlq1WrQmNDzDSdTs+5cw6DelfI90JNW/Tq3YEhQ5WsN2fPXmTNmt+dvldtW6iNB4WouClwJmL+7UKI/UKIHCFEgRBCJ4RwJkTxY8CTUsqnUCLSvgVMlFLOkFK+BzwH/MNeBVLK+VLKzlLKzs8+O6LU9UaN6hv3HX1409IuozPkb2vYMMzplTSeIMMTdLiVZZgPb5RnNd7jD/fGz0/51b12wwEys2zH/CrmxKkLZkemIbyf124nL68AIQS+vr58+cUKvvxiBV98sZjPP/+czz//nC++WEzCCdPvtd+3HjCWO3LkZJn1MGfHtjjjftfbm9spCe3aNadaNaXH5PTpc+Tk5Gpiby1o1MgUWDQoyHEuxUCzMtk5jj8HFfG9UNsWvXt1MO7v22crfFRp1LaFF8/CmShyc1GcpZNAVeCfKAHOHBEGHAGQUsaj5DkxX7Z50FCmzDRrZoq9FheXaKckxMaarjdt2tBOSc+T4Qk6eGWUn8ceNq3q/u9yx0ORAMdOnMOUSs3076L4nJSSBfNXMXvWUsO2kFmzZjFr1ixmz5rPsfjTxns2bdprLPfXIffEPrv8d6ZxPyDQfm+IMuRkGrbKzc3TxN5a0Ky5Kbq8+cRwW+SYlQlyIgF2RX4v1LKF+RBnthM/WIpR2xZqI3zcv3mxjVOPR0qZCPhKKXVSyoVY5lqyxQWU6PoIIZqjJMhsZXY9GiWmRpnp1csUVXnHDvuhy8yjKrsShdwTZHiCDl4Z5aN752Y0i1R+86SkXmLrzjgHdyjkXs8HlNXbSm9DxZkHBZaO18U0+4k88vLyLYa5QkKCNLG3FvTu3d64Hx932k5Jxfk8nXweAD9/X+o3sB+TCyr2e6GWLVLMJuTXqBFkp6QlatvCi2fhjBOWa5hA/5dhMv3LTt73PfBfIcRClGSa7wEfCyHGCyHGAV8Cq8vacIBu3UxLiHftOszJk9anql25cpV165QExZUrV2LAgG5Wy3mqDE/Q4VaXUV6eMIsNZj9Zd2mKV0OCKYXR+AkjiD++ssT2I8ePHyMhIYHjx48Tf/wnhgzpZ7x3xswXjGWfHHVf+RQyEBll6kzfuN6+w7phwy4KC4sAaNasEZUq+Wtiby2oV78O7do3AyAp6SwHDx63WfbH1b9TZFjs0bFjC6fmU1XU90ItW+j1elau3Gw8bt/B9uT6kqhtC7XxzgnTFnshKroYdp8wlBuP8pM4HCVEvyPeAT4BaqMEMHsbJeT/68C7wBYcTMx3hJ+fL2PHDgeUYZGYmE/JzMyxKJOfX0BMzKfG1S2PPTbYYSBAT5PhCTrc6jLKQ7WqlRk2WMnOodfr+fZ/zg1FFiO5ihLzUHHCBNZiJwl8CEcYxh6UVZLqB2u9+97Oxv2fVu1m3dp9VsudTDjHzJkLjMcPPqhMutbC3lox8UXTvNm33/yCixfTS5U5ejSR2f9ZZjwePcbhQneg4r4XrspYvHgtf/1lfyj8Ws51Yl6fZRxKDw4O5N57ezktA9S1hdoIIdy+ebGNMM33KHFBiEMoOZGWoUTJj9eyYaU5YbWhBQWFjB49mQMHlOGVsLDajBgxiIiIeqSlXWbFik0kJSmxkKKiwlm27COLVTjO4AkyPEGHW0FGixbNqFEjnOPHTxuHzjp2bEe3bsVBHHMxX4H4wZwdrFm/n8NxthcsP/5wb+b9W0lltnVHLPc99oFLbc1KjgGq4UMjk5NlFjEfKivOmSHijJSFhoj5Oia9MYcff/wdUHrChg7rb6z37NmLrFyxBYBCvfJle/LEObb/rkyC7tApkg6dLHMI9r+rPc1bhluce23ifH7/zRS68PYeLejVtzW16wRzLSePgwdOsunXgxQUKL1gLVo0Zvnyj6hSRYn+7y57S6z/LwU4m5rGihWbLc4lJCSzdaviNHbu3IrOnVtbXL97YHdatYq0OFekv449pk39iuXLlBye1asH8NDD/WnZqjGFhUX8eeAYP/20zdjz8vAjA5jybukUd/4+1ucl3Wzvnl6W/hEw/oX32bJlHxERYdx+exuaNm1ISI3q+Pr6kJ6eSXz8KTZv2mt0/vz8fPnk01e4667bS9Wls1K/Oe6wBYC/T3tNvZg+a3fa/iCXkW339/R6Yjaw6YSBcS7XSJQEmIXAUmCZlDJZk9ZZYN0JA8jMzGHixPfYs8d2DNno6Ejmzp1EvXplG3P3BBmeoIOny+jatSvffvutS/U898p8u0OMG354i17dlOGU0RM/dyo0hTmKEwYQiA8NKJ0714SUeYZI+coXlD0nbN/eWJ4a9Y5LbfnX9Me5f4jlF2JeXgEzpyxl/c/7Hd7frVtbPvnkVWrXrmFx3h32tueE7d17lFFP2kuHV5qZ773IsGEDLM45csL0ej3vz1zE0iUbsfe//dHHBxHzxih8fUsPhthywuDmevfsOWHOEB5elylTx9Kjh/UE246cMHfYArR3wvr+7H4n7I/7vE6YLew6YRYFhWiH4pANB9KklD3VbFhpbDthoHRfr1+/gzVrfiM+/hQZGVkEBwcSFdWQwYP7MGzYncbl+WXFE2R4gg6eLCMqqjkLFy5yqQ57TliTiNs4uu3fAGRkXiOyywRjwmJnMTlhAL4IaiIojojvg9IblockE4llHj4tnLBi4o4m8/OavRz56zQXzl8h91o+lSv7U/u2YFq3acSQ+++hT59ONodHymvviuCEFXP4rxOsWrmV/fviuXRJWbBw22016dylJSNG3kWr6CY277XnhMHN8+5Zc8IyM3PYteswB/bHc/z4aVJTL3L1ajZSSgICqhIaWouWLZtwR/8u9OvXiUqV/G3W78gJK6Y8tgCvE+bpOOWECWUMYgBKqIp7gd1SyqEqt60E9p0wL15uRQIipqkuw9IJU4drRRccFyon1f0jHBcqB/acMHfhrBNWHhw5YTcL1pwwd+KsE1ZetHbC+v3ififs98FeJ8wWdsNvCyF6ozheQ4CjKPPDXpZSZtq7z4sXL168ePFy8+GdR68tNp0wIUQqkILieE2RUt74fAp2MO++PnbsNOnpmYSEBBEZGc599/Vh6FD3dpHfrDI8QQevDBPXUuwvMC5L/XPmLGHu3KXG41YtnFkMDXV7dKfF00/ZLXP970tc3L2H9KOx5F1Jpyg3F/+AakTVr03bts24/fa23HV3d3x9lTbpdDqSks4SG5tIXFwisbGJJBw/TV6ekjfwhfEjmTDhUafa5wg17e0uPVwZKiyrDvZ69NxnD+sJ1LOzr7Fj+yH27o0lPj6JlDNpXMvJpVq1KoSF1aFjxxYMGzaANm2bOpTgI2wPJYJ69pZScujQcY4eTST2aCJJp86SkZ5FRkY2QiirLZs1i6Bv307c/0Bfqld3bfGCF8/C3urICCdzRGqEd2J+eWV4gg5eGerXX9IJc5aIB++n0QPW439JvZ7kNWtJ/XUjsqjIbj379i+henUl+feECe+xaaPthQSuOGEC2z/x1Z6Y7y491NYBtNHDmhP21YJVzJ69lIICx8N8DzzQl6nvjqNq1co2ywhsO1DueFa2hjvz8wto326kzXrNqVmzOu9OG8eAAV1tlvER0Zr2TQ1Y7/7hyC33eIcjbeH0xPwbj/MhKoYPH0RERBhpaZdZuXKzxZLm5cs/JtDF1BCeIMMTdPDK0MbeSUmpnD591ljX5/HWI9EXXb9OwjeLlAMh6Pb+DKrUrlWqnNTpOLbgGy7tPwCAf1AQtTt1IKhhQ/wCqqHLy6df5Vx27zrM0aMn2bvve6MT9sK4GWzZstdYV3BIECEhQaQYooy7wwlzly3sOS/u0kNtHbTSw5oT9vZbc41hPMLD69K9RztatmhMjRrVyczKYc/uI2zcuNuYM7Jnr/YsWPAvfHysryq05YS561k5csLq1q1J27bNaN48gnr16hAQUJXrefmcPnWOX3/dRUqKMg/S19eHefPfpmfP9lbr8zphno3dOWE3A0uXrje+TNHRkSxcOJ3g4EDj9ccfv49x42awY8dBEhNT+eyzZcTEjLnlZHiCDl4Z2tg7MjKcyEhTLK4fqpy3KuP8738Y90NatrDqgAEkr1lrdMBCe/Yg6tER+FaxjAz+cq8wXn75Cf7+O92YZBugTdumNIlsQHR0FK2jI2kQHsqqVVuY9OYsp5+FI7Swt9p6aKGD2noIIejbrzNPPz2Erl1bl7o+YsRADhyI49lnppGbm8fOHX+xevVWHnpogJXabKP2s/L392Ptz7OIigq3WWbCxJFMn/4Vy5ZuQKfTM3PG1/yybo5LeqiFj9dd0pSbOrVmUZGOL7/8AVBe4A8+eNniZQIlrcWHH75sTAfx3Xc/W+SPuxVkeIIOXhkVy94AaTt2GfdDe/awWuba2XOk/roBgFod2tN8zKhSDpg5t91W02Ieztixw3nllVEMGtSTBuGhLrXPGbR6VmrqoZUOoK4er742innz3rbqgBXTuXM0//fKE8bj1at/c0mGFs/Kx8fHrgMG4Ovry6RJTxMSouSkPHXqHKmpaXbv8eKZ2EtbNEcIMdvWpmUjbbFnz2HS05WFmt27t6NpU+tL0GvVCuHee3sDSle0eXf6rSDDE3TwyqhY9r527jzZp5MB8KtWjTqdOlgtd3bTFqROD0IQNfIRp+vXCi2eldp4gg5AKWfIFoMGmUJUnjzh2rTlivSs/P39iIgw5T69fOmqndLa4SOk2zcvtrHXE3YA+NPOdsPZufOQcb937452y/bu3cm4v3278833BBmeoINXRsWyd9qOncb927p2wce/9Eo0XUEBf+9TotgHR0VSpXZtp+vXCi2eldp4gg6uEBBgGq4uXpXpLBXpWen1es6dNwUdqF0nxO0yyoKPcP/mxTY254RJKRdr2ZCycOLEGeN+dHSUnZLQurXp+smTZ+yU9DwZnqCDV0bFsbfU6bi4x9QzENrb+lBkTsoZ9AXKl2RQ48YAZBw7zvmtf5CVdIrCnBz8qlUjMLwB/7vQnyFD+uPvr+00VS3srTaeoIMrnDxp6v2qV6+OS/dWlGclpWTWf5YYe79atmxMuArD7V4qPg7/4wkh6gAxQCvAOJlDStnf5k0akZx8zrhfv779JfyhobXx9fVBp9OTknIeKaVT2d09QYYn6OCVUXHsfeXwUQqzsgEIaNCAoEaNrJbLTk427leuGcLJ75dy/rffLcoUZmWRERfP5Lfj+e/in/jii7dVmftlCy3srTaeoIMr/LB8o3G/b79OdkqW5kY8q+3bDxpTheVdzyflTBqbN+3h+PFkAEJCgpg2fZzL9arFTT1R/CbEmZ+d3wPLgcHAWGAUcEnNRjlLdvY1436NGtXtlvXz8yUwsBqZmTkUFenIzc2z6Nb2ZBmeoINXRsWxd9pOswn5vbrbLFeQaZrMfH7rNq5fvAg+PtzWtQs1Wja1CRSrAAAgAElEQVTHx9+fnLPnSNu2g8KcHE6ePMOTo95m9er/OD0/qLxoYW+18QQdnOXgweOsWqVMxq9cuRJPPfWAS/ffiGc16c25XL5cer6Xv78f/ft34dXXnqRBg7ou1+vFM3DG6a0lpfwaKJRS/iGlHAPc8F4wgNzcPON+5cqVHJY3L3PtmnM52DxBhifo4JXhvAw16y/IzCL96FEAhJ8fdW+3nkwboCjXVNf1ixfx8fen3Ssv0fKZMYT26slt3brS5KGhdJ4+hWbNlAnS58/9zaef/Ndhm92FFvZWG0/QwRkuXcrg5Zc+Qq9X4oRNfPFRQkNdm2dYkZ5Vkyb16d69LTVrBru13vLinZivLc44YcUR6S4IIQYLIToANVVskxcvXiooF3fvUVY7ArXatcU/yE6PlbQMyNnwvnsJadG8VLFKQUF89PErxqGeVau2kJOT675Ge7npyc3N44VxM7l48QoAfft1ZsyYB29wq5xj+45vOHZ8FfHHVrL/wHcsWTKTkf8YSGJiKlOmzGPEiBjOnKk44Sm8E/O1xRknbLoQIhh4BXgV+Ap4WdVWOUlxHBdQohQ7wryMs93KniDDE3TwynBehpr1Ww5FWp+QX0zJeGBhfXrZLNu8eSPatVcctIKCQg7+ecxu3e5CC3urjSfoYI/8/ALGPT+DI0dOAtCxY0s+/fTVMs3PupHPSghBYGA1OnRswTvvPMeXX76Fr68PiSdTeXrMVIteOi+3Dg6dMCnlz1LKTCllrJTyDillJynlT1o0zhFBQabEp46C6RUV6Yy/rv39/SxeRk+X4Qk6eGXceHtnnTpN7nkl1UqlGiHUbB1tt26/aqZUL5Vr1qBSdftzcKKjI437Z1Iv2C3rLrSwt9p4gg62KCgoZML499mzRxkCb9u2KfMXTC5zuyvSs+rVuwNDht4BwNmzF1mz5ne31l9WfFTYvNjG4fMRQiwUQnxTctOicY5o1Ki+cf/cub/tlIS0tMvGnGMNG4Y5/SvKE2R4gg5eGTfe3uaxwep2vx1hI2dfMVVDTZON/ao67kUICjR9QeZkazMcqYW91cYTdLBGYWERL734Edu2HQSgVasmLPjqHZfztJpT0Z5V716mIMf79sW6vX4vFR9nnNSfgV8M2xagOpCjZqOcpVmzhsb9uLhEu2VjY03XmzZtaKek58nwBB28Mm6svZXAqweMx46GIgECGzQw7hdddzypOTvHtHItMKjsX7SuoIW91cYTdChJUZGOV175N7/9tg+AZs0i+PqbKeVeNVvRnpX5EGd2VsWYB+mdE6YtzgxHrjTbvgeGA53Vb5pjevUyRTzeseOg3bLmEY/NIyHfCjI8QQevjBtr78t/HkRncKSCm0ZRra7jJfXVwkKNUfLz0zMoyLI//BMXl2TcN++xUBMt7K02nqCDOTqdjtdf+5SNG3YDEBUVzsJFUx2GlHCGivasUswm5NeoEaSKDFcRQrp982KbsgzXNgXsR7nTiG7dTMt7d+06bBFJ2ZwrV66ybt12QFlyPGBAt1tKhifo4JVxY+1tkay7V0+b5UpSp6vp99qFbTtslktISObwXwkAVKtWlU6dWjktozxoYW+18QQditHr9UyaNJd165TPSuPG9Vm46F1q1XJPSp+K9Kz0ej0rV242Hrfv0MLtMrxUfJyZE5YthMgq3oC1KBH0bzh+fr6MHTscUNJAxMR8Smam5Uhpfn4BMTGfGleePPbYYJd+UXmCDE/QwSvjxtk77/JlriacAJQVj3W6ON8rED7wLuME/TM/r+Pq8YRSZQqys3nt1X8jpfKL+dFH76Fq1cpOyygPWthbbTxBB1Da/s6/vmDNj1sBiIgIY9HiadSpU8NtMrR4VosXr+Wvv0p/zs25lnOdmNdncSz+NKAkL7/3Xturh7XEOxypLaL4H1/F54TVhhYUFDJ69GQOHIgDICysNiNGDCIioh5paZdZsWITSUmpgNKtvWzZRxYrZJzBE2R4gg5eGTfG3ne/No+Un34GILR3T5o/9aRLuv69dz/HFnwNUoKPD3W7dSWkhRIx/9q5c1zYtoPCbCUNUosWjVm2/EOqVFGcsLOpaaxYsdmivoSEZLZuVeYKde7cis6dW1u2d2B3WrWKpCQC698G7npWEtv/S92lh9o6aKUH6CnJJ598y/x5KwFlNWLMG6MJDa1lsy3F9OzZwarTLvC1Wt5dz0ovC0udAxj/wvts2bKPiIgwbr+9DU2bNiSkRnV8fX1IT88kPv4UmzftNTp/fn6+fPLpK9x1l/XAxz4iWlM3ZvjWbW53Cn64o4/XFbOBQydMCLFFSjnA0Tn1se6EAWRm5jBx4nvs2XPE5t3R0ZHMnTuJevXKNpLqCTI8QQevDG3rl1LSrudo8q8oQTLbv/k6wVGlHRxHpO3Yxckly9Dn59ss06Vra2bPeoMaNU29Dnv3HmXUk2+5JGvmey8ybFjpf0+2HBhw07Oy47y4Sw+1dQBt9LDmhD3xxFvs3xfnUt0Am7fMs5r2x5YTBu55Vo6cMGcID6/LlKlj6dGjnc0yWjthI1VwwpZ5nTCb2MwdKYSoAlQDagshaoDx7a8OaDNr1kmCgwNZtGg669fvYM2a34iPP0VGRhbBwYFERTVk8OA+DBt2J35+tl/KW0GGJ+jglaFt/Xv2HDE6YFVD65bJAQNlNWVIi+ac/2Mb6UdiyU9PR1dQgH9QINUbN+adMYO4887bb1jIBC3srTaeoINWqPmsZswcz+BdhzmwP57jx0+TmnqRq1ezkVISEFCV0NBatGzZhDv6d6Ffv05UquSvgoZlx5tmSFts9oQJIV4EXgLqAecwOWFZwAIp5VxNWmjEdk+YFy9e1OPZHedVlzGvV5jqMuz1IrkDez1I7kJtHUAbPaz1hLkbez1h7sBWT5i70bon7NHf/3D7B2BJv77enjAb2OwJk1LOAmYJISZIKedo2CYvXrx48eLFyw3AO5FeW2w6YWbohRAhUsqrAIahyX9IKT9Xt2muIaU0di0fO3aa9PRMQkKCiIwM5777+jB0aPm74T1Bhjvql+isns/OvsaO7YfYuzeW+PgkUs6kcS0nl2rVqhAWVoeOHVswbNgA2rRt6rCdjn7FeoIt3CHDli3AffaY18t6TDBb9QcGVqNLl47ceWdfevXqTq3aoUAVhGExtuQScNmirjrNv7DbBoBWzcN45IHO9O3RnHqhIQQFVuFKeg4XLmay7+Bpft+VwJZttnNOXkp4DvAFagCBgD/gQ3b2VXZs/529e3cTH3+sHJ9b24vNdTodSUlniY1NJC4ukdjYRBKOnyYvT8lN+ML4kUyY8KjDZ6CFvbXQQ30doFDvXPDTgwePs/6XXezfF8fflzLIzyugZs1gQsNq0alzS/r06UDHTi0M+us5lXSWuLhTxMaeJD7uNCcSUo36jx03hOfHD3VJ553bj/Dj6u0cPZzElStZBARWISKiLnfe3YWHHrmDmhUjfJgXlXBmYv5fUsr2Jc4dklJ2sHWPOngn5pdXhvsm7pb+IvhqwSpmz15KQYHjLvoHHujL1HfH2Q1DoPakWkfcLDJsfSm72x6u1D979mwGDhxo817rTtg8m+WrVvFn2ptDeOKR7vj62nYQMrOuE9nlTZvXLyW8BoQZnUGABQsWMHv2bAoKHCdzdvycbLdtwoT32LRxt83rzjsv1ofx3GvvG6OHuz+zRXrbi0BAyR05bepXbNyw12655i0iWLn6QwBemvhvNm+yPeneFSesoKCQyZMW8Os62/LDw28jNfXvdgkJCbb/SbiZJ/9w/3Dkf/t6hyNt4UxPmK8QQkiDtyaE8AUqqdss5ykoKGTcuOkWy42HDx9EREQYaWmXWblyM0lJqcTFJfHMM1NYvvxjl3OPeYIMtetPTj5v/OcZHl6X7j3a0bJFY2rUqE5mVg57dh9h48bd6HR6fvrpD66kZ7Jgwb/wcZB/UGs9PEWG2vawV390dJRF2YyMDPLzrxMaWs/p9hcTUK0SS758lp7dlDpTz6Xz88YjHDt5geycPKoHVaFpk7r079WCeqG2A3o+8mBnhNl6IkkOkENycpzRAQsPD6dHjx60aNGUGjUKyczKctvnVq+zdDqCQ4IICQkiJdk98+20ev/U1EMrHQAuX77KP0dPIzHxLABNIuvTf0AXGjUKo1q1Kly9mk3iyVS2b//L4j69voT+wQEEhwRyJuWiy214+80FbFivOGAhIYE89Eg/mjZrQEZGDr+s3UXs0VOkpv4N8Gvz5s27JSQkpLosxEuFxxkn7FdguRCi+Kfqc4ZzFYKlS9cbv8iioyNZuHC6RX6xxx+/j3HjZrBjx0ESE1P57LNlxMSMueVkqF2/EIK+/Trz9NND6Nq1danrI0YM5MCBOJ59Zhq5uXns3PEXq1dv5aGHXIt04gm20EKG2vawX38QksskJZ3kxYnTSExMYujQobz//vtOt7+Yj6cONzpgn3yxkY8+20BhYenevykf/mTTCatVI4CP3nnYeCy5AFw16FFkpkd/BLUMZa4CF9z2uW3TtilNIhsQHR1F6+hIGoSHsmrVFia9Oculemyh1funph5a6SCl5NWX/0Ni4ll8fX2IeXMUI/9xt01n7sIFU69t6zZRNG5Sn+joJjRvVZ8GDeqwZvV2/vXWVy61YeuWg0YHLCysFgu/fYuweqaYaCMfHcCUyd+wZvV2gDDgE+ARl4SUEe+cMG1xZjjSB3gWuNNwahPK6kj1l7dYUHo4sqhIR+/eo0hPz0QIwdq1c2jaNKLUnVeuXOXOO58hNzePSpX82bZtkdMRkD1BhrvrtzYElpmZ41Ry3e+++4Xp0xYA0LlLNN99N8NqOWvDkZ5gC3fLsDUc6W57lLd+cyfM2eHI/r1b8MNXYwH4cvEfvD1ztVNtK8mEZwbwzqv3G2RnoSz2tqVHYwRVDCsEk4BCCz3A3nNyrUfG3Hkp73Cke+19Y/Rw92fW1nDk8mWbmDZVcZpi3niSJ0YNdqK9pdFJJaK+uRPm7HDk8GGTSTh+BoC5X/wfvfuWjhOWl1fAkMFvcOHCleJTbRISEmLL1FgXGLP9d7cPR37Tu5/XtbOBMwm89VLKL6WUD0spHwbigQqxWnLPnsOkp2cC0L17O6tfZAC1aoVw7729AWUYaMsW+3MAPE2GFjo4888TYNAgU97Bkyes522zhSfYQisZatujLPW7yvin+wOQnZPHe//5pcz19O5mPok70+JaaT2UJONKKIhg49nyfG61QIv3T2200EFKyeKFSvaH8IZ1eeyJe1y63x2kJKcZHbCGEXWtOmAAVapUYtgjfc1PDVe/dV60xqmfPEKIDkKID4UQycC7wHFVW+UkO3ceMu737t3RbtnevU357rZv//OWkqGFDs4SEFDVuF+8oshZPMEWWslwlvLYw9X6XaFBvRr0MgxDrtt8lGu5ZW9bvdBgsyNH9ZhfN6WqUfs5aYUn6FEeHf48cIwzZ9IAGDy4V5nmk5WXXTuPGvd79Gxjt2zPXm3NDwep0yJLvLkjtcVexPxmwD8M22VgOcrw5R0atc0hJ06cMe6XnAxcktatTddPnjxjp6TnydBCB2c5edL0y7VevTou3esJttBKhrOUxx6u1u8K3Ts3MX5BHjyi1DH4rrY8Mbw7bVrWJ7h6VTKuXuPQ0VRW/vwna9b/ZbOuskfhN628U/s5aYUn6FEeHf48YAph0rpNJHq9njU//sGa1X+QmHiW3Nw8atUKpn2HZgwZ1o+ePW2nEyoriSdNw+GtohvZLdu8RUMAHUpslVbNmzcXCQkJ3sDlHoS9ifnHge3AfVLKRAAhxMuuChBCBACPAj2AUMPpNGAnsFRKec3VOotJTjZ9mOvXtx8mIDS0Nr6+Puh0elJSziOldOqfsyfI0EIHZ/lh+Ubjft9+neyULI0n2EIrGc5SHnu4Wr8rtGvd0Lh/OT2HhbNHc/9Ayy/EsLohhNUN4d472/DPx5IYNeEb0jNK/zv5+3IWzaOK//VUwn5vmGnht8AXiR9QpPpz0gpP0KM8OsTFnTLuVwuowlNPTuXgn5YDOxcuXObChcusX7eLuwd2Y8Z7L7gUvsURKSlpxv169WvbLWuIEXgOaIjSNVsfOOu2xlhB+77BWxt7z3sYcAHYKoRYIIQYAK7lzBBCtAJOAP8G6gDnDVsdw7kEQ5kykZ1t+ofraFK0n5+vcYl/UZGO3Ny8W0aGFjo4w8GDx1m16jcAKleuxFNPPeDS/Z5gC61kOEN57eFK/X5+zizENlG3tilC5Zsv3sv9A9txPa+Ab5bs4PnXv2Psq9/y5eI/yLmmTL7u3iWS5Quew9+/9IKOvQdPmx0Fl7puSUl7+Kj+nLTCE/Qorw6XL1017r/7zgIO/nmc6tUDeGrM/Xzw0QRmvDeOocPuwM/wOdq4YS+vvzrbfQoA2VmmILIhNZyKxHrFbN92HBY34SOk2zcvtrGXtuhH4EdDT9aDKHkkbxNCfAGsllI68xP3M2AHMEpKafHtYUgQvshQpkxDnOZfSJUrOw5dZl7m2rXrTs1X8QQZWujgiEuXMnj5pY+McXYmvvgooaH2fwWWxBNsoZUMR7jDHq7Uf9fdt7t0f/XqJh2jGt/G5fQchjw5l+MnTb0IK9b+ydffbWfNt+OpFxpChzYNGftUP+Ys2GJR19KV+3jxmTvx9/dFUB3JNYpDVFhyG4IqJfTIVPU5aYXa9tYCd+iQnW1ygJKTL9CwYSjfLP4XoaGm8BAPDunL8BF38szT08nJuc7W3w6wft0u7rm3h1v0sHj/nUvefd1s3xs/38NwZnXkNSnlEinl/UAD4BAQ42T93YCpJR0wQ715wHRDGS8eTG5uHi+Mm8nFi8oPur79OjNmzIM3uFW3Lmrbw1r9vXu7lmDDp8SQ69szV1s4YMWcPnOZV9/5wXj87BO9S5VJOXuFT7/cZDwWhAHhKJ0KQShpjBohqIWkyBj2Izc3lxfGTbnpP7ee8P65Swe93rJXZvp7z1s4YMW0aRvFxJdGGo+/+3a9y7JuVrwT87XFpeFfKWWGlHK+lNLZ6HgZQDM715saypSJatVMv1rz8x2vkjEv42xvgifI0EIHe3WNe34GR46cBKBjx5Z8+umrZZrX5Am20EqGvbrcZQ816y8eZgQlHdHqdYdslt34ezwXLio9W2F1Q2japHSuyw/n/orksiH+FwgCEYQhaIAgFEFVJEVAqkGPfJ5//nmOHEkolx43GrXtrQXu1CEgwPTuRUY2oGPHFjbLDhnazzgsGXs0kdxr7pkKYPH+O5GiCTB/6bPd0ggvFQa15+AtABYLId4QQnQSQjQwbJ2EEG8A3wA2k8YJIZ4VQhwQQhyYP395qetBQaYl5BkZWXYbUlSkIydH6Yr29/ezeBHs4QkytNDBGgUFhUwY/z579ihLstu2bcr8BZPLXKcn2EIrGdZwtz3UrD8z2zQCE59wHp3OfmzoI3GmucqNG5bu2VC4BJxGkoEkH4nesOUjuQycAvIoKChi/Pjx7Nmzp9x63EjUtrcWuP1/SHXTu9cqurHdstWqVaFxIyXVlk6n59y5v8sks3QbTOnHrmY45VOZf6CtjaO7FW9PmLao6oRJKacAM4GJwH4gxbDtN5x7T0r5rp3750spO0spOz/77IhS1xs1MuWCc/SCpKVdNv4jb9gwzOlfUZ4gQwsdSlJYWMRLL37Etm0HAWjVqgkLvnrH5RyL5niCLbSSURI17KFm/UmnTc8lK/u6nZKGMjmmXorqQfZ6C/NRFmefAhIM2ykUB01HYaEPL734Etu2bQPc/5y0Qm17a4E6/0PCjPtBQY7rCTQrk52Ta6ek80REhBr3z5+7bKek8iMMjElPr2Ge7kElfFTYvNhG9ecjpfxASlkPiAR6GbZIKWU9KeWH5am7WTPTMva4uES7ZWNjTdebNm1op6TnydBCB3OKinS88sq/+e23fQb5EXz9zRSnI2LbwhNsoZUMc9Syh5r1xyWYEkLbd6oMZQJNPSPOOG3WMOmhrL5r1izKrc9JK9S2txao9j+kuSk7hfkkfVvkmJUJcpMDG9XU9CMsPi7ZbllDZP3iJb/x3hhhnodmTqqU8rSUcrdhOw0ghAgXQnxT1jp79TJFG9+x46DdsubRxs2jkN8KMrTQoRidTsfrr33Kxg27AYiKCmfhoqlO51W0hyfYQisZxahpDzXr370/yTgvrFXzevj62v9X1aZVA+N+UvIll+WZ9PgDgKioKBYumuG256QVattbC9TUoXfv9sb9+LjTdkoqiwFOJys/Bvz8fanfwH5MP2cxj5JvHj3fGjt3HDE//NUtDXCAN0SFttzonsKawKiy3tytW1tq1lTi/uzaddhmdO4rV66ybt12QFnuP2CA8wsyPUGGFjoA6PV6Jk2ay7p1OwBo3Lg+Cxe9S61a7glt4wm20EoGqG8PNeu/nlfIht+UXMXB1asy9F7bqyvv7teKeqGKzOTUyy47YaX1aMzCRV9Qq5b7AnRqgdr21gK1dahXvw7t2itrxZKSznLwoO0MfD+u/p2iQmWlbMeOLdw2ly6iUSgtWio9cmdSLrJj22Gr5fLzC1j1vz/MT/1gtaCXmxpVnTAhxJP2NuD+8tTv5+fL2LFKTlMpJTExn5KZmWNRJj+/gJiYT42xWR57bLBLv6g8QYYWOkgpeedfX7Dmx60ARESEsWjxNOrUqeF0HY7wBFtoJUNte2hh748+20Ch4Utw+qShZlHvTTQKr8VHUx4xHn/29VardTWLrItpVMdEaT0iWLR4EXXqOLVqrcKghT3URisdJr5oml/89ptfcPFieqkyR48mMvs/y4zHo8eU66uqFGPHDTHuz3j3v1w4f8Xiul6vZ+a0b7lwwXh+RUJCQqxbG2ED78R8bRFSqtdVKITQA7mALSE+QBUpZen/jqU4YbWOgoJCRo+ezIEDcQCEhdVmxIhBRETUIy3tMitWbCIpSVl2HhUVzrJlH1msTnMGT5DhzvqL4yiZ88kn3zJ/3kpAWcUX88Zoq/F3StKzZwerKUGElS9Md+thi5tJhjVbgPvt4Ur9VaoEUr++ZWSaoMAa1KnT0NDmXJR/Cyb6D1nI0WOl5xxP+Gd/3nlNiYp+Pa+AJSv3cuCvZPR6SYe2ETz+cDcCDWEHtmw/xshn5mPtf9oLY+5gSsz9Brm5QKFBj2+YP+87gx7+xLwRQ2ioP5bxMUtj/TnZ/k17NjWNFSs2W5xLSEhm61ZlzlPnzq3o3Lm1xfW7B3anVavIEjVZXyXqXnvfGD3c/Zkt0udbKa0wbepXLF+mxI6rXj2Ahx7uT8tWjSksLOLPA8f46adtxl6whx8ZwJR3nwXg7Nm/WbVCmTOohDSBEydS+WOrkru0Y6dmdOrc3ELWgLu60LJVBCV5/ZXP2bB+LwAhIYE8PPwOopo1IPNqDmvX7CT2qDHF0gWgW0JCQqrDh+EG/m/vb253Cj7p1t/ritlAbSfsLDBRSrnKxvX2wJ/lccIAMjNzmDjxPfbsOWKrCNHRkcydO4l69co2ru8JMtxVv7Uv/ieeeIv9++JcbtPmLfNo0KB0XCdbThh4hi3cJcOWE+Zue7hSf9euXfn2229dkjv+jSUsW73P6rWXnruT18cPolIl26mPflx/iAlvLOF6nvUerBfG3MHUmNLBPZ944gn27bMu1x7Wn5Nt52Xv3qOMevItl2TMfO9Fhg0rGZLRuhPmXnvfGD3c/Zm154Tp9Xren7mIpUs2WnXai3n08UHEvDHKOCdx3744xoyyuaDfKu/O+CcPDi0dRLigoJDJkxbw67q9Nu8ND7+N1NS/2yUkJNj+J+FmXlXBCfvY64TZxLWEbq7zJ9ARsOqEofSQlds4wcGBLFo0nfXrd7BmzW/Ex58iIyOL4OBAoqIaMnhwH4YNu7M4GeotK0MLHbTAE2yhlQxP4D/zNrNu81GeHNGDO3o2p15oCH5+Pvx9OZt9B0+zZOVetu85abeOVb8cZEpMN5QcyJVQ/vUJpA2nxotn4+Pjw6S3xzD4vl6sWrmV/fviuXRJiRt+22016dylJSNG3kWr6CaqtaFSJX8++HgcDzzYix9XbePI4STS07MJCKhCw4i63DWwCw89cgc1g/pq5oCBd/hQa9TuCesNBEopreZ8MOSl7Cyl/MPadUts94R50RZbvS/uxF5PmBcTWthCC+o0txmz2W1cSnhOZQlarHPSwmn0DD3s9YS5A13pbHyqUMX3dk3dotf3ub8n7MOu3p4wW6jaEyal3O7g+jXACQfMixcvXrx48aI2whtSQlPUHo7UDCmlcVjn2LHTpKdnEhISRGRkOPfd14ehQx0P60gb6wd0Oh1JSWeJjU0kLi6R2NhEEo6fJi9Pyen3wviRTJjwqBOttP3rLzv7Gju2H2Lv3lji45NIOZPGtZxcqlWrQlhYHTp2bMGwYQNo07apXQmOepDc8ZzU1sEZ3GNv671IWtnCPXrY7rVw1+e2UG8/tcrxY8msWvkHhw4mcO7sJXJz86hWrQqhYbVo2y6KBx7sTcdOzUvdl52dy84dR9i/N55erU9wLvUK167lUbVqZeqGhtC6fSPuebALLaKtB6n1E0EcO5JOyolrtG7dmhYtWlC1qhLYdc6cOcydO9eifIvmpg556Vcfqj/C+2/fwbDBtvMHlqRZ9y9sXovd2QcfAhAiAEFVBP6AH3PmfMZnn33mtIxiHhjShxnvjbU452PnX/ZTT05h//54p+quV68Om7ZYb5OPsC5DSsmhQ8c5ejSR2KOJJJ06S0Z6FhkZ2QihDK83axZB376duP+BvlSvbnuxirAhw33/a00T521R1s9tMT7C3+r5z+eu4IvPbM3AsY01e3vxfDzCCbM1wfnSpQwuXcpgz54jLF26vsyTqF966UM2bdztruaW4qsFq5g9eykFVpK5ZmVdIyvrGgkJySxd+isPPNCXqe+Oc2oFW0nUfE5a6eDVw3nU/tzq9f2jtboAACAASURBVHo+fP87lnxXenJzdnYu2dm5nDyRysr/beWee7szbeazVK5cCYBvvlrLZ3NWWn3OOdnXycm+TtLJC6z5327uGtyRV956mCpVKxnLhFTqTFW/MOp0A1wLn6bgE1yGm+zjJyLwEaUjupc11VQDNwUHdRcFBYU89qjtSfl5eelcvJjO9u2H+PzzH3h32jgGDOjqkgy1P7NQvs+tmlQUe3vnhGnLTe+EFRQUMm7cdIul/sOHDyIiIoy0tMusXLmZpKRU4uKSeOaZKSxf/rHLucf0JZIHB4cEERISREryeRt3uEZy8nnjl1F4eF2692hHyxaNqVGjOplZOezZfYSNG3ej0+n56ac/uJKeyYIF/8LHx/m5G2o/Jy108OpRsT63H73/Pd9/u8F43O+OjnTu2pLb6tQgPT2Tw38lsnHDXnQ6PevX7Uan1/PvTycCkJKcZnzODcJvo0PXJkQ1q0dwjQCys65zcN9J/thyFL1Oz6ZfDnI1PYcP5v7T+JxFifU8+QXXKSi4TlBgTQD6D2xP3SZPGa9LvWTyq98jintHKkeX0mfy+79zJaNsKY+McmQRklxlk/lIihh4T1uaNZ+KEAH4CFMKJp1MRy9NMapycq7z9ptfAuDjI3hwSOkVdc4ye86rdq9XKeMPB4C6dWvStm0zmjePoF69OgQEVOV6Xj6nT53j1193kZJygfT0LF6c+CHz5r9Nz57tHVdqQO3PLJTvc+sMg+7tTvMWpUNSlMSd9nYnNzqC+63GTe+ELV263vhFFh0dycKF0y3yiz3++H2MGzeDHTsOkpiYymefLSMmZoxLMtq0bUqTyAZER0fROjqSBuGhrFq1hUlvznKLDkII+vbrzNNPD6Fr19alro8YMZADB+J49plp5ObmsXPHX6xevZWHHiq57Ns2aj8nLXTw6lFxPrfnzl1iyffKF5mvrw+fz3uNHj3bWpR57Al4asxgRj85ndzcPDb+upfjzybTomUjhIA+fdvz1Jj76NK1JVfyLljce/9Dt3Pk4CliJnzN9dx89u8+wYa1B7jnQaVnpUCfQVFhNoX6TAr1V9HJ61T1b4CShAMaNr6Nmg1M9tu787jRAZM+IeBfn5Ls2HuWc2n2h17tUSRTgNKTtRs1CaRRE2Xo2oea+IpGCCGQUlIoj1Ics+yHZab4W127RVOvfp0yt2XAna71QDmDv78fa3+eRVRUuM0yEyaOZPr0r1i2dAM6nZ6ZM77ml3VznJah9v/a8n5u/5+9846Pouoe9zMpENLpSSAkgRBK6CAdQVBBwQIqKCrYUF6k+VpQbGDD9r58VVSKCv5EEaWjgHSpASIthZIECDWhpJBedu/vj0l2N2R7dje7+87DJx9md+7cM2funZmz9557jjm0bNmMli2r969bsWV7K7guLm30lpermD9fzuQgSRKffPJStQSvdevW4dNPX9KknFi69A+ys29aJGfixNG8/PJ4hg3rR/Pw6lG7a8orr45nwYK39L70K+nRI5Z/v/yk5vPq1dvNrt8R18neOoCihzP127h9iajV8lTOkLtuq/Yiq6R9bBSPjBms+fzPP6cAeOmVsXw9/1Vu69nOoIxO3VoyYco9ms+b1sVrtgvKU8krO0mx6goqYXr0auNanVhgddubLG8dplfLqclCkAvIbe+BNgvC6lU7NdsPjhpo87OrKR4eHkYNMABPT09mznyW4OAAAM6cucSFCxlmy7D3s7am/daWOGt7K7kjHYtLG2FxccfIypIfaH36dKZ1a/1DwA0bBnPvvfJQb2lpGdu2GQ6OVxvc+gI2xLBh/TTbKaf15xvUhyOuk711AEUPZ+q3WVlagzAiwvjLMiIyVLNdVCSHDQgKMi/DwKC7Omu2z6ReMVLSMDdzC9n7t+ywLpDsaISZh6gSjV927k5NuaiJkB4Q6Mudd91WC2dmG7y9vYiI0Lb59Ws5tXg2Valpv7UV7tTeCjXDpY2wvXuPaLYHDOhmtOyAAd0127t3/2O3c7Infn5af5LK1ULm4EzXyVodQNHDmfptw4Zax/b0dOMjHed19rdsGWaRHF9fre9SSYl1+Ry3bjhMWWmFL5h3BHiYZ2jbD11/LFkn3VGRe+/t6xBHcHuhVqu5dPmq5nOjxs6TQNxR/dYUztzeSu5Ix+LSPmGnT5/XbMfGRhst26GDdn9KynkjJZ2XlBTtiEtYmPn+A850nazVARQ9nKnf9r+9M97eXpSVlbNtyyH27U2gb7+O1colJ53l9+XbAHnkYcDt5jtpA5xN074Im4Zal8h547pD2g96HPIr+eCNgUS1CKZRA1+KS8q5er2Aw8czWLPpNPFHrRuFuxWJQDyQ9RBCjZpcystV/LF+j6bMyIcG1VjOv16YQ3LyWXJy8/DzrUdIaEO6d2/HqIcG085M3yZrEELwxf/9ohn9atcuinA7TCtai6P6rTHs0d62RDGaHItLG2HnzmkT/jZrZnx5b0hIIzw9PVCp1KSnX0YIYfXS8drit+WbNdsDB3U3UrIqznSdrNUBFD2cqd82aVKfl15+lE8/XopKpeaF5z5m0B3duK1ne5o0CeZG1k2OHUnRrDJr1aoZX8z7N97elj1y1q+M02z36W/Yf8wQqacuk3JSvt5CqgfehtPQ9Oup9XeqU8eTwIC6REc1YPQD7dmx9xyvvbed3JvmTUtJ+FI51SjhAXjjIQXiIckjMUIIVOI8UM7fOw+TdUOeJotp04LYDjVPlbNrl3a0NTc3n9zcfE6dTOeXnzcxctQg3nr7OXx8ajb6snv3Yc3oZHFRCennM9i6JY6TJ88BEBwcwPsfTKqRDFvjqH5rDHu0t4Lr4tJGWF5egWa7fv1AIyXBy8sTf39fcnPzKS9XUVhYXGVKydk5fPgkq1bJDuB169bhqafuN/tYZ7lONdEBFD2crd8+Of4eGjUKZu5/lnHlyg127jjMzh2Hq5Rp0CCQKdMeYfh9/SyOp5Z49BybKkax6tT14uEnbrf4HKs45NdpA1L1wLf5BaXsPXiR48mZXLlagFqlJqSJP/16NmdAbzlQ7B39Iln6zQM8+vxqCgpNT4t6SE3xlBro3acW+ajEZQTySsw1q3dp9j04smYO2sHBAfTr35n2sS1p0rg+AsHlS9fYufMwR4/IzuWrV+3kyuUbLFg0s0Z5SWe+MY/r16v7e3l7ezF48G288uo4s5LBOxp791tT2LK97YGSMM6xuLQRVlioXY1kzpy6bpmCgiKneZmZ4tq1bF6a/hlqtRxDZ+q0sYSENDL7eGe4TjXVARQ9wPn67Z1334aXtycff/T/uJqZXW1/VtZNFn//B55enoy0YAXYjes3mTXjJ81KtmcmDaNJU8t8i8rKytmyUeflqmcq8qffE5j9+W6KiqtHV/9h2TF6dA7ly4/uplEDX9q0asgbU/vy1sfWZ1oTogy1uImoWEl5/Xoue3YdBWTjZcT9/YwdbpTpL40ltkNLvaM2E54fydYtB3l9xlcUFZUQF5fA99+t5YWJo6yWZ4iWLZvRp08nGjSwfUBcW2GvfmsKW7a3gnvg0kbY/wKFhcW8OOkjMjNvADBwUA+eeeaBWj4ry3AHHcB99LAVF85nMmXSf0hLu0Sz5o356OOJ9OnbkaBgf3Jz8tm/L4Gv563k/PlM3nlzIennrjD934+arLeoqIS3XlrM9avyCtLeA9ox5knLX4R7dyZxM6cQgJh2zTmVWd13L+nUdaN1xB+7wuQ3/uKXbx/Ew0Ni1PC2fPV9PJnXCowepxJnUYmzFZ8kJOoiEYSnFIKXRxhCNKFcnOWPdX9QXi6nzxp0RzeTI6PG6NI1xuj+O+/qyaySF5jx6pcALP5hHU8/cx916uhPv2OK3Xt+AOSp1YKCIlJOn2fd+r/5/bctzJq1gKU/b+Drr9+gRQvn8QkD+/Vbc/hj3W6btbe9UEJKOBaXXh1ZGUMJoKTE9Ao13TLONJpgiJKSUib960OOH08BoFu3dsyd+4rFPkG1eZ1spQMoeoDz9NurV7N5/NF3SUu7RIsWTVn++wfc98AAGjUOxtvbi0aNg7nvgQEs//0DwlvIU1LfL1rPrp1HjNZbUlLGm9MXcyLxAgAdukTy7idPWHWdN67VOuTf+6D1IQAOH89gz0H5fLy8POjfy3isrOoIBMWoyaRMnECIUiTJCy+pFWtW7daUckSsqBEj+hMVJa/0y8sr5PDhmse/kiQJf39funZry7vvvsD8+W/i6elBasoFnn1mdpWR39rGXv3WXNas0o6iOlNsMIXaw6WNsIAAbawhU4Esy8tV5OfLv4q9vb2qvAidkdLSMqZM/pi4uAQAOnVqzcJFb1t13rV1nWypAyh6OFO/XfjtGrKzZZ+mKdMeIShYf9iHoGB/pkx9RPP5l5836y0H8vThOy//yOGDqQC06xDOJ189Z5VPTmFBCYfiTgOyP9mQe4yHAjHFwcPatDktI2oScqEUlZAXChw/nkBammzcNWnagH79Oxs70Gbc1lMbJ+3smUtGSlpH/wFdeXDkHQBcvJjJ2rU7bS7DWuzRb83l+LFU0tLk6+3I9rYUJUSFY3FpIywyUpsa4tKlq0ZKQkbGdVQVeclatAh1ihVmhigrK2f6tM/YtUv2Z2nfviWLvnvX4tyBldTGdbK1DqDo4Uz9dtff2pGB3n0MZxcA6N1Xuz8hIU1vmfIyFbNe/YkDe08C0LptMz79egJ+/tYZnWmnLmvyEA64oyMBATUbQczJ1Y7mBPrXzFFbXRExf+XKlZrv7n+gP56ejnkcV0azh6qLRGzJgP5dNdsHDybaRYY12LrfWoJubDBHtrelKEaYY3HOXmAmMTEtNNtJSalGyyYmave3bt3CSMnapbxcxcsv/4ft2+VVXTExEXz/wyyzI7nrw9HXyR46yPUoejgL13SioPv5Gzdw/HX2FxVWD/FQXq7ivTeWsvdvOZdmy9ahfP7t8wQEWm/opp7Wjlzd80DNo5EHB2mNwZv5NY2erqa4uJgNGzZovnHkKrmcHG1+TN1RWVuiO22ed7PQLjKswZb91hKKi0v5a6M23IozropUqB1c2gjr3187xbBnz2EjJatGG9eNQu5MqFQqXnt1Lpv/2g9AdHQ4i5fMrrHzpiOvk710AEUPZ+q3ui/ZjIwso2WvXNY6vwffMv2jUql547Vv2LVNnuqNbNmU/8x/nqDgmhkHuTnyCE/T0Pp079W6RnUB9OyqjZh+7nxujeqSqMtff/1FXp5sDHXr3rZKihx7E3/ohGY70k5y089rg+zWrx9gpKRjsVW/tZQtmw+Slycbo45ub0vxlGz/p2AYlzbCevXSLoPet+9YlSjmuty4kcOGDbIDbN26dRgypJfDztFc1Go1M2fOY8MGOZJyVFQzFi95j4YNa57yw1HXyZ46gKKHM/Xb6NbNNdubNuw3Wnajzn7dwJRqtZp33lzIpooRgvDIxvxnwQvUb2C7l/aw+3vUeAq3W6cQjTO+SqVm94GaZS7wkBqxatUqzeeRDzluVOTPP/dwpsIPzM+vHt26t7W5DLVazcqVWzWfu3S1vQxrsUW/tYa1q7UO+Y5sbwXnx6WNMC8vTyZOHA3Iy6RnzJhLbm5+lTIlJaXMmDFXs0Ln8ceHO92yYCEE777zLWvX7AAgIiKUJT++T+PG1qVpuRVHXCd76wCKHs7Ub+8d3kezveDb1cTt1+/3E7c/kUUL1mo+j7i/PyDr/d6737NurWxkNgtvxNwFE2nYyHY6SpLEPfcbnop88J4Y+t7W3OB+gO6dQpg3ZygeFY4tazaeJuNqdT+qwf0jkTBtpHvQhMsXSzlwQE7G7udXj7uH1ty4XvrTBo4fSzFaZtvWg7z79gLN56eeHmFRzsIff1zP0aPGV1MW5Bcx47UvOJEsh+cICvLn3nv7my3D3tS031rDpUvXOHhATiBvq/a2J4pPmGNx+Thhjz12D5s37yM+PomkpDQeeGAKY8YMIyIijIyM66xYsUWzAik6OpxJk8ZYLOPihQxWrNha5btTp85ptg/EHUdVrq6y/+6hfWjfvpVZ9c+du5Tff98CyCvgnhw3goSE0yQkGD+uX7+uZq8cs/d1coQOih6WYc9+O/KhQaxe9TeJCWcoKSnjhec+ZvCQHvTp15HgYH9ycvLZvzeB7dviNQFX+w3oxN1DewLw5f/9xsoVOwHw8vbkobH9OZF0AZIuGJV7W+8YfOrVwVOqRz2vqj5y3pLWgOvduzfNWzQmOkI79dsuppgTp7VTTO3bNObTdzpxOSOPPQcucCoti6ycItRqQUhjP/r1Cqd/z3CNAXY6LYuPvtir97zCmwXi7dFKDsbKTYQoAsoQqJHwRJJ88CAYSfJhzZqvEEK+JkOH9bLJitcDBxKZ89ESoqLC6NW7A9HR4QQHByCE4NLla+zc8Y8mYj5Az16xPDdhpEUyDh1M4uM5i4mICKV37460bt2C4PqBeHp6kJWVS3LyGbZuOaD5QeHl5cn7H0yyaDrS3s/amvZba1i7+m+bt7c9UeKEORapsnM4P6cNnmhubj5Tp84hLu64waNjY1sxb95MwsIM5+oT6Bdx4EAC48e9acG5wkdzpjFq1JBbvlXrLfvkk29y6GCSRfUDbN22oFpaEMlI0gnbXSdVte9sqQO4hx7GdADb6GGoz4Lt+m2ZOk9v2ZzsPF5/7Rv27jF8/pXcPawX73/wPL5+8gvo6XEfVPFNMpdlf84kNKwBdTwa0tCnr0XHznh/O6s3aA2RmdP78dSYTmYdu3nnGd6as5McA7kjx4/pxJvTTUc/F0IwePBgLl+WFw789Mssk0FWdfEw8Lt5yuRP2b4t3uTxkiTx8CNDmPH6eIM/Gjwk/TImv/gx27Yd1LvvVsLDmzJr9kT69tUfhkEyIMN2z1r79NuqmB7iEUIw7M5pXK7wL7O0vQHqeHR36FjSF0mbbW4UTIu9WxkPM4DLj4SBPOS9ZMkHbNy4h7Vrt5OcfIbs7JsEBfkTHd2C4cNvZ9SoO2uUJ80dcJfrpOjhHATXD2D+ohns35fIhj/3kXAslczMLIqKSqhXry4hoQ3p3KU1Dzw4gK7d2tT26Vbj+5+PknjiKl07htA+phGNGvhSP9iHOnU8yc8v5eKVmxxOyGTNhlMknzYeWf+XVYm8NrUxHlIAEn5I1EV+vHog//gqQ1DEvn1/awywyKhQi1/Ihnj1tXEMHNid48dSOHkqnawbueTk5FFeriIw0I+IyFC6dWvLyJGDiIwKM12hHj78aDLD9x0j/lAyJ0+e5cKFTHJy8hBC4OdXj5CQhrRr15I7Bt/GoEHdrY7Eb28c2W8PxCVpDDBbtrc9UaYPHYtbjITZCmOjCrZB/0iYLTE1+mIL9I0g2Rp30MMxOtj//jU0omBLbhRfsbuMgUMu2rX+xL3WT1mZi6GRMJvKMDBKZUsMjYTZEvv3W8dYK44eCfsq2fYjYVPaKyNhhnCLkTAFBQUFBQWFmuOc4+7ui8sbYSqVirS0iyQmppCUlEZiYgonT56luFjOtzd58mNMmTLWRjJSSUpKJTExlVM6Ml6c/GiNZVQihGDjxr2sXbuTkyfOkpWVS3BwAK1aNWf4iNsZOXJwjaan5Prl6a8TVeoPZ8SI2xk5smbTX1WvVRqJiWm3XKsxTJnymNX1O0IPR+lgbz2q1r/jlv4UXtGfhlhdvxCCo0dOk5hwhsTEM5xNu0xW9k1ysvOQJInAID9ax4Rz+8CujLivH4GBtg8M+uqkhRzaf1rzecbsMUZXRFqCh4dEq0b/0LFdQ2JjY+nQoQNt28ZSr568ovCr7w7x1fem/bBuRaIeHlIDJAKR8EZ+7ZUjKEOQj1rcRFA9nZWEP14e+qfHhBAcPnyYhIQEEhISOHPmDFlZWWRnZyNJEkFBvrSOacHtA7tx330DrG6LynsjKTFNe2+cOqe9N14czeQp+pNdVzk2+azNnqOnTp5l3bqd7Nt3lIyMG+TnF9KgQRBNmgbTpWsMffp2YMDtXTTl8/IK2bvnOIcOJHPixDnOp2dSUFBEPd+6hIY2omvXGB4cdTsdOprn7K+Pp8e9b7bPY1hYI/7a9qXVsmyNMh3pWFzGCDM07TJt+ids2Ww43ouo+FcTpk//1KgMc7HWUfvatWyuXcsmLi6BX5dtMulwbn39x1m2bKMZ9RuObDLdRHvIQ/g1i4xibz0coQPYRg/JyJSIOfX/asZ18pL0RxYvKS1l3OPvGTyuuLiUq5nZ7N19nAXfrOa99ycxZIj+Kbsm9aIM1mOINat3VDHAAAK9Gxms68Q+y2RkXPahWbOJBve/+GwEk57VXpuw9j8ara+ejzezZ9zHE490xdPj1v5TB4k6gB/5eYHE9Hqn2vF9b2vJ6v+n3wgrLS1l7FjDBkxxcTGZmVns2X2U+d+sMNoWxqYKX3rpM+P3huRh8HhTx5aqbpJfZv6UcXFRKf/9dAVrVu7VrGSsJDPzBpmZN0g4nsaaVX9zKP4XAL5btIovv1xGaWlZtfrybhaSd/M8p0+dZ/mvW7n//oHMfm+SwQUMKnWpwXMzdl/qK+2IaWYF58TlW74yP1wlQcEBBAcHkH7usoEjnFNGaWkZkyZ9QHy8vDIvNLQRo0cPIyIilIyM66xcuZW0tAskJaUxYcIsli//3KL8hfauvxJ7XytH6KG0t2U0bdqATp1iaNMmgrCwxvj51aOouISzZy6xadM+0tOvkJV1k2lTP2XBwrfo16+L6UpNcONGLp98vASAer4+FBUWGz/AivpTU6/TrFm05rvs7Gy8vCAgwPKYcb6+dVj67TP06ymPrly4nM2fmxM4mZJBXn4xgQE+REc1YfCANoQ2DdJbx8mUDNRCf6BYtZANgqZNG9GpU1vatOlEs2bh+Pn5UVh0mbNnUmzSFjW5N6odG+RHULAf59ON50/VR2FhMdMnfcvheDk2WkhoAwbf1YVW0WH4+fuQn1fE5fQCdu85TGbGDc1x585d1hhg4eFN6dO3M+3aRlG/fiC5N/OJ23+czZv3o1KpWbfub25k5bJo0Tt4VDOazefLr14xut/HigT19kQJUeFYXN4I69ipNS1bNSc2NpoOsa1oHh7CqlXbmPnGFy4lY9myjZoXZmxsKxYv/qBKjsInnhjBpEkfsmfPYVJTL/D1178yY8YzTlN/Jfa+Vo7QQ2lv8/D29mL9H18QHR1usMyUqY/ywQff8euyv1Cp1Hz04ff8ueEri+To48MPviM3N5927aOIjg5n/bpdNa7z1vojWnTk2vVMCguy+PHHFVy8eJGlP8/jth53WVzfZ+8+pDHA/m/+Nj7/ZgtlZdUXhrz3+Z+Eheg3wrJyCgH9zube3mqdtqiDhySnahJCheAU0NMmbVGTe0P32Kg2fjRr3oj1a/Yz+62fLDoHgDmzl2kMsKcnDOX5ScPx9q76OvP3DuO1GU9x5co1zXeSJDFwUA+effZBevasnsB7zJihxMcn8fyE9yksLGbvnqOsXr2Dhx6qHgLDXIbcaf8FGwqui8sbYZWRx11ZRnm5ivnzfwPkh8Qnn7xULUl03bp1+PTTl7jzzgkUFhazdOkfPP/8w2ZFUbd3/brY81o5Sg+lvc3Dw8PDqAEG4OnpycyZz7Jp4z5ycvI4c+YSFy5kEB4eYracW9m+/RCbNu7Dw8OD2bMn8svPG62uy3j9cfy6fA6//HyUixetX1l5R/82PHy/HDR24f/bzZwvNhktfznD8tyUum0hoTtSlwsV7hi2aIua3Bu6x1oy7Xgr+/YksfHPQwA89sQdvDjtAaPlQ0Mba7ZfeXV8tXvhVnr0iOXfLz/JB+8vAmD16u01MsJcDSXXo2Nx6bRF7kJc3DGysuQHb58+nWndOkJvuYYNg7n33gGAPN20bdsBp6jfUSh6uGZ7e3t7ERGhTVh8/VqO1XXl5xfy/uyFAIx9fBgdOkabOKL263/xGTlXYF5+sUkDzDZoR9IEVa+1LduitvhpsRxR38/Ph39Nvc+iY00ZYJUMG6YNvJtyWn9uVwUFW6AYYU7A3r1HNNsDBnQzUhIGDOiu2d69+x+nqN9RKHq4Znur1WouXdb6/TRqbH0i9M8/+4nMzCxCQhoybZptViTbs/7mYcH06yVPQ27clkRhoWFnbtvgjyTJQVKFKAaKquy1ZVvUBlcu3yD+oLwYY+DgTnZLAeTnp11wUbl6838FJXekY3H56Uh34PRprbNtbKzxX94dOmj3p6Tod9J1dP2OQtHD9dpbCMEX//eLZsSlXbsoq6ci4w8l8ftvcl7PN99+Dj9//as2rcUe9ffq3lLj1H3kuHx9772rA0883IuO7ZoRGOhDdk4hRxMusOrPI6zbZDqVjjF0pyJvHQWzZVvUFkf+SdXkYYztGAnA9i1HWLNyL6dOXCQvr5CgYD/ad4jgwfvuZtg9/ZAky62AlBTt6FdYWGMjJU3zrxfmkJx8lpzcPPx86xES2pDu3dsx6qHBtGsXWaO67YFiNDkWxQhzAs6du6TZbtbMeOiJkJBGeHp6oFKpSU+/jBDC5EPG3vU7CkUP527v3bsPU1IirzwrLioh/XwGW7fEcfLkOQCCgwN4/4NJVtVdUlLKO2/PRwjBnXf1MhhewVrsVX+XDs0129ez8vn+i3GMuLtjlTKhTYMIbRrEPXd24JnHz/DMlB8rnPAtxROQp9t27dpFcckZQG3ztqhNTiRpfyg0aBDAq9MXsmPr0Splrl3N5e/tx/l7+3F+/nkDX331OvUbWObb+tvyzZrtgYO6Gylpml27tCPTubn55Obmc+pkOr/8vImRowbx1tvP4eNTp0YyFFwXuxthkiR5AO2AbCHE5Vv2+QCjhRD/z97n4czk5RVotk05Rnt5eeLv70tubj7l5SoKC4urDJ3XRv2OQtHDudt75hvzuH69uo+Rt7cXgwffxiuvjtObrN0cvp73G+fOXcbPrx5vvvWsVXXURv1NGgVotmdMHUp0VBOKisv4alarHwAAIABJREFUdfUh4o+mI9SCLh3Defyhnvj51aVPj5b8svA57nv8a72rJ40TjPy4hTfemMH161nVStiiLWqT69e1QWy/nbee8+euUreuN/c92JuOnVvi4SGRnJjOmpX7KCoqIT4+mQkT3uOXZXPMzmV5+PBJVq3aDsgLWJ566n6rzjU4OIB+/TvTPrYlTRrXRyC4fOkaO3ce5ugROZH86lU7uXL5BgsWzXSaHLHKSJhjsasRJklSOLARaA8ISZLWAc8IIbIrigQBi4H/aSOsUCfGUd26pn8R6ZYpKCgy+dK0d/2OQtHDNdu7Zctm9OnTiQYN9IdeMMWJE2dZsngdANOmj6Vp04a2PD271h8YoL2W0VFNuJ6Vz0NPzedkSqbm+5V/HOH7n/ey+seJhIUE07VjOC+MH8C873ZaJEtC179Lf6ynmrZFbZOfp/VxO3/uKsH1/Zn/w3SiW2uTkt8zoiejxw5k4tNfkZl5g8TEVH5csp4Jz48yWf+1a9m8NP0z1Go5ptnUaWMJCWlk8XlOf2kssR1aVgubATDh+ZFs3XKQ12d8RVFRCXFxCXz/3VpemGj6/BTcD3s75n8MZAGxQD+gCbBLkqSaTbIrKCg4Hbv3/MCJk6tIPrGSQ/FL+eWXj3j0saGkpl5g1qwFjBkzg/PnMyyqU6VS8fab31BerqJjx2jGPj7Mpuds7/o9bhlWeGfOuioGWCXnzt/gtdmrNJ+fe6K/hZJ8kCcWQIgydu/53uZt4QxUGkeVvDzj4SoGWCXhLZowa7Y228FPP/1hsu7CwmJenPQRmZlycNeBg3rwzDPGw18YokvXGL0GWCV33tWTWe+9oPm8+Id1eqP41waekrD5n4Jh7G2E3QH8WwhxQggRBwwCTgB/S5Jked4dN0V3hU9JiemVOLplzBm1sHf9jkLRwzXaW5Ik/P196dqtLe+++wLz57+Jp6cHqSkXePaZ2VVG6kyxZPF6kpPP4OXlyez3/1WjyOW1UX9+QYlmO/dmEWs2HjNYdsvOE1zJlEOLhDYNonVL8x+R1WODVXxvw7ZwBnz9tH3bP6Aedw0z7K81aFAPmjRpAMDVq1mkpV0wWLakpJRJ//qQ48flALDdurVj7txX7OpHOmJEf6KiZAMyL6+Qw4dP2U2WJXjY4U/BMPa+PoHoPBGEEGXAY0AS8DcQauA4ACRJel6SpHhJkuIXLlxu1xOtTQICtMl0s7OrJ+7VpbxcRX6+7LTr7e1l1hJte9fvKBQ9XLO9+w/oyoMj7wDg4sVM1q7dadZx6elX+HqefN+PGz+Ctm0jbXpe9q4f4KbO9Fny6SuobkndcysJydpFFZEtzJ0WlagaGyzbYElr28JZCNCZ3m0d08yoH5UkSbSPban5bGjkr7S0jCmTPyYuLgGATp1as3DR2w55ZtzWs71m++yZS0ZKKrgr9nbMTwM6AymVXwghVJIkPQr8Bqw3drAQYiGwEEBwym3HNCMjm3HxojxFcenSVaMOsxkZ1zUP8hYtQs36pWbv+h2FoofrtveA/l1ZuWIbAAcPJvLYY6an/f5Yv5vi4lIkScLT05P5367QW+6UTjDNnTviycyUHdL79utMp06tbVr/yRNnua2HvJ2ZeYMmJnzbU89qU+bk5ZkedbqpUybQ31wjIABJko0RIQoB46Of1rSFsxARpb3g/mZcnwB/7Q+S/LzqK07LysqZPu0zdu06DED79i1Z9N27VudRtZTgYO3CDd0FNbVJbTvmS5K0ExhoZvF0IUSkGXUOA54GegNNgZvIdskKYKEQotYuvr2NsE3ABGRFNVQYYmMqvm9m53NwemJiWrBnj/wQSEpKpVevjgbLJiamarZbt27hFPU7CkUP121v3WnOvJvmhV+ojAclhGDRwlUmSsts2XKALVvkyP++vj5GjTBr6k9KOqPZzsi4QZOmxoOdJp+6otkOCDBtNATqlLmZb95UYdXYYIZHwSqxpi2chdYx2tdFvhnXJy9f+271D6hqWJWXq3j55f+wfftBAGJiIvj+h1lmR9W3BTk52lyguiPYCrZBkqS6wBLg0Vt2Na746wu8KEnSKCFEzYL0WYm9pyPfBB7Rt0MIUQ48BETZ+Rycnv79tVHNK1+ehtCNaq4b7bw263cUih6u297pOlNB9esHGCnpXsTFn6Ggwi+sfUwonp7GH7kd2mmdzNPOXTNSshJvQH55C6FC/oFvHFdui27dW1OvXl0AUk5forzccBgPIQQnks9qPkdGaq+tSqXitVfnsvmv/QBER4ezeMlsi3Pl1pT4Qyd0zs+od47DcLKI+SNN/D1v4vgf0RpgN4A5wFhgKnCw4vtWwKaKaA4Ox64jYRWGlrGnQhjwLvCMPc/D2enVS14ynpWVy759x0hJSdeb7+/GjRw2bNgNyGEFhgzp5RT1OwpFD9dsb7VazcqVWzWfu3Rta9Zxk6eMYfKUMSbLzXz9K9as2QnAhx+9yMhRg+1W/0MPaxM5d+4cg+CqgaNkiorL+GtHMqNGdCUosB4P3tOZlX8c0Vv2rkHtCAuRR9bSL9zgzLnrZmgRrDOFfBMw7nNmbVs4Cz716nD7HR35a0M8+XlFbNn0D/eM0B9Yd+fOeM1Kx+bNmxIVJY+iqdVqZs6cx4YNewCIimrG4iXv0bChY1M4/fnnHs5U+IH5+dWjW3fnaAtnWs0ohFhj7bGSJD0AVN7g54EBQojzOvu/Br5DnqYMBf6LgUEje1LbCxcaAONr+RxqHS8vTyZOHA3Iv95mzJhLbm5+lTIlJaXMmDFXs5rp8ceHm/2rzd71OwpFD+dq7x9/XM/Ro8ZXdBXkFzHjtS80IxJBQf7ce6+l4Rdcm8+/3qIJvPreG/fTJrq6I1lEeEM+eUcbJ+rrH/42q+7K2GBLlizhyNH9Rsu6S1tM+NdwPL3kV9d/PllBWurlamUunr/G7FnzNZ+fffZBQL4f3n3nW9au2QFAREQoS358n8aN61erw1qW/rSB48dSjJbZtvUg7769QPP5qadHmBXTT8EiZuls/0vXAAMQQqiBF5ENNICHJUnq4KBz02DvYK3jTBSpsRPKxQsZrFixtcp3p06d02wfiDuOqrzqr8O7h/ahfftWTiXjscfuYfPmfcTHJ5GUlMYDD0xhzJhhRESEkZFxnRUrtmiWWEdHhzNpkulf8I6svxJ7XytH6KG0t3kcOpjEx3MWExERSu/eHWndugXB9QPx9PQgKyuX5OQzbN1yQGMAenl58v4Hk1xoCswbifrcffcDREZ2AaBZmLaNJfyQQx/KvD5tKH9sTiDxRFWjIO3cNeZ8sYl3XhlOowb+/PX7NJatqoyYr6ZrpxaMfeg2/CvCL2zffYr/tzzOjPPzRZLkF/fBg3HMmbPD7m1Rk3tD99hStTxBknJauyIw/uBpVKp1VY4dfFdX2rarOksUGdWUSVPv56v/riEnO59xYz7h/pF96Ng5Cg8PD5ISzrF21T4KC+Vp4P79uzLm0aEAzJ27lN9/l/ODent78eS4ESQknCYhwbje/fp11UyDmuLAgUTmfLSEqKgwevXuQHR0OMHBAQghuHT5Gjt3/KOJmA/Qs1csz00YaVbdjqC2HfNtgSRJrYEuFR9ThBAb9JUTQhRJkrQIeL/iq9FAogNOUYNU6Zxql8olSQ0UYih8szwS5yOEMJmvwdDqyAMHEhg/7k2LzuujOdMYNWqI6YI2liFhvHfn5uYzdeoc4uIM+wfGxrZi3ryZhIVZHmbNVvULg83pmGtlbz2U9q6KWugPIjn5xY/Ztu2g3n23Eh7elFmzJ9K3b2e9+431KVNYOx1pGj88JctcVqe+sZzla+L17pv2/GBeefEu6tQx/Nt37cZjTJu5nKJi/df8SvJTmm2JZkiSPBI2adKzbNu2x6xzNNUWkmT4/Gpyb1hz7LsfPMl9D/bRu++HhZtY+M2fRv3Chg3ry5yPp2kMqCeffJNDB5MsOgeArdsWVFtlrFLrX4U6ZfKnbN+mvw/oIkkSDz8yhBmvjzdq4Hl5dHaoWbQ2faPNjYIHIu4xWwfd1ZFCCKt0lyRpMvBVxcd5QogpRsr2AA5VfDwkhLBtYloT2Ht15GVgqhBC79IjSZK6AP/o2/e/SFCQP0uWfMDGjXtYu3Y7yclnyM6+SVCQP9HRLRg+/HZGjbrT6hxj9q7fUSh6OEf9H340meH7jhF/KJmTJ89y4UImOTl5CCHw86tHSEhD2rVryR2Db2PQoO5m5+5zV75YuJ2N2xJ5cnRvBvaNISwkCC8vT65dz+Pg4XMsW3WQPQfSzKzNAzkMozzF9uFHkxi+r9f/VFs88/wwBg3pzOrf9xC37wRXM3MoL1fRsFEgnbu0ZMwj99G7TyeHn9err41j4MDuHD+WwslT6WTdyCUnJ4/ychWBgX5ERIbSrVtbRo4cRGRU9Wj/tY0zjYRJkvQn0A1oCOQBF4DdwPdCiKNGDtWdVjRlYxwFVIAn0F6SJEnYc3TqFuw9ErYWSBBCvGVgf2fgiBDCpG+aO8QJMzUy4irUZNTCXBxxreyth7u0t6GRMFviiD5lb8La/2h3GbojYfbC2EiYrcgvu2h3Gf7e9jVwDI2E2RpHj4StP2/7kbD7Wlg3EmaCxcCLQoiiW3dIkrQdOWMPwB1CiJ0mZKajdY8KF0LYv4NWYO+77XPAWNCVVLQXSkFBQUFBQaEWcZKRsBvAX8ijWJeR00JEAiOQY3uBvKqxhSRJwyoiMeiiu9TVnGXGN9AaYcGAexhhQojdJvYXIKcvsoWsimmXHZw8cZasrFyCgwNo1Sqc4SNuZ+TIITWennKsjO2cuEXGiBG3M3JkzabZ7F1/VRmue53cQY8nn3yDgwfN8zFt1qwJ27d/b1H9eXkF7NlzlAMHEjmRfIb09CsUFBTh6+tDaGgjunZry6hRg+nY0XDAVFOMf/IdDh0yz4cnLKwxW7fPN13QAiY8+x5792rzPdbY50wIvLlMHXERT3Lx9CinZas2xHboTvsO3ejYoR3t24ThW092uP9s3mY+/3qLFYLqVqyc9EOOJeaBPONSBhQiKADyjRxfiQ/yO6ke8utCIEQpGzeuZe3aPzh54ozd7ostm/5hw/qDnD51keysfAKDfGnZKpSh9/RgxIO97eJu8Oyzs9i7RzvL9dGcKRb5D9+KEIJNG/ezft0uTp48R1aW7A7QKro5997bjwdHDnI6twlPOxhhkiQ9T9WYXgsrMuLo4w0gviLN4a3MkSRpJLAU8AWGADOAD28ppzv4Y07UY93RNIeuHLLrdKRtOW3wRO3t4OwuMtxBB0VGVcrV1UbiNTw1bhaHDiWbdS5hYY3Zsu1rvfs8Paovnf9u0Sq+/HIZpaWmpyrvv38gs9+bZNT52NDUjq10ADSpfcxlzeodzHxjXpXvjBlhnpLxEAP62vvLL79k6NChRo66UfEnE9nFeGR/Hx8v3n55CI+O6mw0MOzNvGI6Dfg/vfvOHa0MldEY2QDTvpVzc3OZOnUqcXGGV286w30BoBKWTRc6or1vxbxrFePQsalNF20/HTmsufnTkeYgSdJY4OeKj7lAUyFEic7+00Dlr7/WQohUjCBJ0l60I2x9hRDG473YEPtP/tuZ0tIyJk36gPh4+ddyaGgjRo8eRkREKBkZ11m5citpaRdISkpjwoRZLF/+ucV5wdxBhjvooMiwPp/dl1+9YnS/j5nL7ys5d+6yxgALD29Kn76dadc2ivr1A8m9mU/c/uNs3rwflUrNunV/cyMrl0WL3sHDw/rQhLbWwRg3buTyycdLAKjn60NRoXkphAxhqL07d25TpVx2djaFhQU0a9bcYhm+9bz54atH6N1DnlW5eDmXTdtOcSr1OvkFJQT416VVVEMG9o0itKmpmHCNQJMOSQ3kUlqax6RJLxMff7xCh1BGj36EiAg/MjIyXPK+qMRR7W1vPWyBhxMFazWEEOIXSZLeAdogZ6/vB2zXKaI7zGtOEtZ6Ott5BkvZAZc3wpYt26jp6LGxrVi8+IMqub+eeGIEkyZ9yJ49h0lNvcDXX//KjBmWBeh3BxnuoIMiw/rEEkPutO2qa0mSGDioB88++yA9e1aPbzhmzFDi45N4fsL7FBYWs3fPUVav3sFDD1k/tWNrHYzx4QffkZubT7v2UURHh7N+3a4a1We4vf2BLMrK8nnrrc9Zs+YvRo4cyccff2z5Ob81VGOAzftuH1/M30NZefUI+nPm7iC0qbEZl7poDTAV8oK0UpYtW6cxwGJj27B48U8EBQUhz/acd8n7ohLHtbeMvfT4H2MnshEG0JaqRliOznYjM+pqaOBYu1PbEfNrRHm5ivnzfwPkl8Inn7xULflq3bp1+PTTl/D1lY3hpUv/IDvbdH41d5LhDjooMiyTYW9eeXU8Cxa8pdcAq6RHj1j+/fKTms+rV283WNaZ2L79EJs27sPDw4PZsyfiWYPROzDV3lnAdby9i3nttSc07W0pA/tGMXK43BY//HyIz+ft0muAVXIl09iP/YZopyCvA6V6dJhCUFDldJwP4Oey94Vj21vGme9vDzv82YkbOtu35pw6rbMdaawSSV4OXJkZvgC4ZKS4zXFpIywu7hhZWbkA9OnTWW9+PICGDYO5994BgDxMvG3bgf8pGe6ggyLDMhn25taXiiGGDeun2U45nW6v07EZ+fmFvD9b9hce+/gwOnSMrnGd1rS3pTw/Xs77mZdfwufzrB/F8fOtg+zvDPIomGwY6NdBd8BAHllztfvCWdrbme5vJ0vgbQxjo1e6K5K6m6inC3KMMIBkR8YIAxc3wvbu1SbCHTCgm9GyAwZo22H3bvPjw7qDDHfQQZFhmQxnwc9P62pRXOyYuEo14fPPfiIzM4uQkIZMmzbWJnVa297m0iw0kD63yS/6zTtSKCyyPq5br+7haF8LRVQmO9GvQ6HOkb46+13nvnCm9nbF+7uW0Y0ldvqWfX/pbBtb+QIwTGd7U43OyApc2ifs9GltPs7YWOO/YDp00O5PSTlvpKT7yXAHHRQZlsm4lX+9MIfk5LPk5Obh51uPkNCGdO/ejlEPDaZdu0ir6zVFSop29CssrHGN6rK3DvGHkvj9NzkcxJtvP4effz0TR5iHpe29c6fxpOi3clvXcDwqhhuOJcp5K4cOjuGxUZ2JbduUwAAfsnOLOJ50hbUbk/lz80mDdbWJ1m0jzWIzAzpUhrzwRn6VeAIql7kvnKW9K6nJ/W1L7BGiwtZIkvQYsh8YyI70VXJ2CSFSJEk6AnQFWkuSdI8QYqOeenyACTpf/WanUzaISxth585pp26bNTO+HDokpBGenh6oVGrS0y8jhECSTPc2d5DhDjooMiyTcSu7dml/nefm5pObm8+pk+n88vMmRo4axFtvP4ePj/El99bw2/LNmu2Bgywf5dHFnjqUlJTyztvzEUJw5129GDLEdosALG1vD535G7m9jdffKTZEs30ju5BvPx/JPXdWXXUZ0iSAkCYB3H1HDOPGXGDiy6vIzqke3iQqooHOJ+2ImmEdKo0wKv5XucR94UztbYv7212QJGkqcEAIYXBuVpKkB4HvdL76jxBC33LW2cCaiu1vJUm6XQihsXQlSfIAvkYbpHWFEMKhybvBxY2wvLwCzXb9+saXXHt5eeLv70tubj7l5SoKC4urTJW4swx30EGRYZmMSoKDA+jXvzPtY1vSpHF9BILLl66xc+dhjh6RR1xWr9rJlcs3WLBopk0DRx4+fJJVq2Rn/Lp16/DUU/dbVY8jdPh63m+cO3cZP796vPnWs1adpyEsbe+6dbWhNsrKyqljwq5s3NBPs/3vSQNoFdmQ4uIyfl+XwOFjl1ALQefYUMaM7Iyfbx16dQ9nydejeXj8T9Wc9wMDdMN8aBNjG9ZBN3m2p0YHZ78vnKm9a6KHPajlEBWDgS8kSToFbAOSkB3wKyPm34c2nhfADmCOvoqEEGslSVoOjAEigMOSJC0AEpD9ycYBldb3FeDftlbGHFzaCCvUieVSt67pX8C6ZQoKiszq7O4gwx10UGRYJgNg+ktjie3QEm/v6rf5hOdHsnXLQV6f8RVFRSXExSXw/XdreWHiKD01Wc61a9m8NP0z1Gr5JT912lhCQsxZKV4VR+hw4sRZlixeB8C06WNp2rShiSMsw9L29vbWGpHmGGGBAdoVla0iG3Ijq5DHJvzC6TRttpa1G5L58dd/+PW7sYQ2DaRzbCjPPnEb85dUHXDw9dUVpn0ZG9ZB94XtobeMs90Xztbe1uphL5wkbVEbtOEn9CGARcBLQhiNyju+ouyjyIbXTD1l0oBRQogLVp5rjXBpx3wFBQXDdOkao9d4qeTOu3oy670XNJ8X/7DOrAj4pigsLObFSR+RmSmvIB84qAfPPPOAVXXZWweVSsXbb35DebmKjh2jGfv4MNMHORnSLW/N9z7fWsUAqyT9Qg5vfqD1V35qbA+7n5uz4Q7t7ea8jOyj9T0QD5xHXgFSClxF9v36GGgrhHhBCFFoqCIAIUSJEOIx4B7gd+SgdyXIsVf2I49+dRZCGE5rYGdc2gjTjalTUmJ65ZVuGXN/bbiDDHfQQZFhmQxzGTGiP1FRYQDk5RVy+LBlTuG3UlJSyqR/fcjx4ykAdOvWjrlzX7Grn0tNdFiyeD3JyWfw8vJk9vv/qlFEf0NY2t5lZdopPmMGaCUFBdo6b+YV88dfJwyW3b47jYyrcoywkCYBtIqqOgpUWKh7fto2M6yDbruq9ZZxpvvCGdvbnve3NdRmiAohRJoQ4jshxHNCiNuEEBFCCD8hRF0hRFMhxAAhxBtCiFtXQ5qqd5MQYrQQooUQwkcI0VgI0VcIMbcih3Wt4dJGWECA1hfCVKC78nIV+fmy0ezt7WV2UER3kOEOOigyLJNhCbf1bK/ZPnvG+jiFpaVlTJn8MXFxCQB06tSahYvetss534o1OqSnX+HrecsBGDd+BG3bRtrj1Cxu75IS7apEc4ywm3na6a8Tp6+hUhn36Uk8kanZjmheNcblzbwSnU/aaVHDOuj638nGo7PeF87a3va+vxWcG5f2CYuMbMbFi/ID5dKlqzRv3tRg2YyM66hU8i+1Fi1Czf5l7g4y3EEHRYZlMiwhOFibwkbXqdgSysrKmT7tM3btOgxA+/YtWfTduw7Lh2eNDn+s301xcSmSJOHp6cn8b1foLXdKJ8jszh3xZGZmAdC3X2c6dWqt9xhdLG1vtVprRJnT3mfSszTbefklRkpWltEabQEBVfNtntWpS7vq0ZgO3jrl5WlgZ70vnLW97X1/W4pLj8y4IC5thMXEtGDPHvmhn5SUSq9eHQ2WTUzUJlFv3bqFwXLuKMMddFBkWCbDEnJytClsdH/Fm0t5uYqXX/4P27cfBCAmJoLvf5hldlR9W2CNDpWBsYUQLFq4yqxjtmw5wJYtsjO7r6+PWS9la9vbXE6evqrZDvA3ncQ8wF872pKXV9VoO5V6TeeTti79OniiNcLKqRwJc9b7wtnb2173t4Jz49JGb//+2mjElZ3eELrRiC2JSu0OMtxBB0WGddHUzSH+kNaHKDIy1KJjVSoVr706l81/7QcgOjqcxUtmm1yab2tqooO9sba9zeXA4QsUVPhytYtpjKeJaJuxbbWxq6qOfEFc/Hm0vl31qPT50q+D7iin1j/aXe4La3F1PSTJ9n8KhnFpI6xXr040aBAEwL59x6pE59blxo0cNmzYDcjLgYcM6fU/JcMddFBkWCbDXP78cw9nKnyo/Pzq0a17WxNHaFGr1cycOY8NG+Rg1VFRzVi85D0aNrw1l659sVaHyVPGkHxypcm/Bx8cpDnmw49e1Hw/bvwIs+RY096WUFxczta/5YUQgQE+jBjazmDZwQNaEdpUNpDPX8zh7PnsKvvllEeV07meQKARHXTbOa+aDs52Xzhze9vr/rYGyQ5/CoZxaSPMy8uTiRNHA/IQ84wZc8nNza9SpqSklBkz5mpitzz++HCLfqW7gwx30EGRYZmMpT9t4PixFKNltm09yLtvL9B8furpEWbFNao873ff+Za1a3YAEBERypIf36dx4/pmn6Mp7K2Do7CmvS3li/l7Nasq33nlTlq3qh6TrUXzYD54U5tGb+GPhoKSZ6GN/9UIqKNHh6/Iza1c1VcMFLjEfeEI3EUPBccgOThheA04rfdES0vLePrpt4mPTwIgNLQRY8YMIyIijIyM66xYsYW0NDkGW3R0OL/++pnFfi/uIMMddFBkVJdRrq6eegZgyuRP2b4tnqioMHr17kB0dDjBwQEIIbh0+Ro7d/yjiTYP0LNXLAsWvkmdOtXdRD09qhs1//3vTyxcsBKQV3XNeP1pQkJMB73s168r9epV91tSqasv5belDgCSZF02gJmvf8WaNTsBeWRk5KjBest5SoaNP0Pt3bZtDPXrh3Py5FnNSrpu3TrTq1dlUPBC5ETaMl8tOsmmradJOpXJrbzwVC/emH4HAMXFZfy29jiHj11GLQRdOoQy+sFO+PvJ1/7vvWd4avJv6Hv8nzs6Ctn4qkxhpAZyKS3N4+mnXyY+/niFDqGMGTOaiAg/MjIynOq+AFAZjeFpGHu2t3XPkBiHDibFX//T5kZBj0bDlQExA7i8EQZyHrmpU+cQF2c43lpsbCvmzZtJWJjxXF7uLMMddFBkVMWUEWYKSZJ4+JEhzHh9vF7jCPQbYU8++SaHDiaZrP9Wtm5boHe1mDEjzBTm6CCXqz0jDPS3d8+ePfnpp58sOp9X3vmTFesS9O6b9Gwfpk/sTx1vw7r+sfkEr7zzJ8XF5Xr3y0YYQGPkKUft+zM3N5epU6cSFxdnsH5nuC+gdo0wsOUzRDHC3Bm3MMJAHvbduHEPa9duJzn5DNnZNwkK8ic6ugXDh9/OqFF31jgvnjvIcAcdFBlaDBlh589ncPBAEsePpXDyVDpZN3LJycmjvFxFYKAfEZGhdOvWlpEjBxFZEejUELVlhNlSB6g1dVo4AAAgAElEQVR9Iwyqt3d0dBsWL15i0fkYM8IAols2ZOxDXRjQO4qQpgF4e3lw7UYB8Ucv8tuaBPYf0u+jVInWCAPwAYKQnfS9AIEQpWzcuJa1a/8gOTnNKe8LqH0jDGz1DHGsEXbYDkZYN8UIM4jbGGEKCv+LGDLCbIk+I8zW6DPCbI21Rpi5mPNSrimRXcwLrVATqhphrou1Rpi5OKK9ZRxrhB258YfN37VdG45QjDADuLRjvoKCgoKCgoKCq+LSwVoVFBQUFBQUbIcyZOVY3MYI0517P3HiLFlZuQQHB9CqVTgjRtzOyJG29VOwRobA8CivSqUiLe0iiYmpJCWlkpiYyqmTZykulofUX5z8KFOmjDV5jpKJW8gVrpMiw3wZXh7GE/66gg6O0sPQ/Were88caqrH2aMjDe6zlR4fH0sn82QaZ/b+Q0ZyCoVZuahKy/AJ8sevYX1C2kXTvFssTdu2skj3vQt+4fS2fZrPkyc/ZvB8bNHepqYLXeXeUHBv3MInzFVWshkzwqZMmcOWzfsN7reFEeYq10mRYRsZ7qCDLWUYuv8cce+BazxDsrNu8thL/+Fc3BGj5RpENOOBz94wWkaXK0mn2fTeV+jGxDBkhLlSn3KMDMf6hB3Lsr1PWOcGik+YIVzeCNMXj2X06GFERISSkXGdlSu3VonHsnz55xYnFbaVDGMP0Bcnfci2bdrgiUHBAQQHB5B+7rK8v4YvAle6ToqMmstwBx1sLcPQ/Wfve8+WetjzGXL9ejZPP/U2KSnn5eObhRBxWycCw5rg7VOX4rwCci5c5uKRZLx96ppthJWXlrLmlTnkZVzDq24dykvkkTl9Rpir9SnHyHCsEXbcDkZYJ8UIM4jnrFmzavsczOTGLH3fLl36J8uXbwLkXxW//vo5AwZ0IyYmgm7d2vHww3eRkJDK+fNXyMq6SXm5iv79u1ok2REyLlzIoGOn1owbdz+vvDKel18ej59fPc1DtWfPDkYTwVZi6EXgLtdJkeEc9buTDHvfe66ghxCCF154j8SEVCQPD3o9/TADJj1BWKe2NIxsTnDzUBq1akHzrrG0v3cQzbt1oI6v8SnkSv5Ztp6L/yTi2yCY6IE9uZZyruJ8OlY7H3fpU7aV0XC2RcJrSGbR6Vm2rrNpvRiH6uBKuPTqyPJyFfPn/wbIARs/+eQlgoL8q5SpW7cOn376Er6+PgAsXfqHJjK1s8gAmDhxNC+/PJ5hw/rRPDzEomNN4S7XSZFhngx30MFRMsC+9x64hh7Lf91E/CF51Oa2J0fSfthAJA/Drwf/Rualp7p+5gJJf2wHoNfTD+Ndz8dgWXfpU45qb3vhIdn+T8EwLm2ExcUdIysrF4A+fTrTunWE3nINGwZz770DAHmYWHfI3hlk2Bt3uU6KDPNkuIMOjpLhCJxdDyEEixevAaBFixDa3zPQJvWqVSr2LvgZoVYT3qMjkb26GC3vLn3K2dtbwblwaSNs716t8+iAAd2Mlh0woLtme/fuf5xKhr1xl+ukyDBPhjvo4CgZjsDZ9YiPTyI9/QoAI0YYHwGzhMT128g6exEvn7r0fma0yfLu0qecvb1NIdnhT8EwLh2i4vTp85rt2Nhoo2U7dNDur3Q8dRYZ9sZdrpMiwzwZ7qCDo2Q4AmfXo3IaEqBjpxgOqNWk/n2AlJ0HyLl4hfLiEnyCAmgS05LWd/SmWed2JuvMvXKVo79vBKDboyPMmr50lz7l7O2t4FzUihEmSdJ5YIgQIqUm9Zw7d0mz3ayZ8WXEISGN8PT0QKVSk55+GSEEkmTaRneEDHvjLtdJkWGeDHfQwVEyHIGz65GYmKrZ9vX1YeOsL8g8mValTMH1bM5e/4ez+/4hsndXBrz4JF519cfhEkKwd/4vqMrKaNSqBe2GmTe96S59ytnb2xROctv8z2BXI0ySpH8b2BUGTJAkKQNACPFfa+rPyyvQbNevH2i0rJeXJ/7+vuTm5lNerqKwsBg/P9Orexwhw964y3VSZJgnwx10cJQMR+Dsely/nq3Zfvedb8g8d4k6fvWIGdyXBlHNUZeryDyRRtqug6hVKs7FHUFVXs6dr72gt75TW/eSeUJeZdn3+cfwMHN60136lLO3tykUG8yx2Hsk7HPgElB+y/cewFigDBCAVUZYYWGxZruugV9luuiWKSgoMquzO0KGvXGX66TIME+GO+jgKBmOwNn1uHlTazScO3eJgJDG3PPuVPwaaqcQWw/qTZu7+vHX+/MoKyrmQnwCZ/b9Q8u+3avUVZCVQ/xS2cm//b2DaBgVbvZ5uEufcvb2VnAu7O2Yvwi4BgwTQkRV/gEq4O6Kzy3tfA4KCgoKCgZQ3xKwe8CkJ6oYYJU0jo6k22P3aT4nb9hZrcz+75ZTVlSMf+MGdB093ObnqmB/FMd8x2JXI0wI8QLwEbBVkqTnLT1ekqTnJUmKlyQpfuHC5dX2V8ZYASipiMJsDN0y5v7acIQMe+Mu10mRYZ4Md9DBUTIcgbProSsjOjrcaE7I1oN64+Ep5zq8nppOWXGJZt/ZfYe5EJ8AQO9nR+PtU9ei83CXPuXs7a3gXNg9RIUQYgXQHxgvSdJqSZIaWnDsQiFEDyFEj+efH1Ntf0CAn2bbVKC78nIV+fmFAHh7e1W5UYzhCBn2xl2ukyLDPBnuoIOjZDgCZ9cjUOf8TK3m8/apS2BFnkOhVpN/9QYAJfkFxC3+HYDI3l0J79bB4vNwlz7l7O1tCiVYq2NxSJwwIUQ6cDuQDBzDRiOUkZHNNNuXLl01WjYj4zoqlRqAFi1CzV6B4ggZ9sZdrpMiwzwZ7qCDo2Q4AmfXIypKe37+AaZzJOqmKyotLALgfHwCxbl5APgE+nN05Sa9fxkntKsuDx1K4ptvlvPNN8vZu/eI2/QpZ29vUyjTkY7FYcFahRAqIcSbwBPA+4Dx3mkGMTEtNNtJSalGSlZdht26dQsjJR0vw964y3VSZJgnwx10cJQMR+DserRpE6nZzs8rNFm+0vAC9OaPPLl5N0eW/6H3LyPptKbcgQPH+eKLpXzxxVJ27ox3mz7l7O2t4Fw4PGK+EGKnEGK2EOK6JEnhkiT9YG1d/ftroxHv2XPYaFndaMS6UYqdQYa9cZfrpMgwT4Y76OAoGY7A2fUYcLtWjimjoay4hJuX5d/PHp6e+Dcx27vEJO7Sp5y9vU0hScLmfwqGqe2I+Q2A8cAz1hzcq1cnGjQIIisrl337jpGSkq43T9eNGzls2LAbkJcDDxnSy6lk2Bt3uU6KDPNkuIMOjpLhCJxdj2bNmtCla1uOHjlJauoFYk6mGXTOT9kZh1qlAqBJ21Ya5/vWg3rTelBvk7KO/PYnR1fIkfQnT36MKVPGavaVl6vcok85e3srOBd2HQmTJGmcsT/gPpOVGMHLy5OJE+WcZEIIZsyYS25ufpUyJSWlzJgxVxO75fHHh5sMoOdoGfbGXa6TIsM8Ge6gg6NkOAJX0GP6tMc127u/WUpBVk61MtdS0zm8bL3mc8f7h9j0HNylT7lCextD8QlzLJIQ9hsqlCRJDRQiB2TVhwfgI4TwNF3bab11lJaW8fTTbxMfL+c/Cw1txJgxw4iICCMj4zorVmwhLe0CIC+//vXXz6qsXjEHW8kQBi8DXLyQwYoVW6t8d+rUOXbsOAhAjx7t6dGj6oqju4f2oX37qr9YJQNd3pWukyKj5jLcQQdbyzB0/9n73rOlHvZ8hsye9S3LlsmjVHX86hEzpB8NI5ujVqnIOJFK2t8HNaNgMUP60u+FsViKsZEwcL0+5RgZMQ61Y87krbe5UdAy4D7FFjOAvY2wi8BUIcQqA/u7AP/UxAgDyM3NZ+rUOcTFHTd4dGxsK+bNm0lYmPFcXvaUYewBeuBAAuPHvWnROX00ZxqjRlX9NWrsReAq10mRYRsZ7qCDLWUYuv8cce+B8z9D1Go1H364iJ9/3gBG3gvthg2k51MPmZ2OSBdTRhi4Vp9yjAzFCHNn7G2ErQUShBBvGdjfGTgihDDjbjZshIE87Ltx4x7Wrt1OcvIZsrNvEhTkT3R0C4YPv51Ro+7Ey8sMW8+OMmrbCLOFDuagyHAeGe6gg61k1LYRBq7xDHn5979J2b6fK8kpFGXnAuDbIIiQdq1pc/cAGrU0PxXRrZhjhIHr9CnHyHCsEXbODkZYpGKEGcTeRtgAwF8IsdHAfj+ghxDib9O1GTfCXAFjD1BbYc6LQEHhfxF733+OuPcc8Qz55Nh5u8t4vXN1R3UFQyhGmDtj19WRQojdJvYXAGYYYAoKCgoKCgr2xgnixf5PUdshKmyG7rDviRNnycrKJTg4gFatwhkx4nZGjrTt0LI1MiydrrCHHq5wnRQZ5stQizKD9R45cpKEhFQSE1JJO3OR7KybZGfnIUkQFORPTEwEAwd25777BxIYaNjxWJIMPyZUKhVpaRdJTEwlKSmVxMRUTp08S3GxnA/vxcmPGpxyqlKPuljv90+Nm8WhQ8kmjwcIC2vMlm1fG9zv6VFH7/d5eQXs2X2EAwcSSU5OI/18BgX5hfj6+hAa2phu3doyatQQOnZqbVR+udpwnkBb6WFIB1vqYWqU6tY+m5OTR+fOHbn99n4MGtSf6OjWSJIP2sX3Nyr+tNRr8W6Vz088fDuL/vsvo3L1sWt/MkPHvK93X9H52RXnEAj4AXV1zkmFEMVs3LietWs3cOLEGYvvPYHK4D5btQUoqwvdHbtOR9oW13fMr20Z7qCDIqMqhoywkpJSunR+1KzzaNAgkPfen8SQIT317jdmhE2ZMoctm/cb3O/sRth3i1bx5ZfLKC3Vfx11uf/+gcx+bxL16ulPTK2qRSPMlnpIGDY89PXZL7/8kqFDhxqRaD8j7MflO5n46gK9+4rOfwaEoG+sITc3l6lTpxIXF2ewbtOLJPQbYbZsCwCJdg61w87n2346soW/Mh1pCJcfCSstLWPSpA+qLAUePXoYERGhZGRcZ+XKraSlXSApKY0JE2axfPnn+Pubzo/mbjLcQQdFhmUyAJo2bUCnTjG0aRNBWFhj/PzqUVRcwtkzl9i0aR/p6VfIyrrJtKmfsmDhW/Tr18Wi+tUVee8qCQoOIDg4gPRzly0+V1N8+dUrRvf7GHmRGeLcucual2V4eFP69O1Mu7ZR1K8fSO7NfOL2H2fz5v2oVGrWrfubG1m5LFr0jlUrAytxVT0M9dnOndtUKZednU1hYQHNmjU3u+6/9yUx+rn/mCzn4SHxwxcv4ltxjX76fafecj06twLC0I58lQI3gTJKS8uZNOkV4uOPVugRyujRjxARUY+MjKs1vvdqo0/ZEmU60rG4vBG2bNlGzUMhNrYV/7+9846votge+HdSCARCEooktNAFgjRDk6qgIKBSfGB5FuSnIih2UUAFBSz4RASfFBUUGz6kqSBVpGiAGKmhhN4RSAgJIX1+f+zNvTe5Jfcmty7z9ZOPs7uzc+bszLLnnpk5M2/eJMLDKxmv//vf/Rk5cjKbNydy6NBJPvnke8aMcS5Avx5k6EEHJcNxGcHBQfz083QaNbK9ku2Z0fcxadJnfP/dKvLzC5gy+XN+WTHDKT1uatmYBg1rExvbiBaxDaldJ4rFi9cx9rXpTpXjCD17WffUlQUhBN17xDF8+ADat29hcX3o0N4kJOzlicffJjMziy2bd7BkyW8MHlz6QKX+qoftPlsJSCE3N4Px4z9g6dJVDBw4kHfffdfhsk+eucTJM5dKzHd791ZGAyz5yFm2bDtgNd9br96HyQBLA86b6bHcaIDFxjZl3ryvCA8PB1KBC2V+97zRpxT+i2+Y3qUkLy+fWbN+ALSO/957zxf5kIG2HcT77z9PaGh5AL7++mdSU69cVzL0oIOS4ZyMgIAAuwYYQGBgIGPHDiciIgyAI0dOc/LkOYdlAIwYMYQXX3yEPn06U7tOlFP3+gIvvfwIs2ePt/qxLCQuLpYXXnzIeLxkyXpPVM0p3K2H/T6bAlwkODiLV175t7HPuoNHhvYwphf8z/qarnLlgujaoZnhSAIXjNes6xFuuKptRl7Wd8/f+5SKmO9Z/NoIi4/fSUqKFsemU6dWVvfnAqhaNYK+fbsCmkt93bqt15UMPeigZDgnw1GCg4OIiYk2Hl+8YLldjZ4pbvzaok+fzsZ08sHj7qpOqXG3HqXps64mMrwi/Xppm2Pn5eXzzaKN1usQGWY2oT4fMA2ZW+pR0+xO0+ewLO+eXvqUwjP4tRG2ZcvfxnTXrm3t5Cy6Q735zvXXgww96KBkOCfDUQoKCjh95h/jcbXqES6XoQcqVqxgTBeu/PRHSqtHafusK7lvYBfKl9cWJqzduIsz51Ot5ku5nEFubp7hKBDzz5ylHuYLHYo+D3e/e77apwKE6/8UtvHrOWEHD5qCCsbGNrKbt0UL0/XkZMeDEepBhh50UDKck+EIUkqmf/St0fvVrFl96vjwkOJTT75DUtJRLqelUzG0AlHRVbn55mYMGnwbzZrVc6vs5GSTp6JmzeplKssf9XC2z27YYH2uVll46F/djemvfthgM192di5rNu6ib8+2aINh1SmcE2apR+EzkGhzwky4893TynRdn3IlymbyLH5thB07dtqYrlXLfpiAqKhqBAYGkJ9fwPHjZ5BSIhxYBqIHGXrQQclwTkZxNm1KJDtbW7GVdS2b4yfOsXZNPPv3HwMgIiKMtyeNdLpcT7Jxo8mLkZaWQVpaBgf2H+fbb35l4KAejH/9/4yeElfzw8LVxnT3HmXz9PijHs722QAz94fWZ52opBVualaXNjfVB+DCpSv8vMa+Z+qViQvo27Ml2icuHG2+1xWOHTtrzFOrVhxa/LAC4B/gmoUernj3bOHKPqXwX/zaCEtPv2pMR0ZWtps3KCiQSpVCSUvLIC8vn8zMrCLuYD3L0IMOSoZzMooz9rWZXLxoOd8rODiI225rx0svP0zt2jWcLtcTRESE0blLK5rHNuCG6pFIJGdOX2DDhkR2/K15XJYs3sDZM5eYPXdsmQPoFicxcT+LF2sTp0NCyvHoo3eXqhx/1sPZPhsSYgqzkZubR7ky2pTmE/IXLt1Cbq7tQKkAh4+dA04ANYBQtGHHaqSnZxrzREZWAy6jecAsY3q56t2zhqv6lDsQwl9ih+oDvzbCMjNNAR5DQkp+y83zXL16zaEXSg8y9KCDkuGcDEdp0KAWnTq1pEqV8JIze4Hnnn+A2BYNCA62/Kfq8ScGsnbNNl4dM4Nr17KJj9/N558t48kRg1wm/8KFVJ5/bioFBdrk7tHPPkBUVDWny/F3PZzts8HBJgOyrEZYcHAgQwd0MR5/uXCDg3fmoa2MrIYWRgMyM01GmGYoFr5LF8DKvpzuePdc1acU+sCvJ+YrFArH2LT5C/btX0zSvh/ZnvA13347hfvu782hQyeZMGE2Q4eO4cQJ58JTeILWbZpYNVwK6XV7eya89aTxeN4Xyx2KVO4ImZlZjBo5hfPntfhV3XvE8dhj95SqLL3o4Q36334z1apoYVT+2nWEPftLnp8VGBgA3ADUQxtyTAGOUdTQSkf7BEYAdcDOTgGuwh/aQoWo8Cx+bYSZx6PJzi55dYl5Hkd/0ehBhh50UDKck2ELIQSVKoXSpm1T3nzzSWbNGkdgYACHkk8y/LGJRTwe/kL//l2oX18LNZCenkliYtknhWdn5zDyqcns2pUMQNu2zZg27SWXzgkqji/r4WyfNR8utGd8OsLDQ3oY01856AX77MOn0IwrgDPARSCnmB4nME3GL49mtBXFle+eN/pUaRDC9X8K2/i1ERYWZtp0uKRgenl5+WRkaK7o4OAghwMK6kGGHnRQMpyT4ShdurZhwMBbATh16jzLlm1wafmeol375sb00SOn7eQsmZycXJ55+l3i43cD0LJlY+bMfd2tQUgL8VU9nO2z2dnZxuOyGGHRNSLp1a0lANeycli4bEuJ98S1ash9AwuHL68a/jQs9bgIxj0gK2HuDXPlu+fNPqXwbfzaCKtXr5Yxffr0P3ZywrlzF8k37HNXt260w78+9CBDDzooGc7JcIauXdoY09u27XF5+Z6gMOo/FJ1E7iy5uXk89+xUNm5MBKB58wbM/ezNUu3bWRp8VQ9n+2xBgWnYryx99sF7uxkXKCz/dTtpVzJLuAP69GxjdlQ0v6UeEtOqSIHmEdNw1bvn7T7lLGo40rP4tRHWpEldY3rv3kN28+7ZY7reuHFdOzn1J0MPOigZzslwBvNhlnQHPnK+yOXL6ca0ubfDGfLy8nnxxf+wfv02AJo0ieHzLyY4HAHdFfiqHqXts2XloXu7GdNf2okNZk50jUizo6IbzFvXwzyP6ZPoinfPF/qUwrfxayOsSxdT5ObNmxPt5jWPeOxMRGc9yNCDDkqG+yKRHzebkB8ZGWYnp++SsH2fMV2vXrSdnNbJz8/nlZensXrVnwA0alSHefMnlhiOwdX4qh6l7bNl4ZZ2N9KkoTZH7vjJC/y22TEvbXq6ebyvokOh1vUINsthmstW1nfPV/qUswS44U9hG79+Ph06mJbW//HHziIRiM25dOkyK1ZsArQlxz17driuZOhBByXDORmOUlBQwI8/rjUet27T1OUy3M0vv2zmiGH+VMWKFWh7s3M6FBQUMHbsTFas2AxA/fq1mDf/LapW9ewWTr6sR2n6bFkxj5C/YNHvDt+398BJs6OiHidLPU5jGoKUgLYwpazvnq/0qdKgJuZ7Fr82woKCAhkxYgigRWUeM2YaaWkZRfJkZ+cwZsw046qvBx/s59QvET3I0IMOSoZzMr788id27LC/uu5qxjXGvDKdfUlHAW3j4b59u9i9x5N8vWAFu3Ym282zbu023nx9tvH40WH9HYpjVYiUkjff+JRlS38DICYmmvlfvk316pEl3Ok4etCjNH22LIRWCGFw/46AZtAs+MFxI2zF2kQyrhbWIQTzVY+WekwnLa1wocFVoKDM754n+pRCPwgp/SU67kGrFc3JyWXYsNdJSNgLQHR0NYYO7UNMTE3OnbvIokVrOHxY+2XUqFEdvv9+qtNzLfQgQw86KBmWMgqk9VhST496l3XrthETE03HjjfRuHFdIiIrExgYQEpKGklJR1i7ZqvxQxoUFMiH017k9ts7WpQlhO3VbadOnmPRorVFzh04cIzfftPmwMTFNScurkWR63f07kTz5g2LnMsvsPxwP/P0+6xfl0D9+jXp0LEFjRrVISIiDCklp89cYMNvfxkjzQO07xDL7DnjKFfOen0DAyyNmg8/XMCc2T8C2gq4Ma8OIyqqqk19C+ncuQ0VKoQUOZdfYD10gyv1sKaDq/UQNuJl2eqzTZs2ITKyDvv3HzWunGzbthUdOtxiuDOT4lsCdbzzA3buPWazXv++txtzP3wKgPWbd9PvgSkl6mLOqMf68MGER8zOZKPFBcshJyePYcNeJiFhh0GPaIYO/RcxMRU5d+68w++exHrUfle2BYCgmUd9SSnZP7ncKKgScpfyh9nA740w0PZfGz36HeLjd9m8Oza2ITNnjqVmTfv7nulZhh50UDKKUpIR5gh16tRgwsQR3HJLK6vX7RlhW7fu5pGHxzkkp5Ap7zzLoEE9i5yzZ4SVhBCCe//VkzGvPmL1I1aINQPmoYfGsX3bXgdqXZS162ZbbPNUkhFWEo7oYcsIc6UetowwsN5n27dvz4IFC5yS+/gLn/L1oo02r6/53xt06dAMgEefmcHCZX84VT7AtRMfA1WxNuCTlpbG6NGjiY+Pt3l/Se+eLSPMlW0BygjTO369bVEh4eGVmD9/EitXbmbZsvUkJR0hNfUK4eGVaNSoLv36dWPQoF5l2otNDzL0oIOS4RiTpzxNvz92krA9if37j3Ly5HkuX05HSknFihWIiqpKs2YNuPW2dvTocTPlygWXXKiHefmVh+ne/WZ27Uxm/4HjpFxK4/LldPLy8qlcuSIx9aJp27YpAwf2oJ4hyKkvohc9wHqfdfUelw1iahgNsNS0DJb+ur2UJaWieb8KN/AuhxYHTBIeHsr8+TNZufInli1bQVLSYZe/3/6KUEElPIouPGEKxfWKLU+YK7HnCXMV1jxhrsaWF8lV2PKEuRJ36wD2PWGuokLdN90u49qJiW4t35YnzNV42hOWmv2zy7+1kSH9lWVnA114whQKhUKhUJQdIfx6vZ7foRsjTEppdJHv23eUlJQ0IiLCaNiwDv37d2PgwLK7lvUgQw86KBkmAoT9YURX6CCx/cM4Pz+fw4dPsWfPIfbuPcSePYc4sP8oWVmaV2jU0/fxzDMP2C0foIA8i3P/nbmITz9ZXOK9xbl7QDcmvzPC4nwg1r1I6elX2bzpb7Zu3UNS0mGOnzjH1YxMQkPLEx1dnbZtmzJoUE9uatnYrtyggJL3FvSH99sT7Z15YoJT5efk5NGwYUOefXY4vW7vgRZWIgRhmO8luQhcKlJW47hVFuW/92YvBt3VrMT6mcqYYfNackLvYmeCgcpAqCEdgJT5rFz5C8uWLWffvgOkpFx2+b8hrkc5rTyJLoYj/WUStbdl6EEHJcPz5dv7KD/zzDusWf2nzeuOfpRzCzIszpXWCBv59L08NWqQxfngAMttYj6bu5iPP/6OnJySh3Xvvrs7E98aaXPSfEnDeKq9S8ZW+R9//DG9exc3ekxYM8KaxK22yOc+I6wqEIn5IgBXTP7XaOJRq+hyzkqXGwUR5e5Ulp0N/N4TlpOTy8iRk4osmx4ypA8xMdGcO3eRH39cy+HDJ9m79zCPPz6BhQs/cHrPLj3I0IMOSoZvtTdAQX7RbWHCI8KIiAjj+LEzTpdVnD59O3Fj05gS82VkXGP8a7MACAgQ3DOgq8Myjh07YzTA6tSpQadbWtGsaX0iIyuTdiWD+D93sXr1n+TnF7B8+e9cSklj7tw3CAhwbshGtXfZyg8MLGrgavOx8hE2vJuOMH7yei6lXCs5Y1X/bgQAACAASURBVIlEoXnAAPKADHJyMhg58nkSEjSDODo6iiFDhhITE8K5cxdc1h7uQE3M9yx+b4R9991K4z88sbENmTdvUpF9uf797/6MHDmZzZsTOXToJJ988j1jxjx23cnQgw5Khm+1N8BNLRvToGFtYmMb0SK2IbXrRLF48TrGvjbd6bKK06BBLRo0qFVivh++N8Upa98hlpq1qjssQwhB9x5xDB8+gPbtW1hcHzq0NwkJe3ni8bfJzMxiy+YdLFnyG4MH97RSmm1Ue5et/F27dnH48GHq1Ingzr7tgFw0w8f5rZ0K2Rx/gtNn00vOaJeqmAywNEDbFPy775YbDTBTe4RTuC2Sq9pD4f/49XBkXl4+Xbs+QkpKGkIIfvppBo0bW/5yvnTpMr16PU5mZhblygWzceN8hyMg60GGHnRQMrzX3vaGp6xh/lEuy3Cko9w/ZDx7dh8B4N2po+jXv7PVfNaGI9PSMhzaTPnrr39h0ttzAYhrF8vXX0+2yGNrOFK1d9mwXX5lhMEIK81wZI+75pfJCEtOuAuIQZtDlQFo3kDXt7dnhyPTcla53CgIL9dbudds4NfLIOLjd5KSkgZAp06trHZ0gKpVI+jbVxuiyMnJZd26rdeVDD3ooGT4Vnv7CoeSTxkNsLDKofS6vZ1T9ztigAH06WMy7JIPWt830RaqvfVKJJoBJtE8YBr+3h5CBLj8T2Ebv346W7b8bUx37drWbt6uXW82pjdt+uu6kqEHHZQM32pvX2HJ4g3GdN++tzi136IzVKxoWvlYuBLQUVR764+QkEAgzHB0DcxW96r2UDiDX88JO3jwhDEdG9vIbt4WLUzXk5NP2MmpPxl60EHJ8K329gXy8vL5+afNxuOBg3u4TVZyssn7VbOm43POQLW3rzJ5/G3Uj4mkWpVQsrLz+OfCVf7aeZZlK/az/W/7Cw1aNL0Bkw+jMNBwBSCCgwcvGPPFxnZEmzN2BWv4ZnuokUNP4lZPmBDiRiFELbPjO4UQvwghdgshfhZC9ClL+ceOnTama9Wyv6Q7KqoagYGausePn8HRuXB6kKEHHZQM32pvX+D3DYmkXNI+bk1urEtsiwZuk/XDQtP8ou49braT0xLV3r5J5w51qRkVRrlygVQOC6FRgyoMHRjLt3MHM2daf8Ir296H9Kbm5s85D6gO1AHCOHbMZLDXqtUQbfVkDNZ8Hqo9FO4ejvwGuAlACDEEWA5cBhYCKcAyw/lSkZ5+1ZguaQJrUFCgcQlwXl4+mZmObZOiBxl60EHJ8K329gWWLjFtAD1gYHe3yUlM3M/ixesBCAkpx6OP3u3U/aq9fYuMjBxWrT/E1BlbeGHcKp597VfembaZTX+ajKdbu9bnmzmDqFTRejDkalUrmh1FoM0Pk8AV0tPTjFciIwuHLEPQjLSin1xfbA/hhv8UtnH3cGQzYL8h/RLwipRyWuFFIcQmYCzwQ2kKN++wjswFMc9z9eq1IvM89CxDDzooGY7L8IQO3ubixTQ2b9wBQHBwEP3vtr4isqxcuJDK889NpaBAi181+tkHiIqq5lQZqr19h68W7mTCexu4lmW5Q8MX3/xNXOuazHjvTqpVDeXGRtV49bmujJ+83iJv5TDz51wOKABOA9fIzDTFHgsJOU9hdH8tin41zCfxa3l8qz2U0eRZ3O0Jy0Hbwh6gHrCu2PX1gP29QBQKhaIYPy/fRF6eFnOpx61tHQ4P4gyZmVmMGjmF8+e10Afde8Tx2GP3uFyOwnPs3X/BqgFWSMKOM4x6ZQUFBdqw4OC7mlGjekWLfEIUN1RS0CboFycfOAvGsB+V8fP1cAoX4+7esB540JD+C7i12PXbgFOlLTw0tLwxnZ1d8ool8zyO/trQgww96KBkOC7DEzp4m6WLfzemBwxy/VBkdnYOI5+azK5dyQC0bduMadNesvLxLRnV3v5F4s6zbI7XJskHBQXQtVNdizxXM4tvc2UagrRsjxxMk/cD0DxjFMuj4RvtEeCGP4Ut3P10XgMeFUIsADYCk4QQC4QQY4UQXwIzAMuohwaEEE8IIRKEEAlz5iy0uB4WZvqFkppqffVJIXl5+WRkZALa8IX5i2IPPcjQgw5Khm+1tzfZtfMQhw9rk9FvqFGFzl1aubT8nJxcnnn6XeLjdwPQsmVj5sx9vdTPRrW3/7H1L9Nihwb1Ii2up6dnmx3lUhgJH2y1h/lcL9Pwo2oPhVuNMCnlQaC9Qc5rQEU0z9gEoBEwVEr5lZ3750gp46SUcU88MdTier16pi1NTp/+x+K6OefOXSTfsC9Z3brRDv+i1YMMPeigZPhWe3sT89hgd9/Txbi6zBXk5ubx3LNT2bgxEYDmzRsw97M3y7Svn2pv/+NymsloCqtkuUryyPFUs6Oi+11abw/zPKb+6ovtIYRw+Z/CNm73E0opj0kpH0SbGxYN1AIqSik7SymXlaXsJk1MbuK9ew/Zzbtnj+l648aW7mU9y9CDDkqGb7W3t8jKymHVynjjsStXRebl5fPii/9h/fptADRpEsPnX0xwOKq+LVR7+x8R4SaPVHpGtsX1A8nmWyQV/Yxabw/zPCaDTLWHwmODtVLjvJTyrJQyF0AIUUcI8UVpy+zSxRSNePPmRLt5zaMRm0cpvh5k6EEHJcO32ttbrFm9jfR0bfim7c1NialX+g2czcnPz+eVl6exetWfADRqVId58ye6ZMK/am//o31bkzfr6PHLFtc1T1jhXK5gMNs31Hp7mA8zmuaA+WZ7CDf8KWzh7RlzVYBHSntzhw4tqVJFW3z5xx87i0S1NufSpcusWLEJ0JYD9+zZ4bqSoQcdlAzfam9vsWyJaUL+wMGu8YIVFBQwduxMVqzQou/Xr1+LefPfomrVCJeUr9rbv2jbKto4GT8/v4BN8bYi2Ztv/h1uTFm2xxlMRlgBhasofbU9VJwwz+LuiPkP2/sD7ipL+UFBgYwYocV6lVIyZsw00tIyiuTJzs5hzJhpxlg6Dz7Yz6lft3qQoQcdlAzfam9vcPr0BbZtTQK0VWR39C77R0tKyZtvfMqypb8BEBMTzfwv36Z6dcvJ2KVFtbdvMKBfUzp3qGM3z82tovnk/b4EBGiGw9Jf9nPufIaN3KmYJuRXQdu2yFp7fERaWuEE/cuAVO2hMCLcuU2CEKIAyMQUJKU4AUB5KWWgjetmHLRaRk5OLsOGvU5Cwl4AoqOrMXRoH2JianLu3EUWLVrD4cMnAW2I4fvvpxZZveIIepChBx2UDO+0t7T5+sKpk+dYtGhtkXMHDhzjt9+0eVVxcc2Ji2tR5PodvTvRvHnDIudyC2x96Ez8d+YiPv1kMQCDBvdg4qQnSrzHnOAAy8n1H364gDmzf9SuBwcx5tVhREVVLbGszp3bUKFC0QnbAtv/jKn2LtrezpafnHyGe++9l+joakRHa3t3VqsWRcOGTQ11zqR4nK4BD64m6cBF4/G4F7ry6AOtOXMunU1/nuDgoYukXL5Gfr4kqkYlunSoS5eOdY0G2MHDl7hv+CLSM6yH/UhO6I22iXcU2pCbRPOOZZKTk8OwYS+RkLATgOjoaIYOHUxMTGgp2ruJR11JmXlbXG4UhAZ1Vu4wG7jbCDsFjJZSLrZxvTXwV1mMMIC0tAxGj36H+PhdNu+OjW3IzJljqVnT/t5qepahBx2UDM+Xb++jvHXrbh55eJxT9ZryzrMMGtSzyLmSjDApJX16PcuZM9pHdcG3E2jdpolTcq0ZYQ89NI7t2/Y6VQ7A2nWzqV27RpFz9owwUO3tCLbKb9++PQsWLHBK7pgJa1j8837jcaER5gir1x9m3OT1RVZJFkczwkALwGq+obdGWloao0ePJj4+vvitRhxrb2WE6Rl3b1v0F9AWsGqEof10KHPjhIdXYv78SaxcuZlly9aTlHSE1NQrhIdXolGjuvTr141Bg3oRFOSAradjGXrQQcnwnfI9ydb4vUYDrF79aKcNMF9Atbd3+WxBIrv3/UObm6KIbVqdalVCiYyoQLmQQDIycjh55gp/7zzLkl/2k3TgghMlX0Eb8AkHKqF9VgXh4aHMnz+DlSuXs2zZSr9pDzWHy7O42xPWFagkpVxp43pFIE5K+bu160Wx7QlTKBTuw55nxFU4MhxZVqx5wlxJSZ4wf8ET7e0JmsStdmv5Jk+Yu/GsJywr/0+Xd4DygZ2UZWcDt3rCpJSbSrh+FXDAAFMoFAqFQqHQF+4ejvQYUkqjG37fvqOkpKQRERFGw4Z16N+/GwMHlt3tqwcZetBByTC732y7lOKkp19l86a/2bp1D0lJhzl+4hxXMzIJDS1PdHR12rZtyqBBPbmpZWO7dcwtyLR63nyivDPcPaAbk98ZQXp6Jls272L71r3s2ZvMqZMXuXo1i9AKIdSIjqBl6/r0H9CO5i3sB7GUUnLy+EX27T3J/n2n2J90igP7TpF5VQuy2ffuON6YdD8RIdYnh7vqOXmiLUrytrmiz5Y0HOUP7wXAge23WS3377/3s3v3IfbsPsThI6dITblCamo6gYEBtGzZgu7du3DLLR1o1KgJgYGhCBFguPcfJKZhyrqtfnBIl6aNb2BQvxZ06dSA6BvCqFQphJTUTM79k07CjpNs+vMoG7YctnpvYKDgaOK4XkAvtN1nmqEtxcwFzgPbge+Bn8BOB3QK5bTyJG4djnQtamJ+WWXoQQcloyi2PvyfzV3Mxx9/R05O8Y2GLbn77u5MfGukxWq/QlxthI18+l5CQoL5ZMYih+rXp//NvPr6vZSvUM7q9ekfLOe7r2w71O0ZYa58TrZwpQx7Rpi/9FlPySiQls87OzuH1q3us5r/448/pndv20OMxY2weq2X2MwLUL58EG+8dDv3D2pjd2uttCtZ3NT1A4vzndrFMOuDwURGODSMvh24H7BuzTlBVn68G4YjOyrLzgZ+b4RZW5o9ZEgfYmKiOXfuIj/+uLbIUuCFCz9weh84PcjQgw5KhqUMW0bY+HEzjUv969SpQadbWtGsaX0iIyuTdiWD+D93sXr1n8Z96zp3ac3cuW8QEGD5sbBlhB05cpqjR86UqGtGxjXGvzYLgIAAwcrVHzH70yUs/nEDALXr3EBchwY0vrEWEZEVSb+SyfatyWxYu9tYvw63NGHafx+3Wr9p7y1l4TemmQ+hFUOoERXB0cPnAftGmCufky1cKcOWEeZPfdZTMuwZYTVqVKFlyybceGMMNWtWp2LFCrRsdRs1oxsY86amppKWlka9evUA54yw0ArBzJtxH53axQBw6kwaK9ft48ChC2RkZBMWVp6G9arSo3NDomuEcVPX/1iUMbBfC6ZPGVB4mAKsBeKBs2hh+tsDD6MtzwQ4aTh3zmbFHCA7f5vLjYKQwPbKCLOB3xthX365nClT5gLar6N58yYV2estOzuHkSMnG7ePeOyxgYwZ85hTkvUgQw86KBmWMmwZYa+P/4R/LqQyfPgA2rdvYTVPQsJennj8bWPAyMlTnmHwYMtQAraMMEf54fu1vD1R252sY6cWzP1iLBNen8uFC5d59LH+tGvfjKu5Zy3u2/HXEV4Y9RmZmdqw4vi3htJ/QHuLfEsX/cmxo//QrHkdmjavTd161UlMOMyo4Z8C9o0wVz4nW7hShi0jzJ/6rKdkWDPCCgoKOHLkNI0aWQvaWg1BAPkFmcyYMY9Zn37HwIEDeffddwHnjLCPptzDoH43ATBj7mY+mrWR3LwCq3mja1Tm7PkrFucH9mvBiEc70axJjQfQIgxYbmKp7cW8Cog1HH9FGXahAcjO3+4GI6ydMsJs4NdGWF5ePl27PkJKShpCCH76aQaNG8dY3Hnp0mV69XqczMwsypULZuPG+Q5HJ9aDDD3ooGRYl2HLCEtLy3Bo4+mvv/6FSW9rH724drF8/fVkizxlNcLuHzKePbuPAPDu1FH069/Zon7WjDCA/323mf+8o33s2tzcgE/njXJI5l/bDzlkhLnyOdnClTKsGWH+1mc9JcOaEeYoubl5dOs6nFtv7eW0Edb9lgYs+PQBAD7/eisTp64pVR0qh4VwJT2bEzvHl2TAtAB2G9LXgGpoMTNKhTLCPIu3944sE/HxO0lJSQOgU6dWVl9YgKpVI+jbtyugubvXrdt6XcnQgw5KhnMyHPnoA/Tp09mYTj5ofc/BsnAo+ZTRAAurHEqv29s5Vb/b7mhlTB9Otm6olQVPPCd3y9BLn/WEDEcJDg4iJqZ0m8OPeLQTAOkZ2UyduaHUdbiSbs3xZZU9QGFU2gpAo1ILBYQQLv9T2MavjbAtW/42prt2bWsnZ9Ed6s13rr8eZOhBByXDORmOUrFiBWM6K8v69ixlYcniDcZ03763EBJifXK9LSqGmiaoZ2eX3rNRVtz9nMoiQy991pfei4KCAk6f+cfp+2pFh9OpXT0AVv92gMxrHuuz5ruJV7CZS+Fz+HWIioMHTbvbx8baN/5btDBdT04+YSen/mToQQclwzkZjpKcbPK41KxZ3aVl5+Xl8/NPm43HAwf3cLqMw4dMc4yjol23qbazuPM5lVWGXvqsr7wXUkqmf/QtFy9cdvre9m3rGPee3LFHW7TSp+eN3D+oDbFNo6gcVp7LaZns3HOWZSv38PPqfa6ocjnAPLZJGV3aynPlSfzaCDt27LQxXauW/eXQUVHVCAwMID+/gOPHzyCldMhNqgcZetBByXBOhqP8sNAUVbx7j5vt5HSe3zckknJJm3Dc5Ma6xLZoUMIdlixd9KcxfUu35i6rm7O48zmVVYZe+qw33otNmxKNHtasa9kcP3GOtWvi2b//GAChoeWdKq9lc9MQ5qWUq8z6z2D69mpWtO43VCbqtsr0vu1GHrnvBE+88D9SL18rXpQzDAEiDOlEyrg6UuFZ/NoIS0+/akyXNPkzKCiQSpVCSUvLIC8vn8zMrCLufz3L0IMOSoZzMhwhMXE/ixevByAkpByPPnq3S8otZOmSjcb0gIHdnb5/146j/LJsOwAhIUHc/+9uLqubM7j7OZVVhl76rDfei7GvzeTiRUuPV3BwELfd1o5Ro4Y4VV71aqb5fy+O6kHDelXJysrlh2U7Sdx1moICSavYaO4b1IaKoeXocHNdvvrkfgY9Mt/m6skSiATeNzt+pzSFmCP8e5aS3+HXT7twOTfg0FwT8zxXrzr2y0MPMvSgg5LhnIySuHAhleefm0pBgfYP/+hnHyAqqppLyga4eDGNzRt3ANoHrf/dnUu4oyiXLl5h3EsLKCjQFmo9MaoPN0RFlHCX63H3c3KFDL30WV94Lwpp0KAWnTq1pKKTcc4qh5k8Zw3rVeVSylX6P/gF46f8yuKfd7N0xR4mTl1DnyFzjWEpWrWoyf891KE01QxEi5Zf6H77BVhUmoKKItzwp7CFXxthCoXCeTIzsxg1cgrnz18CoHuPOB577B6Xyvh5+Sby8rTwGT1ubetwmAKAa5nZvDx6Hhf+0VbKde7WjAce6eHS+jmCJ56TJ2QobLNp8xfs27+YpH0/sj3ha779dgr33d+bQ4dOMmHCbD79r2NbExVSOB+skIlT13Dw0AWLfMdPpjJ20grj8bAH2pWm+tOBOwzpE8CjpSlE4V382ggzH6/Pzi55NZF5Hkdd13qQoQcdlAznZNgra+RTk9m1KxmAtm2bMW3aSy5fRr50sWkboQGDHB+KzM7O5eXRX5C0R5ts3bJNPSa9/5DHl7l74jm5SoZe+qw33wshBJUqhdKmbVPefPNJZs0aR2BgAOfPpzhVTsZVU1iJtCtZ/LRqr8286zYe4tw/mjcs6obKNKpf1RlRk4HCoHnngduBi05V1gbCDf8pbOPXRlhYWEVjOjXVMuKwOXl5+WRkaPHrgoODHJ5wqQcZetBByXBOhjVycnJ55ul3iY/X4jq2bNmYOXNfL1OZ1ti18xCHD2uTrG+oUYXOXVqVcIdGbm4erz4/n4RthwBo3qIu0z55nAqhzu3VWFY88ZxcKUMvfdZb74U1unRtw4CBtzp9n3lsr/3J/5Cfbz/u6Z59pjn0MXUcXv07HhhrSF9E29z7oBPVVPgQfm2E1atXy5g+fdp+TJdz5y4a92arWzfa4V+bepChBx2UDOdkFCc3N4/nnp3Kxo3adi/Nmzdg7mdvOr23nyOYxwa7+54udjcvLiQvN5+xL37Fn5u1mJNNmtbio1mPU7GSaz+uJeGJ5+RqGXrps954L+zRtUsbp+85cuySMZ2ekWUnp8aVDJPRFuZYX38FeNuQTkXzgO1xooolooK1eha/NsKaNKlrTO/de8hu3j17TNcbN65rJ6f+ZOhBByXDORnm5OXl8+KL/2H9+m0G+TF8/sUEhyO5O0NWVg6rVsYbjx1ZFZmXl8/rY75m0wZt6KZh42hmzHmSypVdbyCWVA93Pyd3yNBLn/X0e1ESpRni3HfwvDHtiFFVuZLJy+uA0fY88J4hnQb0BnY4WUUHCHDDn3MIjaFCiJ+FEKeEENlCiLNCiHVCiP8TQvh1ZAdz/NoI69LFFFW5cENXW5hHVTaPtnw9yNCDDkqGczIKyc/P55WXp7F6lRZvq1GjOsybP9GpifLOsGb1NtLTtWGitjc3Jaae/a1f8vMLeO2VT/ht7S4A6jeswYw5TxIeUdHufa7GE8/JXTL00mc9+V44wvETzofb2pp4gquZ2ly1po1vIDDQvhcotmmUMX3kuN35Z6OADw3pdOBOYLvTFfQDhBCRwFq0lZ/90DYpLwdEAbcBc4GtQgj3WN8exq+NsA4dWlKlSjgAf/yxs0jEaXMuXbrMihWbAG1Zc8+eji8H1oMMPeigZDgnA7StV8aOncmKFVrU+vr1azFv/ltUreq+UA/Llpgm5A8cbN8LVlBQwBvjZvOrwXMWU686M+eOoErVMLfVz1Y93P2c3ClDL33WU++FIxQUFPDjj2udvi8rK481G7TpWeGVy3NX71ibeXt2a0R0Dc0AP3EqlaO2jbDHgRmG9FWgL/CnrcxlxZsT84UQ5YBlaMYWwEngdeB+4GWgcIuBtsBKIYR7fk16EL82woKCAhkxQgumJ6VkzJhppKVlFMmTnZ3DmDHTjDFoHnywn1O/PPUgQw86KBnOyZBS8uYbn7Js6W8AxMREM//Lt6le3X1b/5w+fYFtW5MAbSjnjt62P45SSt5683OWL9M+prXrVmPmZ09RtZpn/031xHNytwy99FlPyPjyy5/YseOA3TxXM64x5pXp7Es66nC55nw0ayO5uVp4ljdfvp0mDS1jvsXUjmTyuL7G41nzrdtUg/vfBDAbLdhWJtAf2Gw1sz54CuhqSCcCraSUk6SU30spP0AzvlYZrjdHM9D8GiGl/dUbvsNBqxXNycll2LDXSUjQ5pNER1dj6NA+xMTU5Ny5iyxatIbDh08Cmvv/+++nFlmF4wh6kKEHHZQMSxmSfKvlf/jhAubM/hHQVo+NeXUYUVElL4Hv3LkNFSoUXY2YW5DpkE7/nbmITz9ZDMCgwT2YOOkJm3mnT/uez+YsByAoOJBnX7qbG2qElyijQ6cbKV+haCDP9CvX+ObLDUXOnTubyq8/a0NWjZpE06V7LOUDTUZPx4430bFTS5c+J1u4UoYg0Gpef+qznpJRIC03z3561LusW7eNmJhoOna8icaN6xIRWZnAwACysyEivDZHj542bmXUtOmN3Hqr5pSR8iqaHaQxY+4BVq7bx9795y3kjHi0E2Of7wlAVlYuC5fuJHHXKQoKJK1b1GTowNZUqqi17YYth3lk1HcU/xT36NyQLz4eSlCQ0VcyE1jnwGNMRIsbVioKZJLLjYIA0bxEd5hhntcZoDoggZuklBYxPoQQNwBHgIpANlBLSnmpeD5/we+NMIC0tAxGj36H+PhdNu+OjW3IzJljqVnT/p5kepahBx2UjKLYMsIeemgc27fZjlFki7XrZlO7do0i5xwxwqSU9On1LGfOaKGKFnw7gdZtmtjMP+zht0nY7vzmxYtXjqNmrSpFzp05ncKgOyc7Vc6op4fyzDP3u/Q52cKVMmwZYeA/fdZTMuwZYdZo3749CxYscKquL7y+nEXLrddz1PDOPP9UN8oF226zn1cl8cIby8nKyrO49vyIbjz/VKm26hoGzC/NjQCSfS43CgTNHDHC7sDk5VorpbzdTt7PgOGGw+FSyi/KXkvvoIsVBuHhlZg/fxIrV25m2bL1JCUdITX1CuHhlWjUqC79+nVj0KBeBAXZfhmuBxl60EHJ8E22xu81GmD16kfbNcAU7kEvfdadMiZPeZp+f+wkYXsS+/cf5eTJ81y+nI6U0mV7shbyyedbWP3bAR4Y3IZunRoQVaMywUEB/HPpKgk7TvLD0p38se2YS2X6OXeYpX8tIe+vmIywPoDfGmG68IQpFNcrtjxhrsTR4ciycDX3rNtlRIQ0dLsMd2PPE6YoijVPmCup13qJW8sv5MTO8R4NtCU54AZP2I2OeMJ+RQu7AXCrlHKDnbz1gMJJe/uklM3LWEWv4dcT8xUKhUKhUOgCc/f5sRLyngLjL9DGwo8jwupiOFKhUCgUCkXZ8eJej+bxWuzugymlzBNCXAEi0eyYikCGvXt8FT8ajnQeIcQTUso53q5HWdCDDqAPPfSgAyg9fAk96AD60EMPOvgqQognAPPl0nOKP2shRA4QbDgMllJarlYomv80UNNwWFNK6f45DW5A70ZYgpQyztv1KAt60AH0oYcedAClhy+hBx1AH3roQQd/5no1wtScMIVCoVAoFN7GfDjRkd3MzZezpru4Lh5DGWEKhUKhUCi8zWWztOU2A2YYArsWbpWQi7adk1+idyNMD+P7etAB9KGHHnQApYcvoQcdQB966EEHf+agWbpeCXlrgzFeyyHpx/OqdD0nTKFQKBQKhe8jhPgAeNFw+JKU8j928t4L/M9w+D8p5RB3189d6N0TplAoFAqFwvdZZZbubTOXRh+zdEnR9X0a5QlTKBQKhULhVUq5Dz5HegAACvxJREFUgXcWUNufN/BWnjCFQqFQKBRexRCSYrLhUABfCSEizfMIIcoDX6IZYAAz/dkAA514woQQtYGngFuAKMPpc8AWYLaU8qS36qYAIUSwlG7eyE2hUCgUfo0QohywFuhqOHUSmA0cQpuMPxxoZriWBNwipUzzdD1did8bYUKILsBK4CywGjhvuFQDuB2IBu6UUm7xTg0VhiB8raSU+7xdF4VCoVD4Lgbv1yLgNjvZEoGBUsoTnqmV+9CDEZYA/CGlHG3j+nQ0a7mdZ2vmPEKICKAzkAr8ab7sVghREXhRSvmWt+pXEkKIj21cGgV8B6QA2GorX0EI0RX4R0p5wHA8Ek2HusBxNBf4LC9W0SGEEAHAa0AH4Bcp5WwhxDDDuQBgMTBeSpnjxWo6hKH/P4B1b/d3Ukq/iBNkaJNmQKqU8kyxa+WBIVLKr7xSuTIghDgB9JRSJnu7Lo4ghLgRyJBSnjYc3wk8TdF33K8nfPszhg25hwAPAW3Q4oalAnuB74F5JUXU9xf0YIRdA1oXfjCtXG8K/C2lrGDtuq8ghIhFc8NWR/tAJgKDpZTHDddrAGeklIG2S/EuQogCYCdFg+4BdAcS0ALqSSmlvV84XkcIsQd4Rkr5mxBiFPAu8DGwD7gReAYYJ6X8xIvVLBEhxNtoxuNytF+V8w3HHwIFwPNow/Wve6uOjiCEaA6sAcKAjRT1dndFi5Z9h5QyyTs1dAwhRB00r31ztInHy4HHpJSphuv+8I6/YOPS+2j96hyAlPJDj1WqFBh+vI+XUv4qhBgCfAP8gPaONwGGAg9JKX/wYjUV1wF6MMKOAJOklF/YuD4c7YPZwLM1cw4hxHIgD83yrwxMR/vVf6uUMtlP/oF+DXgcGCal/N3sfC7acKRPfyQLMRj2TaWUx4UQfwMfSSm/NLv+L+BtKWVTr1XSAQzvxmgp5c8GQ2Y38LCU8hvD9YHAVCllI2/WsySEEL8B/wCPSCmzil0rj2Zc1pBS3uqF6jmMEOIboA7wJBAO/AftXb9NSnnBT97xAuA02r9V5sSgrWzLRfuh5ev/3l4FYqWUx4QQ29C8qdPMrj8OjJJStvZaJRXXBUHeroAL+ACYJYRoj/ZruficsEeB57xTNafoiGZwXUXzGA0RQnwIbBBC3Ar4/ORDKeU7hg/m10KIH9B+aRZ4u16lIB3N/X0cbYPYHcWuJ6INW/g60cAuACllkhAin6K6JBry+DodgLjiBhiAlDJLCDEJ2Ob5ajnNrcDdhXMjhRA90DwwvxvS/sBcoB1wv/nog+GHls97I83IQTOEQYvOvq7Y9fXAR56skOL6xO9DVEgp/4vmPWqNNla80fD3veHcw/4wfwcIQRuiMCKlfAHNRb4B04oQn0ZKGQ/cDDQEtgohGnu5SqVhBdr8EIDf0OYmmDOUolts+CpngRZgnAMTiDYUVkgsmofJ10lFGyKyRWNDHl+nMmY/pgwrhu9Hm+fyO35gEEspnwSmAGuFEE94uz5lYD3woCH9F5qBbM5twCmP1khxXaIHTxhSyoXAQiFEMKaNPy/6WViEA0Ac2rJbI1LK5w2TeZd5pValwLBkeKjBpb8F/zP2XwW2CCE2AVuB54UQ3TDNCesIDPBi/RzlG7RYOz+hfWTeAT4wDHsVoOm5yIv1c5S5wJdCiHew7u0eA0yzca8vcRhoBRgnr0sp84UQ96H92PrJWxVzBinlIiHEduBbw4T2//N2nUrBa8BmIUQ02o/2SUKIOEzv+FDAn41MhZ/g93PC9IJhPlU3KeWdNq5/AjwlpfQrg0YI0QToBCyRUl7xdn0cRQgRjvZxvwdogGZInkUzKqdJKRO8WD2HMBjvr6I9/81SyvcMH/z3gVC0j/7T/rCyUAgxBngWbWVk4T9aAm0i+EdSyve9VTdHEUK8h7aIyGJLFkO08EVow5V+8Y4LIQKBt4BH0NqlpR8NRyKEqIcWHPQuoJLhdB6wHXhfSuk3P3wV/osywhQKhd8ghKiPWYgKKeVRb9bHGQyGVqitHyMGo6Z24Ypof8Ewn6078ImU8qKXq+M0hnAIN6D90PK3ERSFn6OMMIVC4dcYQj9MlFI+5u26lAU96KEHHUA/eih8H2WEKRQKv0YI0QpI9OXQDo6gBz30oAPoRw+F76OLifkKhUK/CCEeLiGLP4QL0YUeetAB9KOHwv9RnjCFQuHTGAKEZlIshIsZAUB5X/da6EEPPegA+tFD4f/4xSochUJxXXMGLd5fmLU/tP1W/QE96KEHHUA/eij8HGWEKRQKX+cvoK2d6xItXIWvowc99KAD6EcPhZ+j5oQpFApf5wNMcZyscQjLiOe+iB700IMOoB89FH6OmhOmUCgUCoVC4QXUcKRCoVAoFAqFF1BGmEKhUCgUCoUXUEaYQuFlhBD5QogdQog9Qoj/CSFCy1DWfCHEvYb0Z0KI5nby9hBC3FIKGceEENWKnZsnhHiy2LkBQoiVjtRVoVAorkeUEaZQeJ9rUsrWUsoWQA4wwvyiYc9Bp5FS/l8JGyr3AJw2wmzwHXBfsXP3Gc4rFAqFwgrKCFMofItNQCODl2qTEGI5kCSECBRCTBVCbBdC7Cr0OgmNmUKIA0KItWgbEWO4tkEIEWdI9xFCJAohdgoh1gkh6qEZe88bvHBdhRDVhRA/GmRsF0J0NtxbVQixWgixVwjxGdaX7q8Dmgohog33VAR6AUuFEG8YytsjhJhj2DC5CObeNSFEnBBiQ2E5QogvhBDbhBB/CyHuMZyPNZzbYXgejV3w7BUKhcKjKCNMofARDB6vO4HdhlNtgWellE2A4UCalLId0A54XAhRHxgI3Ag0Bx7GimdLCFEdmAsMllK2Av4lpTwGzAKmGbxwm4DphuN2wGDgM0MRbwKbpZSxwBKsbOkipcwHfgSGGE7dBWyQUl4BZkop2xk8fRWA/k48lnHAeille7SQAVMNBt4IYLqUsjUQB5xyokyFQqHwCVScMIXC+1QQQuwwpDcBn6MZU9uklEcN5+8AWprNoQoHGgPdgO8MRtAZIcR6K+V3BDYWliWlTLFRj15AczNHVWUhRCWDjEGGe38RQqTauP87tPhL09GGIhcYzt8qhHgFCAWqAHuBn2yUUZw7gLuFEC8ZjsujGYF/AuOEELWBxVLKZAfLUygUCp9BGWEKhfe5ZvDoGDEYQlfNTwHPSClXFcvX14X1CAA6SimzrNTFEf4AooUQrdCMyPuEEOWB/wJxUsqTQogJaIZUcfIweebNrws0D96BYvn3CSG2Av2AFUKIJ6WU1gxQhUKh8FnUcKRC4R+sAp4SQgQDCCGaGIblNgJDDXPGorEe5Tse6GYYvkQIUcVwPh0IM8u3Gnim8EAIUWgYbgQeMJy7E4i0VkGpRX5eCHwJrDQYc4UG1UWDV83WashjwM2G9OBiej9TOI9MCNHG8P8GwBEp5cfAMqCljXIVCoXCZ1FGmELhH3wGJAGJQog9wGw0T/YSINlw7Su0YboiSCkvAE8Ai4UQO9EMJdCGBAcWTswHRgNxhonuSZhWaU5EM+L2og1LnrBTz++AVob/I6W8jDYfbQ+aQbXdxn0TgelCiAQg3+z820AwsMsg/23D+SHAHsMwbguD7gqFQuFXqG2LFAqFQqFQKLyA8oQpFAqFQqFQeAFlhCkUCoVCoVB4AWWEKRQKhUKhUHgBZYQpFAqFQqFQeAFlhCkUCoVCoVB4AWWEKRQKhUKhUHgBZYQpFAqFQqFQeAFlhCkUCoVCoVB4gf8HLKyHo9U2qVcAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 720x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Experment (3)"
      ],
      "metadata": {
        "id": "Q9QTj4m77BvA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelc3 = Sequential()\n",
        "\n",
        "input_shape=X_train2.shape[1:]\n",
        "\n",
        "modelc3.add(Conv2D(64, (10, 10), input_shape=input_shape,activation='relu', padding='same'))\n",
        "modelc3.add(Conv2D(64, (10, 10), activation='relu', padding='same'))\n",
        "modelc3.add(BatchNormalization())\n",
        "modelc3.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "modelc3.add(Conv2D(128, (5, 5),activation='relu',padding='same'))\n",
        "modelc3.add(Conv2D(128, (5, 5),activation='relu',padding='same'))\n",
        "modelc3.add(BatchNormalization())\n",
        "modelc3.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "modelc3.add(Conv2D(256, (3, 3),activation='relu',padding='same'))\n",
        "modelc3.add(Conv2D(256, (3, 3),activation='relu',padding='same'))\n",
        "modelc3.add(BatchNormalization())\n",
        "modelc3.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "modelc3.add(Flatten())\n",
        "\n",
        "modelc3.add(Dense(200))\n",
        "modelc3.add(Activation('relu'))\n",
        "modelc3.add(BatchNormalization())\n",
        "modelc3.add(Dropout(0.8))\n",
        "\n",
        "\n",
        "modelc3.add(Dense(100))\n",
        "modelc3.add(Activation('relu'))\n",
        "modelc3.add(BatchNormalization())\n",
        "modelc3.add(Dropout(0.6))\n",
        "\n",
        "\n",
        "modelc3.add(Dense(50))\n",
        "modelc3.add(BatchNormalization())\n",
        "modelc3.add(Activation('relu'))\n",
        "modelc3.add(Dropout(0.3))\n",
        "\n",
        "\n",
        "modelc3.add(Dense(units = num_labels, activation=\"softmax\"))\n",
        "\n",
        "modelc3.summary()\n",
        "\n",
        "modelc3.compile(loss = 'categorical_crossentropy', \n",
        "              metrics = ['accuracy'],\n",
        "              optimizer = 'adam')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "USkV1J8-UdWC",
        "outputId": "30fd943e-1674-4fdb-a97c-4cc6e8bfc174"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_9 (Conv2D)           (None, 40, 174, 64)       6464      \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 40, 174, 64)       409664    \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 40, 174, 64)      256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 20, 87, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 20, 87, 128)       204928    \n",
            "                                                                 \n",
            " conv2d_12 (Conv2D)          (None, 20, 87, 128)       409728    \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 20, 87, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 10, 43, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_13 (Conv2D)          (None, 10, 43, 256)       295168    \n",
            "                                                                 \n",
            " conv2d_14 (Conv2D)          (None, 10, 43, 256)       590080    \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  (None, 10, 43, 256)      1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 5, 21, 256)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 26880)             0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 200)               5376200   \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 200)               0         \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  (None, 200)              800       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 200)               0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 100)               20100     \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 100)               0         \n",
            "                                                                 \n",
            " batch_normalization_9 (Batc  (None, 100)              400       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 50)                5050      \n",
            "                                                                 \n",
            " batch_normalization_10 (Bat  (None, 50)               200       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 50)                0         \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 50)                0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 18)                918       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,321,492\n",
            "Trainable params: 7,319,896\n",
            "Non-trainable params: 1,596\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VV44ALOQhuo",
        "outputId": "72750149-7f1e-4e3b-95f4-9bba96047dfa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 2.8909 - accuracy: 0.1153\n",
            "Epoch 00001: val_loss improved from inf to 2.77273, saving model to new2(3).hdf5\n",
            "64/64 [==============================] - 23s 272ms/step - loss: 2.8909 - accuracy: 0.1153 - val_loss: 2.7727 - val_accuracy: 0.1319\n",
            "Epoch 2/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 2.5974 - accuracy: 0.1591\n",
            "Epoch 00002: val_loss improved from 2.77273 to 2.71934, saving model to new2(3).hdf5\n",
            "64/64 [==============================] - 17s 262ms/step - loss: 2.5974 - accuracy: 0.1591 - val_loss: 2.7193 - val_accuracy: 0.1078\n",
            "Epoch 3/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 2.3937 - accuracy: 0.1957\n",
            "Epoch 00003: val_loss did not improve from 2.71934\n",
            "64/64 [==============================] - 17s 258ms/step - loss: 2.3937 - accuracy: 0.1957 - val_loss: 2.7501 - val_accuracy: 0.0912\n",
            "Epoch 4/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 2.2465 - accuracy: 0.2372\n",
            "Epoch 00004: val_loss did not improve from 2.71934\n",
            "64/64 [==============================] - 17s 258ms/step - loss: 2.2465 - accuracy: 0.2372 - val_loss: 2.9634 - val_accuracy: 0.0832\n",
            "Epoch 5/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 2.1220 - accuracy: 0.2784\n",
            "Epoch 00005: val_loss did not improve from 2.71934\n",
            "64/64 [==============================] - 17s 258ms/step - loss: 2.1220 - accuracy: 0.2784 - val_loss: 3.1190 - val_accuracy: 0.0813\n",
            "Epoch 6/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 1.9979 - accuracy: 0.3070\n",
            "Epoch 00006: val_loss improved from 2.71934 to 2.55226, saving model to new2(3).hdf5\n",
            "64/64 [==============================] - 17s 262ms/step - loss: 1.9979 - accuracy: 0.3070 - val_loss: 2.5523 - val_accuracy: 0.1649\n",
            "Epoch 7/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 1.8799 - accuracy: 0.3529\n",
            "Epoch 00007: val_loss did not improve from 2.55226\n",
            "64/64 [==============================] - 17s 258ms/step - loss: 1.8799 - accuracy: 0.3529 - val_loss: 2.5821 - val_accuracy: 0.1985\n",
            "Epoch 8/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 1.7961 - accuracy: 0.3771\n",
            "Epoch 00008: val_loss improved from 2.55226 to 2.41941, saving model to new2(3).hdf5\n",
            "64/64 [==============================] - 17s 262ms/step - loss: 1.7961 - accuracy: 0.3771 - val_loss: 2.4194 - val_accuracy: 0.2084\n",
            "Epoch 9/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 1.6807 - accuracy: 0.4132\n",
            "Epoch 00009: val_loss did not improve from 2.41941\n",
            "64/64 [==============================] - 17s 258ms/step - loss: 1.6807 - accuracy: 0.4132 - val_loss: 3.0140 - val_accuracy: 0.2183\n",
            "Epoch 10/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 1.6070 - accuracy: 0.4493\n",
            "Epoch 00010: val_loss improved from 2.41941 to 1.50893, saving model to new2(3).hdf5\n",
            "64/64 [==============================] - 17s 262ms/step - loss: 1.6070 - accuracy: 0.4493 - val_loss: 1.5089 - val_accuracy: 0.4726\n",
            "Epoch 11/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 1.5022 - accuracy: 0.4890\n",
            "Epoch 00011: val_loss improved from 1.50893 to 1.39869, saving model to new2(3).hdf5\n",
            "64/64 [==============================] - 17s 262ms/step - loss: 1.5022 - accuracy: 0.4890 - val_loss: 1.3987 - val_accuracy: 0.5284\n",
            "Epoch 12/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 1.4317 - accuracy: 0.5162\n",
            "Epoch 00012: val_loss improved from 1.39869 to 1.39576, saving model to new2(3).hdf5\n",
            "64/64 [==============================] - 17s 262ms/step - loss: 1.4317 - accuracy: 0.5162 - val_loss: 1.3958 - val_accuracy: 0.5217\n",
            "Epoch 13/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 1.3599 - accuracy: 0.5417\n",
            "Epoch 00013: val_loss improved from 1.39576 to 1.25030, saving model to new2(3).hdf5\n",
            "64/64 [==============================] - 17s 262ms/step - loss: 1.3599 - accuracy: 0.5417 - val_loss: 1.2503 - val_accuracy: 0.5695\n",
            "Epoch 14/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 1.3007 - accuracy: 0.5671\n",
            "Epoch 00014: val_loss did not improve from 1.25030\n",
            "64/64 [==============================] - 17s 258ms/step - loss: 1.3007 - accuracy: 0.5671 - val_loss: 1.3930 - val_accuracy: 0.5543\n",
            "Epoch 15/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 1.2378 - accuracy: 0.5840\n",
            "Epoch 00015: val_loss did not improve from 1.25030\n",
            "64/64 [==============================] - 17s 258ms/step - loss: 1.2378 - accuracy: 0.5840 - val_loss: 1.3935 - val_accuracy: 0.5217\n",
            "Epoch 16/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 1.1785 - accuracy: 0.6052\n",
            "Epoch 00016: val_loss improved from 1.25030 to 1.19515, saving model to new2(3).hdf5\n",
            "64/64 [==============================] - 17s 262ms/step - loss: 1.1785 - accuracy: 0.6052 - val_loss: 1.1951 - val_accuracy: 0.5870\n",
            "Epoch 17/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 1.1416 - accuracy: 0.6241\n",
            "Epoch 00017: val_loss did not improve from 1.19515\n",
            "64/64 [==============================] - 17s 258ms/step - loss: 1.1416 - accuracy: 0.6241 - val_loss: 1.3266 - val_accuracy: 0.5435\n",
            "Epoch 18/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 1.1073 - accuracy: 0.6274\n",
            "Epoch 00018: val_loss improved from 1.19515 to 1.11590, saving model to new2(3).hdf5\n",
            "64/64 [==============================] - 17s 262ms/step - loss: 1.1073 - accuracy: 0.6274 - val_loss: 1.1159 - val_accuracy: 0.6404\n",
            "Epoch 19/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 1.0261 - accuracy: 0.6618\n",
            "Epoch 00019: val_loss improved from 1.11590 to 1.10594, saving model to new2(3).hdf5\n",
            "64/64 [==============================] - 17s 262ms/step - loss: 1.0261 - accuracy: 0.6618 - val_loss: 1.1059 - val_accuracy: 0.6333\n",
            "Epoch 20/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 1.0074 - accuracy: 0.6736\n",
            "Epoch 00020: val_loss improved from 1.10594 to 1.02383, saving model to new2(3).hdf5\n",
            "64/64 [==============================] - 17s 262ms/step - loss: 1.0074 - accuracy: 0.6736 - val_loss: 1.0238 - val_accuracy: 0.6616\n",
            "Epoch 21/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.9674 - accuracy: 0.6819\n",
            "Epoch 00021: val_loss did not improve from 1.02383\n",
            "64/64 [==============================] - 17s 258ms/step - loss: 0.9674 - accuracy: 0.6819 - val_loss: 1.3559 - val_accuracy: 0.6186\n",
            "Epoch 22/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.9012 - accuracy: 0.7092\n",
            "Epoch 00022: val_loss improved from 1.02383 to 0.95615, saving model to new2(3).hdf5\n",
            "64/64 [==============================] - 17s 262ms/step - loss: 0.9012 - accuracy: 0.7092 - val_loss: 0.9561 - val_accuracy: 0.6975\n",
            "Epoch 23/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.8710 - accuracy: 0.7231\n",
            "Epoch 00023: val_loss improved from 0.95615 to 0.87650, saving model to new2(3).hdf5\n",
            "64/64 [==============================] - 17s 262ms/step - loss: 0.8710 - accuracy: 0.7231 - val_loss: 0.8765 - val_accuracy: 0.7141\n",
            "Epoch 24/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.8201 - accuracy: 0.7308\n",
            "Epoch 00024: val_loss did not improve from 0.87650\n",
            "64/64 [==============================] - 17s 258ms/step - loss: 0.8201 - accuracy: 0.7308 - val_loss: 1.0146 - val_accuracy: 0.6994\n",
            "Epoch 25/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.7633 - accuracy: 0.7428\n",
            "Epoch 00025: val_loss improved from 0.87650 to 0.79664, saving model to new2(3).hdf5\n",
            "64/64 [==============================] - 17s 262ms/step - loss: 0.7633 - accuracy: 0.7428 - val_loss: 0.7966 - val_accuracy: 0.7387\n",
            "Epoch 26/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.7391 - accuracy: 0.7583\n",
            "Epoch 00026: val_loss did not improve from 0.79664\n",
            "64/64 [==============================] - 17s 258ms/step - loss: 0.7391 - accuracy: 0.7583 - val_loss: 0.9574 - val_accuracy: 0.6994\n",
            "Epoch 27/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.7481 - accuracy: 0.7552\n",
            "Epoch 00027: val_loss did not improve from 0.79664\n",
            "64/64 [==============================] - 16s 258ms/step - loss: 0.7481 - accuracy: 0.7552 - val_loss: 0.8268 - val_accuracy: 0.7198\n",
            "Epoch 28/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.7162 - accuracy: 0.7604\n",
            "Epoch 00028: val_loss did not improve from 0.79664\n",
            "64/64 [==============================] - 17s 258ms/step - loss: 0.7162 - accuracy: 0.7604 - val_loss: 0.7979 - val_accuracy: 0.7410\n",
            "Epoch 29/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.6577 - accuracy: 0.7795\n",
            "Epoch 00029: val_loss did not improve from 0.79664\n",
            "64/64 [==============================] - 17s 258ms/step - loss: 0.6577 - accuracy: 0.7795 - val_loss: 0.8404 - val_accuracy: 0.7316\n",
            "Epoch 30/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.6533 - accuracy: 0.7847\n",
            "Epoch 00030: val_loss did not improve from 0.79664\n",
            "64/64 [==============================] - 16s 258ms/step - loss: 0.6533 - accuracy: 0.7847 - val_loss: 0.8728 - val_accuracy: 0.7292\n",
            "Epoch 31/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.6612 - accuracy: 0.7758\n",
            "Epoch 00031: val_loss did not improve from 0.79664\n",
            "64/64 [==============================] - 17s 258ms/step - loss: 0.6612 - accuracy: 0.7758 - val_loss: 0.8546 - val_accuracy: 0.7264\n",
            "Epoch 32/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.6398 - accuracy: 0.7872\n",
            "Epoch 00032: val_loss did not improve from 0.79664\n",
            "64/64 [==============================] - 17s 258ms/step - loss: 0.6398 - accuracy: 0.7872 - val_loss: 0.8310 - val_accuracy: 0.7382\n",
            "Epoch 33/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.6106 - accuracy: 0.7946\n",
            "Epoch 00033: val_loss did not improve from 0.79664\n",
            "64/64 [==============================] - 17s 258ms/step - loss: 0.6106 - accuracy: 0.7946 - val_loss: 0.7998 - val_accuracy: 0.7439\n",
            "Epoch 34/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.5965 - accuracy: 0.7947\n",
            "Epoch 00034: val_loss did not improve from 0.79664\n",
            "64/64 [==============================] - 17s 258ms/step - loss: 0.5965 - accuracy: 0.7947 - val_loss: 0.8346 - val_accuracy: 0.7325\n",
            "Epoch 35/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.5671 - accuracy: 0.8056\n",
            "Epoch 00035: val_loss improved from 0.79664 to 0.77804, saving model to new2(3).hdf5\n",
            "64/64 [==============================] - 17s 262ms/step - loss: 0.5671 - accuracy: 0.8056 - val_loss: 0.7780 - val_accuracy: 0.7609\n",
            "Epoch 36/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.5551 - accuracy: 0.8066\n",
            "Epoch 00036: val_loss did not improve from 0.77804\n",
            "64/64 [==============================] - 17s 258ms/step - loss: 0.5551 - accuracy: 0.8066 - val_loss: 0.8735 - val_accuracy: 0.7287\n",
            "Epoch 37/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.5794 - accuracy: 0.7984\n",
            "Epoch 00037: val_loss did not improve from 0.77804\n",
            "64/64 [==============================] - 17s 258ms/step - loss: 0.5794 - accuracy: 0.7984 - val_loss: 0.8499 - val_accuracy: 0.7377\n",
            "Epoch 38/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.6892 - accuracy: 0.7776\n",
            "Epoch 00038: val_loss did not improve from 0.77804\n",
            "64/64 [==============================] - 17s 258ms/step - loss: 0.6892 - accuracy: 0.7776 - val_loss: 1.2648 - val_accuracy: 0.6673\n",
            "Epoch 39/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.7453 - accuracy: 0.7568\n",
            "Epoch 00039: val_loss did not improve from 0.77804\n",
            "64/64 [==============================] - 17s 258ms/step - loss: 0.7453 - accuracy: 0.7568 - val_loss: 0.8918 - val_accuracy: 0.7387\n",
            "Epoch 40/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.5777 - accuracy: 0.8021\n",
            "Epoch 00040: val_loss improved from 0.77804 to 0.70248, saving model to new2(3).hdf5\n",
            "64/64 [==============================] - 17s 262ms/step - loss: 0.5777 - accuracy: 0.8021 - val_loss: 0.7025 - val_accuracy: 0.7713\n",
            "Epoch 41/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.5332 - accuracy: 0.8181\n",
            "Epoch 00041: val_loss improved from 0.70248 to 0.67341, saving model to new2(3).hdf5\n",
            "64/64 [==============================] - 17s 262ms/step - loss: 0.5332 - accuracy: 0.8181 - val_loss: 0.6734 - val_accuracy: 0.7750\n",
            "Epoch 42/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.4996 - accuracy: 0.8215\n",
            "Epoch 00042: val_loss did not improve from 0.67341\n",
            "64/64 [==============================] - 17s 258ms/step - loss: 0.4996 - accuracy: 0.8215 - val_loss: 0.8554 - val_accuracy: 0.7429\n",
            "Epoch 43/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.4875 - accuracy: 0.8247\n",
            "Epoch 00043: val_loss did not improve from 0.67341\n",
            "64/64 [==============================] - 17s 258ms/step - loss: 0.4875 - accuracy: 0.8247 - val_loss: 0.7401 - val_accuracy: 0.7675\n",
            "Epoch 44/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.4856 - accuracy: 0.8275\n",
            "Epoch 00044: val_loss did not improve from 0.67341\n",
            "64/64 [==============================] - 17s 258ms/step - loss: 0.4856 - accuracy: 0.8275 - val_loss: 0.7483 - val_accuracy: 0.7665\n",
            "Epoch 45/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.4670 - accuracy: 0.8325\n",
            "Epoch 00045: val_loss did not improve from 0.67341\n",
            "64/64 [==============================] - 17s 258ms/step - loss: 0.4670 - accuracy: 0.8325 - val_loss: 0.7258 - val_accuracy: 0.7623\n",
            "Epoch 46/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.4622 - accuracy: 0.8360\n",
            "Epoch 00046: val_loss did not improve from 0.67341\n",
            "64/64 [==============================] - 17s 258ms/step - loss: 0.4622 - accuracy: 0.8360 - val_loss: 0.8403 - val_accuracy: 0.7495\n",
            "Epoch 47/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.4623 - accuracy: 0.8310\n",
            "Epoch 00047: val_loss did not improve from 0.67341\n",
            "64/64 [==============================] - 16s 258ms/step - loss: 0.4623 - accuracy: 0.8310 - val_loss: 0.8448 - val_accuracy: 0.7524\n",
            "Epoch 48/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.5060 - accuracy: 0.8212\n",
            "Epoch 00048: val_loss did not improve from 0.67341\n",
            "64/64 [==============================] - 17s 258ms/step - loss: 0.5060 - accuracy: 0.8212 - val_loss: 0.8625 - val_accuracy: 0.7495\n",
            "Epoch 49/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.4834 - accuracy: 0.8218\n",
            "Epoch 00049: val_loss did not improve from 0.67341\n",
            "64/64 [==============================] - 17s 258ms/step - loss: 0.4834 - accuracy: 0.8218 - val_loss: 0.7572 - val_accuracy: 0.7807\n",
            "Epoch 50/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.4658 - accuracy: 0.8308\n",
            "Epoch 00050: val_loss did not improve from 0.67341\n",
            "64/64 [==============================] - 17s 258ms/step - loss: 0.4658 - accuracy: 0.8308 - val_loss: 0.7243 - val_accuracy: 0.7760\n",
            "Epoch 51/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.4432 - accuracy: 0.8412\n",
            "Epoch 00051: val_loss did not improve from 0.67341\n",
            "64/64 [==============================] - 17s 258ms/step - loss: 0.4432 - accuracy: 0.8412 - val_loss: 0.7585 - val_accuracy: 0.7698\n",
            "Epoch 52/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.4522 - accuracy: 0.8346\n",
            "Epoch 00052: val_loss did not improve from 0.67341\n",
            "64/64 [==============================] - 17s 258ms/step - loss: 0.4522 - accuracy: 0.8346 - val_loss: 0.7301 - val_accuracy: 0.7840\n",
            "Epoch 53/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.4510 - accuracy: 0.8324\n",
            "Epoch 00053: val_loss did not improve from 0.67341\n",
            "64/64 [==============================] - 17s 258ms/step - loss: 0.4510 - accuracy: 0.8324 - val_loss: 0.8210 - val_accuracy: 0.7561\n",
            "Epoch 54/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.4519 - accuracy: 0.8335\n",
            "Epoch 00054: val_loss did not improve from 0.67341\n",
            "64/64 [==============================] - 17s 258ms/step - loss: 0.4519 - accuracy: 0.8335 - val_loss: 0.7978 - val_accuracy: 0.7656\n",
            "Epoch 55/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.4427 - accuracy: 0.8385\n",
            "Epoch 00055: val_loss did not improve from 0.67341\n",
            "64/64 [==============================] - 16s 258ms/step - loss: 0.4427 - accuracy: 0.8385 - val_loss: 0.7724 - val_accuracy: 0.7727\n",
            "Epoch 56/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.4449 - accuracy: 0.8346\n",
            "Epoch 00056: val_loss did not improve from 0.67341\n",
            "64/64 [==============================] - 17s 258ms/step - loss: 0.4449 - accuracy: 0.8346 - val_loss: 0.7713 - val_accuracy: 0.7680\n",
            "Epoch 57/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.4493 - accuracy: 0.8346\n",
            "Epoch 00057: val_loss did not improve from 0.67341\n",
            "64/64 [==============================] - 17s 258ms/step - loss: 0.4493 - accuracy: 0.8346 - val_loss: 0.7605 - val_accuracy: 0.7845\n",
            "Epoch 58/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.4438 - accuracy: 0.8344\n",
            "Epoch 00058: val_loss did not improve from 0.67341\n",
            "64/64 [==============================] - 17s 258ms/step - loss: 0.4438 - accuracy: 0.8344 - val_loss: 0.9301 - val_accuracy: 0.7448\n",
            "Epoch 59/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.5123 - accuracy: 0.8195\n",
            "Epoch 00059: val_loss did not improve from 0.67341\n",
            "64/64 [==============================] - 17s 258ms/step - loss: 0.5123 - accuracy: 0.8195 - val_loss: 1.1069 - val_accuracy: 0.7401\n",
            "Epoch 60/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.4623 - accuracy: 0.8351\n",
            "Epoch 00060: val_loss did not improve from 0.67341\n",
            "64/64 [==============================] - 17s 258ms/step - loss: 0.4623 - accuracy: 0.8351 - val_loss: 0.8496 - val_accuracy: 0.7604\n",
            "Epoch 61/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.4510 - accuracy: 0.8354\n",
            "Epoch 00061: val_loss did not improve from 0.67341\n",
            "64/64 [==============================] - 16s 258ms/step - loss: 0.4510 - accuracy: 0.8354 - val_loss: 0.9059 - val_accuracy: 0.7481\n",
            "Epoch 62/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.4284 - accuracy: 0.8422\n",
            "Epoch 00062: val_loss did not improve from 0.67341\n",
            "64/64 [==============================] - 17s 258ms/step - loss: 0.4284 - accuracy: 0.8422 - val_loss: 0.7604 - val_accuracy: 0.7779\n",
            "Epoch 63/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.4153 - accuracy: 0.8456\n",
            "Epoch 00063: val_loss did not improve from 0.67341\n",
            "64/64 [==============================] - 17s 258ms/step - loss: 0.4153 - accuracy: 0.8456 - val_loss: 0.8230 - val_accuracy: 0.7689\n",
            "Epoch 64/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.4215 - accuracy: 0.8417\n",
            "Epoch 00064: val_loss did not improve from 0.67341\n",
            "64/64 [==============================] - 17s 258ms/step - loss: 0.4215 - accuracy: 0.8417 - val_loss: 0.7731 - val_accuracy: 0.7755\n",
            "Epoch 65/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.4229 - accuracy: 0.8445\n",
            "Epoch 00065: val_loss did not improve from 0.67341\n",
            "64/64 [==============================] - 16s 258ms/step - loss: 0.4229 - accuracy: 0.8445 - val_loss: 0.7024 - val_accuracy: 0.7911\n",
            "Epoch 66/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.3926 - accuracy: 0.8511\n",
            "Epoch 00066: val_loss did not improve from 0.67341\n",
            "64/64 [==============================] - 17s 258ms/step - loss: 0.3926 - accuracy: 0.8511 - val_loss: 0.6997 - val_accuracy: 0.7968\n",
            "Epoch 67/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.3910 - accuracy: 0.8492\n",
            "Epoch 00067: val_loss did not improve from 0.67341\n",
            "64/64 [==============================] - 17s 258ms/step - loss: 0.3910 - accuracy: 0.8492 - val_loss: 0.7240 - val_accuracy: 0.7921\n",
            "Epoch 68/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.3909 - accuracy: 0.8535\n",
            "Epoch 00068: val_loss did not improve from 0.67341\n",
            "64/64 [==============================] - 17s 258ms/step - loss: 0.3909 - accuracy: 0.8535 - val_loss: 0.7508 - val_accuracy: 0.7897\n",
            "Epoch 69/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.3914 - accuracy: 0.8537\n",
            "Epoch 00069: val_loss did not improve from 0.67341\n",
            "64/64 [==============================] - 17s 258ms/step - loss: 0.3914 - accuracy: 0.8537 - val_loss: 0.7473 - val_accuracy: 0.7888\n",
            "Epoch 70/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.3903 - accuracy: 0.8548\n",
            "Epoch 00070: val_loss did not improve from 0.67341\n",
            "64/64 [==============================] - 17s 258ms/step - loss: 0.3903 - accuracy: 0.8548 - val_loss: 0.8472 - val_accuracy: 0.7741\n",
            "Epoch 71/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.3964 - accuracy: 0.8538\n",
            "Epoch 00071: val_loss did not improve from 0.67341\n",
            "64/64 [==============================] - 17s 258ms/step - loss: 0.3964 - accuracy: 0.8538 - val_loss: 1.2249 - val_accuracy: 0.7174\n",
            "Epoch 72/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.4193 - accuracy: 0.8463\n",
            "Epoch 00072: val_loss did not improve from 0.67341\n",
            "64/64 [==============================] - 17s 258ms/step - loss: 0.4193 - accuracy: 0.8463 - val_loss: 0.8331 - val_accuracy: 0.7670\n",
            "Epoch 73/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.4532 - accuracy: 0.8351\n",
            "Epoch 00073: val_loss did not improve from 0.67341\n",
            "64/64 [==============================] - 17s 258ms/step - loss: 0.4532 - accuracy: 0.8351 - val_loss: 1.4082 - val_accuracy: 0.6777\n",
            "Epoch 74/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.4869 - accuracy: 0.8228\n",
            "Epoch 00074: val_loss did not improve from 0.67341\n",
            "64/64 [==============================] - 17s 258ms/step - loss: 0.4869 - accuracy: 0.8228 - val_loss: 0.9369 - val_accuracy: 0.7595\n",
            "Epoch 75/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.4373 - accuracy: 0.8418\n",
            "Epoch 00075: val_loss did not improve from 0.67341\n",
            "64/64 [==============================] - 17s 258ms/step - loss: 0.4373 - accuracy: 0.8418 - val_loss: 0.8533 - val_accuracy: 0.7750\n",
            "Epoch 76/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.4297 - accuracy: 0.8429\n",
            "Epoch 00076: val_loss did not improve from 0.67341\n",
            "64/64 [==============================] - 17s 258ms/step - loss: 0.4297 - accuracy: 0.8429 - val_loss: 0.8414 - val_accuracy: 0.7684\n",
            "Epoch 77/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.4245 - accuracy: 0.8444\n",
            "Epoch 00077: val_loss did not improve from 0.67341\n",
            "64/64 [==============================] - 17s 258ms/step - loss: 0.4245 - accuracy: 0.8444 - val_loss: 0.9440 - val_accuracy: 0.7509\n",
            "Epoch 78/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.4266 - accuracy: 0.8445\n",
            "Epoch 00078: val_loss did not improve from 0.67341\n",
            "64/64 [==============================] - 17s 259ms/step - loss: 0.4266 - accuracy: 0.8445 - val_loss: 0.8721 - val_accuracy: 0.7618\n",
            "Epoch 79/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.4011 - accuracy: 0.8502\n",
            "Epoch 00079: val_loss did not improve from 0.67341\n",
            "64/64 [==============================] - 17s 258ms/step - loss: 0.4011 - accuracy: 0.8502 - val_loss: 0.7957 - val_accuracy: 0.7784\n",
            "Epoch 80/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.3903 - accuracy: 0.8530\n",
            "Epoch 00080: val_loss did not improve from 0.67341\n",
            "64/64 [==============================] - 17s 258ms/step - loss: 0.3903 - accuracy: 0.8530 - val_loss: 0.7512 - val_accuracy: 0.7850\n",
            "Epoch 81/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.3883 - accuracy: 0.8530\n",
            "Epoch 00081: val_loss did not improve from 0.67341\n",
            "64/64 [==============================] - 17s 258ms/step - loss: 0.3883 - accuracy: 0.8530 - val_loss: 0.7741 - val_accuracy: 0.7869\n",
            "Epoch 82/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.3850 - accuracy: 0.8546\n",
            "Epoch 00082: val_loss did not improve from 0.67341\n",
            "64/64 [==============================] - 17s 258ms/step - loss: 0.3850 - accuracy: 0.8546 - val_loss: 0.7593 - val_accuracy: 0.7902\n",
            "Epoch 83/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.3942 - accuracy: 0.8510\n",
            "Epoch 00083: val_loss did not improve from 0.67341\n",
            "64/64 [==============================] - 17s 258ms/step - loss: 0.3942 - accuracy: 0.8510 - val_loss: 0.8077 - val_accuracy: 0.7817\n",
            "Epoch 84/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.3861 - accuracy: 0.8574\n",
            "Epoch 00084: val_loss did not improve from 0.67341\n",
            "64/64 [==============================] - 16s 258ms/step - loss: 0.3861 - accuracy: 0.8574 - val_loss: 0.8653 - val_accuracy: 0.7736\n",
            "Epoch 85/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.3833 - accuracy: 0.8570\n",
            "Epoch 00085: val_loss did not improve from 0.67341\n",
            "64/64 [==============================] - 17s 258ms/step - loss: 0.3833 - accuracy: 0.8570 - val_loss: 0.8543 - val_accuracy: 0.7750\n",
            "Epoch 86/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.3763 - accuracy: 0.8585\n",
            "Epoch 00086: val_loss did not improve from 0.67341\n",
            "64/64 [==============================] - 16s 258ms/step - loss: 0.3763 - accuracy: 0.8585 - val_loss: 0.7364 - val_accuracy: 0.7925\n",
            "Epoch 87/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.3663 - accuracy: 0.8606\n",
            "Epoch 00087: val_loss did not improve from 0.67341\n",
            "64/64 [==============================] - 16s 258ms/step - loss: 0.3663 - accuracy: 0.8606 - val_loss: 0.7228 - val_accuracy: 0.7930\n",
            "Epoch 88/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.3799 - accuracy: 0.8562\n",
            "Epoch 00088: val_loss did not improve from 0.67341\n",
            "64/64 [==============================] - 16s 258ms/step - loss: 0.3799 - accuracy: 0.8562 - val_loss: 0.8676 - val_accuracy: 0.7802\n",
            "Epoch 89/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.3743 - accuracy: 0.8573\n",
            "Epoch 00089: val_loss did not improve from 0.67341\n",
            "64/64 [==============================] - 16s 258ms/step - loss: 0.3743 - accuracy: 0.8573 - val_loss: 0.7582 - val_accuracy: 0.7954\n",
            "Epoch 90/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.3640 - accuracy: 0.8614\n",
            "Epoch 00090: val_loss did not improve from 0.67341\n",
            "64/64 [==============================] - 16s 258ms/step - loss: 0.3640 - accuracy: 0.8614 - val_loss: 0.7561 - val_accuracy: 0.7925\n",
            "Epoch 91/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.3682 - accuracy: 0.8557\n",
            "Epoch 00091: val_loss did not improve from 0.67341\n",
            "64/64 [==============================] - 17s 258ms/step - loss: 0.3682 - accuracy: 0.8557 - val_loss: 0.9793 - val_accuracy: 0.7628\n",
            "Epoch 92/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.3890 - accuracy: 0.8565\n",
            "Epoch 00092: val_loss did not improve from 0.67341\n",
            "64/64 [==============================] - 17s 258ms/step - loss: 0.3890 - accuracy: 0.8565 - val_loss: 0.8822 - val_accuracy: 0.7750\n",
            "Epoch 93/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.3976 - accuracy: 0.8513\n",
            "Epoch 00093: val_loss did not improve from 0.67341\n",
            "64/64 [==============================] - 17s 258ms/step - loss: 0.3976 - accuracy: 0.8513 - val_loss: 1.0153 - val_accuracy: 0.7533\n",
            "Epoch 94/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.4003 - accuracy: 0.8500\n",
            "Epoch 00094: val_loss did not improve from 0.67341\n",
            "64/64 [==============================] - 17s 258ms/step - loss: 0.4003 - accuracy: 0.8500 - val_loss: 0.9877 - val_accuracy: 0.7595\n",
            "Epoch 95/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.4005 - accuracy: 0.8496\n",
            "Epoch 00095: val_loss did not improve from 0.67341\n",
            "64/64 [==============================] - 16s 258ms/step - loss: 0.4005 - accuracy: 0.8496 - val_loss: 1.3207 - val_accuracy: 0.7292\n",
            "Epoch 96/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.4163 - accuracy: 0.8480\n",
            "Epoch 00096: val_loss did not improve from 0.67341\n",
            "64/64 [==============================] - 17s 258ms/step - loss: 0.4163 - accuracy: 0.8480 - val_loss: 0.9942 - val_accuracy: 0.7609\n",
            "Epoch 97/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.3899 - accuracy: 0.8560\n",
            "Epoch 00097: val_loss did not improve from 0.67341\n",
            "64/64 [==============================] - 17s 258ms/step - loss: 0.3899 - accuracy: 0.8560 - val_loss: 0.7998 - val_accuracy: 0.7864\n",
            "Epoch 98/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.3738 - accuracy: 0.8623\n",
            "Epoch 00098: val_loss did not improve from 0.67341\n",
            "64/64 [==============================] - 17s 258ms/step - loss: 0.3738 - accuracy: 0.8623 - val_loss: 1.0903 - val_accuracy: 0.7457\n",
            "Epoch 99/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.3804 - accuracy: 0.8560\n",
            "Epoch 00099: val_loss did not improve from 0.67341\n",
            "64/64 [==============================] - 16s 258ms/step - loss: 0.3804 - accuracy: 0.8560 - val_loss: 0.8551 - val_accuracy: 0.7826\n",
            "Epoch 100/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.3827 - accuracy: 0.8628\n",
            "Epoch 00100: val_loss did not improve from 0.67341\n",
            "64/64 [==============================] - 16s 258ms/step - loss: 0.3827 - accuracy: 0.8628 - val_loss: 0.8616 - val_accuracy: 0.7784\n",
            "Epoch 101/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.3741 - accuracy: 0.8589\n",
            "Epoch 00101: val_loss did not improve from 0.67341\n",
            "64/64 [==============================] - 17s 258ms/step - loss: 0.3741 - accuracy: 0.8589 - val_loss: 0.8366 - val_accuracy: 0.7836\n",
            "Epoch 102/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.3666 - accuracy: 0.8606\n",
            "Epoch 00102: val_loss did not improve from 0.67341\n",
            "64/64 [==============================] - 17s 258ms/step - loss: 0.3666 - accuracy: 0.8606 - val_loss: 0.8499 - val_accuracy: 0.7831\n",
            "Epoch 103/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.3582 - accuracy: 0.8645\n",
            "Epoch 00103: val_loss did not improve from 0.67341\n",
            "64/64 [==============================] - 16s 258ms/step - loss: 0.3582 - accuracy: 0.8645 - val_loss: 0.8880 - val_accuracy: 0.7784\n",
            "Epoch 104/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.3636 - accuracy: 0.8656\n",
            "Epoch 00104: val_loss did not improve from 0.67341\n",
            "64/64 [==============================] - 17s 258ms/step - loss: 0.3636 - accuracy: 0.8656 - val_loss: 0.8184 - val_accuracy: 0.7888\n",
            "Epoch 105/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.3849 - accuracy: 0.8563\n",
            "Epoch 00105: val_loss did not improve from 0.67341\n",
            "64/64 [==============================] - 16s 258ms/step - loss: 0.3849 - accuracy: 0.8563 - val_loss: 0.8104 - val_accuracy: 0.7906\n",
            "Epoch 106/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.3721 - accuracy: 0.8629\n",
            "Epoch 00106: val_loss did not improve from 0.67341\n",
            "64/64 [==============================] - 17s 258ms/step - loss: 0.3721 - accuracy: 0.8629 - val_loss: 0.8776 - val_accuracy: 0.7717\n",
            "Epoch 107/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.3544 - accuracy: 0.8686\n",
            "Epoch 00107: val_loss did not improve from 0.67341\n",
            "64/64 [==============================] - 16s 258ms/step - loss: 0.3544 - accuracy: 0.8686 - val_loss: 0.8129 - val_accuracy: 0.7892\n",
            "Epoch 108/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.3609 - accuracy: 0.8609\n",
            "Epoch 00108: val_loss did not improve from 0.67341\n",
            "64/64 [==============================] - 17s 258ms/step - loss: 0.3609 - accuracy: 0.8609 - val_loss: 0.8804 - val_accuracy: 0.7836\n",
            "Epoch 109/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.3548 - accuracy: 0.8652\n",
            "Epoch 00109: val_loss did not improve from 0.67341\n",
            "64/64 [==============================] - 17s 258ms/step - loss: 0.3548 - accuracy: 0.8652 - val_loss: 0.8384 - val_accuracy: 0.7888\n",
            "Epoch 110/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.3539 - accuracy: 0.8667\n",
            "Epoch 00110: val_loss did not improve from 0.67341\n",
            "64/64 [==============================] - 17s 258ms/step - loss: 0.3539 - accuracy: 0.8667 - val_loss: 0.8842 - val_accuracy: 0.7940\n",
            "Epoch 111/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.3603 - accuracy: 0.8634\n",
            "Epoch 00111: val_loss did not improve from 0.67341\n",
            "64/64 [==============================] - 16s 258ms/step - loss: 0.3603 - accuracy: 0.8634 - val_loss: 0.8398 - val_accuracy: 0.7850\n",
            "Epoch 112/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.3468 - accuracy: 0.8721\n",
            "Epoch 00112: val_loss did not improve from 0.67341\n",
            "64/64 [==============================] - 17s 258ms/step - loss: 0.3468 - accuracy: 0.8721 - val_loss: 0.8766 - val_accuracy: 0.7897\n",
            "Epoch 113/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.3724 - accuracy: 0.8626\n",
            "Epoch 00113: val_loss did not improve from 0.67341\n",
            "64/64 [==============================] - 17s 258ms/step - loss: 0.3724 - accuracy: 0.8626 - val_loss: 0.8405 - val_accuracy: 0.7906\n",
            "Epoch 114/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.3662 - accuracy: 0.8647\n",
            "Epoch 00114: val_loss did not improve from 0.67341\n",
            "64/64 [==============================] - 17s 258ms/step - loss: 0.3662 - accuracy: 0.8647 - val_loss: 0.9411 - val_accuracy: 0.7717\n",
            "Epoch 115/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.3677 - accuracy: 0.8642\n",
            "Epoch 00115: val_loss did not improve from 0.67341\n",
            "64/64 [==============================] - 17s 258ms/step - loss: 0.3677 - accuracy: 0.8642 - val_loss: 0.8624 - val_accuracy: 0.7845\n",
            "Epoch 116/500\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.3529 - accuracy: 0.8647\n",
            "Epoch 00116: val_loss did not improve from 0.67341\n",
            "64/64 [==============================] - 17s 258ms/step - loss: 0.3529 - accuracy: 0.8647 - val_loss: 0.8626 - val_accuracy: 0.7854\n",
            "Epoch 00116: early stopping\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4653444f10>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "es = EarlyStopping(monitor='val_accuracy', min_delta= 0.01 , patience= 50, verbose= 1, mode='auto')\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath='new2(3).hdf5', \n",
        "                               verbose=1, save_best_only=True)\n",
        "start = datetime.now()\n",
        "\n",
        "\n",
        "modelc3.fit(X_train2, y_train,\n",
        "          batch_size = 100, \n",
        "          epochs = 500,\n",
        "          validation_data = (X_val2, y_val), \n",
        "          callbacks=[checkpointer, es])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "ZHm-KDEjdzCh",
        "outputId": "eb98214b-08ad-483f-8af4-eadb5b825adf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Training-Validation Accuracy')"
            ]
          },
          "metadata": {},
          "execution_count": 47
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "#saving the model history\n",
        "loss = pd.DataFrame(modelc3.history.history)\n",
        "\n",
        "\n",
        "#plotting the loss and accuracy \n",
        "plt.figure(figsize=(10,10))\n",
        "\n",
        "plt.subplot(2,2,1)\n",
        "plt.plot(loss[\"loss\"], label =\"Loss\")\n",
        "plt.plot(loss[\"val_loss\"], label = \"Validation_loss\")\n",
        "plt.legend()\n",
        "plt.title(\"Training and Validation Loss\")\n",
        "\n",
        "plt.subplot(2,2,2)\n",
        "plt.plot(loss['accuracy'],label = \"Training Accuracy\")\n",
        "plt.plot(loss['val_accuracy'], label =\"Validation_ Accuracy \")\n",
        "plt.legend()\n",
        "plt.title(\"Training-Validation Accuracy\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = modelc3.predict(X_val2)\n",
        "\n",
        "# finding class with larget predicted probability using argmax of numpy \n",
        "y_pred = np.argmax(prediction, axis = 1)  # prediction using model \n",
        "y_val_orig = np.argmax(y_val, axis = 1) # original y_val\n",
        "#print(y_pred)"
      ],
      "metadata": {
        "id": "ogjD9R5CCTVE"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_val_orig, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6fs2jnQCTcb",
        "outputId": "9bf9fdc9-4f02-454d-bb41-c96e95cb43b5"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.13      0.09      0.11        53\n",
            "           1       0.25      0.06      0.10        51\n",
            "           2       0.19      0.55      0.28        51\n",
            "           3       0.00      0.00      0.00        31\n",
            "           4       0.22      0.42      0.29        64\n",
            "           5       0.00      0.00      0.00        30\n",
            "           6       0.28      0.34      0.30        71\n",
            "           7       0.00      0.00      0.00        20\n",
            "           8       0.92      0.98      0.95       214\n",
            "           9       0.95      0.95      0.95        84\n",
            "          10       0.81      0.89      0.85       199\n",
            "          11       0.92      0.81      0.86       227\n",
            "          12       0.95      0.83      0.88       209\n",
            "          13       0.98      0.98      0.98       180\n",
            "          14       0.95      0.93      0.94        67\n",
            "          15       0.90      0.95      0.93       198\n",
            "          16       0.94      0.97      0.96       168\n",
            "          17       0.95      0.81      0.87       199\n",
            "\n",
            "    accuracy                           0.79      2116\n",
            "   macro avg       0.57      0.59      0.57      2116\n",
            "weighted avg       0.79      0.79      0.78      2116\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "cnf_matrix = metrics.confusion_matrix(y_val_orig, y_pred)\n",
        "plt.figure(figsize=(10,8))\n",
        "ax= plt.subplot()\n",
        "\n",
        "sns.heatmap(cnf_matrix,annot=True, fmt='.5g', ax=ax,cmap=\"YlGnBu\");\n",
        "plt.rcParams.update({'font.size': 1000});\n",
        "ax.set_xlabel('Predicted Values', fontsize=10, color='Black');\n",
        "ax.set_ylabel('Actual Values',fontsize=10, color='Black'); \n",
        "plt.xticks(fontsize=14, rotation=90);\n",
        "plt.yticks(fontsize=14, rotation=90);\n",
        "\n",
        "ax.set_title('Confusion Matrix \\n', color='Black', fontsize=23);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        },
        "id": "z1N0PAZqCTfx",
        "outputId": "c2b4f92a-d918-4b7a-8a9c-16aa8d671e1c"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmEAAAIaCAYAAABoEJpJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydd3xURdeAn0khhAQSCCUBQgIhgRA6SA+CgIJgARULAvr5qgiIFZEioCK8KjaqgL5YsCBdVJAiSFF6kRogQOgoBAIhJCGb+f6425LsbnaT3c1mnYff/XHL3Dlz5t7dPZk5c46QUqJQKBQKhUKhcC8+Jd0AhUKhUCgUin8jyghTKBQKhUKhKAGUEaZQKBQKhUJRAigjTKFQKBQKhaIEUEaYQqFQKBQKRQmgjDCFQqFQKBSKEkAZYQqFkxFCdBBCrBJCXBVCSP3Wyc1tGK+X+4U75SpACPGFvu/Hl3RbFAqFZ6OMMEWpQAiRIIT4UAixSwhxSQhxSwhxWQjxpxBikhCiXkm3EUAI0QBYA3QD0oE/gM1AWkm2y5MxM1SlEOL9Qsp2yFf+fie1IVpvuL7ojPoUCoXCHpQRpvBohBD+QojpwF/AS0ATIBXYBVwGbgNeBw4KISaUWENNPAUEAMuAWlLK9lLKDlLK3W5uxyUgCTjvZrnFpZ8QwtfG9YEukhsNjAOcYYSdR+v7S06oS6FQeDHKCFN4LEIIH2AJMBjIBEYBVaSUcVLK1lLKOKAqMAg4C3QoscaaiNf//6uUMrekGiGlnCalrC+lHFlSbSgCh4EItFHEAgghAoG+wFXgghvb5RBSypH6vp9W0m1RKBSejTLCFJ7Ma0BPIAvoKqWcJKVMNS8gpUyVUs4CGgCLSqCN+QnU/3+zRFtROvlK//8AK9d7AxWA+WjvhEKhUJRqlBGm8EiEEMFoRhjAO1LKP22Vl1KmSymnWqinvBDiDSHEHiFEuhDihhBinxDiLSFEiBXZ6/X+Rk8IIaoJIWYKIc4IIbKEEMeFEBOFEGUt3QN00p+aa+a3tF5fJtpwzobeRtkWrj0ihFiTzyfuoBDicyFEYr6yNh3z9W2ZKYRIFkJk6hcRbBRC/MfadKCZPtFCiBZCiGX6ttwUQuwWQjxpTS87WYU2wnW/EKKCheuGqcgvrVUghCgjhHhA7xy/XwhxRa9fshBithCiroV71gPr9IdR+XzOpBAiWl+uk/74pP54oBDiD7MFGIZyBRzzhRAhQoiTthz2hRCT9deThBBB1rtJoVB4C34l3QCFwgp3AxUBHTCzKBUIIWqiOcnXAyRwAMgFGuq3x4UQXaWUx61UEYnme1ZZf68OqA2MBBoB95iV3Yf2eWqENlpzFPjb7FqxEEJMQvN9A7gI7AWCgFpoU6AS2GhnXXeg+awFo43Y7QdC0aZzOwAPCCF6SykzrVTRA/gYyACS0fypmgL/E0KESSknO6qfHh0wD3gVbdrxM7M21wC6AkeklH8KIazVEQcsRHvOF4HjaKOTUcDTwCNCiDullFvM7tkHhKG9E1nAjnx1FugHIcRUYChwDjiC1gdWkVKmCSH6Ab8DY4QQa6SUm8zquxN4GcgGHpVS3rBVn0Kh8BKklGpTm8dtwBQ0w2JvMer4XV/HPiDW7HxtNONKov3g+uS7b73+WjaaT1qY2bXeaMaCBLpZkGm49wkL16L116SNNhe4H80IzAFuAQ8AwuyaAG4HHshXz3h9PV/kO18FzWFcok3rhZhd64y26EECH1pomzTrlzcAf/15H+AD/bUbQAUHn5Oh3qZohpAENuQr87r+/Gj98Un98f35ylUD+gEV850PNuuTw+Z9qL/eSX/tpI12GsrkoBmgD5pd8wP89Ptf6MuNt1DHOP21FCDU7Jmc159/taQ/e2pTm9rct6npSIWnUkP/v7VRKpsIIToCHdF+2B6VUh41XJNSngAeQjOmWqCNulkiFegvpbxsdu8S4Ef9Yc+itK0I1AV8gf1SykVSSuN0ptT4XUpprz/cc2ijPmfRdDOGzpBSrkMbjQEYLISobKWO1VLKt6WUt/T35aKNDl4EygF3OKBbHqSU+9EM5A5CiDpmlwaiPcuvC7n/opTyGynllXzn06WU49HChdQDWhW1jWjPYqyUcqFZ/TlSyhw77p0AbEIbwZyjPzcXCAdWoxmzCoXiX4IywhSeisEnKL2I9xsMqzX6H/Y8SCmT0abkzMvm5zsppSX5W/X/xxSxbY5ySv9/nBCieTHrMug6Q0qZbeH6PDRjKgDrxtTs/Cf0de3RHxa3X75EG+EbACCEaA3UB9ZJKU/ZulFfXggh7hRCfCyE+EkIsUEIsUkIsQmI1Rdr5oQ2OoyUUgc8jrbC80EhxAo0Y/4SMNDcwFYoFN6PMsIUnso1/f/BRbzfELy1gAFmhsFXq76V68esnDf4ehW1bQ4hpTwHfIs2yrRD7wz+jhDibiFEeQers9kv+tGcw/rDkuqXb9GmXvsLzfmrUId8A/r+WAP8CryAZuAkAu31W1V90bBitO+SlPKfot4spUwBntUfdtf//6SUsrTFdFMoFMVEGWEKT+Ws/v/aRbzfYJxctFHGEGvKmiFjzTnaEP/Lqne4C3gSLU7aCaCtfv9n4G8hxP+EEPYaFR7fL1LKS2i61QG6AI+gjYjaM+X6AdoI3kXgCX0dgVJKIaUUmKYz/YvRRGc4zf+B5lcG2kjnr06oU6FQlDKUEabwVAwrxxra8E2yxXX9/9VslAnPV9bVGKeahPXlfRZDE0gps6UWJy0GzTDtjxZXS4dmoC0WWnDbwvDEfrGEYdTrM7RVsgtlISsGhRB+wKP6wyellF9KKU/IvKs8izMC5hT0z2ke2shmLpp/2Dsl2iiFQlEiKCNM4amsQPOb8UVzJneUJP3/DW2UMVw7bKOMMzE3IqpaKVMgjlV+pJQnpZTzpJQDgdZoxl1HtIC1hWGzX/SGjGEa0l39Yomf0fykovTH9vhgVcE0Fbop/0V9/LOWVu51py/WSLQVraeBO9GmXl8VQnRxYxsUCoUHoIwwhUcipbwOGJI5jxZCtLVVXggRLIQYanbqF/3/XYUQCRbK1wEMyZ9/Lm577UE/zXZVf1hgdZ4Qoi9avC5H6jyAKTl4dTtuMfTLc0KIMhauP4Y2SpYJ/OZIW5yJfuXlu8BaYDFauJHCyDDbD7dw/XGsG7+GDAeBVq47BSFEG7RQGbnA41LKtcBotCncrxyYVlYoFF6AMsIUnsx/gZVoK/XWCCFGCCEqmRfQRyJ/Cs3R/EHDeSnlBmAD2o/bd0KIWLN7ooAf0EbZdqKNurkLgxE0QQhhNJr0RuYUtFGRPAghugohPhRCNMl33k8I8TKa4ZaDFsC1MGaiJT6vifajb8waIIS4HfjQUE5vNJYYUsrJUsquUsoH7Fk1qA+38Zf+8EPzqPtCiPuA6VgIvKrHEAqlqiWj3Rno2/MNWkyxifp3FGAymrFZHfjcFbIVCoVnoowwhceijz91H1pIhEA0o+wffVqXrUKIJLQpq8/QjIr8oyX90KKZNwIOCyH+EkLsQYvy3gLNyb2vdG+i7XFoI1eNgRNCiL1CiKNojtq/6v/PTzDwErBHCJEqhNgphNiJthrREFdquJTSlrM9APpVfX3RHN0fBs4LIbbr27AezWfqVzTH/9LICDQ/uV7AWX1fnQKWovXtQks36Q1Og3P8Tv196/WbpVG1ojADbaHAFuBNM9kSLRzHZeA+IcQgJ8lTKBQejjLCFB6N3iH9WTSj5WO0sBJVgOb6/3cAE4F4KeW4fPeeQfMBGoc2UhaDltbmMPA20FxaT1nkEqSUx9BCJSxDmz6L0/8/BG01nyU2oqXIWYL2Qx2LZljeABYAHaWUHzvQht/Q+nMW2krIxmjTdJuBZ4Ce0nrKIo9GSrkS6IaWC1Kg+bddRfPD6olmoFnjcUx90gjNb+t2oKyNe+xCCPE42h8F14DH8gd21Ych+Y/+8EMhRHxxZSoUCs9HqNiACoVCoVAoFO5HjYQpFAqFQqFQlADKCFMoFAqFQqEoAZQRplAoFAqFQlECKCNMoVAoFAqFogRQRphCoVAoFApFCaCMMIVCoVAoFIoSQBlhCoVCoVAoFCWAMsIUCoVCoVAoSgBlhCkUCoVCoVCUAMoIUygUCoVCoSgBlBGmUCgUCoVCUQIoI0yhUCgUCoWiBFBGmEKhUCgUCkUJoIwwhUKhUCgUihJAGWEKhUKhUCgUJYAywhQKhUKhUChKAGWEKRQKhUKhUJQAyghTKBQKhUKhKAGUEaZQKBQKhUJRAigjTKFQKBQKhaIEUEaYQqFQKBQKRQmgjDCFQqFQKBSKEkAZYQqFQqFQKBQlgDLCFAqFQqFQKEoAZYQpFAqFQqFQlADKCFMoFAqFQqEoAZQRplAoFAqFQlECKCNMoVAoFAqFogRQRphCoVAoFApFCaCMMIVCoVAoFIoSwK+kG1Bc6tWrtx643c7iKUlJSdHFkCWAvkB/oClQBUgFDgLfAV8kJSXl5LsnBLgL6Aw0B+oCFYB04BSwGZiblJS0vRjtmg08bXbqzaSkpPHO0kF/ny8QD7QEWuj/bwIEFibTgvxYs3paoPVLeX2RL5OSkp6ws55/rR724ur6vUGGs96Jkpahl1Oqn4WSofi3UWqMMJ38S1o6f9ttDdi+/aBddVSvXiXKWj0AvqKs1XvT0tJp06YxW7b8lf9SuH67IyEhZs65c5uoXr0qAHPmLKJMGX+ys29ZqjJUvzUGnnvhlccYObYvZQPL2KWLgZ3bjyGEQEqTWkOHPjoOjoxzhg4G7ryzLatW/Wm1HYMG9x6XpdtWQGZ+BgzswVdfrrB6/d77OwzM0m0bGOAbarVMadEDjgy0VUdx9LAHV9df2mRILH/0u93ZltU23okhQx8ZJ0kq9J2whbNkCITVa6XpWSgZjsiIs/7QXUBgrUet/kYWlZunvnOrDqWJUmOE2cOUacNtXg8sG1CkerOzbzF48AR27DgAQEREZfr27U5UVAQXLlxi0aI1JCef5sCBZJ5+ejzz508mOLgcJ0+eNRpgkZHhtGhdm7j6NQgNDeLatQx2bD3KujV/odPlsvKnnVxJTefjmc/g42PfLHFmZjYTx89HSklgYBlu3sx2ug4GdLrcPPWFhAQTGhpMSsoFh/pSl5u3nqCgsoSHh5GcfNau+5Ue9uHq+r1JRm7+dyK0PKGh5Uk5ec6hekpShrc8CyVD8W/Dq4ywrl1buaTe775bYfwwJSTEMHfuBEJCgo3XH3+8F4MHv8OmTbs4duw006d/z4gR/4cQgk6dWvLUU31o1aoRV7OP5am390Pt2L0zmZcHzyEjI4utfyTx87Lt3NO7tV3t+mzGr5w5dYkqVUPoeldTvvv6d6frYKBx4zhiYiJJSKhLbHwVatasyrIlG3hj9By72mogJqY6/Qd2p0FCbRok1CY6Opwd2w/z1BMT7bpf6WEfrq7fm2Q0ahxLnZiaJCTUpWFCDDUjw1m8eC2jRn7iUD0lKcNbnoWSUfIIoVzF3Ynq7ULIydHx6ac/ACCE4N13X8rzYQIICCjDe++9RLly2nTmvHk/ceXKNYYPf5JZs8bRqlUjq/U3axHD4Bd6Go9/Xmafa9jhg6f59qv1ALwysg9BwdanUoujg4FBg/ryyisD6d69PTVrFm14HuDBvncwfEQ/evZqR+3aEQhh/yi10uNagbpKon5vkgH53onIcIfu9QQZ3vIslAzH3luFd6CMsELYsmUvqalpALRt24TY2CiL5cLCQrn77kRAG4peu3ZrgQ+eNe64s6lxP/no+ULL5+TomDh+PjpdLomdGtK5a2OX6eBJKD3s08Md/eQtMrwBb3kWSoZnvLcCH6dvCuuo3imEzZt3G/cTE5vbLJuY2MK4v3HjTrtlBAWZfNWysiw68efhmy/WkXToLOXKBTB8dJ9Cy7tDB3eg9LBPD3f0k7fI8Aa85VkoGf+u91ah4VU+YYOencjBgye4evU6QeUCCY8Io0WLeB548A7i42sXqc4jR04Z9xMS6tos27Ch6frRo6dslMxL8jHT6Fd4REWbZU+l/MPnn64C4Nnne1At3HZ5cI8O7kDpYZ8e7ugnb5HhDXjLs1AyPOO9VT5h7sWrjLANv5v+AklLSyctLZ2kwyl8+81KevfpzBtjn6KsgyskT540rXarUcO2D1F4eGV8fX3Q6XJJSTmHlNIuX6GlC01L19t3bGC1nJSSiePmk5V1i/iESB56NNEODdyjgztQetinhzv6yVtkeAPe8iyUDM94b5UR5l68ordDQ8vTs1cHXhsxgMkfvMj7k1/gxZceo1mzesYySxavY/Bz75KTo3Oo7uvXbxj3K1asYLOsn5+vcZlxTo6OjIzMQuv/a88Jflq6DYCAAH8e6W897uySBX+ye2cyvr4+jBzXF19f+x6fq3VwF0oP+/RwRz95iwxvwFuehZLx73pvFRqlfiTspZcfI6FhDP7+BVV55tnerFm9lRGvTeXmzSy2/LmPzz5byqBBD9hdv/mHIiCg8ECq5mVu3LhJUFCg1bKXL11j1CtfkpurxcZ7ZmgPqoVbDlL698WrTPtoOQAP9+tIvfiadrUfXKuDO1F62KeHO/rJW2R4A97yLJQMz3hvS3IkTghhV4YZKaXdGWaEEN2BJ4E2QDXgGnAUWAjMllLesHF7/rraomWnuR2IADKBE8AS4FMp5SV76zLg0pEwIURNIcQ7Qoh1QohD+m2dEGKCECLSGTKaNqtn0QAz0LVba95861nj8dzPf7QWwd6t3MzIYviwz/nnb20VTfuODeg3sJPV8u9NWMSN9EwiqlfkmSHd3dRKhUKhUChcjxDiNeAiMB8YBLQCKqENFhmzywDbhBBfCyFsRrcVQgQIIb4DVqCljqoFBKCljmoHfAjsFULYDi+g1SWEEB+iGYFPAnXQUo5VRDMW3wb2CyHucFRvlxlhQogOwCHgIeAA8K1+O2A4J4Ro7yr55vS6J5HatasDcP16Brt2Hbb7XkMcF4CsLOsR6S2VsfYXTVbWLV4d9jkH9mmOmI2b1ead9wdY/QtkzcrdbFy/H4BXRz9AYDnH/NpcoUNJoPSwTw939JO3yPAGvOVZKBme8t76uGCzizg0IwngODAbGIxmQD0L/AAY/IkeB5YI2w5sXwKP6PcvA5OAx4BhwDb9+RhgpR2DQpOAlwAB3ACm6NswCFitL1MNWCaEaGqxBiu4ciTsY7Rhwzgp5VAp5dv6baiUsh4wV1/GKkKIZ4QQO4QQO+bMXlisxtzWKsG4f+K4/alCypcPMu4XFkwvJ0dHenoGAP7+fnk+jAZu3cphxItz2bH1KAAJjWrx0YxnrBpWaWk3mDxpMQBd7mxCh44JFsu5U4eSQulhnx7u6CdvkeENeMuzUDL+Xe+tBSTwM9BJShkjpXxWSjlTSrlASjlbSvkw2jRlur78nYDF/LxCiPuAh/WHp4DmUspRUsrvpJRTgbZoNgho04ofWmuUEKIZ8Jr+MA1oJ6V8QUr5jZRylpTyTuBN/fVgYLZwYE7XlUZYAjDdxvWZQENbFeg7vqWUsuXTzzxYrMaEhpoCp167ZvcUMNHRNYz7Z8/+bbPshQuXjLkJa9UqGEU955aOkS9/yZ+bDgFQL74GH898lmAb0e43rT/AlVTtnQutGMz/Zq2yuO3emWy8Z/v2A8yYMZ8ZM+azefNup+pQkig97NPDHf3kLTK8AW95FkqGZ7y3Qvg4fbOT16SUvaSUVvPvSSk3AiPNTj1hpeh4s/3npJR54n9IKXOBIWgGGsCDQghr9shYtBEwgFFSygIZ2dGMMMPo2m3A3VbqKoArjbDzgK3pxvb6Mm7h6tV0436FCkE2SuYlLq6Wcf/AgWM2SsL+/abrsbG18lzLydExZsRXxmnFurERTJ39HBVCbCdtlWb57BfN38ysaSssbju3mWRv3foXn3wyj08+mcf69TucpkNJo/SwTw939JO3yPAGvOVZKBme8d6WlBEmpbxiZxMXmO0XyAkohIgFDFOCR6WUv1iRdxMwTxrc10Jd5YEe+sNrwBdW6pLAVLNTD1sqZwlXGmGTgU+FEJ8KIR4QQnTQbw8IIT5FGyV7z4Xy87Bj+0HjflR0hN33dehgini8adMum2XNIx6bR0LW6XQMH/4B61ZrBnTtmGpMnfMcIaH2G4PFwRk6eAJKD/v0cEc/eYsMb8BbnoWS8e96b4vBdbN9S050d5nt/1pIXSvN9i2teLsdk5/aBillho26zGXZvXrOZSEqpJQzhBCX0ZzZngJ89Zd0wE5ggJTyB1fJN+fnnzZx/LgWQC8oKJAWLerbfW/r1o2pVCmE1NQ0/vhjL0ePpljMBXb58lV++WUjoC057tKlNQC5ubmMGjXFeC0quirTPxtMpbDydsnvdX8ret3fqtByc2as5LOZ2jswdOijPP/8Y8ZrOTm6YungKRT3WXgKrtbDHf3kLTK8AW95FkqGZ7y3pSDXo/m0YUoh1wvLBbUHzSbxBRoIIYR+VMvhuqSU/wghUoAooIoQoqqU0vZ8NC4OUSGlnC+lbAOUA2rot3JSyjbOMMC+/uoX9u49arPMmjXbGPvGp8bjJ568x67YLQb8/HwZNEgbpZRSMmLER6Slpecpk5WVzYgRHxnjw/Tr15OKFSsgpWTs2OksXfobADVrVWb654MJq2w7gJ+zKY4OnoTSwz493NFP3iLDG/CWZ6Fk/Lve22LwjNn+zxaux5ntn7RVkZQyBzCkOAhCs1GKVJcec6MwzmopM0Reo89z0cm/CjR06JD3+G3tdmrXrk6bto2oWzeS0NBgpNQcItev28nu3UnG8q1bJzBrzmjKlPG3KMNXWHaQz86+xZNPvsGOHQcAiIiozMMPdycqqjoXLlxi4cLVJCefBqBu3Ui+//59ypcP4sMPv2LWLG362t/fjxdevZeq1SwHYzWndbt6lA2031AE2yNhxdHBwOnTF1i4UFuJq5PaF8eRI6f5fZ2WKqp5i3q0aFnPXCRdu91GfIPoPOeuXbvBl3PzTtGfP3eZn5ZvBiCuXiS3d2qW51m0adOYtm2blDo97ujcNs91Z+pRGK6uvzTKkFj+rjtz+gILF67Jcy4p6STr1ml+ti1bNqBly7w+u3fe1ZYGDWLs1sNZMgSWHbdL27NQMhyREedWb/1KsUOdbhSkHp3mFB2EEO2AjWgDSJlArJTyTL4yu4Bm+sNGUsr9hdRptbwQYjHQW394j5Typ0Lqcqg8eIkRVhhCCB58qAuvj3yCwEDrMbasGWGg5aIcNmwSW7ZYWhihkZAQw7Rpo6heXcsX1r//SLZts/n8LbJk5RtUr1HJoXsKM8KgaDoY2Lp1HwMGjHKoTW+/8zT39e6Y59zZs//Qo9vLDtWTXx+lh324uv7SJsOaEbZ16z4GDhjtUJsmTnqBPn262F3eWTKsGWFQup6FkuGIDPcaYWFxw1xghE19lrwjWLOllLMdqUMIEQ7swDRaNVxKOdlCuSNArP4wVkppc3WEEGIzWvBW0MJP/Gl2bRXQTX/YTUq5Jv/9+er6Bi0WGcBjUsrvbJWHUp626LURA+jUqQV79x4h6XAKl1PTuHrlOjk5OipUCCIqOoLmzevTp09novXBWotKSEgwX3wxgRUrNrFs2W8cPHicK1euERISTN26tejZsyN9+nTFz8+38MpKCG/QAZQenlK/N8nwBrzlWSgZ3ofe4HLI6DJHCBEELMNkgP0MfOCEppU4pXokzNnYGglzBlezbS9XdgahZeq6XEaW7qrLZQT4Fj5tW1xcrYc7dFDYj7WRsNKErZEwhbfi3pGwyvVedPoH5VLSx0XWQQhRFs3oMqQE2gzcZS3nY2mbjvT4ZRAKhUKhUCj+fQghygCLMRlg24C7C0m6bf7XdWU7xIRZudfZdVlEGWEKhUKhUCgAbbTV2f+K1A4h/NECsxqCpe4GukspbeeCgiNm+9GFyPDDNMV5A9NKSYfr0mMei+SI1VJmlBqfsFyZW+Dc9GkLmDnd8ZyS991/O+9MGlzgvCCnwDkpJbt3H2bfvmPs33eM5ONnuJKaxpUr1xECQkLKExdXi9tvb8k9995eIBq/TqcjOfkMB/Yns3f/QQ4eOMnRpNNkZmpJW58dfC+DhtzvsA7mvD3uCxYv3GA8tuaYb9DH4KNw6NAJUlPTCA0tT0xMJL16daR3b8s+Ctev32Djxl1s3bqPfQcOcvrUP9y4kUm5wACqRVSkSbM63HN/axo0LBgPx5zMzGy2b0li+9ajHDpwilMpf3P92k0CAvyoUjWUho2j6d6rJd062o51V1Q9zPH3cTxY7n+eeovNm/cYjydOHErvPnfYuMM2ztCjJOsvTTIK+zEorgxb052G74H9+49x4MAx9u8/RtLhE8bvgSFDH7H6mXWE0vIslAznyXA2DqQZcmEbhB/wHXCv/tQ+NMd4e6Lqm08/tsBKlHs9TTHFMD0oC/pn5a/LKkKIKpiMsH/siREGpcgn7FbungINLaoRNmToQzw3pGAuSl9RMCxEVlY2TZvYl4GgUqUKvPX24DxB94Y9/y6rV2+xek9xjbAd2w7zzP+9j/lzdPbqyDlzFjFlyjdkZ98qtD09erVk5NhHLIbYWPnTdv779g9kZGQVWk9iYnPee+9lKlUKcZoe+cmVhetjztIl6xg5cmqec7aMMB9hORSKAbU60rtk2DLCnn9+EqtX/Wn1ur1GmFod+W+U4V6fsKr1X3G6UfD34Q/s1kEI4Qt8gyn1z0Ggs91GjZa2yDAKdVRKaTVelxBiDPC2/vBtKeXYfNeDgUtoUfOvAeH6dEeW6noc+Fp/+LWUcoBd7S3NRtjx42c5cfxcofemp2cweuQMAHx8BCtXTaV6jSoFytkywqpVC6Nx41jq1YumevUqBAUFcjMzixPHz7By5R+kpGhpMH19fZg1+w3at9dSVw0dMom1a7cZ6wsJCSIkNJhTKReB4hlhmZnZ9O09ltOn/iYwMICbNzXjxt44YX37dicqKoILFy6xaNGaPHFr5s+fTHCwltdy9OgpxthakZHhtGxdh9j6NQgNDeb6tQy2bz3CujV7jYloW7erzyczB+Hjk/cvqs9n/cqsaVpsvcpVKtCqbX0aJNSiYoB+s5oAACAASURBVKVgMm9ms2dXMqtW7CIrSzOO6tWLZv789wkMNC2YKI4e+XHECLt8+So97x5GWlo65cqVNQZZLKoR5kw9SqJ+JaOgDFtG2JDB77B27VbjcUhoeUJDy5NyUvv+Kq4RVpr6SclwVIZ7jbBq8cOdbhRcPPS+XToIbRhuLmAwYJKATlLKC47Iy+dsf7eUcoWFMmX19RuSdlp04s/nbD9YSjnTQhkB/AkYRmB6SSktBZItQKmZjrREnTo1qFMnf4Dbgsz/frVxv1XrhhYNMGv4+/ux/Kcp1K0babXM88MeZcKEz/j+u5XodLlMfOczfv5lGgCNGsVSp05NEhJiqBtfmRo1q/Djkk2MG/M/u9tgjVnTl3H61N9UrVaRbnfdxjdfrbJa9rvvVhi/EBISYpg7dwIhIcHG648/3ovBg99h06ZdHDt2munTv2fEiP8DtDhrnTq15Kmn+tCqVSPSsk/kqbv3Q+3ZvTOZlwZ/SkZGFlv/OMzPy7ZxT+82BdrRpFkdBjzVlXYdGuDrm9dIu6d3G/o9cQdDn57OpX+ukZR0kjlzFjFsWD+n6FEcJkz4jLS0dOIb1KZu3Vos//H3YtXnaj3c0U9Khv00ahxLnZiaJCTUpWFCDDUjw1m8eC2jRn7iUD0lqYOS4VkyvA29ITMLkwF2DLjDUQNMz5vAUv3+TCFERynlKTNZPmj5qw0G2EIbqyjfBu4HBDBJCLFZSpl/eHMsJgNsu70GGJTykTB7eaTvKPbvSwbg3fefp2evDhbLWRoJs5dbt3LomPh/XL2q5RZdtXomkZHhecpk6rTpbHMjrKgjYYcOptD/kbfR6XKZ/PEQjh45zawZPwKWc0cmJg4kNTUNIQTLl0+1msusa9enycjIpEwZfzZs+IKKFSuQlpae5wskvxFm4IdvNzB5kjY93KxFDLO+eCHP9WtpGVQIKfwvyo2/7+eVoVpImerVq7Bu3f+cokd+7B0J++23bQwZ/F98fHyYP/+/fPPNCpYuXQcUbSTM2Xq4u34lw7IMR0NgmBthxRkJK239pGQ4KsO9I2HhDUY43Si4cPDdQnUQQkwERuoPbwEvA2es32FklaXE2kKI7zFNaV5GM/D2oa1gHAAYkjKfB1pLKU/baNt/gRH6wxvAZ2grNYOBB4A79dfSgUQp5Z4ClVih5D3wXMyxo6eNBliFCkF07VZ4Muyi4O/vR1RUhPH40j+ui0GVk6PjrbFz0elyub1zU7p0s+kvyJYte0lNTQOgbdsmFr8QAMLCQrn77kRAG043TJ+YG2C26HJnU+N+8tHzBa7bY4ABtOvQgHLltCnIc+f+IT09wyl6FIX09AzeelMzCPv160HDRsWPw+ZqPdzRT0pG0d8pZ+Mt/aRkeM47VUK0M9v3B6YCS+zYrDnUDQS+1++HAaPQnP2nYTLAktFWXFo1wPSMBD4GJFqOyRfQ/NZmYTLA/gbuc8QAg3+BEbZk8Trjfo+72zmUvNsRcnNzOXvuH+Nx5SquC9T51dyVHD50inLlAnh99OOFlt+8ebdxPzGxuc2yiYkmg27jxsIS0OclKMjku2Xw6yoKvr4+lC1rSi+Vman5urlLD3Mmv/8VFy+mEh4exgsvFH/1GrheD3f0k5JR9HfK2XhLPykZnvJO+bhgcz9Syiwp5aNoIS4WAKeBLDRH+z/RRtqaWJhatFSXlFK+BLRHW215HC135VVgF9p0ZIKU8jdH21mqfcIKIydHx/Llm4zHvR/o7BI5Uko++fhbLv2jTTfGx9cuMBXpLFJSLjJ7pjbtOGRYH8IjCs8xeeSIcSqchATbIzkNG5quHz16ykbJgiQfM41+hUdUdOhec1IvXzf+JRkYGGBcIekuPQxs336AH37Q/AnHvPE0QcGBRaonP67Wwx39pGQU7Z1yBd7ST0qGZ7xTJRWiQkrZyUX1rgRWOqmuP9EMOKfh1UbY7+t3kXpZ+zGPq1eLhg1jil3nxo2m1XuZN7NIOXWeNau3cPjwSQBCQ8vz9oQhxZZjCSklb42dS1bWLRokRPPwY/YlED550hR/rkYN28utw8Mr4+vrg06XS0rKOaSUaP6ShbNk4WbjfvuOCXbdY7meP4z7iYnNjass3aUHaKtix74xEyklXbu1pksX501ju1oPd/STkuH4O+UqvKWflAzPeacU7sOrjbClS9Yb93v37uSUOkeNnMqlSwX9vfz9/bjjjtt4dfhAatas5hRZ+Vm04Hd27TiCr68Pb7w5sMDqQmtcv27K8FCYc6mfny/BweVIS0snJ0dHRkYmQUGFjwD9tec4Py3VfBoCAvx5tH8nu9qWn7OnL/Hl59rokxCCp582xXNzhx4Gpk/7gZMnzxEUFMiYMf9xUAvbuFoPd/STkuH4O+UqvKWflAzPeKc8IVjrvwmv7e1Ll66ycYM2N+/v70evexNdKq9OnZq0bdvEYnBRZ/D3xSt88sECAB59vCv1421HpjfHENMKsMsnzrzMjRsW49Ll4dKla4x6ZS65udqimmeH3k21cMenI29mZDH8xc/IvKlFEX/ssbtp3NgUZ8/Vehg4dOgEc+cuA+DFFx+jWrWwQu5wDFfr4Y5+UjIce6dcibf0k5LhOe+Uwn147UjY8h83kpOjA6BT5xZ2Ly8ujI2b5gLa1OCNGzc5euQUPy7/nQU/rGL8+E+Z983PTJ8+klq1IgqpyTEmvv016ek3iagexuChvQu/wU3czMhi+LA5/P23Nu3bvmMC/QY6nsZHp8vljRFfcuyIFrwyISGmROLm6HQ6xoyeTk6OjkaN6vJYvx6F36RQKBRegvDesRmPxGt7e+ni9cb93n2c75AvhCA4uBzNmtdn3Lhn+fTTMfj6+nDs6Gme+r838/w1VFxWrdzG7+u0Va8jxzxOYLmAQu7IiyHcA2i+ToVhXsbW0HhW1i1eGTaHA/tSAC0Q68T3n3DYpyE3N5e3xsxjw3otVl5UdFXmzBlf4K9IV+lhzty5P3Lw4HH8/Hx56+3nCkT9dwau1sMd/aRk2C/D1XhLPykZnvFOCeHj9E1hHa/snb/2HiU5WYvxVq1aJdp3aOJymR0Sm3F/b20E6MyZiyxbtt4p9aZdTefdid8C0O2uliTe7rgu5cubElVfuWI7AX1Ojs4Yl8vf3y/PF4o5t27lMOLFz9mxVUvRldAoio9mPOuwgSilZNJb81nx0w4AakZWZvpnQwkLKxjiwxV6mJOScp7p0+YDMGDgPdSvX9tuPRzB1Xq4un4lwzEZrsZb+knJ8Jx3SuE+vHI60jw22D33dbTbgb24JHZoxqKFawDYtm0/jz7avdh1/r5+L6mXtQ9yxYrlmfPpcovldu04Ytzfvv0AM2ZoxkSTJnFER9fgzBktV+XZs3/bXDhw4cIlYw7IWrUiLI5q5dzSMfLl//HHpoMA1IuvyScznyO4CCEc3n9nAcsWaSt+I6pXYsbnQ6lazXKMNWfrkZ+flm8gMzMbIQR+vj7MnLnAYrmkIyeN++vW7eDCxcsAtG/flMaNYwuV42o9XF2/kuGYDFfjLf2kZHjGO+UJbfg34XVGWGZmNitXmMJ4OGtVpD2YDyVfv3bDRkkHMEsr9cP362wUNLF1619s3arFnxsw4F7i4mqxadMuAA4cOEbr1o2s3rt//zHjfmxsrQLXc3J0jBnxhXHqsG5sdabOHmJ3NHxzPnx3EQvna3HcqlYLZcZnQ23GPXOmHpYwpPCSUjJ79mK77lm9egurV28BtGkIe4wwV+vh6vqVDMdkuBpv6Sclw3PeKYX78LrpyNWrtnL9uja826JFfaKinesgb4uUU6Zgpc5aCOAMOnQwRW02fDlYwzxqs3k0Z9Cc1ocP/4DfVu8FoHZMONPmDCE0NAhHmfLBUr6fpyXBrlylAjM+H0qNyMo273GWHiWNq/VwRz8pGZ7zTnlLPykZnvFOKZ8w9+J1I2F5YoO5KEK+JXJzc1m0aK3xuGmzek6p997eHbi3t+WE4+Z8On2pzQTelSqFkJqaxh9/7OXo0RSrCWV/+WUjoC2b7tKltfFabm4uo0ZNMV6Piq7K9M+GUimsvMM6zZzyE/O+0LI7VAorz4zPnqdWlO2ghgCtWzcuth62GPr8Iwx9/pFCy418fapdCbyt4Wo9XF2/kuGYDFfjLf2kZHjGO6VWR7oXr+rts2f/ZtvWA4A2NXjnXW2KXeeXXy5nz54km2VupN9kxGufcOjgcUBLeH333YUbTu7Cz8+XQYP6AtpU24gRH5GWlp6nTFZWNiNGfGRc1dmvX0/jaJ6UkrFjp7N0qWY4RdaqwozPn6dyZcdH+z6f9Stz56wCoGKlYKZ/NpToOvYFty2uHp6Cq/VwRz8pGZ7zTnlLPykZnvNOKdyHkGY+R57Mrdw9hTZ0+rQFzJy+EIA+D3TmrQmDHJLhKwoG1hs6ZBJr124jKiqCNm0aERsbRWjF8vj6+pCaeo2DB4+zZvUW44fMz8+XDz96lW7dNAPwzJmLLNQ76+tytQ/ckSNn2LBeCznRrEUcLVrE5ZHZ5c4WDgVjBdsjYQDZ2bd48sk32LFDM1IjIirz8MPdiYqqzoULl1i4cDXJyVoi+bp1I/n++/eNq3w+/PArZs3SnNT9/f144dX7rTrPm9OmXX3KBpr6dMmCzUx6a77x+JnBPagbV8PivUH+ppGx5s0bGIPgFkeP/OTKoiUZt3ckzEf4W63DmXqURP1KRkEZEutfUWdOXzB+DxhISjrJunXbAGjZsgEtWzbMc/3Ou9rSoEHeVGsCy07TpamflAxHZcS51VM+uul/nW4UnNzzuvL2t4LXGGFSSu7q+jznzv0DwNffvkUzB6cEbRlh9hAZWY3xbz5Hu3amMBLbtu5n4MA3HGrHmxP+z64pSHMKM8IA0tLSGTZsElu2WE8an5AQw7Rpo6he3WQE9e8/km3b9jvUHoClK8dRvYYp2vybo+fx84/29aU5X301MY9za1H1yE9JGmHgPD1Kqn4lIy+2jLCtW/cxcMBoh9o0cdIL9OmTNz+sNSMMSk8/KRmOylBGmDfjNT5hW7fsNxpgtWtXd9gAs8Y7E5+n5x972bH9AIcPn+D06YtcvXodKSVBQYGEh1cmPr42ne+4jU6dWlKmjO0f3pIkJCSYL76YwIoVm1i27DcOHjzOlSvXCAkJpm7dWvTs2ZE+fbri5+db0k21idLDM+pXMjwLb+knJaNkUY707sVrRsKcgaWRMGeSqbvi0voByvlVcbmMtOwTLpcRUsY1gVLNKepImL0UNhKm8C5sjYQ5C1sjYQpvxb0jYbWbvef0F/nE7tfUi2sFrxkJUygUCoVCUTzU6kj3UmqMMN8ijir856m32Lx5j/HYtg+P7e6QUhqHlg8dOkFqahqhoeWJiYmkV6+O9O5dcGj5+vUbbNy4i61b97F3/37Onr7MjRuZBAYGUC0ilEZNo+l5323EN4y0S58zpy7x46Kt7N6RzJlTl8jIyCIgwJ/KVSoQnxDJA/fdw+23t3SqDqDFCEtOPsP+/Uf5a99BDhw4wZGkU2RmannPBg3uzeChD9ilg4FNG/eybMkG/tp7jMuXrxEUHEhUVDW63dmKxx6JsJnCo6h6mJMjbxbaxqSkUyz4fi07th/iwoXL5OToqFwllCZNY7nv/kTatW9s9d4ydryzztCjJOtXMkzYM0qlnreS4WwZTkdNR7qVUjMdmSsPONzQpUvWMXLk1DzniupIXRQnyzlzFjFlyjdkZxc+7XVXz+YMf+OBPKsJ8/P157/x+YxV5OTobNbVpk1jPvnkdUJD88bwKo6j6PPPT2TVqj+t3OWYEZadfYsxo2ax8pctVsvUqhXB1KkjLeZvdJbDa3au9bxuOTk6Pnj/W+Z9tdJqGYDuPdowYdKzBZKNA5Txsb3kXDnmKxnOlOENOigZlnDvdGSd5h863Sg4vutlNR1pBa81wi5fvkrPu4eRlpZOuXJljfFYimKEWVpu3Ldvd6KiIrhw4RKLFq3Js9x4/vzJBAeXY/ToKSxcuBqAyMhwmrWKIrZ+dUJCg7h+7SY7tx7j97X7jLnDWrWNY/KMp/DxKfiXyA/zNjLl/R+Nx01b1KFtYn2qhody/dpNjh4+y68/7SI7O0e73rQe3377Lr6+vsXSwcDgwRNYu3ar8TgkJJjQ0GBSUi4Ajhlhr70yjZUrNAMsNDSYBx7qTGxcJFevpPPT8s3s35cMQJUqlViwYDIRESY/t+LqYY4tI2zcmDksXrQeAD9/X3rd04EWLesRUKYMx4+fZfGi9fx9UfPxu6NLSz6e+mKBnGu2jDBn6lES9SsZniXDG3RQMqzJcK8RFtPiY6cbBck7X1RGmBV8x48fX9JtsAvJP+MdKT969DQO7E8mvkFtWrZM4EhSCgBdurQiPt6y07cQloeF5837mfnztRGRhIQYvv9+MomJzYmLi6J583gefLAb+/Yd49Sp86SmXiMnR0eHDs1Yt24bVatW5O23hzJy5H9o1r4q8QmR1I4Jp36DmnS+szHNb4th3ep95NzScfbMZcKrVyKuft7YWZk3s3l16P/IuaWNgL0+/iFefP1+GjerTUxsBPENI+nQKYFudzdnw9pD3LhxkwsXLtOgQR3q1Ikslg4GTp++QOPGcQwYcC/DXu7Diy8/TFBQWdb9pqXdaHlbPLe1alDoc1m3difTpmix3CIiwvjm+zfpemcrYuMiadQ4ht4P3M6F85c5fDiFjIybnD9/iR49TOE6iquHOTqZZfH8xg17mPzetwAEBZXli6/e4JFHu1E/PprYuEhatW7Agw91ZtfOJM6fv8yJE+eoWbMq9ernje3mKwKs9oMz9SiJ+pUMz5LhDTooGdZkhL3pkPBiMmX2lvHOrvOFZ9u4VYfShFdO/v722zZWrvgDHx8f3nrzOXwtjCzZS06Ojk8//QHQssu/++5LhIQE5ykTEFCG9957yejDNG/eT1y5co3hw59k1qxxtGplPYFrk+Z1GDSsh/F4xY87CpTZt/ckNzM0gyE+IZJevVtZrKt6zUo888yDxuMdOw4WWwcDgwb15ZVXBtK9e3tq1iza8DzAzOmmxNhjxj5JRPW8+SJ9fHwY9cYTVK+ujX79+utmjhxJcZoe9vDNvF+N+8NeepiGjWIKlAkKCuTdyUPw99f8CKdNWYC9o8qu1sMd/aRkeI4Mb9BByXD8e8pVCCGcvims43VGWHp6Bm+9ORuAfv160LBR3WLVt2XLXlJT0wBo27aJxRxgAGFhodx9dyKgDUWvXbu1wAfPGp3vNDl3Jx89X+D6ldQbxv2aUbaTXEdHVzfuG6Zgi6ODM0k5eYHDhzWDKioqnMTbm1osV7ZsGR566C7j8YoVWn41d+iRm5vLzu2HAe3LqGev9lbLhoeH0aqNNvp3/vxldu20nd7KgKv1cEc/KRmeI8MbdFAynP99W1QEPk7fFNbxut6Z/P5XXLyYSnh4GC+8UDBqvKNs3rzbuJ+Y2Nxm2cTEFsb9jRt32i2jXDnTtFVWVkEn/kphJmPuTMolm3WlpJiMuJgYbSrSHTrYwx+bTQ6q7dpbHx3U2mFq58aNuwD36HH1arpxxWelsAqEhNhOVxIdHWGSs2GPjZImXK2HO/pJyfAcGd6gg5Lh/O9bRenAq4yw7dsP8MMPmiP8mDeeJig4sNh1HjlyyrifkGB7VK1hQ9P1o0dP2SiZl+PHLhj3wyMqFrjeqGk0oRU1Y+DQgdP8vHS7xXrOn0015ngMDS3Pvfd2Atyjgz0cO3rGuN8gwXYw1vj4Ovj6aq9ncvJppJRu0aM4C1WOHjltVzlX6+GOflIyPEeGN+igZDj/+7aoCOHj9E1hnVITJ6wwsrKyGfvGTKSUdO3Wmi5dLPtNOcrJk2eN+zVq2PaFCg+vjK+vDzpdLikp55BS2jUf/uMi0zB028T4AtcDAvx5ZXQfxr/+DbqcXCaN+4EVP+6gXcd4qlYL5fr1DI4cMq2OrFYtjGnTRlGxYgW36WAPJ1NMxmb1GranVf38fKlWLYxz5/4hIyOTixcvu0WPkJBg/Px9ybml40rqNa5du0GFCtZHw06eNI08njxRcCrZ8j2u1cMd/aRkeI4Mb9BByXD+962idOA1Jur0aT9w8uQ5goICGTPmP06r9/p1kz+Wwaixhp+fr3GZcU6OzuiTZYt9e07yyzJtZKtMgB8P90+0WK5zt8Z8MOM/RNfRPtR7dh5nxkc/M/71b/jgnSUsX7wNX18fRoz4P378cSqNG8e5TQd7uX7N1I7QiuVtlNSXMYtzdu3aDbfo4efnS+PG2l+nubmSn5dvtlr24sVUtm05aDy+fj3DLhmu1sMd/aRkeI4Mb9BByXD+922REcL5m8IqXmGEHTp0grlzlwHw4ouPUa1amNPqNv9QWArImR/zMjdu2I7IfvnSNcYOn0durjYF9p8hd1G1WqjV8s1vi+GF1+4juk41i9dv3sxm7tylLFiwKs+0mit1cATDCk+AADsSnQcEmHzlbty46TY9Hniws3F/ysc/cOBAwVyZGTcyeX34DG7dyjGeS0+3T4ar9XBHPykZniPDG3RQMhyT4VJ8XLAprFLqpyN1Oh1jRk8nJ0dHo0Z1eaxfj8Jv8gBuZmTz+gtf8M/f2iqadonxPDrgdqvlr1xOZ8yrX7F31wlCKwbx8qjetOsYT+XKFUhPz2TvzuPMnb2aY0nnmTz5C5KSTvLeey9ZDPyqsE3Pe9rz47KNbN1ygPT0m/R/dDy97mlPi9vqE1DGn+PHz7Fk8e9cOH+ZmpFVOXP6bwB8fNRffAqFQqGwH5f+QgshQoUQPYUQ7US+iW4hRJAQYmxxZcyd+yMHDx7Hz8+Xt95+zulGh3n+wqys7ELLm5cJCrK8MCAr6xavvzCXQ/s1R+5GTaN5873HrfoC3MzIZvCTM9i76wQhoeWYPW8YfR5uR3hERfz8fQmtGMTtXRsx6+vnadasPgDLl6/nu+9WuEyHohBovgrUjlROWVmmkbOgoEC36eHr68OHn7xAh8QmANy6lcOSxb8zZuQshr8yjZnTF3Ph/GUSGtZh3JtPGe+z5Ttmjqv1cEc/KRmeI8MbdFAyHJPhUtR0pFtxmREmhEgADgHLgE3AdiGEecCUYGBcIXU8I4TYIYTYMXv2ggLXU1LOM33afAAGDLzHYp7B4lK+vOmHtbBgejk5OtLTNb8gf38/iwmob93KYfTLX7Fz2zEA4htGMnn6UwSWsz5svXj+Zk6n/APAowM7Ub1mJYvlAgL8ef11k1Hw9dfLXaJDUSlvZqRcvXK90PJXr5rKVKgQ5FY9KlQIYubs15g24xW63dWKauGVKFPGn/IVytGkaSyjxgxk3nfj84x+Va5sfSrZHFfr4Y5+UjI8R4Y36KBkOP/7VlE6cOV05CTgT6A/UAH4BNgshOgspTxqTwVSytnAbLCcO/Kn5RvIzMxGCIGfrw8zZxY01ACSjpw07q9bt4MLFy8D0L59Uxo3jrXZhujoGpw5cxGAs2f/pmZNy/5YABcuXDLmgaxVK6LAyFbOLR1vvPo1WzZpwUDj6tfgg5n/ISjY9gfvz42Hjfst29hub5Mm9ShXLpCMjJucOHGW9PQMp+pQHKKjwtm+VXNkP3fWdryznBwdF/XPqVy5slSrFlYietzeuTm3d7Ye6yf5mGklVEKjOnbV6Wo93NFPSobnyPAGHZQM53/fFhlPaMO/CFdOR7YB3pBS3pBSnpdS9gV+ANYLIeIKudcuDM7nUkpmz17MlE++s7gdOmhyrF69eovx/O7dh61VbSQurpZx/8CBYzbL7t9vuh4bWyvPtZwcHeNf/4ZN6zUjJCY2nI9mPU2FCoUnhr30j+mvqaAg6/kIQYvyHmwWHy0jI9NpOhSXurE1jfsHLTi7m3Po0HHjl1NMTCRCCI/Rw5wdO0zvUPMW9ey6x9V6uKOflAzPkeENOigZrv2eUngurjTCAoA8o1dSypfRG2JAwYBYHkiHDqZRkE2bdtksax7x2DwSsk6nY/jwD1i/Zh8A0XWq8fGsZwkJtdOHyMzw+vtCms2ymZlZeYbAQ0PLO0UHZ9CuvSk90x+b9xXSDlM7DVGnPUUPA1euXGfDei06dvkK5eja7Ta77nO1Hu7oJyXDc2R4gw5Khuu+pxxGrY50K67sniSgZf6TUsqXgAVovmLFYujzj3Do8OJCt/vvN4UcmDhxqPH8wIH3FCqjdevGVKoUAsAff+zl6NEUi+UuX77KL79oOQ4DAsrQpUtrQMtFOGrUFOO1WtFV+GTOM1QMsy+vJECduuHG/TW/2k6N8+uvfxjDJsTFRVOmjH+xdXAWUdHh1I/X3AJTUi6wccNei+WysrJZsMCURLtHDy12mqfoYWDyu98YUxw98mg3AgNtj1IacLUe7ugnJcNzZHiDDkqG676nHEUK4fRNYR1XGmFLgEctXZBSvgDMAzz+6fj5+TJoUF9Am/YcMeIj0tLS85TJyspmxIiPjPFh+vXrScWKFZBSMnbsdJYu/Q2AmrUqM2XOs4RVth3ALz9de5gSXf+8ZBu//mQ5x9ixI+eYOHGO8fi++zoXWwdn89zgPsb9d96ay/lzeX3DcnNzmfj2l5w7py1EuOuu9sTFRbldj717jpJtZQVndvYt3vvvPH5cpn2B1q5TnWefu9/uul2thzv6ScnwHBneoIOS4ZrvW4XnI4qTK8+dWHLMt5eRr09l6dJ1gDYS1rvPHRbL+QjLAUSzs2/x5JNvsGPHAQAiIirz8MPdiYqqzoULl1i4cDXJyVq4ibp1I/n++/cpXz6IDz/8ypjL0d/fj6Gv9KJKtZBC29uqbRxlA/Oulhz54hdsXHcgT5l2HeMJq1KBG+mZ7Nl5nN9+3Ut2tjYKVr9+bebPf5+yZQOKpYOB06cvsHChlpdTJ7XQEUeOnOL3ddp0XPMW9WjRsn6eNnftdhvxDaIL6PfaK9NYuWILAKGhwTzY9w5i4yJJu5rOj8s2sX9fMgBVdlzFsgAAIABJREFUqlRiwYLJRERUKfazsER2rvWVS0MGvc+ePUdJ7NiURo3qULlKRTIzs0g+dpZVK7dy9qxmJFatVpH/fTGGqOjwAnWU8bH+pepMPUqifiXDs2R4gw5KhjUZcW4drIjtOMvpRsHRDc96/IBLSaGMMDOsGWEAaWnpDBs2iS1b/rJaJiEhhmnTRlG9upZaqH//kWzbtt/h9i74ZSQRNfKGocjKvMV7by3k159t+xiANhz+4YevUrly3mTgRdHBwNat+xgwYJQDWsDb7zzDfb07FjifnX2LMaNmsfKXLVbvrVUrgqlTR1oMO1IcPfK0oxAjbMPvtqd+W7VuwJsTnqZmTcsybBlh4Dw9Sqp+JcOzZHiDDkqGJZQR5s0oI8wMW0YYaEPLK1ZsYtmy3zh48DhXrlwjJCSYunVr0bNnR/r06Yqfn6+xvDONMAMH951ixfId7N+TwvlzV7iZkUWZAH8qV6lAg0aRPHDvPXTs2MLqUmdHdTDgTCPMwKaNe1m6+Hf+2ptMauo1goLKUisqnDvvasVjj9xvM2ZOUfUwx5YRdvDACX5fv4sd2w9z9sw/XL6cho+PD1WqhNKkWSzde7QhsWNTq/dD4UaYs/QoyfqVDM+S4Q06KBn5cbMR1mm2842w9c8oI8wK/wojzF4KM8KKyz+ZhYfEKC5VytYvvFAxydLZXqHpDAJ8C5+2LS62jDBnYI8RplAoFLZxsxHWeY7zjbB1TysjzApq8ahCoVAoFApFCVBqEng7MlV46NAJUlPTCA0tT0xMJL16daR378KHfSWW/wDQ6XQkJ59h//5jHDhwjP37j5F0+IQxPMGQoY/w/POPFXrv3n37OHjgJEeTzhjvfXbwPQwacl9h6jN21P9YvuyPQssZSEpabvG8M/rJV1hPsWTOrl2H+eXnzWzfdpC//0klKzObSpVCCI8Io2XLeBI7NqdFi6KN3DlDD3tISjrFgu/XsmP7IS5cuExOjo7KVUJp0jSW++5PzBP7zBP1cEc/KRmeI8MbdFAyShg1ZuVWSs10JByx2lBnOUBaM8Kef34Sq1f9afU+W0ZYYfe60whzVj/l5N60KfvKlWu89eZnrPrVuuM9QL36USxe8r7Fa34+1hPZusMxPydHxwfvf8u8r1ZaLQPQvUcbJkx6loCAgoapcsxXMtwpwxt0UDIs4ebpyDtcMB35m5qOtEapN8IsLQXu27c7UVERXLhwiUWL1uRZCjx//mSCgy2nCrJmhA0Z/A5r1241HoeElic0tDwpJ89p120YYQXuDQkiJDSYUylabrGiGGFjxvWnUpjlH3iDL1XXrm3znHdmP9kywi5duspTT77NsWNaXXViatCly21ERVenXLmypF29ztGjp9m4cTflypV12Ahzph62jLBxY+aweNF6rS3+vvS6pwMtWtYjoEwZjh8/y+JF6/n74hUA7ujSko+nvlhgMYSjISqKqkdJ1K9keJYMb9BBybAmw81GWNfPnG+ErfmPMsKs4Dt+/PiSboOdXB5v6ey8eT8zf742WpGQEMP3308mMbE5cXFRNG8ez4MPdmPfvmOcOnWe1NRr5OTo6NChmUOST5++QKPGsQwYcC+vvjqQV14ZSFBQoNG4atWqIa1bNyr03qEv9WLYSw8QVK4s63/Twh+0vK0eLVsVPiW3bu1ujiRpH9oRox+jcZMYateJKLDVq1ufOnUiXdpPuTLH4nkpJYMH/Zf9+5Px9fVh5OgneWfiYNq2a0x8fDR169YkoWEMHTs24/H+d9Px9uaUL2/5i8fa9LMz9TDEO8vPxg17mPzetwAEBZXli6/e4JFHu1E/PprYuEhatW7Agw91ZtfOJM6fv8yJE+eoWbMq9epH5anHV1iPoO/q99Ydnwslw3NkeIMOSoY1GWFvOiS8mEz9evd4hMCZ27ABzd2qQ2miVDvm5+To+PTTHwAtcfW7775ESEjedEABAWV4772XjOEO5s37KU9uRXsYNKgvr7wykO7d21MzsmBQTnvvrVGzSuE3uAB39dMP81ezY8chAF4d3p9+/brj42P9FYuIqOxQ/e7S45t5ppRJw156mIaNYgqUCQoK5N3JQ/D319wqp01ZgL2jyq7Wwx39pGR4jgxv0EHJcPx7SuEdlGojbMuWvaSmauES2rZtQmxslMVyYWGh3H23ln8wO/tWnunBfwPu6CcpJV/M/QmAyFrVeLx/j2K2uiDu0CM3N5ed27VQIkIIevZqb7VseHgYrdo0AOD8+cvs2pnkEXq4o5+UDM+R4Q06KBke9LskXLAprFKqjbDNm3cb9xMTm9somTdDvXnm+n8D7uinnTsOcerUBQB69uxgcwSsqLhDj6tX040rVyuFVSAkxHa6kujoCJOcDbYj7BtwtR7u6Cclw3NkeIMOSsa/73dJoVFqQlRY4siRU8b9hIS6Nss2bGi6fvToKRslPZ+3xn1JyomLXL58jYCy/lSpEkrTZnXpeW9bEttUK1DeHf1kmIYEaNSoLrm5uSxb+jtLl6zn2LEzZGRkEhYWQtNmcfTu05n27ZvYXbcBd+hRnIUqR4+ctqucq/VwRz8pGZ4jwxt0UDI86HfJRw1duZNSbYSdPHnWuF+jhu1lxOHhlfH19UGnyyUl5RxSSqupfTydrX+aDJ5bt3JIv36TE8fPs2TRRjp1+o13332Z0NDyxjLu6KcDB5KN++WCyjJwwHh27cybIeD8+UucP3+JFb/8wZ13tWHipCEEBlp3Xs+PO/QICQnGz9+XnFs6rqRe49q1G1SoYH007OTJ86b9E+etlst7j2v1cEc/KRmeI8MbdFAySv/vkqJolOrpyOvXbxj3K1a0HZPJz8/XuAQ4J0dHRkamS9vmCoKCynJH1+YMe+kBJr77NP+d/AwvDX+Itu0SjGXWr99B//4jSU/PMJ5zRz9d+seUyujNcbPZtfMwFSoE8eT/3cO77w/jnUmD6dOnM37+WmDCVb9uYfirn9hVtzv18PPzpXFj7a/T3FzJz8s3Wy178WIq27YcNGtfhtWy5rhaD3f0k5LhOTK8QQclw4N+l5RPmFsp1SNh5i+spWCZ+TEvc+PGTYKCrAcE9TQe6XcHI8f0I7BcwZGjAU/cxa6dRxj+0kxSL1/nyJEU/vvfz5kw4XnAPf1k/sVz8uR5atUKZ+6X4wgPDzOev//+Tjz0cDeefupt0tNvsu63Haz45Q963N2u0PrdpQfAAw92NjrZT/n4Bxo3jSUhoXbettzI5PXhM7h1yxSuIz3ddhBb470u1sMd/aRkeI4Mb9BByXBMhiuRaiTOrZTqkbB/Ew0Soi0aYAaat4jjg48HG4eyFy9ew8WLl93VPHJz8/pSvTNpcB4DzEDjxnUZ9uKjxuN5X//i8rY5Ss972tO6jTa6mJ5+k/6Pjmfs6NksW7qBlb/8yYxpi7jvntfYsf0QNSNN0w0+ypdCoVAoFA5Qqo0wQ4wVgKys7ELLm5cp6b82XEHT5rG0b68F/NPpctm4cRfgnn4KCjLJiImpSfPm1gPQ9u7dyTgtue//2TvzuKiq/o+/L4sbIriQgAIqi7KIirilqLmUW6bWTzOfsj1zrcx8NC23tLKyTDO1J63HSssls9THfRfXXAAXQMEVU0AUlWWG+/tj5DLI3Flg5jKM9/16zet1595zzud8z5k7851zz/mek0ncuWPeELxS/e3s7MQXX42hQ4xu8UB+voY1q3cyacJCxo2dx4L5q0m7mk54RCM+nPqKlM/Y3DF9bG2HEu2katiPhiPYoGpYpmFTnATrv1RkqdBOmLt70Y+eqUB3Go1Wmifl6upS7EZxJNq0iZCOz527BCjTTu56Dkh4eCOjaatVq0LDBr6Azlm8cvkf8zQU7O8aNdxYsOg95n0zlu5PtKaudy0qVXLFvUY1mjUPZuKkoSz7ZUqx0a86dTztwg5F+lvVsBsNR7BB1XDs3yUVeSq0E9agQT3p+LKJH/K0tBtotQUA+Pv7OOwKFE/PoomghfO0lGinBvedKoDqMlsR6aOf5na2eRPay6O/Oz0WxRdfjmHL9q85cnwp+w4sZtkvUxg85HFcXJxJTipaCRXe1LjzWYit7VCmv1UNe9FwBBtUDTv6XVIn5itKhXbCQkL8peP4+CSjaePiiq4HB/sbSVmxuXmz6J9X4T8yJdqpceOitNlmrBLUT+Nu5ua49tjfhw8XheGIatnYrDy2tkOJdlI17EfDEWxQNezod8nK+0ZiD46lHVOhnbAOHYqiEe/Zc9RoWv1oxPpRih2NgwfjpOOGDXWjU0q0U0xM0eaz8fHnjKa9ezeH8ylXAHBxdaZefeOxdAqxt/7OzLzNrh266NjuNarRrXsrs/LZ2g4l2knVsB8NR7BB1XDs3yUVeSq0E9amTSS1ankAsG/fcRITUw2mS0+/yfr1uwHdcuCuXdsoVkclOXY0kT17dE6Bk5OT9GWgRDv51vOiefMQAJKTL3H06GnZtGvW7ECTrwUgKqqJ2fMg7K2/P/vkJ2mLo2cHdzc78Kyt7VCinVQN+9FwBBtUDTv6XVIn5itKhXbCXFycGTZsIKDbbmb8+DlkZWUXS5Obm8f48XOk2C1DhvQ2GUDP3li3dh+x++KNbqnz95FExr71jZSmX7/H8PHxApRrp1FjnpWO35/wDdeuZZRIc/JkEnO//EV6//LLfc0uX8n+Pn4skby8fIPX8vLy+fTjZfyxVvcF2rCRL2+82c9u7FCinVQN+9FwBBtUjYr3u6RiHYSy7JWnLGcNVjQvL5+XXprM4cPxAPj41GHQoB4EBPiSlnaDlSs3k5ys29MvKMiP5ctnF1u9oo+I4ba4dDGNlSu3FDt35kwK27cfBCA6Oozo6Ihi1x9/oh1hYYHF8moKdBPlz569xK4dxwFo0TKYli1DiuXt+nhLmoQWzQ+YPWs5Py/bgrd3Ldq1DycopB41a7rj7OzEtbRMYvfFs39fguSABQf78/PPn1CjRnWbtJOmQD4o6bSp37Fi+SZAt8Lw6We6EhrWAE2+liOHT7H2j53SKNgz/9eVqdPeMFiOi5PhpdrWtCOvQH7l0ohhszl2LJGYjs1p2rQRdbxqkpOTS3LSZTZtPMDly9cBeKRuTb5fOomABt4lyqjkJP+lak07yqN8VcO+NBzBBlVDTiNE0aGkoP4/Wt0pSFrzgjocJkOFd8IAsrKyGT16FrGxJ2Rzh4cHMm/eRHx95ecfyTlhBw6cZOgL71tQV5g5awwDBnQtVd6pM16ib//20vtCJ8wcundvx/TpIw3+q7JWOxlzwgoKCpg1cym//Pw/oyN3Q/7Vg/H/fhFnZ8ODsXJOGFjPDlNO2K6dx2SvA7RuE8bUGa9RX2ZOmzEnDKxnR3mVr2rYl4Yj2KBqGEJhJ2zAf63vhK1+XnXCZHAIJwx0w74bNuxh7dptJCScIzPzFh4e1QkK8qd3744MGNANFxdnowr26oT9cy2TQwdPc+LYOU6dSiUj/RY3M7PJzc2nuntV6tWrQ7PmQfR5qh0tI1sbLdsa7WTMCSvk+LGzrFq1jUMHE7h+PROARx6pRXSrUJ599nHCTMQSM+aEWcsOY05YQvx5du44yuFDp7l86Trp6Vk4OTnh5eVJsxbB9OjZlpiOzY2Wb8oJs5Yd5Vm+qmFfGo5gg6rxIKoT5sg4jBNmDeScMGtxT2NeUNKyUM2lrs01zHHCyoopJ8waGHPCrIE5TpiKioqKcRR2wp5eZn0nbNW/VCdMhgo9MV9FRUVFRUVFpaLiUt4VMJf8gpIBQOfP+40F81daXNZT/Trx0azhJc7Ljb5otVqSky8RF5dEfHwScXFJnDl9XgpPMGLks4wa9ZzJvMdPniQhPoXEM5ekvG8Mf5JhI54yWecPJn7PurX7zDWRM2fWGTyvPzx+6tR5MjKy8PR0JzDQjz59OtK/v+Hh8du377B791EOHDjJibg4Ll1M586dHKpVrUxdH0+aNm9A76daERbhJ1unv9Ye4qMPfjXbhkJat47gv/+dZRU7ivojkRMnE4iPP8/ZMxek/hg2vD/DRw4wWSdRFElNTSM+7jyn4lNISDjPqYQUaR/Mvv06MPuT8WaVUxo7zMXW5VckjQJRY7Dcv/8+zcmTScSdTCL53CUyM7LIzLyNIICHhzshIf506hTNk307Gd0f1Ekw/XWq9reqYW0Nq6MOzShKhXkcmV9wrERFS+uEjRj5f7w54pkS5+WcsFGjZrF5034j5ck7YabyKumElXai6OLFq5g79yfZkA36PNE7ivGTn6ZK1UolrpXWCRswoBuzZo2R3pdlwuuoUTPZZKQ/zHXCPvvkZ378YYPsdXOcMHWitrIahpyw3Nw8mjcbZFY9atWqwbTpw2XjOZlywtT+VjVKp6Hw48iBP1n/ceSvQ9THkTJUmJEwQ/Ts9ShNmjQwmS47+y7vT/gGACcngaf6dbJIp+D+3l6FeHi64+npTur9qO8W5fVww8OzOhdSr1lUB30mffg8tWobnm9U2dnD4Pm8vHyGD59RbMn0wIE9CAjwIS3tBqtWbSE5+SLx8cm89toUVqz4jOr3txNKSbksOWB+ft5EtQ4guIkvnp5u3Lp1jyMHktix9SRabQH/++somRnZfPHNKzg5Ff9L1bJ1ELPmDDVpn1ggMu395dLo1NNPd7OKHYC0T1shHh7V8fSsTmpqmsl66aMtKF6Om1sVvL1rk5x8WSZHccpqR3mX70gaAHXr1iYyMpjGjRvg6+uFm1tV7uXkcv7cJTZu3Edq6lUyMm4xZvSnLFw0mfbtjS/KUNoOR+kLVUPlYaNCO2GNGtWjUaN6JtOtWL5ZOm7dJgLfel4W6TSNDKZRYH3Cw4OICA+kvp83q1dvZeKEryzKG9TEk3r1vfhjzV4+nLTEojro0659OL716hi8Jjcx/5dfNkhfCOHhgSxZMgMPj6I4Yv/6Vx+GD/+IPXuOkpR0kfnzlzN+/MsACIJA587RvPLKAFq3bkp6TvFo+P2eacuxo+d4d8T33L2by8H9Z1n/xxH69Cu+jY+3T028fWqatC9272nJAWvQwJfo6HCr2AEQGRlCYKAf4eFBBId6Ub/+I6xds4vJ7y82WS99AgN9eX5oD8LCGxIW3pAGDbw5fOg0r7w406z8ZbWjvMt3FA1XVxfW/TmXoCD5x+ijRg9mxozvWP7LRrTaAmZ+9B1/rZ9nV3Y4Ql+oGpZp2Ax1zEpRHoqnv2tWb5eO+w/obHH+YcMGMnbsUHr0aE99v5JBOc3NW6++Zc6ftdBotHz7re4xoCAIfPLJ28W+EEC3bcann74tbSG0bNmfZGbqVg+OG/cSCxd+SOvWTWU1mkc1YtjontL79X8cLnV9//z9kHTcv39Xq9kBD/SlmXtWGuKZgV0YN34Ivfs8SsOGPggWbFJrDTvKs3xH0nBycjLqgAE4OzszceIreHq6A3Du3GUuXjR/5FTtb1XD2hoqjoPDO2FJiReJO5kM6CK4d+tuPI6WIxIbe5yMjCwA2rVrRnBwgMF0tWt70qtXDKAbTt+69QBAiS8QObo8HikdJydeLVVdb2XdZc+OBACcnZ2KOWFltcNesLUdSrSTo2iYi6urCwEBPtL7G9dvmp1X7W9Vw9oatkR0Eqz+UpHH4Z0w/VGwnr0epXLlkhPGHZ29e/+WjmNiooymjYlpKR3v3n3EIp1q1Yo2sM7NNT2J3xD/++soeXm6CdTt27egbt3a0jWl7LA1trZDiXZyFA1zKSgo4PKV69L7Ol6eZudV+1vVsLaGiuNQoeeEmUKj0bJu3R7pff+nHyvH2liPaR/+QOr5a6Sn36JyFVe8vDxp3iKI3n3bEdO25Jyws2cvSMfh4UFGy46IKLqemHjBSMqSnEsqekRjztwvQ/y1tugx5tNPdy92TSk7bI2t7VCinRxFwxxEUeSrL3/mxv2dH0JDG+JnwbQEtb9VDWtr2BQLplaolB2HdsJ27jhKRrpuWDiksT8REYHlXCPrcGD/Kek4P19D9u17nD93lTWrdtO58zY++eQdaf4K6FY3FlKvnvF5UN7edXB2dkKrLSA19QqiKJo932ntqqLh9EdjQs01RyLxzBXOntbVtWbNGnTpUvzRsVJ22Bpb26FEOzmKxoPs3n1UGsXNuZdL6oWrbNkcy+nTKQB4erozfcYIi8pU+1vVsLaGTbGPr8mHBod2wn5fs0M67t+/c7nVw1q4uVWhTbswIpo2xNu7Fk7OAteuZRK7N4H9+3QrcXbsOMzzz0/gl18+lZY83759RyrD0Mbe+ri4OFO9ejWysrLRaLTcvZuDm5vpLYROHkvhr7W6CfWVKrvw7PMxFtunPyH/ySc7U6mSa7HrStihBLa2Q4l2chSNB5k44Wtu3Cg538vV1YUuXVrx7rih1K9v2dZgan+rGtbWUHEcFHfCBEFwFUWxdBOGLODGjZvs3qV7Nu/q6kKfvpY7BfbEs0O6MGHSEKrqzbsq5IUXn+DokbOMe3sBGem3OXs2lY8//g8zZowC4O7dHCmtOXPi9NPcuXPP5JdC+o1bTBq3jIICXYy/10c8wSN1zZ8zA7oRvU3rj0rv9WODFWJrO5TC1nYo0U6OomEujRrVp127ZtSqZTgOnzHU/lY1rK1hU9SJ9IpSHhPz7wiCYPmzKgtZ98duNBotAJ0fa2nyH4m9ExbewKADVkhUyxA+/3K4NJS9evUWrl1Lt3m97t3NY/yYpVz/R/fY99GYUAa/YFkwXIDdOxLIuqnbmqpJWH2aNGlo1XqqqJjD7j1LOHV6DQmnVnPo8E/8/PMsnh3cg6SkC0yZ8i2DBr3HhQulW/mroqKi8iA2c8IEQZhr6AU4A+/rvbcJv6/eIR33H+AYE/JN0TwqmPbtWwC6yPC7d+tGlgpj0YBumxZT6Kcx9q8sNzef98YsISHuIgCRzRsw/dN/lWpOw196jyJ7PxDktRBb2aE0trZDiXZyFA05BEGgevVqtIhqwocfvsG3307C2dmJpMSLvPLy1GKjHaZQ+1vVsLaGTREE679UZLHlSNhIIAZo+sBLAELuH0cYK0AQhNcFQTgsCMLh7xatMlv4xPFEkpMvAVC3bi3ad2hWKgMqIm3aFDXpuXO6NnB3L9p02FRAQI1GS3a2bkTK1dWl2BeKPvn5Gia+8yNHDiYBEBbhx+fzX6FqNctDgFz/J4uD+88Cuvlkj/dsYTCdLewoD2xthxLt5Cga5tIhpgX9+ncB4NKla6xdu8PsvGp/qxrW1rApgg1eKrLY0gl7H/AApoii+FjhC9ACL95/38VYAaIoLhJFMVoUxehXX3/abGH92GBPPtURZ2eHD4cm4elZ9Ni1cIJogwZFWztdvvyP0fxpaTek/RX9/Q1Hgtfka3n/3f+yf49u+6KQJvX4YsGruFUv3RfIhnVHJM1OXSJwr2H436C17SgvbG2HEu3kKBqWENOh6M/BwYNxZudT+1vVsLaGiuNgM+9EFMVZwHPAfwRBmCkIgiKeUE5OHhs37JfeO8KqSEu4ebPon1fhP7KQEH/pXHx8ktH8cXFF14OD/Utc12i0fPDvn6So9oHB3ny18DVq1Cj95rPr9WKDPbjfpD7WtKM8sbUdSrSTo2hYgv6jotu37hhJWRy1v1UNa2vYFCfB+i8VWWzqGImiGAu0BAKBA4IgBNtSD2DzpgPcvq0b3m3ZsgkBDXxM5HAs9P+hN2zoC0CHDkVRm/fsOVoijz76UZv1ozkDaLVaxo37nB1bTurKb1SXrxa+gYenG6Xl+NHzXEjVRSL39q1JdBv5j4i17ChvbG2HEu3kKBqWkKo3Id+ShT5qf6sa1tZQcRxsPjolimKWKIqDgEXAXltrFosN5iAR8s3l2NFE9uzRheVwcnKSvgzatImUltbv23ecxMRUg/nT02+yfv1uQLdsumvXNtK1goICJk6cK133b+DF3MWvU6u2eftKylEYWwygV99oo8Px1rDDHrC1HUq0k6NomEtBQQGrVm2V3jdv0djsvGp/qxrW1rAp6kiYoig2WUoUxcVAB+Bl4JItNC5f/oeDB3RBS93cqvL4E21tIaM469buI3ZfPKIoyqb5+0giY9/6RkrTr99j+Ph4AbqAgMOGDQR0W7CMHz+HrKzsYvlzc/MYP36OtOpryJDe0r99URT54IP5/P77NgDq+9fh68VvULtO2cJ+3Lubx7ZNJwDdarTeT8k/irSGHfaCre1Qop0cReOHH9Zx7NgZo2nuZN9j/HtfcSrhHKDb0L5Xrw52Y4ej9IWqYR/fU6Jg/ZeKPIKxH3Z7Ir/gmMmKzp/3GwvmrwRgwNOPMW3GMIs0XJwMTwi/dDGNlSu3FDt35kwK27cfBCA6Oozo6OILPR9/oh1hYYHF8moKdPNIzp69xK4dxwFo0TKYli1DiuXt+nhLmoQWzQ+YPWs5Py/bgrd3Ldq1DycopB41a7rj7OzEtbRMYvfFs39fguSABQf78/PPn1CjRtEoVV5ePi+9NJnDh3VOqo9PHQYN6kFAgC9paTdYuXIzycm6UBNBQX4sXz5bmlP2xRc/snDhb4BuBc+osX3wqms6aGWbdiFUqSq/WvKvtYf46INfdW3YJoi5i96QrtWu0sRgnrLYAXDxYhorV24GQCvqvgDPnr3Izu26EcSolo1pGV18lKNb91aEhjUodu7WrTv8sGR9sXNXr6Tz57q9AIQ09qPLY+2KXW/bNpJ27ZpZxQ5T2Lr8iqhRIGpKnBs5YhZbtx4kIMCHtm2bEhwcgOf9eysj4xYJCefYsjlW+hF1cXHmiznv0r17yT94ToJ87Gu1v1WN0muEKOrGNHr1N6s7Bee++z/VFZPBYZwwURR5otsorlzRzS/678/TaGHBIwOQd8IOHDjJ0Bfet6ismbPGMGBA11LlnTrjJfr2by+9L3TCzKF793ZMnz7S4L+qrKxsRo+eRWzsCdn84eGBzJs3EV/foj3Pnn9+gkWrwQpZtX4CPvVqyV5/86VvOH70PADKfnxTAAAgAElEQVRTZj3H472KVp/JOWFQejtA15cvvDDRXBMAmP7RazzVv2Oxc5cvX6dn93csKmfkyMGMGvWc9L4sdpiDrcuvaBrGnDBz8POry5Spb/Loo4ZD3hhzwkDtb1WjtBoKO2Gvr7S+E7boGdUJk8Fh9o48EBsnOWANG/pa7IDZM0NffoKwiABOHDvHqVOpZKTf4mZmNrm5+VR3r0q9enVo1jyIPk+1o2Vka9lyPDyqs3TpDDZs2MPatdtISDhHZuYtPDyqExTkT+/eHRkwoBsuLs42t+nShRuSA+buXpVOXY2GjCuGPdlRFmxthxLtVNE1Ppo5it77jnP4UDynT5/n4sVr3Lx5G1EUcXOrird3HUJDG/JYl1Z07hxdYj9Te7FDifJVDfvTUKn4OMxImDWQGwmzFvc0xmPGWINqLpZtLlwa0nNO21zD2EiYtcjVltyo2ZpUdrZs/0wV22JoJMyamBoJU1EpHQqPhL2xyvojYQufVkfCZHh4opiqqKioqKioqNgRFeavm4uT4c2rb9++w57df3PgQBwJCcmkXkjjTvZdqlWrgo+PF1FRTRgwoCtNI0sfokyr1ZKcfIm4uCTi45OIi0vizOnz5OTo9vwaMfLZYnN95PKeOBlPQvx5zp65KOUdNrwfb47sb7IOOTl5xO6P59CBBOLizpOaksbtW3epXNmVR+rWpGlkIH2efJROHYyPhImiKA2Pnzp1noyMLDw93QkM9KNPn4707296eNy9kq/J+p45c4Hflm/l8KFTpKWlo9FoqePlSbPmwTzVL4ZH20eaLMPWdrg6WR7f7NVXprF37zHp/cyZI+k/wOjGD0axhh3lWX5F0hAEw9fLcn+Xhx3lWb61NEQMD7ZYsy8EE/vlVJS2Uhw1pISiVJjHkSKnSlT0u8WrmTv3F/Ly8k3m79u3E1OnDadqVcPOnA7DA4OjRs1i86b9Bq+B8S8GU3nNccL+WrePGVN/MGvT4JiYKD799B0pTo0+1poomlcgvx+aRqPl89k/s+zHjUbr2aNnW2bMeoPKlQ2vnqzkJL9c23oTtU1/bvT5fc12Jkz4utg5Y06Yk2B8/pA6UVtZDbkf/rLc3/qY+tFX+7sIW/cFGO+PitRWij+OHLHa+o8j5w9QPTsZKsxImCFSUq5IDpifX13aPdqM0CYNqVmzBlm3sondf4JNm/aj1Rbwxx87Sc/IYvHiD3BysuwpbMH9vb0K8fB0x9PTndSUK5bn9XDDw7M6F1Kvma1/+fJ1yQHz8vKk7aPhhEc0pFatGty7l8vRI2fZuD6W3Nx8du8+yosvTmLFitlUrVq0l2NeXj7Dh88otmR64MAeBAT4kJZ2g1WrtpCcfJH4+GRee20KK1Z8RvXqlm9FNH3K96xetQMAF1dn+jzZgZbRjalcqRLnzl1m9aod/HMtk40bYsnL0/Dl129ZtF+aUnY8SHr6TT7+eAkA1apVMcshLk87lGgnR9Eoy/1tL3aofWFfdpTX95RKxaNCO2GCINCpczSvvNKP1q1Lrq4bNOgJDh+O5/XXpnP3bg579xxjzZrtPP10V4t0mkYG0yiwPuHhQUSEB1Lfz5vVq7cyccJXFuUNDvWifn0v1q7ZzQfvf2dRHZpHBfPyq33oEBNZYkPyfgM6MvSlnrzxyqdcv36TM2dSWLx4FaNHD5HS/PLLBukLITw8kCVLZuDhURRH7F//6sPw4R+xZ89RkpIuMn/+csaPf9miOu7edUxywNzcqvDdkolENA0slubFl3sz/I3ZHD1yhm1bD7Nu7R769osxW0MJOwwxY8Z3ZGVlExrWkKAgf9b9sbNM5dnaDiXayVE0ynJ/24sdal/Ylx3l9T1lFdRNxBWlQk/Mf3fcUBYunGTQASskOjqcd8Y+L71fs2abxTrDhg1k7Nih9OjRnvp+3qXPW9/LYm2AZwd344dlk+jUuXkJB6yQwKB6TJ76kvR+zZqiLVY0Gi3ffqsLiioIAp988naxLwTQbZvx6advU62abvRs2bI/ycyUf+xoiJ+W/U86Hv32oBIOGOh2MvjksxG4uur8/3lzfzO6E4A+StnxINu2HWTjhn04OTkxbeqbOFs4kvogtrZDiXZyFA0o2/1tDmp/m09F7wulNFQchwrthD34wZajR4+iwKeJZw3v42XP1PAwbwJ5h5hI6aa+cuU62dm6jcxjY4+TkZEFQLt2zQgODjCYv3ZtT3r10o1K5eXls3XrAbPrWFBQwJFDutAVgiDQu0972bTe3rVp3TYMgKtX0zl6xPi2MYUoYceDZGffZdrURQAMGdKTiKZBpS6rEFvboUQ7OYqGEqj9bT+obWUG6t6RilKhnTBzcXMriv9VuMrGEXF2dqJKlaKFBzk5uQDs3fu3dC4mJspoGTExLaXj3buPmK1982a21La1atfAw4Tj2KCBT5HOrmNGUhahhB0P8tnsH7l2LQNv79qMGWOdFXK2tkOJdnIUDSVQ+9t+UNvKNKIgWP2lIs9D4YTp72Lv61u6R4IVgfT0W9I/sKpVK0srJM+evSClCQ83PpITEVF0PTHxgpGUxSnLKtvEsxfNSqeEHfocOhTPr7/q9pmcNPk13KpbJ5ivre1Qop0cRUMJ1P62H9S2UrE3Hgon7NcVm6TjTp1bGklZsVn123bpOCYmSloFmpJyWTpfr57x5dbe3nWkeWepqVfMdq48PKrj4qqLd5OZcYtbt+4YTZ+ScrXo+PxVIyn189jejkJyc/P4YPICRFGkW/c2dO0qvx2UpdjaDiXayVE0lEDt74enL5TSsClONnipyOLwzXP06GlWr9ZNxq9cuRIvvti3nGtkGy5d/If/LP4T0M3Jeu21Z6Rrt28XOUSGNvbWx8XFWVoqrdFozQ7F4OLiTGSk7l9dQYHIX+v2yqa9di2Dg7EJevW7a5aGEnYUMn/er6SkXMHNrSqTJr1qUV5T2NoOJdrJUTSUQO3vh6cvlNJQcRwc2gm7fj2Tt9+aTUGBLvbM6DHP4e1dp5xrZX3u3s3l7dFzybmnm5P13HO9iIwM0btedGPLBUfVRz/NnTv3zK7H0888Jh3P/fJX4uPPl6zrnRz+Pe4b8vOL9vHLzjZPQyk7Tp06z5IlawF4663nqFu3ttl5zcHWdijRTo6ioQRqfz88faGUhk1RJ+YrSoWOE2aMu3dzGDF8JteupQPQqXM0L7/8VDnXyvpotQVMGLeAs2d086rCwwPLLd5M7yfb88fa3RyIjSc7+x7PD55Cnyfb07JVEypXcuXcuSusWb2TtKvp1Pd7hEsXdRuaO9nRTarVapn0/nw0Gi1Nmwbx3JCe5V0lFRUVFeVQJ9IrikOOhOXm5jH8zY84cSIRgKioUObMedeiyOwVgYKCAiZPXMyO7brVOA0a+rB48ZQS/74Kw1aArm1MoZ9Gf2WpKZydnfjiqzF0iGkGQH6+hjWrdzJpwkLGjZ3HgvmrSbuaTnhEIz6c+oqUr0YN80JwKGHHkiV/kJBwDhcXZ6ZNf9Pi3RXMwdZ2KNFOjqKhBGp/Pzx9oZSGiuPgcE5YXl4+o0Z+TGzsSQAiI4NZtHhysRvDERBFkelTlvLXun0A+Pk9wqLv36N2bc8Sad3di5wcUwEBNRqtFF/M1dXF4narUcONBYveY943Y+n+RGvqeteiUiVX3GtUo1nzYCZOGsqyX6YUG/2qU6dknQ1haztSU68yf94KAF4Y+iRNmjQ0q16WYms7lOhvR9FQArW/H56+UErDpqiPIxXFoR5H5udreGvMbHbtOgpAWFgjFn/3oUPuyTVrxn9ZvVK3dY6vbx0WL/k3devWMpi2QYN6XLqk26vy8uV/qF+/rmy5aWk30N7fv83f36fUo4edHoui02PyMXKSk4pWEIU3bWRWmba24891u8jJyUMQBFycnViw4DeD6c6cTZGOt28/TNr9R97t2zcnMjK43O1Qor8dRUMJ1P5+ePpCKQ0Vx8FhRsI0Gi1jx37Otm0HAQgJCeA/308xO6p+ReLTWT+x4hfdtkR1vWuxeMl4fHzlJ4+HhPhLx/HxSUbLjosruh4c7G8kZdk4fPi0dBzVsrFZeWxtR+HycFEUWbRoNXO/+sXg61RC0YKDzZtjpfN//31armhF7VCivx1FQwnU/rYf1LYyA8EGLxVZHMIJ02q1vDduDpv+tx+AoCA/liydanJ5cEXki9nL+em/urhnXl6eLP5+PPX9jMei6dChaERqz56jRtPqR23Wj+ZsTTIzb7Nrh24em3uNanTr3sqsfPZmR2mxtR1KtJOjaCiB2t/2g9pWKvZGhXfCCgoKmDhxHuvX7wGgYcN6LFk6zeDcqIrOvK9W8sOSDQDUru3B4iXjCWhgepPbNm0ipej5+/YdL7aDgD7p6TdZv343oFs23bVrGyvVvDifffKTtMXRs4O7U7VqZRM5dNjajpGjnuXU6dUmX/36FYXimDlzpHR+6NAn7cIOJfrbUTSUQO1v+0FtK9OIToLVXyryVGgnTBRFPvxgAWt/10WKDwjwYekP0/HyqlnONbM+i75dy+KF6wCoWcudRd+/R8NGvmbldXFxZtiwgYCuzcaPn0NWVnaxNLm5eYwfP0eKcTNkSO9SjSQeP5ZIXl6+wWt5efl8+vEy/lir++Jp2MiXN97sZ3bZStphS2xthxLt5CgaSqD2t/2gtpUZqBPzFUWwi20SzEDkVImKfvHFf1m0cBWgW1ky/t8v4e1tOrBm+/YtZEZfDPukly6msXLllmLnzpxJYft23fyz6OgwoqMjil1//Il2hIUFFsurFXWB+M6evcjO7bpNq6NahtAyuvicqK7dWxEaFiC9X/nrdqZPWSq9f3Nkf0JC/AzWtZJz0Ry4qKgw6R9ZXl4+L700mcOH4wHw8anDoEE9CAjwJS3tBitXbiY5WRdrLCjIj+XLZxdb5aNPXoH8ip8Rw2Zz7FgiMR2b07RpI+p41SQnJ5fkpMts2niAy5evA/BI3Zp8v3SS7EheJSfDX0jWtKNANOwsmmLCv7/m9/uO/8yZI+k/oIvBdE6Cq2wZ1rSjPMqviBoihr/rynJ/6yMYmfyi9ndxbN0XIN8fFa2tIERRL6bB++ut7hSkfNRL9cRkqNBO2PPPv8+hg/EWl7Vl60KZFSuGnbADB04y9IX3LdKYOWsMAwZ0LVXeaR+9ylP9Y6T3kycu5o/f91hUBsCPP86kTZum0vusrGxGj55FbOwJ2Tzh4YHMmzcRX1/5eWamnLBdO48ZrVfrNmFMnfEa9evLa8g5YWA9O8rTCQPr2VFe5Vc0Dbkf/rLc3/oYc8JA7W99bN0XYLw/KlJbKe6ETdpgfSdsRk/VCZPBoUJUqBjHw6M6S5fOYMOGPaxdu42EhHNkZt7Cw6M6QUH+9O7dkQEDuuHi4lxqjRGjniGiaSMOHzrN5UvXSU/PwsnJCS8vT5q1CKZHz7bEdGxu93Yoga3tUKKdHEVDCdT+th/UtlKxFyr0SJj1se0UuVxtpk3LB6jibDhWmDUxNhJmLYyNhFmL0o6EmYupkTAVZZEbfbEWpkbCVIqwdV+AI/WHwiNhH9hgJGyaOhImhzoSpqKioqKioqJDDRirKHbthDVu3NgZCAWih/yrF3FxyZw5fV4KbzBi5CBGjRpsshxRFElJuUJcXBLx8cnExyeTEH9O2rG+X//H+PjjMbL5b9++w57df3PgwAkSEs6ReuEqd7LvUq1aFXx8vIiKCmXAgG40NRAtXT9vXPxZLl64xp07OVStVhkfn9o0bxHMU/1jiDAzarwhpn34Pat+2ym9HzlyMKNGPSfbFoXD46dOnScjIwtPT3cCA/3o06cj/ftbZ3j8zJkL/LZ8K4cPnSItLR2NRksdL0+aNQ/mqX4xPNo+skzll9aO27fvsHv3UQ4cOElCQhKpqVe5c+fe/b6sQ4uoJgwY0IWmTU1Hvpfjg8kL+O23zdL78uoPrVZLcvIl4uISiY9PJi4ukdN694+xelmCEp8pZTW2c/oBjd59OtK/f1e7t0PtC3u1w7bftyoVF7t+HNm4ceNVwAC568OG92f4SNnLEp998jM//rBB9nrffh2YMfMNKjm7l7j23eLVzJ37i2zYhWLl9O3E1GnDpZWXluTt0aclEz4YSJWqlUym1efIoSRGvPIN+v0o9+OqxMR8jUbL57N/ZtmPG43Wu0fPtsyY9UaJzcYLscXE/MWLVzF37k8O1R/GHuuMGjWLzZv2y14fMfJZs5wwx5ng7NgajmCDqmEIhR9HTv2f9R9HfviEOrwmg12PhAHF/iJ4eFTH07M6qalpFhWiLSgo9t7NrQre3rVJTr4sk6OIlJQr0o+2n19d2j3ajNAmDalZswZZt7KJ3X+CTZv2o9UW8McfO0nPyGLx4g9wcnIqkbdlm0aENKmHp6cbt27d5fCBRLZvOYFWW8DGP4+QmZHNlwtex8nJvLlpOTl5zJyyAlEUqVq1Evfu5cmmzcvLZ/jwGcWWTA8c2IOAAB/S0m6watUWkpMvEh+fzGuvTWHFis9Ktefm9Cnfs3rVDgBcXJ3p82QHWkY3pnKlSpw7d5nVq3bwz7VMNm6IJS9Pw5dfv2XRfmllsSMl5bJef3jTsk1Dh+6PAm3xz72Hpzuenu6kplyxqJzytEHVsI/yVQ3701BxDJynTJlS3nWQZd68eY2AQ8BX6zd9PvCtdwbh5laF7dt0W0FEtwqlVetQk+WkXb2Bf4A3g4d0Z/RbAxk7bjCBQfX543dd0NDGTfzp0jUaZ6eSscO2bz+E1yO1mD59OBMmvMJjj7WiadNggoL9iYgIokeP9rRpE8HGjfvIz9dw8UIavvUeISysUYm8rWLqERbhT6Mgb0LD/ej6eHOiWgWxbdNx8vO1XL6Yjo9vLRqH1jerfb6du549O+PxesSDXn1bEXdCF5m5deumxUJTACxb9hcrVuhGp8LDA1m+/DNiYqIICQkgKiqUZ57pzsmTSVy4cJWMjFtoNFo6dGhhUFcr5ho8v3vXMT779GdA5+gu/XEyzw7uTpPQBgSH+NG6TRjP/N9jHD1yhqtX0zl//gr16z9C4yYBJcpyFgxH0S+LHdu3H+SRR2oyffpIJkx4lVYxPg7RH3JcvJhG08hgXnihL+++O5SxY4fi5laVrVsP3K9XRIl6GUJuJEwJG1QN+yhf1ShPjdpTLRIvI1/uPjcFQcCar7c6BSpqQ0XCriPmnzlzZuaZM2cmnDlzZqWxmFKmeGZgF8aNH0LvPo/SsKFlO9W/O24oCxdOonXrCNk00dHhvDP2een9mjXbzM7bomUgw8f0lt7/tfaQWfU6nXCRn3/cAcDYCQNwq15FNq1Go+Xbb38FQBAEPvnk7RIbm1euXIlPP32batV05Sxb9ieZmZatgvxp2f+k49FvDyKiackAim5uVfnksxG4uuoGYefN/Q1zH4mX1Y5x415i4cIPad1a3vFwpP4YNmwgY8cOpUeP9tT3M729lSUoYYOqYZ6GI9igalh+f9sKURCs/lKRx66dMHvgwZtHjh492kvHiWdTLcrb5fGiuFnJiVdNptdotMycsgKttoCYzhE81s34JPfY2ONkZGQB0K5dM4KDS448AdSu7UmvXrogsXl5+dKIiTkUFBRw5NBpQPfF07tPe9m03t61ad02DICrV9M5euSMWRplteNh6g9bo4QNqoZ5Go5gg6phX/e3inKoTpiVcHOrKh0Xrj4zP2/Ro7fcXNOTxn9aup0zpy5TrVplxr1vemHC3r1/S8cxMVFG08bEtJSOd+8+YrLsQm7ezJbsrlW7Bh4exrf5aNDAp0hnl/EI+4UoYQc4Rn/YGiVsUDXM03AEG1QNO7q/nWzwUpFFbR4rkZiYKh37+npZlDc5qWi0xdvH+ObjF1Kv859vNwHwxqie1PU2vVn52bMXpOPw8CCjaSMiiq4nJl4wkrI4ZVllm3j2olnplLADHKM/bI0SNqga5mk4gg2qhn3d3yrKoTphVuLXFZuk406dWxpJWZLfVxaFEWjfMUw2nSiKzPxwBbm5+YSG+/F/g2Nk0+qTklK0CrRePeNz67y96+DsrPtYpKZeMdu58vCojourbjFrZsYtbt26Y6JORY5OynnTj/x0eWxvBzhGf9gaJWxQNczTcAQbVA07ur+tPClfDf5qHNUJswJHj55m9WrdZPzKlSvx4ot9zc574th5/vz94P28rjz7fCfZtGt+28/fR5JxdnZiwocDpZvXFLdvFzlENWsa3w7IxcVZWiqt0Wi5ezfHLA0XF2ciI3X/6goKRP5at1c27bVrGRyMTdCr312zNJSww1H6w9YoYYOqYZ6GI9igatjX/a2iHKoTVkauX8/k7bdmU3A/FtnoMc/h7V3HrLzpN24xcewPFBTo/v28PrIndb09Dab959pN5s1ZB8CgIR3NDpsAFLux5YKj6qOfpnBXAXN4+pnHpOO5X/5KfPz5knW5k8O/x31Dfr5GOpedbZ6Gre1wtP6wJUrYoGqYp+EINqgalmnYFCfB+i8VWew9WKtdc/duDiOGz+TatXQAOnWO5uWXnzIr7727uYwb/R+u/6NbRdO+YxhDhnaWTf/pjFXcyc7Bx7cmr4/oUea624LeT7bnj7W7ORAbT3b2PZ4fPIU+T7anZasmVK7kyrlzV1izeidpV9Op7/cIly7+A4CTHdykjtgfKioqKhZjB9/HDxM2GwkTBCFGEITGeu+HC4IQLwjCbUEQ4gRBGGYrbSXIzc1j+JsfceJEIgBRUaHMmfOuWTHIcnPzeXf0f4g/qZuIGdmiIR/NfkE275aNf7N7RxwA777/NFWrGQ5kKkdhLJrCepuuX1Ea/VWfpnB2duKLr8bQIaYZAPn5Gtas3smkCQsZN3YeC+avJu1qOuERjfhw6itSvho1jK+kLMRWdjhqf9gSJWxQNczTcAQbVA3LNFQcB1s+jlwA+AIIgjAC+AT4HXgTWAN8fP+8LIIgvC4IwmFBEA5/t3iNDatqGXl5+Ywa+TGxsScBiIwMZtHiycVuPjny8zWMf2sJhw/onLfwpv7M+eZ12R/yrKw7fDZrNQBdH29Gh47hFtfX3b3IyTEVEFCj0ZKdrZuj5erqYpZN+tSo4caCRe8x75uxdH+iNXW9a1GpkivuNarRrHkwEycNZdkvU4qNftWpY/iRnxJ2OHp/2AolbFA1zNNwBBtUDTu6vwUbvFRkseXjyEDg3P3jV4GRoij+UHhREIQTwHRgvlwBoiguAhYB5GoP2sGyEd2P9ltjZrNrl27rpLCwRiz+7kOz9v3S5GuZ8M4P7N9zCoDGofX4csEbVDcSXX3PjngyM7IB8KxZne8XbjKY7u8jydLxoUPxfPPNCgCaNQuhQYN6XLp0DYDLl/+hfv26snppaTfQ3t9z0N/fst0F9On0WBSdHpOPkZOcVLSCKLxpI7PKtLYdD1N/WBslbFA1zNNwBBtUDfu6v1WUw5ZO2G2gDpCKbkTswYicRwF/G+pbHY1Gy9ixn7Ntm271XEhIAP/5fopZkdg1Gi2Txv8oPcYKCvbh60VvUsPDuPOmv2J51Qr5FYf6HDhwggMHTgDwwgt9CQnxZ88endMYH59kdL/AuLgk6Tg42Hbdc/jwaek4qmVjIymLsKYdan+UDSVsUDXM03AEG1QN+7m/RXVOmKLY8nHkemDk/ePtwMAHrg8CztpQ36potVreGzeHTf/TxZAKCvJjydKpJpcg6+fdvln3Q9wwsC5fL34TD0/z5kKVlQ4dikakCr8c5NCP2qwfzdmaZGbeZtcOXVRp9xrV6Na9lVn5rGWHVqtl3LjP1f4oA0rYoGqYp+EINqgadnR/q3HCFMWWI2H/BvYKgrAbOAC8LQhCR+AU0BhoC/Szob7VKCgoYOLEeaxfvweAhg3rsWTpNGrXNj2X6cG8AQ0eYf53w6lV290s7T79WtOnX2uT6RZ/s5HvFug20B45cjCjRj0nXdNotNSq5UFGRhb79h0nMTHV4H5m6ek3Wb9+N6BbNt21axuz6mgpn33yk7TF0bODu1O1qnkT29u0iSyzHbr+mCtdV/ujdFijL1QN62g4gg2qhn3d3yrKYbORMFEU04AoYDfQE930vNbA48AloL0oihtspW8tRFHkww8WsPb37QAEBPiw9IfpeHmZ3p7mwbz1/esw/z/DqV3H9OiZNXFxcWbYsIFSncaPn0NWVnaxNLm5eYwfP0eKcTNkSG+zRvke5PixRPLyDO+3mJeXz6cfL+OPtbovnoaNfHnjTfP98LLaIYoiH3wwn99/1wXWfRj6w1YoYYOqYZ6GI9igatjR/a3GCVMUwS62SZChcePGDYFXAF57o+/7AGfPXmTndt2jrKiWjWkZXXw+UbfurQgNa1Ds3K1bd/hhyfpi565eSefP+1HdQxr70alzC5yFohGZtm2b0rZdJF988V8WLVwF6FavjP/3S3h71zZZ9/btW7Bgwa/F8o55ty+P1DU9etbm0cZUqWo6yJ8+xkZeQOcAvfTSZA4fjgfAx6cOgwb1ICDAl7S0G6xcuZnkZN0ejkFBfixfPrvYKp9iZRXIr/gZMWw2x44lEtOxOU2bNqKOV01ycnJJTrrMpo0HuHz5OgCP1K3J90snEdDA22A5lZwMfyGVxY4vvviRhQt/AxynP0Tk799LF9NYuXJLsXNnzqSwfbtuTmN0dBjR0RHFrj/+RDvCwgKLnRNkljdZ8zMlh6phH+WrGuWpEaKoF+P/1U6rOwUXxnRSPTEZ7N0J64xuPpnZTP/oNZ7q37HYucuXr9Oz+zsWaY8YOYhRowbz/PPvc+hgvEV5AbZsXciECXNLlXfNxsn41qtlUR5TP/oAWVnZjB49i9jYE7LlhIcHMm/eRHx95fc8M+WE7dr54BqM4rRuE8bUGa9Rv768hpwTBqW34/nnJ3DwYJzRuhnCnvvDmBN24MBJhr7wvkX1njlrDAMGdC12Ts4JA+t9poyhathH+apGeWko7ITNtYETNiRCCFMAACAASURBVFp1wuRQI+Y/RHh4VGfp0hls2LCHtWu3kZBwjszMW3h4VCcoyJ/evTsyYEA3XFycS60xYtQzRDRtxOFDp7l86Trp6Vk4OTnh5eVJsxbB9OjZlpiOze3eDiVwBDuUsEHVsI/yVQ3707AFTupmhopi1yNh+igRJ6ySs3mTs0tLVl7JvRStjWelIJtrGBsJsxbGRsKsxc28JNOJyoASfWFsJMxaGBsJU1FRsTXKjoQ1mGf9kbCUkepImBzqSJiKioqKiooKoEaUUBp14FFFRUVFRUVFpRyoMCNhco8Kb9++w57df3PgQBwJCcmkXkjjTvZdqlWrgo+PF1FRTRgwoCtNI4NNaggYfzYviqL0fP/UqfNkZGTh6elOYKAfffp0pH//ks/3tVotycmXiItL5MTJBOLjz3P2zAUpTtaw4f0ZPnKAybqJokhqahrxcec5FZ9CQsJ5TiWkcOeObolz334dmDHzDbPKsdSGB3ERSrfJ7KuvTGPv3qJJ+zNnjqT/gC6lKssadtRwbWCw3L//Ps3Jk0nEnUwi+dwlMjOyyMy8jSCAh4c7ISH+dOoUzZN9O5m9+bit7DD1qNAa7WRrG1QN62k4gg2qRvmijoQpS4WZEyZyqkRFv1u8mrlzf5GNS6VP376dmDptuNHAoMacsNKudBk1aiabNu2XzWOuE/bZJz/z4w/yYdUKnbDKzvIhF6y1WqdANN3eD/L7mu1MmPB1sXPGnDAnwVW2LOvZoSlxLjc3j+bNBsnm0adWrRpMmz5cNsiik2D8P466Wk7VsKaGI9igahhC2Tlhjb6x/pywc8PVOWFyVGgnbNL786Q4SH5+dWn3aDNCmzSkZs0aZN3KJnb/CTZt2i9tkNq+Q3MWL/4AJ5nlH3JOmKGYLwMH9iAgwIe0tBusWrWlWMyXFSs+kzb0Hj58Blu3HpDK8vCojqdndVJT0wDznbBPZi3jp//+T3rv5lYFb+/aJCfrNsI25YSVxYYHsdQJS0+/Se9eo8nKyqZatSpSgMLSOGHWtUPeCatbtzaRkcE0btwAX18v3Nyqci8nl/PnLrFx4z5SU68C4OzsxMJFk2nfvuSKT2NOmDXtKI/yVQ370nAEG1QNOQ1lnbDABbus7hQkv9lRdcJkcJ4yZUp518FMbkx58Mz27YfweqQW06cPZ8KEV3jssVY0bRpMULA/ERFB9OjRnjZtIti4cR/5+RouXkjDt94jhIU1MqggyEyRW7bsL1as2Ajo/rksX/4ZMTFRhIQEEBUVyjPPdOfkySQuXLhKRsYtNBotHTq0AODixTQiI0N44YW+jH6nP2+9Mwg3typs36bbUyy6VSitWoeatD7t6g38A7wZPKQ7o98ayNhxgwkMqs8fv+uizzdu4k+XrtG4OFWxug0PIlJgsr76vP/+POLjkgkNa0h0dDhnz6QC0LVra0JDGxrMIwiGHWJb2+HkJNCzZwfeGfs8PXt1oHXrCEJDGxIY5EeTJg1o2y6Swc/1ICPzFnFxSYiiSFxcEkOG9DJgg/yUS2vaUR7lqxr2peEINqgachq1p1okXka+PpI6xdpbR46ODlDUhopEhR4Jy8rKxsOjusm8y5b9xYzpiwGIbhXOsmUfGUxnaCRMo9ESEzOUjIwsBEFg3bqvZfcB69btNe7ezaFSJVd27VpaYhuKXO1NANau2cXk93X1MXckzBCHDp7ilRdnAsZHwqxpA1g2ErZt20FGDP8YJycnVqz4mJ9+2sDv97dxsnQkzPp2lBwJM5f8fA0dY17m5s3bAGzavAA/v+LR/+VGwqxth9Llqxr2peEINqgaxjSUHQkL+tb6I2FJw9SRMDkq9OpIcxwwgB492kvHiWdTLdKIjT1ORkYWAO3aNTN4MwHUru1Jr14xgG4oWv8RZHlTXjZkZ99l2tRFAAwZ0pOIpmWLm2VPfeHq6kJAgI/0/sb1m2bntbUdSrSTqmE/Go5gg6phP78Z1h4FUyf6G6dCO2Hm4uZWtJqvcFWiuezd+7d0HBMTZTRtTExL6Xj37iMW6diS8rLhs9k/cu1aBt7etRkzpuS2PZZiT31RUFDA5SvXpfd1vEzvQVmIre1Qop1UDfvRcAQbVA37+s1QUY4KE6KiLCQmFo1++fp6WZT37NkL0nF4uPGRnIiIouuJiReMpFSW8rDh0KF4fv11MwCTJr+GW/XShbXQx176QhRFvvryZ25czwQgNLRhiUeRxrC1HUq0k6phPxqOYIOqYT+/GUamsqrYgIfCCft1xSbpuFPnlkZSliQl5bJ0XK+e8aXK3t51cHZ2QqstIDX1CqIoItjBWKzSNuTm5vHB5AWIoki37m3o2rV1qer9IOXRF7t3HyU3VzcHLudeLqkXrrJlcyynT6cA4OnpzvQZIywq09Z2KNFOqob9aDiCDaqG/fxm2MFP1kOFwzthR4+eZvXqbQBUrlyJF1/sa1H+27fvSMemJma6uDhTvXo1srKy0Wi03L2bU+xRaHmhtA3z5/1KSsoV3NyqMmnSq6WqsyHKoy8mTviaGzdKzvdydXWhS5dWvDtuKPXr17WoTFvboUQ7qRr2o+EINqga9vWboaIcDj3weP16Jm+/NZuCAl0ogtFjnsPbu45FZRTGtAKdE2cK/TR37tyzSMtWKGnDqVPnWbJkLQBvvfUcdevWtii/MeypLxo1qk+7ds2oVcvD4ry2tkOJdlI17EfDEWxQNSzTsCVOgvVfKvI47EjY3bs5jBg+k2vX0gHo1Dmal19+qpxr5dhotVomvT8fjUZL06ZBPDekZ3lXqczs3rME0M0Du3PnHolnL/DHup389usmpkz5lmU//cX8+RPw9/cxUZKKioqKikpxHHIkLDc3j+FvfsSJE4kAREWFMmfOu6V61l6tWlHw09xc0ysr9dPYy7CyUjYsWfIHCQnncHFxZtr0N2V3Jigt5dkXgiBQvXo1WkQ14cMP3+Dbbyfh7OxEUuJFXnl5arF/v6awtR1KtJOqYT8ajmCDqmGZhi1RQ1Qoi8M5YXl5+Ywa+TGxsScBiIwMZtHiycVuDEtwdy/aoDkz85bRtBqNluzsu4BuzlBpNa2NEjakpl5l/rwVALww9EmaNDEcCb8s2FNfdIhpQb/+ukCzly5dY+3aHWbntbUdSrSTqmE/Go5gg6phP78ZqhOmLA7lhOXna3hrzGx27dJtCRQW1ojF331o8b5f+jRoUE86vnz5H6Np09JuSPtU+vv7lPsql0KUsOHPdbvIyclDEARcnJ1YsOA3g68zZ1OkPNu3H5bOF45alrcdlhCjt83IwYNxZueztR1KtJOqYT8ajmCDqmFfvxkqyuEwTphGo2Xs2M/Ztu0gACEhAfzn+ylmR9WXIyTEXzqOj08ymjYuruh6cLC/kZTKooQNhdtfiaLIokWrmfvVLwZfpxLOS3k2b46Vzv/992m7sMMS9B8d3L51x0jK4tjaDiXaSdWwHw1HsEHVsJ/fDEEQrP5SkcchnDCtVst74+aw6X/7Ad2u9EuWTjV7ry9jdOhQFPF4z56jRtPqRzzWj4Rc3jiCDWB/dqReuCodW/JZs7UdSrSTqmE/Go5gg6phf9+3Kspg0gkTBOFTQRBqCILgKgjCVkEQrguC8C8lKmcOBQUFTJw4j/Xr9wDQsGE9liydRu3a5m8jY4w2bSKlMAT79h0vFn1fn/T0m6xfvxvQLTnu2rWNVfStgRI2jBz1LKdOrzb56tfvMSnPzJkjpfNDhz5pF3aYS0FBAatWbZXeN2/R2Oy8trZDiXZSNexHwxFsUDXs5zdDcLL+S0Uec5rncVEUbwF9gBQgCBhny0qZiyiKfPjBAtb+vh2AgAAflv4wHS+vmlbTcHFxZtiwgZLe+PFzyMrKLpYmNzeP8ePnSCvkhgzpbZVROGvhCDaAMnb88MM6jh07YzTNnex7jH/vK04lnAN0G8n36tXBbuxQop1UDfvRcAQbVA37+75VUQahcC6PbAJBiBNFMUIQhO+AlaIobhQE4bgois2UqaIOkVMlKvrFF/9l0cJVgG5lyfh/v4S3t+ngoO3bt6Bq1colzgs4G0yfl5fPSy9N5vDheAB8fOowaFAPAgJ8SUu7wcqVm0lOvgjoHoUuXz5bWiFz8WIaK1fq9lDUirob7uzZi+zcrtvkNaplY1pGFx9F6da9FaFhDYqdu3XrDj8sWV/s3NUr6fy5bi8AIY396NS5Bc5C0eqatm0jadeuWZlteJACMd/geXOY8O+v+f2+0zxz5kj6D+hiMJ2T4GrwvHXt0JQ4N3LELLZuPUhAgA9t2zYlODgAz5ruODs7kZFxi4SEc2zZHCt9qbq4OPPFnHfp3r2tARvkw/BZ047yKF/VsC8NR7BB1ZDTCFF0UlXkf3cbdwpKwYnnY9SJYTKY44R9DPQD7gGtAU/gT1EUFR07NeSEPf/8+xw6GG9xWVu2LjS41YycEwaQlZXN6NGziI09IZsmPDyQefMm4utbtF/YgQMneeGFiRbVb/pHr/FU/47Fzl2+fJ2e3d+xqJyRIwczatRz0vvS2vAg5emEgTXtkHfCzMHPry5Tpr7Jo48a/j9izAkD69lRXuWrGval4Qg2qBqGUNYJa7bM+k7Y8X+pTpgcJp0wAEEQagFZoihqBUFwA9xFUUyzee30KG8nDHRDyxs27GHt2m0kJJwjM/MWHh7VCQryp3fvjgwY0A0Xl+Jl2JMTVlobHqS8nTCwlh0lnbCsrGz27TvO4UPxnD59nosXr3Hz5m1EUcTNrSre3nUIDW3IY11a0blzNJUqydfTlBNmLTvKs3xVw740HMEGVeNBVCfMkTFnJKwa8A7gL4ri64IgBAONRVH8U4kKFmLICbM2ppywspKrLbkRtLWp7GydBQnGKIsTZi6mnDBrYMgJsybmOGEqKioqxlHWCWv+k/WdsGNDVCdMDnMm5i8B8oBH77+/DMywWY1UVFRUVFRUVB4CzPmrHiiK4iBBEAYDiKJ4VyiH6GuWPCo8deo8GRlZeHq6ExjoR58+Henf37pDy6XRMGeUytZ2WKN8Sx4V2mtf6Oww/vEvDzvy8rQ8/ng3OnfuRLNmkdSqVQdBcAYKAA26qZlZQC4AVf0/NKnRvVMzXhjYidYtgnikjge3su+RnJLGmr8O8J+ft3H3Xq7R/PcuTL1/5IxuSmg1oBIgAFpEMZcNG/5g7dq/7Lq/HUFDRH6QQqvVkpx8ibi4JOLjk4iLS+LM6fPk5Oj2Jhwx8tkS0xMMIWD8690a7WRoFFoURf7++zQnTyYRdzKJ5HOXyMzIIjPzNoIAHh7uhIT406lTNE/27USNGsYny9v6/laiLwATvWF9nNQxK0Ux53HkPqArsFcUxShBEAKBX0RRbK1EBYs4K1vRijXJsvw0HMEGR9Z49dVXGT16NJUrl1y5W5JbwDWq+n8gm6JSJRcWf/4mA596VDZNckoaz74+h7jTF2TT6Jwwd6AuDw6eZ2VlMXr0aGJjY2XzV8S+sFcNYz/8o0bNYvOm/bLXreGE2XJRTG5uHs2bDTJZP4BatWowbfpwo7G1jDlhFaUvAAQaK+oWtfzF+o8jjwxWH0fKYY4T1h2YBIQBm4D2wIuiKO6wee2KYdgJM7QUeODAHgQE+JCWdoNVq7YUWwq8YsVnFu8l6QgajmCDo2t88808wsJ0+1FevXqFnTt3cfr0aSpXduLtt1+iShVPoDpF/43vUC3gNeTu4R/njeL/+uocsBsZt/n+563En75I7VruDO7fgVYtgnRa1zLp2HcSl65mGCzn3oUvAB+9M3eAbPLycnjppXEcPnz8vg0+DBz4NAEBbqSl/VOh+8JeNYz98I8Y/hFbtx6Q3nt4uuPp6U5qyhXd9TI6YdZsJ2NOWN26tYmMDKZx4wb4+nrh5laVezm5nD93iY0b95GaqtupwtnZiYWLJtO+fXODGnJOWEXqC1CdMEfHecqUKUYTTJky5dzUqVPXAYeBOOADURQTFKjbA6RPMXR22bK/WLFiI6D757J8+WfExEQREhJAVFQozzzTnZMnk7hw4SoZGbfQaLR00Nt42RwcQcMRbHB0DT+/QHSPHK9RqdJNvv56MevXb+bYsZPk5d2mQ4dgdI8j3dE5YpVIvXSdEwklI3L36d6SKe/pRhUuXLpOp6cms3bjIeLPXOTwsWSWrthBfd/aNI9ogHv1qtT3rc3qvw6UKKdOLXfeGfYsRY7fNeA6kMuyZWtYsWL9fRsas3z5r8TEdCQkpBFRUf4Vui8qosbFi2k0jQzmhRf68u67Qxk7dihublUlZ6B16wjatGlqshw5J8yaNogUlDjn5CTQs2cH3hn7PD17daB16whCQxsSGORHkyYNaNsuksHP9SAj8xZxcUmIokhcXBJDhvQybIdMqPaK1BcAAnWmmk5lPRbHX5giCGDN1+sRAYraUJEwZySso6HzoijuskmNZCk5EqbRaImJGUpGRhaCILBu3dcEBweUyJmefpNu3V7j7t0cKlVyZdeupWZHJ3YEDUew4eHQcAK9Hyd5DU9A94hkd+wpHh84rYTG/vWzaB7RAIB+Qz/hf9uPlUhTpbIrx7d/jn99LwBadhtHwtlLxdKMffNJZkwo/Md+G7hqxIaOQGVARLe5Rn4F7gv71DA2+mKI1au3MnHCV0DZRsKs3U5lWZmcn6+hY8zL3Lx5G4BNmxfg5+ddIp2hkbCK1heg/EhY9HLrj4QdflYdCZPDnNWR4/Rek4F1wBQb1slsYmOPk5GRBUC7ds0M3kwAtWt70qtXDKAbitYfJn4YNBzBhodDo/jogLzGbSlNeBO/EuUHNvCWHLDEc1cNOmAAObn5fP/Ldun9031KRv3v9Gi43rtbJmwovC6gG62ryH1RsTRsjT3Z4OrqQkBA0ePxG9fND/1jT3bYK4KTYPWXijwmnTBRFJ/Ue3UHIoBM21fNNHv3/i0dx8REGUlZfId6/Z3rHwYNR7BB1dDXKHLWqlapVCJP906R0vGWnfITjwE27zwuHT/euWTk/3o++tuA5UlHhm3Qjx/npnfdkfvCPjRsjT3ZUFBQwOUr16X3dbzMj41oT3bYK9Z+FKl8LIWKRWn2N78EhFq7IqXh7NmiFV3h4UFG00ZEFF1PTJRfCeaIGo5gg6qhr1G0evLCpes8SFjjotGxoyfPGS3/eHwKGo0WgCbB9Utcl/sCNW1DkXPo2H1hHxq2xl5sEEWRr778mRvXdeMAoaENDT6KlMNe7FBRKcRknDBBEL4G6eG3E9AcOGrLSplLSspl6bhePePLxr296+Ds7IRWW0Bq6hVEUcSccGeOoOEINqga+hoe0vWN20o+agxuWPSoJtWAk6aPVlvAlbQM/Ot7Ud2tCvW8a3E5rWiV5LV/sgiVnLNKFI52GbZBP36cM7qvF42D94V9aNia8rBh9+6j5ObqPm8593JJvXCVLZtjOX06BQBPT3emzxhhUZmO0Be25iEw0a4wJ1jrYb1jDboYYXttVB+LuH37jnRsapKsi4sz1atXIysrG41Gy927Obi5VX0oNBzBBlVDp5GT40TVqoV5Cvj6u/Ul8njUKFpOn55xu8T1B0nPzJYm53vUqFbMCdt/+Ayd2xfOC6uBLjyFnA0P2uJk0AZH6Qt70rA15WHDxAlfc+NGyflerq4udOnSinfHDTW4B7AxHKEvVBwLc+aE/aD3+sleHDCAu3dzpOPKlUvOjXkQ/TR37tx7aDQcwQZVA+rUqUOlSv4UhYtIL+YwFVLdrYp0nJNrep/PnNyiuV7u1Yv/yPz4206KBsLdKXS0StpQB/3HpDqcHkijwxH6wt40bI092dCoUX3atWtGrVoephM/gD3ZYa+oc8KURXYkTBCEk2BwDa4AiKIoRhq4pqKiYgOqVq3KN998g7Pz/7N33vFRVNsD/86mkR4ISBIIoSS0QOggQgDBgoIoqCAWQH0+EaT4A0URFZRie/pEfCr4HhZ8oI8iIIIgID1AQIEECEkgIZQESC+k7O78/phkd0O2JruTzbjfz2c/mezcueeeuTOzZ+4995wqQ6cIOdbHpF28BuQAVQ76IVStfNTTsvI7NdLjoW6pfVy4ANi3fyUg+YEVF98k+dxFNm3ew/9+3M78+V+w6vstfPbZa7RqFWqhJhcunBdzI2EjgQeMfKq+N4sgCCpBEF4XBGGTIAjPV373tCAI5wRBSBEE4X1BECy/ipjBx0f/xl9m8DZvCsMy1g4rK0GGEnT4K8sQRfj888/p1q1q9eJNquJ1GaOoWP+238jLfJ5PqYz+NiwsMva2n135qXon88XHR7/6saxMhWSAXbnlOI1BGWX0hbPKcDT1qYMgCPj5+dCjZ0feeut5vvhiHm5uKlKSM3j2mQXVRrcsoYS+cDQqwf4fF6YxaYSJophu7mNF3QuAWUiv0a8LgvA28CHwDfBvYBJS3DGTCILwd0EQ4gVBiF++/Ica+/399T8EubkFNfYbolZrKCoqASSfAsOb0RxKkKEEHf7KMhYvfo/+/fsDIIo3gcsYH6SWyC8o0W0HN7l11KomwY39jB5bnWwgHcgDyvH319ebm3sBKThrKfpHikiVEaakvnBWGY7GmXQYGNuDh0YPBeDSpSw2bvzd6mOdSQ9nxTUdKS8WfcIEQbhdEISjgiAUCYJQLgiCRhAE81evxBPABFEUJwHDgdeB6aIoLhJFcQnwPDDeXAWiKC4XRbG3KIq9//73moldW7duodu+fPma2cZkZt5Ao5HiK7VqFWr1KhclyFCCDn9VGRUVtzFokJS0IiUlGUG4zK1BXW8l+YJ+lCyi0uHeFG5uKsJCmgDSCJoxHzM95cA1II3WrfUryy5fTqpskyd6f7UKXTuV0hfOLMPROJsOsQZphI4cSbD6OGfTw4ULa+KELUMylpIBb+BvwGdWHBcKnASozDWpAQzX0x+nelZgm2nfvpVuOzExxWzZhAT9/qioVmZKKk+GEnT4a8oIxdtb8sVKSkri3/9eiiUDDOB0UoZuu2fXtmbLdotujbu75MN1NvmS2bKGGNfBcLpGP62pjL5wbhmOxtl0MJwaLCwoNlOyOs6mhzMiqOz/cWEaq06PKIopgJsoihpRFFcijWxZ4ipSdH0EQeiA5K3b2WB/NNJrda0ZOFAf8Xj/fvOhywwjHhtGQv4ryFCCDn89GXoH+OTkZCZNmkSvXh2tqn+HQZT8uwabXz9z92B9lPztv58wU7I6xnUwXK2Wr9tq+H3h/DIcjbPpkH5RP9prbQ5PcD49XLiwxggrqXSg/7PSmf4lK4/7HvhWEISVwK/AEuBDQRBeFARhCvAFsKG2DQfo1y9Gt0z54METJCcbd1XLzs7jl1/2AdKS42HD+v2lZChBh7+WjOZUhYK4cOECkyZNori4yGoZqWmZ/HHqAgBRbUONpiOS2u3BM+Pv1P2/7ue4OuiQDVT5zNxE8g9TQl80DBmOxpl00Gq1rFu3U/d/9x4drD7WmfRwVlw+YfJi0pgSBKFP5eZTleVeRIrUGA48bEXdbwEfIQUQ+lwUxXnAHOAV4G1gJxYc8y3h7u7G5MljAWkZ85w5H5OfX1StTFlZOXPmfKxbQfPEEyNsenNSggwl6PDXkdGcqhGlrKyrTJgwgRs3btgsY/E/1+m2ly56lvCw4Gr7BUHgn+88rQvSun5LHKfPmZqO9OTWsBM1dXif/Px8pOnSTEAJfdFwZDgaOXT45pvN/PlnktkyxUU3mfPKJ5w5LaXjCgz04/77BzqVHg0dQRDs/nFhGkEUja+yEgThD8APWIMUJf+0nA2ryTmjDS0vr+Dpp98gPj4RgNDQpowbN5yIiDAyM2+wdu0OUlMlH5nIyHDWrPmg2goZa1CCDCXooHQZH330Hj17Sj8oFRUVLFmyhMzMTEJDmzJ79iS8vW8Nhgpj/7aG3/ae5GZpzeX23y6bxqOj7gDgRk4h//7+NxLPZtCksR9PPDyIPj2k3HhXs3IZNGoel64ad8q/eXEpUpywEqRRLnWlDiJPPz2L+PjjlTqEMm7cfURENG3wfeGsMkQzq2IvZWSydu1v1b5LSkpj9+4jAPTu3ZnevbtU23/Pvf3p3Lldte8EjP9o2vM8aUV1je9enLqEnTuPEBERyu23dyUqKoKgxv64uanIySng9Onz/LYjTmc0ubu78dHHs7n77tuNylAJxsNgNqS+ABDoIKsVM2jzAdOK1ZK9DwxwWWImMGmEgc6X6zFgHNJyp9XAGlEU02RpXTWMG2EA+flFTJ++hLi4k6aKEB3djmXL5hIWZj5fmJJlKEEHJcv49ttv6dfP9mmPDndM4+KlGzW+9/R0Z8U/XmDsg3eYPDY1LZPH/v4xCWdNJyiWjDDjqyzz8/OZPn06cXGmpzIbYl84qwxzP/yHD59i4oTXbWrT4iUzGDNmWLXvTBlhYL/zZM4Is4bw8ObMX/ACd9xhfKodTBth0HD6AuQ3wgb/bH8jbM9IlxFmCrNGWLWCgtANySAbC2SKojjAkQ2riWkjDKSh5a1b97Nx4y5Onz5Pbm4BgYF+REa2YsSIQYwZc5duFVhtUYIMJeigVBmTJ8+iR4+elg+6BVNGWBV3D+7GxHFD6NsjkmbBARQWl5J6IZP1W+L49393UXKzzGz9Ny8uQhoU90E/NSkgLXguQxQL2br1F0X1hbPKqG8jzB46gHEjLD+/iIMHTxB/NJGzZy+QkZFFXl4hoiji6+tNSEhTOnVqw51D+zBkSG88Pc0HIjZnhNlDD5cRZj0uI8w0VhlhgiCogGFIoSruBw6JojjawW27BfNGmAsXf0W8W73lcBk3Ly5wuAwX1mHuh99eWDLC7IExI8zeWDLC6oocfQHyG2FDttjfCPt9hMsIM4XZq1QQhFgkw+sh4BSSf9hLoijmmzvOhQsXLly4cNHwcPnRy4u5BN4ZSHlK1gDzRVGsU0wvR2M4tHzmzAVycvIJCvKnXbtwRo4cxOjRlofITb3ZaDQaUlMvkZCQDlyYYgAAIABJREFUQmJiCgkJKSSdvUBppTP01BcfY9q0xy220Zo3THvo4ej6zb0BynWuHH2eGooMS6NUda3/zJnzjJj2ITeSUim+no26tAz3Rl74BDcmOLINEbF9adYx0mpdM+KOk77/CHnplygrKMLTz4eAFiFMH3+P2bY0hL6QQ4ZS7gtbpgqdVw/TgZMLC4vZv+8PDh9O4PTpVNIvZlJcVIKPTyNCQ5vRs2dHxowZRteYqDrp4KLhY251ZISVOSJlwvGO+aaMi2nTlrBj+yGTx9nLsGgojvnmjDA5zlVDcaKubxl1qV+r1bJ48VesWvUzllwWwvv3ou/zT+FmxkenvKiEg5+s4FriOZvbooS+kEOGEnRoSDJEgwT1hny1Yj1Ll66mvLzCYjtGjRrMgrenGF35XIVAJ1nHpoZttf905M77XNORprDaMb/+sT5Exdixw4mICCUz8wbr1v1WbbnxDz98iJ+fj1EJpoyLqVMWsXPnYd3/gUH+BAX5k552RdpvB8PCnno4un5zRpijz5Wjz5NSZNS1/kWLVvDtt5t0/4f17EqzTlF4Nw6ktKCQ7OQLXDr8B6JWGg1o2a8Hd8z4m9G2aNRq9ixeyo2zqQD4BDem7dAB+DVvRklOHml7DlFwOdNoW5TQF3LIUIIODU2GKSNs3uvLdOEpwsOb0/+ObnTq2IbGjQPILygi7tBJtm8/pMtLOWBgd1aseBOVynjYTpcRpmzc5s+fX99tsJLs+ca+XbVqCz/8sA2Q3lzWrPmQ2NietG8fQc+enXjkkbs5dSqFixevkpNTgFqtYaBB8ldryMjIpGtMFBMmjGL27InMmjURX19vnbHRt28X+vXrarEec0aYo/WQ4zyB48+VHHooQUZd6r90KYuXX/4Hoiji5qYids5UOo++j6bt2xIYHkZwZBvC+/UgrEcXLh6MR6vWUHA5k7BeMXgHBdZoS8qvezi/6wAAjVuHM2zBbEK6dSYwPIym7dvSZsgdBN+4ZrQtSugLOWQoQYeGJ8O4rbJ791Ga3daEd96ZwmuvPcudd/aha9coIqNa0aVLJMOHD6Bfvy5s23aQigo1GRczCWtxG507G8/zKtBM1pUxq1Iz5ts7Yv6EyFau1T0maNAjYWq1htjYieTk5CMIAps3f0pUVESNI7Oz87jrrucoKSnF09ODvXu/NhoB2ZbVLuvX72Tua58AdR/dsbcejq7f1lVB9jpXjj5PSpFR1/r/979fmTdvGQDDhw8gYILp/vrz+/Wc2yKlkOkx8VGi7h1Sbb9Wo2Hz1LmUFRSBIHDve3MJbBlWo56ZrQNqtMXf37fB94UcMpSgQ0OUYWokLD+/iMBAP4ttWbVqCwvfWQFA7z7RrFq1yGg5uUfC7t5m/5GwHcNdI2GmMJe26FNBEJaa+sjZSFPExZ0gJ0daqNm/fzejNxNAcHAQ998fC0hD0YbTZc6Ao/VwnSfr9VCCjLrWn52tX/zcunVNg8kQ/xC9v4y6rGbU/muJ5yQDDGge3cGoAWaqLUroCzlkKEEHJcmwxgAD6QWniuRzzuN+rRJEu39cmMZcIu544JiZT71z4MAfuu3YWPNBLmNje+m29+1ziubrcLQervNkvR5KkFHX+oODg3TfpVX68pmiKFO/aDogrHmN/Zmnzui2Q7p1sqktSugLOWQoQQclybAWX19v3XapkbRj9YVKsP/HhWlMrhMWRfEbORtSG86d06daiY42v0y+Sxf9/uRk0yla6gNH6+E6T9broQQZda1/0KBeeHi4U1GhZseOQwzo0YOQrjUNqNwLF0mt9PXyC7mN0O5dapQpyNAbcY3btLKpLUVFN+ukhzW4+ts6XDLs/yxMTtaPfoWFGU8L5kL5WAwpLAhCM2AO0BloVPW9KIpDHdguq0hLu6zbbtHC/FLlkJCmuLmp0Gi0pKdfQRRFp8nu7mg9XOfJej2UIKOu9TdvHszs2ZNYsuQrNBote5csk1ZHdm6Pd+NAygoKuXHuvG51ZECLEAb83/OojMRUKryqHynzbRZsU1vKDKY3G2pfyCFDCTooSYa1/PjDdt324CG9zJSUF3PTYy7sjzXn+3vgDNAGWACkAUcd2CarKSws1m1bcsx0d3fTLTNWqzWUlJQ6tG224Gg9XOfJej2UIMMe9U+a9CAfffSy7g39yvFTnFi1jrhP/8Mf3/yPjEPH8PTzodffHueuhXPwDzX+g1ZRoh/N8vT3taktBZW+ZHXRwxKu/nYOHZQkwxqOHz/L+vW7APDy8mTSpFF2q9tFw8IaIyxYFMV/AxWiKO4RRfEZoN5HwYBqN4WXl6fF8oZliotvmikpL47Ww3WerNdDCTLsVf8999zBq68+i3eTIGOHUVZQRNLmHWQcMu0voy7VJwd38zCfcPnWtiihL+SQoQQdlCTDEtev5/LSzA/QVsbYmz7jcUJCmtqlbnvgcsyXF2synFaF/b0qCMII4ArQxHFNcuHCRX1z8eJVXnjhHVJSMvBtFkzfFybQvGtHvPz8KCsqIuvUWRLXbqEo6zpHl6+iMPMaMY89WN/NduHCqSkpKWXqlMVkZWUDMHhIb555xrnuG5cjvbxYMxK2UBCEQGAWMBv4CnjJoa2yEh8fnYtaNf8RUxiWMVyZUt84Wg/XebJeDyXIqGv9WVnZjB07m5SUDCIiQrlr0Rxax/bDOygQlbsb3kGBtI7tx12L5uDXXHqDP7tpO1f+SKhRt3sjfToWTYXlNC6GbVFCX8ghQwk6KEmGubqmvLCIkyeTAejZsxMffzzbaXxuXdQPFo0wURR/FkUxXxTFBFEU7xRFsZcoipssHScH/gY+Jrm5BWbLqtUaiopKAPDwcK92M9Y3jtbDdZ6s10MJMupa/+ef/6A7bubMp/DyM+7L5eXnS5dHH9D9n/Lr7zXKePjof7jKDfxxrGlLQIA+3lJD7Qs5ZChBByXJMEZ5eQXTXnyXuLhTAMTERLF8xRtO9XytQuWAjwvTWDw/giCsFAThP7d+5GicJVq3bqHbvnz5mpmSkJl5Q5erq1WrUKd6+3C0Hq7zZL0eSpBR1/r37InX7e/fv5vZ45t36ajbzkmtGXDS0GG/+Hq2TW1RQl/IIUMJOihJxq1UVKiZOeMD9u49DkDnzm1Z8dVbNue8dKFMrDFSfwa2VH52AgFAkdkjZKJ9e33cocTEFLNlExL0+6OizMcrkhtH6+E6T9broQQZda3/2rUc3XeWfigMR7qMRcwPCNdHyM+9YD7W0q1tUUJfyCFDCTooSYYharWGWbP+wa5dRyrlR/Dv/8y3Oqp+feAK1iov1kxHrjP4fA+MBXo7vmmWGThQH/F4//7jZssaRjw2jITsDDhaD9d5sl4PJcioa/2Ghldm5g2zxxff0I9ueRqZtgyJ0Qd5zTx5psZ+c21RQl/IIUMJOihJRhUajYZXXv6Y7b8eAiAyMpyVXy+wOs9lfSEIot0/LkxTm+naKMB8lDuZ6NcvhiZNAgE4ePBEtQjEhmRn5/HLL/sAacnxsGH9ZGujNThaD9d5sl4PJcioa/2Gb/1btuw1K8swPEWTtjVHC27r3B6vSt+urIQk8i8ZT4NkrC1K6As5ZChBByXJANBqtcydu4xfftkPQJs2LVj59dvVUoK5cAHW+YQVCoJQUPUBNiNF0K933N3dmDx5LACiKDJnzsfk51efKS0rK2fOnI918WGeeGKE072JOFoP13myXg8lyKhr/SNGDNaV+9e/fiAr4axROVkJZznz06+6/yMG9q1RRuXmRqcHh1PZGI7861vKK52dq9CUVxhtixL6Qg4ZStBBSTJEUeStNz9n40+7AYiICOXrb96hWbPGVtdRn7imI+VFEMWGMlR4zmhDy8srePrpN4iPTwQgNLQp48YNJyIijMzMG6xdu4PU1AxAGg5es+aDaitkDBExfi4uZWSydu1v1b5LSkpj925pnr9378707l09b9499/anc+d21b4TMH012lMPR9dv6jyB48+Vo8+TUmTUpf6KCjXjx7/CqVPSUnpBEAjr3Y2QmI54+vlSXlRM5smzXIk/QdXzI6RbZ2JfmWLUeVmjVrNn8VJunE0FwCe4MW2HDcSveTNu5uRy4fdDFFzONNoWJfSFHDKUoENDkyGiMVr/Rx99x/Iv1wHSqso5rz5NSIj5lF0AAwb0wNvbq8b3Ap1kNWPG7t5rd6PgxzsHuUwxE1g0wgRB2CmK4jBL3zke40YYQH5+EdOnLyEu7qTJo6Oj27Fs2VzCwkzPpJoyLg4fPsXECa/b0FZYvGQGY8ZUP0XmjDCwnx6Ort+cESbHuXL0eVKKjLrUn5tbwOzZ/7DoNwPQsl8P+jz/JB6NTC+3Ly8q4eAnK7iWeM7mtiihL+SQoQQdGpIMU0bYU0+9ztEjiTa36bedX9KyZfMa38tthD3mACNsjcsIM4lJI0wQhEaAD7AbGAK6X8UAYJsoih2NHugwTBthIA0Bb926n40bd3H69HlycwsIDPQjMrIVI0YMYsyYu3A3kmC4Wh31bISBffRwdP31bYSB48+TUmTUtf6DB/9kwddbyElJ42ZOHuqycty9PPFp2oTgyDa0HtSPph3amTz+1rZkxB0nff8R8tIyKCssxtPXm4CWoUx77B6zbVFCX8ghQwk6NBQZSjXCHv99j92NsP8OGewywkxgzgibAcwEwoDL6I2wAmCFKIrLZGmhDvNGmD0wZ1zYA2uMsIaAo88TKOdcKYE3jpkPLWEP3unlXOFQXLiwhCkjzN64jDBlYzJ3pCiKnwCfCIIwTRTFT2VskwsXLly4cOGiHnA50suLNQm8tYIgBImimAcgCEJjYLwoiv9ybNOqY2r0RaPRkJp6iYSEFBITU0hISCHp7AVKS6XAkVNffIxp0x63SoYtU2BnzlwgJyefoCB/2rULZ+TIQYwebd8hckfIsEf9omj8DVAURf744yynTqWQcCqF1POXyM3JJze3EEGAwEB/2rdvxeDBvXlg1GACAkw71AqC+UtTCX1hDxla0XI+RmP87dm3OXDgT93/ixe/yOgxQ42WtTRKdasOeXmFdOvWlUGDBjBkyEAiI6OQvBuqFmNnV370tB+4q9r/o+/rwHuv32mrWhz+4wpPTTOeVe303v6AGwKNEYQABBoBVedWjchNRLGAY8cP8cuW/Rw9cppr13MoKy2nSZNAQkKD6d27E7GDetKrV01vDDeVaZ84ez2nlPKMkuN5bgp7yRBFba3k23LvAThR0hIXDsAaI+w5URQ/q/pHFMVcQRCeA2Q1wkwxc+b77Nh+yOFyTDlyXr+ey/XrucTFnWT16q0OcRa1lwxH119eXsETj881ub+0NJusrGz27fuDf/3rB95+Z0qtYpEpoS/kkmGMnzbsrvYjUBeM6bB06VLuvfdeu9RvKxlXTOcDFPBHJYQjCB5G9nqSm1PE/Pkf8Ouvv9bYe/XqDa5evcEfx5PYu/cP1m/4wKZ2yfGcUsI1K8d5kus3wxj2vPcchSvXo7xYY4S5CYIgiJXOY4IguAGejm2W9Wg11d9GAoP8CQryJz3NeFDI2lBeXsGUKQurLWkeO3Y4ERGhZGbeYN2630hNzSAxMZXnnpvPDz98aHNeMEfLkEOHKpo3DyYmJooOHVoTFtYMX19vbpaWceH8JbZtO0h6+lVycgqYMf19vlz+BgMGdHcqPZQiwxjZ2Xm8++5KAHx8GuliIdUGUzp069ahWrnc3FxKSopp0aKl1XXHHb/MlNe2WSynEgQ+eHMo3o0kw2r9FuMxzWI63YZKaI0gSD8xoliGVswFygGB7Owinnl6NsnJUqqadu3aMnRYdyJah+Dj04j8vEKSkzPYt+8Pq3UwxNHPKaVcs3I8z+WQYQx73nsulIM1Rtg24AdBEL6s/P/5yu+cgq4xUbRt15Lo6Ei6RLejZXgI69fvZO5rn9hNxurVW3UPnujodqxcubBa7q8nnxzJlCmL2L//OCkpGXz22RrmzHnGqWTIoYOHhzubf15KZGS4yTLTpo9n4cKvWLN6GxqNlsWLvmLLL9av8VBCX8glwxgLF35Ffn4RnTq3ITKyFZs37al1XaZ18ANyqKgoYt68D/npp18ZPXo07777rtV1X80q4mqW5RS1sf3CdQbYhYw84k9mGi036/m+OgNMK+agFTN0+0RR5KWZ80lOTsHNzY25c+fy+OOPg5CNVqz5w3z1qvlUTsZw9HNKKdesHM9zOWQYw573niNx+YTJizUjj3OAXcALlZ+dwMuObJQtTJ48llmzJjJ8+ABahofYvX61WsMXX/wISEEr33vvpRrJV728PHn//Zfw8ZF8Qlat+pncXNPTInLLkEMHAJVKZdYAAyp/5J4lKMgfgPPnL5ORYfyHsz70UIoMY+zadYRtWw+iUql4e8ELuKlqP/FgXocc4AYeHqW88sqTOh0cwcMj9L5ZG35JMlrGw0NFn+5SInFRFNGKl6vt//GHHcTHS3ktZ788iSeffBKVSoWAcZ/F0NCmNrfTkc8pJV2zjn6eyyXjVux57zkalSDa/ePCNNYk8NaKoviFKIqPiKL4CHAa+MusloyLO0FOTj4A/ft3Iyoqwmi54OAg7r8/FpCG7XfuPOw0MuTQwRY8PNyJiAjV/X/jep5VxymhL+SScStFRSW8vWA5AE88cR9dukbWui6onQ72JtDfi2EDJLlqtZYNW40Hgm0c0Ah396pHnRrQT0eJosjXK38GILxVc5586h6DI533h9IQpV6zSsHe954LZWHVU0YQhB6CILwvCEIa8DZg3PFCgRw4oPcBiY3tabZsbGwv3fa+fcfMlJRXhhw62IJWq+Xyleu6/5s2sy6prRL6Qi4Zt/LhB9+SlZVDSEgwM2bUbXUZ1F4HezLqnii8vCSPigNHL5F1o9houbzCMirUVSt63TB87B2LP8PFi9JI7IgRA1EZrHAUKXNIu+2NUq9ZpWDve8/RuHJHyotJnzBBENoD4ys/N4AfkIK72r5uvAFz7pw+UGV0tPk3mC5d9PuTk60PcOloGXLoYC2iKPLJP//Ljeu5AHTq1IZwK6cElNAXcskw5OjRRH78cQcA8954Dl8/71rVY4itOvz+u/Gpwrow5n79AoC1JhzyAcrLNew/fIk7B0QgCCpUhKEVLwHopiEBunaNAjGUdevWsX79elJSzlFScpPg4EC692jP6DF3MmBAN7vrUVeUeM0qBUfcey6UhTnH/LPAPmCkKIopAIIgvGSrAEEQfIHHgTuAql/bTOAAsFoUReOvr05CWpref6RFC/NLrkNCmuLmpkKj0ZKefgVRFI0mNJZbhhw6GGPfvuOUlUlxrEpvlpF+8Sq/7Yjj7Nk0AIKC/Hln4VSr61NCX8glo4qysnLefONzRFHkrrv7MWxYX6uPNYetOqgMXoclHeomv2NkMNEdmgGQk3uTXfvTzJZf/OlBhtwRhiB4oBKCEfBDK+aSmKh30Pfzbc+Ep17g2LHqozdV4Sm2/nKQe+69ncVLphpNtFxfKO2aVQqOuvccTcOYhFcO5oywMcBjwG5BELYBa8C2XDKCIHQGdgD+wF6gaqlRc+AfwHxBEO4RRfG0rQ2Xi8JCvY3YuHGA2bLu7m74+fmQn1+EWq2hpKQUX1/Lbz6OliGHDsaY+9qn3LhR09/Lw8OdoUP7MPvliUZzpZlCCX0hl4wqPlv2I2lpV/D19WbevL9ZfZwlbNXBy0tvtFRUqPGsY5AbQ4f8TTuSqVCbD5yZfikfjZiMinAE/BAEL9yEELINpjDfeutt0tLSCAjw5eFHhtKxUxvUajXHjp5h0+a9qCs0bP81jooKNcs+e6VuCtgRpV2zSsFR956jcTnSy4u5tEU/AT9VjmQ9iJRH8jZBED4HNoiiuN2K+j8D9gMTRVGsFhSlMkH415VlnHaK0zCWi5eX5V8OwzLFxTetevg4WoYcOthC27Yt6d+/G02aBNp0nBL6Qi4ZAGfOXGDlyo0AzJz5OM2bB1t1nDXYqoOHhz6Cel2NMA93FaPu1k95rTMzFVmdCrTiFVRCCALStVdQoF+9l5aWRkREK77+Zim3Ndc78D/00BAeHXc3zz37DkVFN9m9K56tvxzkvvvvqL0SdkRJ16xScOS950JZWLM6slgUxf+KovgA0BL4AylshTX0AxbcaoBV1lsKLKws40KB7Nu/kjNnN3D6zHqOxn/Pf/+7hMfGDycl5SLz53/BuHGvcPHi1fpupiLRaDTMe/0z1GoNXbtG8vgT99V3k+zG0IGtaRwk/aifOnuNpNQci8e4uQmohBa4qzogEIBWvIZaexattvqjacmSdwkL7YSbEInhO2pMTCTTZ47X/b/qu1/so4wLxdHQ7z2XY7682DT9K4piriiKy0VRHGblIblAezP7oyrLOC2GMY7KysotljcsY+3bn6NlyKGDOQRBwM/Phx49O/LWW8/zxRfzcHNTkZKcwbPPLLA6crQS+kIuGStXbuL06fO4u7vx9jsvoLJzXCJbdaio0Ocb9fCwJka0aR4xmIpct8U6h//3Xh+KSpDie2nFNLTiVaAMX1+9Hu3ataRHTylPpiB4oxJaVKtj9OghuFeO6J06lUJxsXNEPFfKNasUHH3vuVAWjr46VgDfCILwqiAIvQRBaFn56SUIwqvAf4AvTR0sCMLfBUGIFwQhfvnyHxzcVOP4++sDNloKPKhWaygqKgGkHxprg1Q6WoYcOtjCwNgePDRaSlh76VIWGzf+btVxSugLOWSkp1/ls2XS/TJh4gN07NjGqnbZgq06lJXpwz3UxQi7LdiHAX2k9EelZWo270i2eExMp9sYdU8UAFqxABF9e/0NkshHR7dFK15FFNUAlVOW+rb6+DSiTWsp6KtGo+XK5Wu11sOeKOGaVQpy3HuOxjUSJi91eyW1gCiK8wVBuAnMABYDVR5/AtIKySWiKL5v5vjlwHIAkaR68RZs3boFly5lAXD58jWzjuSZmTfQVOYla9Uq1OoVQY6WIYcOthI7sAfr1v4GwJEjCYwfP9ziMUroCzlk/Lx5L6Wl5QiCgLubis8//5/Rcknn0nTbu3fHk5mVDcCAAd2JiYmyqw5arf72rcs1Nfq+DrrAqzv2XqCwyPKozJD+rXTbolg9FVLr1mEcjksAwM/fBxARKUEgAEEQEESfakabVEaisNLQqG+UcM0qBTnuPUfjGreTF4caYQCiKL4HvCcIQhsMQlSIonjB0bLtQfv2rdi//zgAiYkp9OvX1WTZhIQU3XZUVCuT5eSWIYcOtmI4RVFYYF2UEiX0hRwyRFHU/V2+fL1Vx+zYEceOHXGANOJj6YegtjrUldEGscGsdci/ralh+iFNtX0dOujPaVFhiZEy1X+S9GXA3w4J1e2BEq5ZpSDHvedCWchm9IqieEEUxUOVnwsAgiCEC4LwH7naUBsGDtRHh656CJnCMDq0LVHCHS1DDh1sJd3AId/SkvcqlNAXcslwNLXVoS70igmhbSspu8Klq4UcjL9s4QiJohL9aJkgeFTbFxvbQ7edmHheKoPh6j+1bqukpJQLaVKUHXcPN1q0NB8vSy5c16wLe+LKHSkvDh8Js0ATYCLwTD23wyT9+sXQpEkgOTn5HDx4guTkdKN507Kz8/jll32AtDx72DDrF306WoYcOtiCVqtl3bqduv+79+hgprQeJfSFHDJenPYYL057zGK51179lJ9+2g3A4sUvMnrMUIfpcO+9dV8hZhghf8NW6yPwnzuvXz0pEARk6f4Pa9GM7t3b8+ef50hNvcTx4yn06RUDSKMZIjf1Mjf8jrpygUHPnh2dxtdJCdesUpDj3nOhLBw6EiYIwgRzH+ABR8q3B+7ubkyePBaQHspz5nxMfn51v5KysnLmzPlYt8rviSdGWD26I4cMOXQA+Oabzfz5p/kfx+Kim8x55RPOnJZGHQID/bj//oFOo4dSZDia2uhQF7wbuXPf0HYAaLWiDbHBYPeBdIpLpMwNgtCoxqrHaTP0P5rz5n7OtWuSw71IIVVTk6dOpbD0n6t15Z55ZlSt9HAErmvWhT1xOebLi6NHwr4GStA75N9KnY3ASxmZrK108K4iKSlNt3047iSaW6Jp33Nvfzp3bme1jPHj72P79oPExyeSmJjKgw9OY9y44UREhJGZeYO1a3eQmiqlP4mMDGfKlHE26+FoGXLocPRIAu8u+Q8REaHcfntXoqIiCGrsj5ubipycAk6fPs9vO+J0D293dzfeWTjVpge1EvpCLhmOxpQOHTu2p3HjcM6evUCvXoPo1WsQPXsa5lz0BqoHr+wUFcyZ5GyTsobf2Q4/H2maMO74Za5kFZkseyu5+aV8vOII82YMAEAlNEXAF62YB5TR//aBPDb+Idas/on09AxGjhzJo48+QodOjVFXlHIs/gwbN+3RjYI98ugwYgf1MCOxJo5+TinlmpXjeS6HDBcurEWociR0SOWCcAmYLoqiUQ9FQRC6A8dEUXQztt8QU6sjDx8+xcQJr9vUrsVLZjBmTM1QZ4KZrEz5+UVMn76EuLiTJstER7dj2bK5hIXVzlfE0TLsVb9WVBv9/sWpS9i584hVbQkPb878BS9wxx3GEyKrBNPvB0roC3vJ0IoVtZIN1k+JqG7xozLEmA59+/blu+++s6ktcxbtNjvF+P2yUfTpLoWH+L8Fv/HzDtud/c/sHSVFyxdqvvtptVoWLVrE999/j7ln4hNPDmfOq5Nwc6tZh5vK9PSkvZ5TSnlGiSbey+35PDeFvWSIJp6D1mDLdKRKiJZ1LGn24V12Nwo+7DfUNR5mAkePhB0DegKmlomI2JiPsr4IDPTj668XsnXrfjZu3MXp0+fJzS0gMNCPyMhWjBgxiDFj7sLd3aI9WW8yHF3/osXTGHHwBPFHEzl79gIZGVnk5RUiiiK+vt6EhDSlU6c23Dm0D0OG9MbT0/SPe33qoSQZjsaYDvZub6sWAToDLL+wjO17arewWuQ6GjEPFU0Q8AM+nEHnAAAgAElEQVS8AKmtgqDm9XnTGTGiL2vXbeTokUSuX5fiSN92WxN69+nEY4/dQ+fotvZQySG4rlkX9sA1fSgvjh4JiwX8RFHcamK/L9BbFMU9luqSI06YubdMF3pMjYTZE3MjYS701GUkzFrMjYTZi/YDdzlcxum9/R1av7mRMHuhlGeUqZGwhkRdRsJsQe6RsFeO2H8k7P2+rpEwUzg6WOs+C/uLAYsGmAsXLly4cOHC8QiukBKy0mCGGyy9AYqiqBsiP3PmAjk5+QQF+dOuXTgjRw5i9Oi6D5ErQUZt69doNKSmXiIhIZk/T53kdGI6yUkZlJZKIzF/nzKSyVPNrxjbtOEg8+d9bXOb+/btwnffLbGLHtXqMPE2rtc1hcTEFBISUkg6e4HSUine1NQXH2PatMctttuaUYu66mHMv6mKwsJi9u/7g8OHEzh9OpX0i5kUF5Xg49OI0NBm9OzZkTFjhtHVQnBI8ZYAp/auHyBhb2+LZZKSLvK/NTuJP3qGa9dyadUqgn639+GOO/oRExNDgH8wgiCdK414BY14pdrxHfrsNll3RMtAxo3uSr/eLWkdHoSvrwelpWqu3SjmZGIWP/+axO8H0sy2L+XY05WpjmoiXVOpJCQkkJiYSEJCAmfPnrb5mjLVF2Df/nB0/QIW7k073N8a0fiq3IlPvcXRo6ctthEgLKwZv+36l9F9KsHLtGw7PUNcKJ8GY4SZw5Sz6PXruVy/nktc3ElWr97qEIfUhiSjLvXPnPke27cfsl0pO9CyZUi1/x19nmbOfJ8dMujqSD2+WrGepUtXU15ec7qyoKCYgoJikpLSWL16G6NGDWbB21Pw9jb9oyJ3/Yao1Rr+8cF/WfXtNt13S5cu5d57761Vfbfy/KTezJzcH0+P6j/qHn5u+Pt50a51E0aP6MTBIxd5cc4W8gvKTNRkmpkzZ7J9+3a7tNcYSupvOZ61jkauZ4gjcPmEyUuDN8LKyyuYMmUh8fGJAISGNmXs2OFERISSmXmDdet+IzU1g8TEVJ57bj4//PAhfjamG1GCjLrWX5ULrorAQF8Cg3y5mG59EuM+/Trwj6UvWCyn1Yq88ep/dG+NDz98l930sAbtrboG+RMU5E962hUTR9iOo/VIS7ui+8EMD29O/zu60aljGxo3DiC/oIi4QyfZvv0QGo2WTZv2kJ2Tz4oVb6JSWRc1xtH1G/LO/P+wft3vgBSpfuQDA+nStXq4gNzcXPLy8mjTxraEyZPG9+CVafo4dYePXeL3/Re4mlVEQIAX0R2a8dD9nfDycueOvq346pOHGPfsj9VyYRpDJBPD9EcaTfXUXIFBAQQF+dntmlJKf8txfxuydNnLZvd7N6qdISnHM8RRuHJHykuDN8JWr96qu2Gjo9uxcuVCAgP9dPuffHIkU6YsYv/+46SkZPDZZ2uYM8e2AP1KkFHX+mNi2tOuXTjR0ZG07RhAi5ZNbZ5eDA0LJjQs2GK5A/sSdAZY69Zh9O4dbTc9rKFrTBRt27UkOjqSLtHtaBkewvr1O5n72ic21WMOR+shCAKDh/Tm2Wcfom/fLjX2jxt3L/Hxifz9uXcoKSnlwP4/2bBhNw8/bN1Sf0fXX8W+vX/qDDBf30Z8tXIuXbq2Q0UjNOJVtGIJJSXZTJm6kIhWnXn33XetrrtRI3deekHvrD9nwXbWbqo5TfWv/xxlzVePEtrcn54xoQwb1JYdv6daqL0Yw5RHXWPa0LZdiMOuKaX0txz3tyF33dW31seaQ45niAtl0KCNXrVawxdf/AhID4n33nup2g0LUuqM999/SZdiZNWqn8nNLfhLybBH/ZMnj2XWrIkMHz6AFi2bWq1bbdi04YBue/Ro/UNcjr6A6rq2DA+xfICNyKHH7Jcn8uWX84z+YFbRu3c0/zfrKd3/GzZYv0LR0fVX8f2qX3Xb018apxsB05KJRryMSC7ePire+3Aqbm766URrVn33jAnFz1cKAHsiIdOoAQZw6UoBX34dr/u/d48wm/Vw9DWlhP6W6/6WA0f3tyNx5Y6UlwZthMXFnSAnJx+A/v27Gc1lBhAcHMT998cC0nD3zp2H/1Iy5NDBXuTnFbNn9wkA3NxU1YywhqSHOeTQ49YfL1MMHz5At518Lt1p6gcpgOqxo1J6IkEQGDFygMmyISHBtG2nN46uXjUdfb+K4Cb6aay0jDyzZS9czNVt+zRyfMgOW1FCfyvl/nbhwhYatBF24MAfuu3Y2J5my8bG9tJt79t37C8lQw4d7MXWLYcpL5emcQYM6EHz5vrpy4akhzmcSQ9fX2/ddtUUsLPUn5dXpDumSXAAgYG+Zss3bapfmXgxPdNi/dnZJbrt1uFBZssa7k9NyzFT0rlx5v52pvvir4wrd6S8NGifsHPnLuq2o6MjzZbt0kW/Pzn5opmSypMhhw72wnAq8uGH7662ryHpYQ5n0iM5WT9aERbWzKnqr0sg6ezsfKCJ2TLxJ66QnVtCcGMfunUJ4eEHOrNuc80pyRahAUx+ug8AOXk3+ekXa5KHhwCeSBH5RST/sJtAQeXf+sGZ+7s+7ovJzy/m9OkL5OUV4uvjTUhoML16deLhR4bSqZNtizyUgstokpcGbYSlpV3WbbdoYX6pckhIU9zcVGg0WtLTryCKIoJg+WpTggw5dLAH585mcPaMlAC4ceMAhg6t7jTbUPSwhDPp8eMP+rAJg4f0MlNS/voDA/1w93BDXaEhN6eAgoJiAgJMj4bduJGv287LtZzgu7xcw5tLdvHPxffh4e7G+/Pv4eEHOrN73wWuZhUSENCILh31qyOvZhUy5eWfycs3Hn/KEIFb2+mGlCYpCJEi4KrFOhyBM/d3fdwXe/foR9/y84vIzy8i6Ww6//1+G6PH3Mkbbz5Lo1qukHThwhoatBFWWKhf9t24cYDZsu7ubvj5+ZCfX4RaraGkpLTa0LmSZcihgz3YaDAK9sADQ2rklmwoeljCWfQ4fvws69dLztNeXp5MmmQ+2K7c9bu7uxETE8nxY0lotSJbNh9g/BP3GC2blZXD+VT98n9j8ayMsW1nCs+8+BNvvjKEqLbB9OvVkn69WlYrU1xSzj8+3svaTYkWY4RJwVRLgFKgqg3ugK/OMBPwQ6QVcqfNdfb+lvO+CAryZ8DAbkRHt+W225ogiiKXL19nz+/H+OMPKZH8hvW7uXr1BstXvP6XyoX519HUOWjQRlhJif6N1MvL02J5wzLFxTetummVIEMOHepKRbmarT/rHWwNY4NV0RD0sAZn0OP69VxemvkBWq0Uz2j6jMcJCbHfqld71f/wI3dy/Jj0o7j0nz8S0z2K6Ojq00QlxaW8+vK/CG/ZUfedtUYYwKH4DN75cA/zZg2mfbuaIVR8fTx55omeuKkEln9rzv8oF8gCo5kYchHxBsIQcEfAC/C3uo11pSH0t1z3xUv/9zjRXdrh4VHz5+/vz4/mtx2HmfPKp9y8WUbcoVN89dVPTJ78sFV1u3BhKw3aCHOhHPbsPkFenvQm3Ck6go4d/5r+GHJQUlLK1CmLycqSVhAOHtKbZ5550CnrH/HAADZt3MfhuESKim7y1Pj5jHxgAL36dMTL04Pz56+wYf0eMq9m0y1GP31t7dRUcGNvlr0/gr49W5KdU8Kb7+5i174LXL9RjL+fJ316tGDac7fTuUMz5syIpUNUU2a/+SvG3dUsRdK/CVxBJLwypZU8LwUNqb/loHuPDmb333V3Pxa8Xc4rLy8FYOW/N/HMM6NqjMwrFVdICXlp0Ksjq2LFAJSVWV6JY1jG2rcmJciQQ4e6YjgV+eBo46EIGoIe1lCfepSVlTPlhUWcPJkMQM+enfj449l28zOzd/1ubio++mQGA2O7AVBRoWbD+j3Me+1LXp61jM8/W0/m1Wyiu7TlwdGDdMd5eVn+wfRu5M6arx6lb8+W5OTdZMzENXz/v5NczSxErdaSm1fK9t2pPDxpDcdPSFOdD93fiSceiamVLhI3kaYrrcstWlcaUn870/098oFY2rSRQp4UFpZw/Lg1izFcuLCdBm2E+fvrnV8tBexTqzUUFUkPPw8P92o3vNJlyKFDXbh+LY+4g9KqNC8vD+4bYTyKtbPrYS31pUd5eQXTXnyXuLhTAMTERLF8xRt2OzeOqj8gwJfPl7/Csn/N4u57+9I8pAmenh74B/jQrXsUc+dNZNXq+Rj+7lsj86mx3WjbWlpBueLbY1y6Yrwvyss1LPpor+7/CY91r5M+VUaYo2lo/e1s93efvvpMHRfOO3+6IXvhClEhLw16OrJ16xZcupQFwOXL12jZsrnJspmZN3T5D1u1CrX6TU0JMuTQoS5s3nhIJ/POYT3wDzCeC87Z9bCW+tCjokLNzBkfsHfvcQA6d27Liq/eqlPePTnrBxh8Z08G32k6ftS1rGu0r4xc0Oy2xhbrGzJQP+V98LD5MAd/JmRSVFyOn68n7Vo3wc/Xk6Li2sbZ0lguUkcaYn872/0dFKQPUFtQUGympLJwGU3y0qBHwtq3b6XbTkxMMVs2IUG/PyqqlZmSypMhhw51YfNPB3XbD465w2Q5Z9fDWuTWQ63WMGvWP9i160il/Aj+/Z/5VkdBr+/6rSUtTR/2ITTMslN482b6kRdrDCrDMt7edXl/dez6s4ba3852f+fl6cOcmAuN4sJFXWjQRtjAgfq34v37j5staxhV2TDa8l9Bhhw61JY/jiWTnia9/YaGBdP39k4myzqzHrYgpx4ajYZXXv6Y7b8eAiAyMpyVXy+wGALAWeq3ltzcQpLO6kez2ra1nN/R0KgKDTFvQHh5udGksd7vKD/fkhO+ORznn9iQ+9vZ7u/4o/rAvRGtQx0iwxlxE+z/cWGaBm2E9esXQ5MmUqqSgwdPVIvWbEh2dh6//LIPkJY1DxvW7y8lQw4dassmg1GwBx7qb3ZawZn1sAW59NBqtcydu4xfftkPQJs2LVj59dsEB5tP0eMs9dvCh+99T0WFWve/sfADt3IuVZ9fcuQ95lfMDR8ahaeHNIJ1Nvk65RW1nVL0hsp4YaLRUBa1p6H3tzPd31t+3s/581LwWF9fb3r16mjhCBcuakeDNsLc3d2YPHksIKU4mTPnY/Lzq0fKLisrZ86cj3UxaJ54YoRNb21KkCGHDrXhZkkZO7bFA1JIgVEmVkVW4ax62IoceoiiyFtvfs7Gn3YDEBERytffvEOzZpZ9pZyhfkNO/JlsMu5XeXkF77+7ik0b99lc7+ZtSbrtRx+M5sH7jP/QdohsyrzZg3X//7Sl5kq50SM6AZb8oarihFW9aFiOvG8tSuhvOe6L7779hRMnks2W+e23I7z5xhe6/yc9/YBVccuUgssxX16EuuRnk5dzRhtaXl7B00+/QXx8IgChoU0ZN244ERFhZGbeYO3aHaSmSqlwIiPDWbPmg2qrcKxBCTLqWn9GRiZr1+4AoEIrPRiTz11i7+8nAejRK4qevaKqyRx2T086djLtr7Fpw0Hmz/sagL63d+SLf/+fbp+vu/Hhf3ueJ1MjEZcyMlm79rdq3yUlpbF7t+QD07t3Z3r37lJt/z339qdz53bVvjMXgsBeeogmnLw/+ug7ln+5DpBGhea8+jQhITUDkd7KgAE98Pa2nKbF3vVXaE07Pk+d/AF//plM7KDudO3alqbNGqNSeREUEMGF81coLJRWyXWN6cLAAbEAaMVCRAqr1fPQE7s5nXS92neffziSe+7U5yHceyid3fvOc+1GMX6+nvTr1ZIRd7fHy0saWTuddJ1Hnl5DWVn18z5v1mCefrwHIhVAMVLMsKoy7lzKyGPt2i0GR2hISjph8zUFWqPnqKH1t2DCL86e97dGrGnkvjj1fXbtPEqbNmHc3r8rkZHhBAX5IYrSYoDfd+sj5gP06xfNlyteNxojTCWYPm/2eoYACHSQ1Yz5JHG73Y2CGdH3uEwxEzR4IwyknF/Tpy8hLu6kyaOjo9uxbNlcwsLM5yRTsoy61H/48CkmTJhrk7z5CycxarRpR/tnJ3zAH8ekt9JF7z3LfSP10wqmjDCw33kyZYQdPnyKiRNeN3mcMRYvmcGYMcOqfWcpDpQ99DBlhD311OscPZJoodU1+W3nl2ZXpTmqfktG2N49f1b7rm/fvnz33Xc2yX5l/vYaCbq9vNxY9PpdlSNZ5jl0NIMZc7eSnVMzxESVEWaKw4cPM2HCBJvaa+yaMmWENbT+NmWEgf3ub3NGmCUEQeCRR4fx6muTTBqp5owwez1DwGWEKZ0GHaKiisBAP77+eiFbt+5n48ZdnD59ntzcAgID/YiMbMWIEYMYM+auOuX/UoIMOXSwlovp13QGmH+AD0PvNh164FacSY+6oBQ9HM3UaY/QpWtb4o+e5fKl62Rn59tteqisTMPsN3/l2x/+ZMzIzvSMCaVlWAC+Pp6Ulqm5dr2IEwmZbP71HHsOppmsZ8W38Ux6PARoVPlxq/yoAA2ixWj6Lqpw5H3xypwJDBnSixMnzpF0Np3snHzycgtRqzUEBPgS0TqUnj07MmbMnbRuY3lxhxJxTR/KiyJGwlzIS7H6quVCdcTcSJi9sLdj9K3IERHd1EhYQ8PcSJi96NRnv0PrTzl2n0PrlzA+EtbQMDcSZi+MjYTZE3MjYfZE7pGwT0/bfyRsWmfXSJgpFDES5sKFCxcuXLioO3/tcXf5UYwRJoqibvj6zJkL5OTkExTkT7t24YwcOYjRo2s3fC2KIsePn+HUqWROnUrm/PkMcnIKyM0tQBAgMNCf9u0jGDKkD6NGDSEgoG4BCx2lh1z1azRaLpy/yumEdM6cTud0YjrJSRmUlkqr2/4+ZSSTp46qdf1y6VFF0tkLrFmzjaNHE7h69QZqtYZmzRrTvXtHHho9lIEDTfsBOZMet/Lss/M5sF/vZ7V4yTSj/ijWIOlwgI0bf+dsNR1aMmLkIEaPHlprHQoLSziw/yRHD5/mzJk0LqZnUVx8E28fL0JDm9KjR3seGjOILl1rOjRb2XjQZiJoriForyNoc0G8CWIpKpUb7SI70qVrH6K79KJLl450an8b3o0kJ+1Pvoxj6fI4CwICELB9VFekBMgwsscDaZWlN9K0pzvVpj3FcrZu3czGjT9z9kyqXfsCpDhhqamXSEhIITExlYSEVJLOXqC0VIq5NvXFcUybNt7isacTL5CQkMxZg2NffHE806Y9brENpaVlHDx4gri4E5w6lUxa2hUKC4vx9PSgefNgunfvwKhRd9L3duNhRzQaDedTL5OQkEpi4nkSE1JJSkrXtWPK1Ed5cdrY2pyeGujv79233Bvhlf0xzOncDVzTkfKiiOlIezlyakV1je/Kysrp3m2cVS1s0iSAt9+ZYjJujUowb/M6s2O+Ieam8aZNW8KO7YdM7p/64mNWPWjNTeXZS49yren8dGq1hn988F9WfbvNbDuH33c7C5c8b9RHyVNlfum8PfTQisZDN5jjpw27ee21T6t9t3jxi4weM9RoeZVgOhm2/a6pmtOqX61Yz9Klq02GpzBk1KjBLHh7itmVfsaedebu76VLl3Lvvfeaqe86IvrVlh3uqXndj7knivdeHlTje0us3XaO1/5RM+xG8o5HAePXVX5+PtOnTycuzrRhWJ/3t6VjJ095iBdeHG1yP8CWzQdZuOAbXYgKc8TG9uS991/SxR6zth32eEaBPZ/n7WU1i744Y//pyMmdXNORpmjwI2Hl5RVMmbKw2pLmsWOHExERSmbmDdat+43U1AwSE1N57rn5/PDDh7XKb9a8eTAxMVF06NCasLBm+Pp6c7O0jAvnL7Ft20HS06+Sk1PAjOnv8+XyNxgwwLYkv47WQ67zpNVU91kJDPInKMif9DT7JMCVS4935v+H9et+B8Ddw42RDwykV+8OeHl6cv78Zdav+51rWbls2xpHebmaf34606b8dXLpcSvZ2Xm8++5KQEpybc2PWX3pkJZ2RWeAhYc3p/8d3ejUsQ2NGweQX1BE3KGTbN8u5R3dtGkP2Tn5rFjxJiqV7eEPjd3fXWOqh1zJzc0lPz+f1q1bW13voT+u8MJbv1ksp1LBh3OG4N1IeiSv+/WcmdJapBhjZUA5oKnsi5eJjz8BQGhoKGPHjiUi4jYyM1Oc4v6ucWygL4FBflxMz7Ja/uXL13XXbLNmQdx+RzTRXdrQpEkAN2+WcfzYObb9EkdZWQX79h3n6UlvsOaHD6oZ545+RkH93d/2QCU0lIEZZdDgjbDVq7fqLvTo6HasXLmwWg6zJ58cyZQpi9i//zgpKRl89tka5sx5xur6PTzc2fzzUiIjw02WmTZ9PAsXfsWa1dvQaLQsXvQVW35Z5lR6OLr+KrrGRNG2XUuioyPpEt2OluEhrF+/k7mvfWJzXfWlx769f+oMMF/fRny1cm6N6a5Jz4xgyvMfcPxYErt2xrN5435GPRTrVHoYY+HCr8jPL6JT5zZERrZi86Y9ta7L0ToIgsDgIb159tmH6Nu3S43948bdS3x8In9/7h1KSko5sP9PNmzYzcMPWz+tav7+9kMUb6DRFvPpp1/zxef/ZfTo0bz77rtW13/1ejFXr1tedBDbu4XOALtwKZ/4BFOGSTaQBbeMVq1evUlngEVHR7Fy5XcEBlYFUr3oFPe34bFRnZrRsmUzNm7Yx5uvf2VTG7r3jOKZv41kYGwMbm7VDe6Hxgxi4tP38fyz73P9eh5JSWmsWLGO6dP1I1uOfkZB/d3fLhoeDTpivlqt4YsvfgSkB/Z7771UI4msl5cn77//Ej4+jQBYtepncnNNT0PdikqlMmuAAbi5uTF37rMEBfkDcP78ZTIyMp1GDznOUxWTJ49l1qyJDB8+gJbhITYfbw659Ph+1a+67ekvjTPqb+Tr6817H07VpcdZtvR/Rqe76lOPW9m16wjbth5EpVLx9oIXcKvFiFEVcugw++WJfPnlPKMGWBW9e0fzf7Oe0v2/YcMuW9SwcH/fQOQaKlUxU6aM1t3fjuCR4e112+u3m4voXsGtBljNvphBYLUZOF+nuL+rHduymc2yAR4bfxffrJrH4CHdaxhgVbSLbMEbC57W/f/Thp2m22HnZxTU3/1tL1y5I+WlQRthcXEnyMnJB6B//25ERUUYLRccHMT990ujFOXlFezcedjubfHwcCciQu+Ae+N6ntXHOloPZzpPdUEOPbRaLceOSmlpBEFgxEjTqZRCQoLpe3tnAK5ezeb4sSSTZeXW41aKikp4e8FyAJ544j66dI20cIR55NDh1h8uUwwfru+j5HPG8w3WlVvvb3sS6O/JsP5SZgm1RssGs0ZYTYz3RblBCcnx29nvb2sICLQuS8jA2BidgXPlynWKimoG2HUUSnneupCHBm2EHTjwh247NtZ8sM/Y2F667X37jtm9LVqtlstX9E66TZtZn9TW0Xo403mqC3LokZdXpFsl1SQ4gEALD/3WrfU/zPv2/mmmpJ766I8PP/iWrKwcQkKCmTHDstOxJZzpmvL19dZtV/Wdvbn1/rYno4ZG4uUpjajuP3aZrGzbDAbjfWG4mEJjsN9572974uamolEjvR9Yaal8wXKd6d6oDa7ckfLSoH3Czp27qNuOjjb/Zt+li35/cvJFMyVtRxRFPvnnf7lxPReATp3aEG7DMLej9XCW81RX5NCjLquFk88ZCylQE7n74+jRRH78Ucr7Oe+N5/D187ZwhGWc6ZpKTtaPfoWF1W6ayxy33t/25uF79QsA1m0z55BvnJp94QVUvQSKgD4JtjPf3/YkO7tANxrl7e1VY4WkI3Gme6M2uIwmeWnQRlha2mXddosW5kM2hIQ0xc1NhUajJT39CqIo2rSarYp9+45TViat2Cq9WUb6xav8tiOOs2fTAAgK8uedhVNtqtPRetTHeXIEcugRGOiHu4cb6goNuTkFFBQUExBgejQsLU2fPSDtgnWZBOTsj7Kyct5843NEUeSuu/sxbFhfq481hzNdUz/+sF23PXhILzMlLWPp/q6a4rIXHds2ITqqKQA5eTfZeciWH2JPwKPaNdiiRRegFejCJ2SDQcokZ76/7cm6/+3WbQ+M7VmrFbO1xZnuDRfOj8ONMEEQVEAnIFcUxSu37GsEjBVF8dva1F1YqF911Lix+ZhM7u5u+Pn5kJ9fhFqtoaSktNo0hrXMfe1Tbtyo6e/l4eHO0KF9mP3yRKsS4hriaD3q4zw5Ajn0cHd3IyYmkuPHktBqRbZsPsD4J+4xWjYrK4cjcfqE0IWF1k0jydkfny37kbS0K/j6ejNv3t+sPs4SznJNHT9+lvXrJWd8Ly9PJk2qWyBgS/f31KnWxQy0FkOH/E27UqlQ25KWKABoUu26a9y4JZIBVgrkYDgKBs59f9uLSxnX+PeKnwHJr/Pvzz0iq3xnuTdqi2skTF4c+nogCEI4cBI4BWQIgrBBEITGBkUCgZW1rd8wxpE1CX0NyxQX36ytWKO0bduS/v271WrY29F6ONN5qgty6fHwI3fqtpf+80cSEy/UbEtxKa++/C8qKvQBfouKrJMhlx5nzlxg5cqNAMyc+TjNmwdbfawlnOGaun49l5dmfoBWKxku02c8TkhIU7vUfStV97c9pnKr8HBX8cBQ/crbtbWYigQoKdEbYV5eXkg+YCVgImm4s97f9qCkpIyXpi+l9KbkGzj+8ftqxHtzfBvq/95w0XBw9EjYu0ivY9FIBtc/gL2CIAwVRdExXq4OZt9+yWYURZHi4pskn7vIps17+N+P25k//wtWfb+Fzz57jVatHJ+A2oVjGPHAADZt3MfhuESKim7y1Pj5jHxgAL36dMTL04Pz56+wYf0eMq9m0zL8Ni5lXANA5USvkBqNhnmvf4ZaraFr10gef0KO5NLyUVJSytQpi8nKygZg8JDePPPMg3Wu19L9nZlZwUsvvVJnOQDD+reiSaA0vXnq3HWSLtjqc3aj8mPox3gNaAY0QfILuwY4R+gDR6PRaIv5TFkAACAASURBVHnt5c85lyT5ZnaObueKvVUL3FzBWmXF0RPldwL/J4riGVEU44AhwBlgjyAItufduQVD/4yyMsurogzL1HXIVxAE/Px86NGzI2+99TxffDEPNzcVKckZPPvMApsikTtaj/o8T/ZELj3c3FR89MkMBsZ2A6CiQs2G9XuY99qXvDxrGZ9/tp7Mq9lEd2nLWwue1R1nznfMEDn0WLlyE6dPn8fd3Y2333nB7j4x9XlNlZWVM+WFRZw8KYVy6NmzEx9/PNuuvjSm7u+srBy7yXjYYCpy7TbbwlIYUr0vrgPpSKNgKiAEqH5dOuv9XRe0Wi1vzF3B77ullYmt24SyYsVbVo1E2ZuG/rxVOeDjwjSOPj8BQH7VP6IoVgDjgURgD5jPbCsIwt8FQYgXBCF++fIfauz399c/XCwFulOrNbpYMR4e7nZ3sB0Y24OHRku59y5dymLjxt+tPtbRejjTeaoLcuoREODL58tfYdm/ZnH3vX1pHtIET08P/AN86NY9irnzJrJq9fxqo19Nm1oXlsTReqSnX+WzZdL9MmHiA3Ts2MaqdtlCfV1T5eUVTHvxXeLiTgEQExPF8hVvOPw6Nby/7cFtwT4M7NUCgNIyNZt3pda6rpp9oUWKql9FE92WM9/ftUUURd6Z/zVbNh8EIDz8Npb/5xWCg60PE2RPlPK8dSEPjp6OTAW6AbrXPFEUNYIgPAb8CGw2d7AoissBKcKkkQTerVu34NIl6WFz+fI1sw7xmZk30FTmDGvVKtQhK1BiB/Zg3VopT9yRIwmMHz/cquMcrYeznafaUh96DL6zJ4PvNB3rJzVFvxIqumtbq+p0tB4/b95LaWk5giDg7qbi88//Z7Rc0rk03fbu3fFkVk7tDRjQnRgLfjT10RcVFWpmzviAvXuPA9C5c1tWfPWWbDn3Ygf2YM+eFLvUNfruSNwrI77vOJBOYXHt45sZ74tSJN8wN6ARkrO+6NT3d21ZsvA71q+V0m+FhTVlxcpXad68iYWjHEdDf97+P3vnHV9FlT3w76RCCkkISBJIAqRQQjMiRQiioDQbrIIrq4i77Loo6NpYsYEN2y4/EVdXdgVXVFBAIyu9uBAwQKQlgQAJJKEFSSGVtJf5/THJK+TNK8mbl/fG+fLJh3kzd+6Zc8+dmTO3nOtCoyp+FSjdErYJmHXtTlEUdcA04GewshS9BeLjo/TbmZmWH44ZGYbjcXFRFlK2HOOm5PIy6+vFNaG0Hq5WTi3FFfVIS8vSbyfe0Mumc5TWoynWmSiKfPLJOpa8/5XZv+PHDBMOtm5N1e8/dChLLmun6XAt9fU6nn76b+zYsb9RfjT//nSBzVH1HYEju4qm3G5wcls6IL8JeVs0fbcKND3qXfn+bgnvLPqC1V9JyxJ1CevIsuXzCI9w3ASUluCKzykN10VpJ+wF4D5zB0RRrAd+A7S4r2TkSEMLRUrKQYtpjaMRG0cpdiR5+YZ4PdamJhujtB6uVk4txdX0KCkpZ9eP0hiUwA5+jL3tRpvOczU9WoIzddDpdDz37GK2bP4JgNjYSJavWGjXPeYIjO/v1nBDQhd6RkpdZecKytl76IKVMyxj3hYeNC1XJDljUtR8V61PLeHv767ii8+lGHGdOwez7NN5dIts9VDjVuPu97cWMd+5KOqEiaJYL4qipU7xCOCVluY/dOgAfUiIvXuPmETONqao6AobNuwGpOnAY8YMbalIWRoaGli71rBQ7KDrbWsVAeX1cKVyag2upsd7b3+hXybn/t/eRvv2vlbOkFBaj8fn3M/xrHVW/+65xxCK4803H9fvnzHjzjbXoYmGhgbmz1/Khg0pAPTo0ZXlK151+nifa+/v1mAcId/yYt22Yd4WHTB0MkihKlz9/raHpe+v4bPlGwEIDQ1i2fJ5RHd3/GLcLcHVnlP24imIDv/TkKetJy50BGa09GQvL08efXQqIHW9zJu3mNJS0+CENTW1zJu3WD9bcfr0SXZ9QX/22XoOH7a8MHNlxVXmPfc+x4+dBqSo6xMnjnQZPZxRTs7AmXocOXyK2to6s8dqa+t4562VfJ8sPUB79IzgT3++xyX1UApn6CCKIq+8/BHJ30nRz6Ojw1nx2Wt07hxi5Uzbacn93Rrat/Niws1S439Dg8jazbY7Ydf3vQ4p0o9p00JzWyyhtNR47cgrLl+f7OGTj5NZ9k9pOHFIx0A++fQ5evSMaOOrMqCG+1vDeSg6MF8QhIesJGl1J/hvfzuBLVv2kpaWSWZmDnffPYdp08YTHR1BQUEha9ZsJSdHihsTGxvJ7Nn2Rbw+sD+DtxZ9SnR0OMOG9ScuLprgkEA8PT0oLi7j2LHTbNuaqr/JvLw8ee31x+y+oZTWQ+n8mzh3toA1jZMTmjhxIle/vS/1KLprooLfPm44ffvGYAvO0uOTj7/j8OFTJI0aRP/+PenUOYTq6hpyss+zZdM+zp+Xwtxd1yWEDz582u6p8M7SQ0mU1mHx4pV884205qW3txcPPnQH6eknSU+3fN6IEdfb3Cpp6f6uqYHgoG6cOXOe2NhEnnwykd69jVu4/RAwrFX5l4dvYPPuXI7lFMnKmzCqBwF+Ul356fAFLvxSIZv2WkKD2wNdgE4YgrHWASK//e00tmzZT1raETIzT3L33ZOZNm0a0dHXUVCQ7RL3t/G5OlEKSnrSaL3V/fuOodPpTM4dc9uN9Okbrf+95uudfLhknf73/Q+MJT/vEvl5l7gWb0/DeMEbEvsS0rFDq3WwFXe+v7XuQ+citGbBYquZC0ID0tNCTogH0E4URU+Z40Y0nx3ZRGlpBXPnLiI19ajs2QkJMSxdOp+ICPkxAw1ifbN9jz+2iO3b91u/PCAysgsLFv6Zm24aaPa4h2DZ53WUHkrnL8qaE/btS2fGQy/YdV1vLnqCKVPGmOwTLMzXcJQetQ3yPeWPPfouu/532MJVw5ChfVn4+iy6dTMvw8fDsiPuCD0aRPOtdbbw/F8/4LvGVqY333ycyVPMh2DwELzN7gdH1ilds30PPvgCB/Znyp4jx7bt/zQ7I83cs87S/T1kyBA+//xzu2TPe3eXxS7GL/82iRsHSN1mT725k/U7bW9dG3tTNB8tHCt7vLS0lLlz55Kamiqbpi3v75ac++obf+DuyUn63y/NX8b336XYlQfAZ/95g6FD+wPOeUaBI5/n8U51i5LzNjrcKbg7eoLm2smgdIiKC8BcURTXmTsoCMIgpBmSrSIoKIAVK15n48YUkpN3cOzYaUpKyggKCiA2NopJk0YxZcpYvLxs8PWu4Y035zBp7xHSDmSSlXWGs2cvceVKOaIo4u/fnrCwTvTp04Nbbr2R0aMH4+Mj/8JqSz2ckb+zcIYej825l379e5J2IIvz5y5TVFSKh4cHnTsHM/D6OMZPGEbSqEEur4fSuLsO1u5vRxIVEah3wErLa9icYn6skBw7UvOBfMAPKeyED9IjXAo/ERTkx4oVS9m48QeSk//LsWM5bmULteGu94bWEuZclG4JSwbSRVF8Ueb4QOCQKIo2jE2TbwlzFOZawhyJtZYwd8HSl7KjsPaV6QgstYQ5AmstYY6gNS1htmKpJcxRmGsJc7gMBZ91AL1u/0nR/AFObU2ynqiVOOP+rtHZu0ST/fh6Om7soDmc8YyScG5L2Pp8x7eE3RmltYTJobRX8B5gKZBPNtLSRhoaGhoaGhptjNYS5lwUdcJEUdxt5Xgl0vJFjpClb/Y9fvwMxcWlBAcHEhMTyR13jGLy5NY3+0oy9vB98o9kZeVSXFxKUHAgsTHdmDgpicmTb3WQDOX0cF45pZCcvJOsa2RMumMUkyePcflyapKxeWMq679PISsrj5LicoKCAoiJ7cqEicO5e/Iol9ajvLySlJTD7NuXwfFjp8nLu0hl5VX8/NoRHt6J6xN7M2XKrfTvbzk6flvqYCpjD8nJP15Tp7o11ilH3XvK3t+IIlRlIVRmQt0veIg1xMT1od+AISQMHEL/hN707hlK+3bSo3nJfw7yweeHrGTaAWmNSHupAs7ZkM6zUUYA4I0oerBx4waSk78n63gWxcUlBAcHOOT+Li+vYm9KOgf2H+f4sTzO5l+isrKa9n6+hIeHMuj6OO6enEQ/G1ensIRanlOOxlNzwpyKot2RjkX5gfmWUIMMNeigyTBFrhvvX8vWsWTJV7JhNoy5666bWfjqbNkZhQLyLwl3KSdXlbFkyRLGjRtn4ayixj+JuNE/NksxZXw8b/91tN3Xs2bDCZ5/p/k38KkfjfMKBkJpCvzquMH/zeutI+ssqKneOrc7ctM5x3dHju+mdUfK4fZOWG1tHTNnvkRamjSLKjy8E1Onjic6OpyCgkLWrt1mMhV49er37F5rTg0y1KCDJqO5DDkn7MUXluqn4UdGdmH4TQPp07sHISEdKC2rIPWno2zZ8pN+3boRIwexbNnLeHg0H54p9zJzp3JyVRlTpjxIWFh3fbqSkhKqqirp2rVb4x7rTlj4df4kxHeyeg0egsB7L9yqb2X77ZzvSUsvaJbO4IR1wrD4t47a2hJmzvwzaWlHG3XowtSpvyE6OoaCgizWrt1kczmZq7eOrLOgpnrrXCdsy/kNDncKbu86UXPCZPBcsGBBW1+DjRQtMLd35cofWL16EyB9Vaxa9R5JSYnEx0eTmNiHe++9jfT0bPLzL1JcXEZ9vY6RI6+3S7IaZKhBB02GORnmn5c7dx6g83Udee212Tz//O+55ZYb6d8/jti4KPr1i2X8+BEMHdqPTZv2UldXz9n8AiK6Xkffvs27eQSZmM7uVU6uKSMgIAiopq7uMvPnv8QzzzxPWVk5Y8c2haK42vgn8cGK3GZ5V1TWcTq/1OpfRFgA906Q4pydOXuFtz/eZ/Za5z7cHan7sSkGWgVwnpUrV7F69UYjHd4hKSmB+PjOJCb2srOcmtdbR9ZZUFO9DV1ol/BWklN+aoGj84zpEOdUHdwJt24Jq6/XkZQ0g+LiUgRBYP36D4iLi252ZlHRFcaOnUVVVTU+Pt7s2rXC5mCqapChBh00GeZlyLWElZZW2LS49cqVP/D6a8sAGHxjAitXvtEsjbkWBXcrJ3eSMW7cBN56662mvVhrCbOV918Zw8RbpICjf1u2n4+/MB8H79SPY4DuSF2Q1UC+w8vJXL11ZJ0FNdVb57aEbVOgJWys1hImS1svW9QqUlOPUFxcCsDw4QPNVnSA0NBgJk6UpnbX1taxfbv5L0C1ylCDDpoM+2TY8jIDGD9+hH771Enb41appZxcVYajCQr0ZcwISW69roFvN5+0lBrD4t/SyhBqqLPguva2V4aSaAt4Oxe3dsL27DHMGkpKSrSQ0nSFeuOV638NMtSggybDPhm2YhyQtGkxcltQSzm5sgxHctfYWHx9pLFgKQfOcamwykLqptaYOpq6QtVQZ8G17a1EWWm4Pm7thJ08ma/fTkiItZi2Xz/D8VOn8i2kVJ8MNeigybBPhq2cOmVoSYiI6GwhpSlqKSdXluFIfjPBsObl2o3yC5aHdfZHisQPUlckgC8nTxoG8CckJAHdkGZONm/mcNU6C65tbyXKqiV4Co7/05DHrZ2w3Nzz+u2uXS1PIw4L64Snp6RuXt4Fm6Nnq0GGGnTQZNgnw1a+Xr1Fv33zaNtbYdRSTq4ow8Oo/8YR9u4d01E/e7L4ylW275HvwuvXy3iWZT0QAkSRm2uIJ9a1axTS0knXIY0dMw0T4ap1FlzT3kqWlYbr49ZOWHl5pX7b2qBJLy9P/RTg+nodVVXVFtOrSYYadNBk2CfDFg4ezGLduh0A+Pr68PDDd9l8rlrKyRVl+PoanJq6utYvpXavUSvY99uyqatvkE3buaNxmAR/pBmSAuXlhiW+QkIakLoqAbyRWsUMS1u5ap0F17S3UmXVUjwE0eF/GvK4tRNmXGF9fX0spGyeprLyqoWU6pKhBh00GfbJsMblyyX85cl3aWiQXshzn3iAsDDrsaaaUEs5uaIMb2/DrL7WOmHeXh7ceZthRYQ1G+S7IgECA4yvzwcplMRFqqoMY8h8fSuBXKSI+yAN4jdt8XHFOguuaW8lyqo1aAPznYtbO2EaGhr2U1VVzWOz3+TSJSn0wc2jB/PII3e38VVpKMGYEdF0DGoHQPqJy5w4XWwxvYdw7RuzDCg3k1JyzqCpVc0f49YwR6PVWQ214tZOmJ9fO/12TY31WTLGaYxn2Khdhhp00GTYJ8NSXrP//AZHj54CIDGxD4sXP4PQ7OVrGbWUkyvKqKszxNDy9m7d8r7GA/KttYIBVFZdu2TQFUBOBx1SINcm/MykcZ06C65pb0eWlSPQWsKci1s7YYGB/vrtkpIyCyml/vaKCqn53Nvby+RGUbsMNeigybBPhjlqa+uY8/hbpKamAzBgQByfLHupRXmqpZxcUUZNTY3+d2ucsOtC/Rh5o7T8UXVNPeu3Z1s9p6zC2GkQAela5HWoMdqWWsJctc6Ca9rbUWWl4Z64tRPWvXtX/fb5879YTFtQUKhfcywqKtzmryg1yFCDDpoM+2RcS11dPU8+8S67dh0EoG/fniz71yt2r4nXhFrKyRVlNDQYBjK31N4Ak8fF49U4827r7lzKK6y3ypw5e8Xol+E65HUwjnwvjWVz1ToLrmlvR5SVI/FQ4E9DHrcun/j4KP12Zqblr7yMDMPxuLgoCynVJ0MNOmgy7JNhTH29jqef/hs7duxvlB/Nvz9dYHOEcnOopZxcWUZrmTI+Xr+9xkJsMGNO5ZZgcL4MDoG8DsZLA0kOmavWWSkf17V3S8tKw71xayds5EhDNOKUlIMW0xpHI7YnKrUaZKhBB01Gy6Kp63Q6nnt2MVs2/wRAbGwky1cstHkdPDnUUk6uLKM13NC/Cz2jggE4V1DO3p/PWzlD4mp1PYYFwwWaYoDJ62AcI0waT+aqdRZc295KrZZgL4Lg+D8NedzaCRs6dAAdOwYBsHfvEZNIysYUFV1hw4bdgDQdeMyYob8qGWrQQZNhnwyAhoYG5s9fyoYNKQD06NGV5SteJTQ02K58zKGWcnJVGa3lN+MNA/LXbbK0TqQ5jGdDSnXFvA6eQFPLlAhUunSdldejOa5ep5REUOBPQx63dsK8vDx59NGpgBRZet68xZSWVpikqampZd68xfrYLdOnT7Lri0oNMtSggybDPhmiKPLKyx+R/N1OAKKjw1nx2Wt07hxicx5trcOvWUZraN/Oiwm39ASgoUG0uEyReUqBpvFjHYBAGR38MLxCKqipqXLpOguua297ZWioB8F9lkk4afZCa2vrmDnzJdLSMgEID+/EtGnjiY6OoKCgkDVrtpKTcxaQmrVXrXrXZPaKLahBhhp00GQ0lyGaDIw28Pe/f84n/1wLSLOu5v11JmFhoVava8SI62nf3nQZGsFk3I/jdbCE2mX07h1PSEgkWVln9DPpEhMHMnToTY1nVmHoHoR/fJ7H5v+d4Vh2kaysKePjefuvowHY8/M5Hn56g13XeurH0UB7oCvGTlZtbQkzZz5FWtrRRh3CmTZtGtHRXSkoOMGaNZttLidz9daRdRbUVG/jndqYlFb4g8OdgsGdJmkNYjK4vRMGUFpawdy5i0hNPSp7dkJCDEuXziciwvJaXmqWoQYdNBmmyDlhDz74Agf2Z9p9Tdu2/5Nu3bqY7JN7mYH7lJOryhgyZAiff/65XfnMe+tHi12MX75/JzcODAfgqde2s357jl35S04YSHG/wgBDmIzS0lLmzp1Lamqq7Pm2lJO5euvIOgtqqreaE6ZmVOGEgdTsu3FjCsnJOzh27DQlJWUEBQUQGxvFpEmjmDJlLF5e8jelLahBhhp00GQYnd/GTpgjdLAFtcqIje3F8uUr7MrDkhMW1bUD27+4H4DS8hpu+s1KamvN1xE5DE4YSC1hwUhjv7wBD0Sxno0b15Oc/D3Hjp1oUTm1tRMG7lSnnOuEHVTACUvUnDBZVOOEaWj8GpFzwhyJtZeZhvOIG/2j4jJMnTBl0OqtPTjXCTtU9F+Hv2uvD71Dc8JkcOuB+RoaGhoaGhoa7krrFibT0NDQ0NDQUA1ak5VzUY0TZtz3fvz4GYqLSwkODiQmJpI77hjF5MmO7d9viYwGsV4230OHskhPzyYjPZuc0+coKS6lpKQcQYCgoEDi46O4+ebB3HnXzXToID9Tx0OwbFJ3KCdnyRAx3+qu0+nIyTlHRkY2mZnZZGRkcyLrDNXV0rT9xx6/nzlzHrB6jYINj7PW6mHPuBdXtoUzZKjB3ta6Ch1RTt/m5pCbeZojOw9y+mg2ZUVl1NXWERAcQFDnYHr0i6H3kL5079ez2bl1NbWcOnSSnMOnOHcyn8Jzl6muvIqXjxcdQoOI6t2d68cM5tnJExTXwxpqkaHh3qhiTJi7zHSRc8JqamoZNHCaTdfRsWMHXn1ttmxgP0tOmLuUk7NkyL2U58xZxNYtP8me56iXsjYb1rkyNHtbz7+4uJQ/Pvcu6buPWJQV3jOCJz56zmTfoR1pfLvkG2qv1sicZSApKZF33nlKH9TU0XpYw71kOHdM2JFix48JG9hRGxMmh9s7YebisUydOp7o6HAKCgpZu3abSTyW1avfs3sBWEfJsOaEdekSyoABcfTq1Z2IiM74+7fnanUNZ06fY9OmveTlXQTA09ODf37yEiNGDGqWl5wT5k7l5CwZci/lx2a/wfbt+/S/g4IDCQ4OJC/3gnTcAS9lpcvK3WzhDBmavS3nX1hYwsMPv8ipU/kAXBfVhb7D+9OpW2d82/tSVVZJQW4BJw8cx6e9TzMnbPuXW9j6mRSTLLBjB+ISe9EtPoqA4ABqq2s5k5HDkR8PUV8rLW/Uq1d3Vq9+l/bt2zmtnNxThnOdsKMKOGEDNCdMFs8FCxa09TXYSNECc3tXrvyB1as3AdJXxapV75GUlEh8fDSJiX24997bSE/PJj//IsXFZdTX6xg58nq7JDtKhkiD2fw9PAQmTBjJU08/yISJIxkypB99+vQgJjaS3r27M2z4AH77wHiKS8rIyMhGFEUyMrKZPn1is7wEwfxcC3cqp7aWcfZsAf0HxPHQQ3fxzDMzePrpGfj7t9e/qIcM6cfQof2t5mPppay0HmqxhWZv22ht/qIo8qc/LSQ9PRsPDw/u/PMU7n36t8Ql9iIiphtdosPoFh9F7yF9GXHPKHoP6Us7//Ym13AmPQddfT33PH4f98y5j34jBxLZO5ou3cOJiO1Gwk39SRgxgMw9R6m9WkNR0RU8PT0ZOnSA08rJPWWELrRLeCu5dPXkAkfn2aV9vFN1cCfcuiWsvl5HUtIMiotLEQSB9es/IC4uutmZRUVXGDt2FlVV1fj4eLNr1wqbl4hwpAy5ljBbqaurZ1TSI1y5Iq3ttmXrR0RGhpmkMdcS5m7l5CwZci0j5li3bjvzn38faH3LiNJl5Y62cIYMzd7y+X/11UYWLPgHAHf86R5GThltVe61VJVX4RdovcXoeGomn72yDICIiM7s3Pmpw/SwhnvKcG5LWEaJ41vC+oVoLWFyuHWIitTUIxQXlwIwfPhAsxUdIDQ0mIkTkwCpmdi468EVZNiKt7cX0dHh+t+Fl6/YdJ5aysmVbNEalNZDLbbQ7O0ce4uiyPLl3wIQFRXOTfeMslEzU2xxwAB63dgHPz+pC/LChctUVFQ5RA9bUIsMDfXg1k7Ynj2H9NtJSYkW0yYl3aDf3r37Z5eSYSsNDQ2cv3BZ/7tT52CbzlNLObmSLVqD0nqoxRaavZ1j77S0TP140zvuGIWHh7KvBQ9PD9q1M6z1WF0tDeRXS51y93orKPCnIY9bh6g4eTJfv52QEGsxbb9+huNNA09dRYYtiKLI+//3JYWXSwDo06dHs65IOdRSTq5ii9aitB5qsYVmb+fY+8ABw1JBAwbEU9zQwMGtB/h5634u5RVQe7WGgJBAovt254bbhxJ/Q2+brkuOiivl+pai9u199TMk1VKn1FJvNZxDmzhhgiDkA2NEUTzVmnxyc8/rt7t2tTyNOCysE56eHuh0DeTlXUAURQTBuo/uDBnXsnv3QWpqpBlE1VdryMu/yLatqWRl5QIQHBzIa68/ZnN+aimntrCFEiith1psodnbOfbOyDA8hv382vPWM0vJzTxtct6VX0q48ksJR348RP+kgdz3zHR82vlYlCXHvg2GcCBJSYn6lje11Cl3r7cuctv8alDUCRME4SmZQxHALEEQCgBEUfx7S/IvL6/Ub1sbNOnl5UlAgB+lpRXU1+uoqqrG/5rZPW0l41rmP/8BhYXNx3t5e3tx66038syzM8wuWCuHWsqpLWyhBErroRZbaPZ2jr2NnzUvv/whubnnaRfQniHjhxER0w2dTseZ9BwObU9DV68jffcR6ut0zFj4B4uyzFF0sZAfV20DQBAEZs2612F6uEqdcvd6q/lgzkXplrD3gPPAtdMCPYAHgDpABFrkhFVVVeu3fX2tf5UZp6msvGpTZXeGDFvp2bMbw4cPNBvg0BJqKSdXskVrUFoPtdhCs7dz7F1WVqH/nZt7ntCITvzxnccJMhpzesNtQxg68Sb+9fxH1FRVczw1gyM/HmTgaMtjnoypra7h84WfUlcjrUTwwAMTGTAg3mF6uEqdUku91XAOSg/MXwZcBsaLotij6Q/QAbc3/m6+9sWvnN0pyzme9S3Hjq/jQNoXfPnlIu7/7Xiys/NZsOBjpk17jvz8i219mRoaGirg2jBF9z3zgIkD1kRk72jGPTxJ/3vPd7tsltGga+CrRZ9TcEYKgJuQEMO8eY+08Io1lEQbmO9cFHXCRFH8E/AmsE0QhD/ae74gCH8UBCFNEIS0Tz5Z3ex40zRnkKLOW8M4ja1fG86QIYcgCAQE+HF9Ym9eeeVPfPzxi3h6epB96iy/f2ShyReXJdRSTm1pC0eitB5qsYVmb+fY21hGbGwk3RPkv4sHjxuCCBNwAQAAIABJREFUZ+Nah+dO5FNjwxJFDQ0NfPO3LzmemgFA527XsWzZgmatRGqpU2qptxrOQfEQFaIorgFGAjMEQfhWEIRQO879RBTFwaIoDv7jH5uvrRgYaFjIuqSkzGJe9fU6fTwab28vkxvFEs6QYSsjk67nnsm3AnDu3CWSk3+06Ty1lJMr2aI1KK2HWmyh2ds59jY+39psPp92vnTqJg02b2hooORSscX0oijy7ftfc2h7GgCh4Z34w9uzCQ1t3tKmljrl7vXWQ3D8n4Y8TokTJopiHjAKOAYcwUEtlN27d9Vvnz//i8W0BQWF6HTSskFRUeE2z0Bxhgx7SDJa2mL//gybzlFLObmaLVqK0nqoxRaavZ1j7x49DOcbOxBytPM3OArVlVctpk3+cC0HNqUCENwlhFnvPEZQJ/PxDdVSp9y93mrdkc7FacFaRVHUiaL4AvA74DXAcu20gfj4KP12Zma2xbQZGYbjcXFRFlI6X4Y9GDdXl5dVWkhpQC3l5Gq2aClK66EWW2j2do69e/Xqod9nPLNPjupKwzCIa9ePNGb9R+tIXZ8CQFCnYGa9/RjB14XIpldLnVJLvdVwDk6PmC+K4o+iKC4URbFQEIRIQRA+bWleI0caZuakpBy0mNY4GrFxlGJXkGEPeUYD8m1dy0wt5eRqtmgpSuuhFlto9naOvUeNMsix5jTUVtdQeE76fvb08qRjWEez6TYsS9YP3A/s2IFZ7zxGaHgni3mrpU65e70VBNHhfxrytPWyRR2BGS09eejQAfpwDXv3HuHUqTyz6YqKrrBhw25Amg48ZsxQl5JhKw0NDaxdu13/e9D1vWw6Ty3l5Eq2aA1K66EWW2j2do69u3a9juuvl6LgZ2efbRao1Zi0zfvR1esAiE7oiY/R8kNNbF7xA7vW7AQgICSQWW8/RqeunRXXwxbUIkNDPSjqhAmC8JClP+DO1uTv5eXJo49OBaQBoPPmLaa0tMIkTU1NLfPmLdbPJJw+fZLNLUjOkvHZZ+s5fPiExTSVFVeZ99z7HD8mPSCDggKYOHGky+igFhnOQGk91GILzd7Os/cTT/xOv/3Ne19SaiZY9NkT+Wxe8YP+98333dIszfYvt7Dzq60A+AcFMOut2VwXZVtgabXUKXevt9qYMOciXBsjxqGZC0IDUIUUkNUcHkA7URQ9red20mwetbV1zJz5Emlp0vpn4eGdmDZtPNHRERQUFLJmzVZycs4C0vTrVavetWnwqRIyGsRrY9ZKPP7YIrZv3090dDjDhvUnLi6a4JBAPD09KC4u49ix02zbmqq/kb28PPn74me47bZhzfLyEMzH33WncnKWDFGmWp47W8CaNdtM9p04kcvOnfsBGDy4L4MH9zM5fvu44fTtG2OyT7Dw+FG6rNzNFs6Qodnbcv4LFvyDr77aCCBFzJ8wnIiYrujqdZzJOM2hbQf0rWBDJgxnypOmM9b3bdjLt+9/rf899sHxhPeMMHu9w64zrHubmNhX33LkbnXKOTLinerHnC5f73CnoGfgnZovJoPSTtg5YK4oiutkjg8Cfm6NEwZQWlrB3LmLSE09Knt2QkIMS5fOJyLC8lpeSsqw5oTZQmRkFxYs/DM33TTQ7HE5Jwzcp5ycJUPupbxvXzozHnrBrmt6c9ETTJkyxmSfpZcyKF9W7mQLZ8jQ7G05/4aGBt54YxlffPFDswCuxtx0dxJ3/GkyHp6mHSlfv/cFB7cesPu6//OfNxk6tL/D9LAF95KhOWFqRmknLBlIF0XxRZnjA4FDoija0C0q74SB1Oy7cWMKyck7OHbsNCUlZQQFBRAbG8WkSaOYMmUsXl42+HoKypBzwkpLK9i79whpBzLJyjrD2bOXuHKlHFEU8fdvT1hYJ/r06cEtt97I6NGD8fHxlpVhyQlzhA624C4y2vqlDMqXlbvYwhkyNHvblv/7G7dzYFMqp49mU1YkxbkK6hREj/4xDLtjBF3jIs2e5ygnzFF6WMN9ZDjXCctVwAnrrjlhsijthCUBAaIobpQ57g8MFkXxf9Zzs+yEuQNyTpgjseaEaRiQeyk7ClteyhrOQ7O3bXybm6O4jMndY6wn0mhEc8LUjKJvbFEUd1s5XgnY4IBpaGhoaGhoKI0LxIv9VaGaZhPjZt/jx89QXFxKcHAgMTGR3HHHKCZPdmzTcktkCIL8MZ1OR07OOTIyssnMzCYjI5sTWWeorpbWFXvs8fuZM+eBVl2/I3T4Nchwli0coYdc66ooihw6lEV6ejYZ6dnknD5HSXEpJSXlCAIEBQUSHx/FzTcP5s67bqZDB/mBx/Z0cbuyva21VLXeFnUt0u0Pv3+VPXsO63+/+ebjTJ5yq9m0HoL8UARH6ADWW6mulXHlSjkDB/Zn1KgRjB49ktjYOAShHYbJ90WNfwa6DzI7TBiA6MhgfjtlEMMGR9E9KgR/Px+qa+r55XIFRzIv8v2mY/yYIh9Go4ncw1MAbyAIaA/4NF5TA6BDFK+yceN6kpM3tqisLLWsOvIZovlE6kbR7kjH4v4D8y3dtHPmLGLrlp9kj9t601p60bhLOTlLhpw9nGELUHayR01NLYMGNl9v1RwdO3bg1ddmy8Yp0iZ72CajJU7Yd9/u5PnnPzDZ11InrK3KacmSJYwbN87CWbY7YX+eOYy/zE7Cx9uyo7hnXy6zn/2O0rJq2TS5h38PdMKcG1NaWsrcuXNJTU2VPd8VnucAAr2c6oflVzi+OzIqQOuOlMPtW8Jqa+uYPft1k6nAU6eOJzo6nIKCQtau3UZOzlkyM3OYNWsBq1e/R0CAn8vJaGhcP6yJoOBAgoMDycu9YFc+bamDWmQobQtn6QHQpUsoAwbE0atXdyIiOuPv356r1TWcOX2OTZv2kpd3keLiMp6Y+w7//OQlRowY5FI6qEWGOYqKrvDWW8sB8PNrp48Z1RLaspwGDjQNGl1SUkJVVSVdu3azK/9Hpg9m3hOj9b/3peWzIyWHiwVldOjQjoTeXZgyqR++vl6MGNqd5R/cx70zV9LQ0NxneGT6YMA4QGwVUAnUU1urY/bsp0lLO9yoRzhTp04hOtrPrZ4hSqF1RzoXzwULFrT1NdhI0QJze1eu/IHVqzcB0pfLqlXvkZSUSHx8NImJfbj33ttIT88mP1962dTX6xhptAi2LThDxtmzBfQfEMdDD93FM8/M4OmnZ+Dv357t2/cBMGRIv2YziMwh1/qilnJSgy0cqYdIQ7N9AB4eAhMmjOSppx9kwsSRDBnSjz59ehATG0nv3t0ZNnwAv31gPMUlZWRkZCOKIhkZ2UyfPrG5HoL5yctqsbfStpDjhReWkpmRQ5++PRg8OIGTJ6TI6mPGDKFPnx5mz5Eb0tCW5RQQEARUU1d3mfnzX+KZZ56nrKycsWPHNp55tfHPwP99fNzkd7t2Xixfeh8+PlK7wLOvbGDhu9v4+fB5TmQXcjSzgO3/y+a7DZlMGNuLwABfwsM6kJl1iZzcYot5QQFwGagGalm5ci2rV29o1KMvq1atJinpZuLju5CYGOtSzxAAgU4L7RLeSsrqTi5wdJ5BPr2cqoM70dbLFrWK+nodH38sBQcUBIG33/4LQUEBJml8fX14552/4OfXDoCVK/9LSUmZS8kAePTRqTz99AzGjx9Bt8gw6yfYgVrKSQ22AOfo4eHhQWys+VACTXh6ejJ//u8JDg4E4PTp85w9W+AyOqhFhjl27NjPpo178fDw4NWFf8bTo+WP4rYvp2KgEG/vap577nd6GfZww8CuBPhLSyAdzrjAN8nmu1TPXSjlo08NXYg3Xt+8jhvnJTleBj2b6/FXgoKCGo9Ki5G7wzNESbSI+c7FrZ2w1NQjFBeXAjB8+EDi4qLNpgsNDWbixCRAalJv+hpxFRlKo5ZyUoMtwLX08Pb2Ijo6XP+78HLz5WrMoRZ7t4UtKiqqeHXhJwBMnz6Bfv1jW5wXuG452UNoR8PEkNz8Eotpz+QbWr782jcfI2ecF9SaHGuuR1ejo4bXoas/QzTUg1s7YXv2HNJvJyUlWkhpukK98cr1riBDadRSTmqwBbiWHg0NDZy/cFn/u1PnYJvOU4u928IW7737Hy5dKiYsLJQnnmj9LFtXLidbKSyq1G93jwqxmLZ7VEf9dvaZombHjfOSZkQaaK6HsRNn6rC58jNESTwEx/9pyOPWTtjJk/n67YQEy1+T/foZjp86lW8hpfNlKI1aykkNtgDX0UMURd7/vy8pvCy1PPTp04NIG7tO1GJvZ9viwIFMvv5aWuD6xZdm4R/QvkX5GOPK5WQrPx8+R1FxFQCD+kVw393mx0t1iwhi9iPSmrnFJVV8+0OGxbygHWBYGNtUj15Ak0Onw7jb8lo9XO0ZoiRad6RzcevZkbm55/XbXbtannIdFtYJT08PdLoG8vIuIIoigg3TQJwhQ2nUUk5qsAW0jR67dx+kpkYKoVB9tYa8/Its25pKVlYuAMHBgbz2+mMupYNaZDRRU1PLyy99hCiKjL1tKGPGDLH5XEu4Yjl5GDV/SDIs519Tq+PFNzezZNFdeHt78u7CSdx7Z3+2787mYkE5QR3akdDHMDvy4qUyHn36W66UNp9R2pTXR+/dg+QChCE5YpXk5l400uMGpJawOuAiXDOxwpWfIRrqwa2dsPJyQ7NzSEgHCynBy8uTgAA/SksrqK/XUVVVjb+/9a9QZ8hQGrWUkxpsAW2jx/znP6CwsPl4L29vL2699UaeeXYG3bp1sTk/tdjbmbb4cOnX5OZewN+/PS+++Aebz7OGK5aTr6+v/nddXT0+PhZOaGTjthPMKPuahfNuIy6mE0MHRzF0cJRJmsqqWt792w6+ST5qMUbYxm0ngHPAdYAv4Af4UV5epU8TEhKMNGuylGsdsCY9XPUZoiSC4C6xQ9WBW3dHGsfV8fW1fpcbp6msvGohpXNlKI1aykkNtgDX0qNnz24MHz6Qjh2DrCc2Qi32dpYtjh8/w/LlyQA8+eQDdOkSavO51nDFcvI2CrZaV2f7mrk/Hchj4bvbOJlz2exxfz8f/vDgjdw/ZaANuV1FcrJq9HuqqgxOmK9veyAEKaK+eVz1GaKhHty6JUxDQ8M2dqdIQUFFUaSy8iqnTubz/fr/8c3XW1iw4GNWfvEDH374PFFR4VZy0rAXnU7Hiy98SH29jv79Y3lg+oS2viSXJDTEj3+8N5mhN0RSWFzJi29uZseuHH4prCAwwJchiZE88acR9O3VheefvIXecZ156sX/Ym7Rl9AQP6AbUgtYPXAJKVirceJqIAApqKsvUjwxDa3D1bm4dUuYcTyamppaCymbp7G1WdkZMpRGLeWkBltA2+ohCAIBAX5cn9ibV175Ex9//CKenh5knzrL7x9ZaHPUdrXY2xkyli//nmPHTuPl5cmrr/0Zj1bEBDOHK5ZTXZ1Ov+3tbf1bv307b75ePp2hN0RSXFLFPb/7Dyu/PsSFgjLq6xsouXKVzTtOMvnB//DzkXMATJ7Uj99NbT5TsykvyQHTAflIXY711+hxGkMQ2Q6YaxFz1WeIkgiC4/805HFrJyww0BAPxlowvfp6HRUVUlO0t7eXzQEFnSFDadRSTmqwBbiWHiOTrueeydI6hefOXSI5+UebzlOLvZWWkZd3kQ+XrgbgoRl30ru3+Uj4rcEVy6mmxtAFaIsT9tD9icR0l7poP/lsH+culJpNV1Or4/X3duh/P3x/83AYxnlJgWQN3aGmepQidVc2YRoaw5WfIRrqwa2dsO7dDYH2zp//xWLagoJCdI3reUVFhds8y8UZMpRGLeWkBluA6+mRZLQky/79zaf8m0Mt9lZaxn/X76K6uhZBEPDy9OCjj74x+3fiZK7+nJ070/T7jx491eY6tESG8XqOtsi4dWSMfjtlX67FtIfSL1BRKTl5MT1CCfA3HaNmnJe0ZqSB5npUYxiU74PxK9GVnyFKooWocC5u7YTFxxtmzmRmZltMm5FhOB4XF2UhpfNlKI1aykkNtgDX08O4m6W8rNJCSgNqsbfSMsTGAUuiKPLJJ+tY8v5XZv+OHzujP2fr1lT9/kOHstpch9bIsJXrrjMss1RRab270zhN+2ui5hvnde2sR/N6GKcxuAyu/AzRUA9u7YSNHGkYD5CSctBiWuOIx/ZEdHaGDKVRSzmpwRbgenrk5RtiJ1kLP9CEWuztarZoCa5cTrZSUWFwqsK7WK6Dvr5edAzx0/8uvSZWmHFe1849a66HABgvim5wyFzV3krjocCfhjxuXT5Dhw7QT63fu/cIp07lmU1XVHSFDRt2A9KU4zFjhrqUDKVRSzmpwRbgWno0NDSwdu12/e9B1/ey6Ty12FtpGY/PuZ/jWeus/t1zzy36c95883H9/hkz7mxzHVoqwx6MQ1LcOb6PxbQTxvTCpzEExvGTv1BrNAng2rwg0ORYcz0uY2j9qqFp9qSrP0OURBuY71zc2gnz8vLk0UenAlJz/7x5iyktrTBJU1NTy7x5i/WzvqZPn2Tz176zZCiNWspJDbYA5+jx2WfrOXz4hMU0lRVXmffc+xw/dhqAoKAAJk4c6TI6qEWG0rhqOdnD9xuP6ben3TOAeyYmmE3XO64zLz87Rv/b3LJFxnlJMx4NjlhzPd6ltLRpEkCZWT1czd4a6kIQzQVZcUlOmr3Q2to6Zs58ibS0TADCwzsxbdp4oqMjKCgoZM2areTknAUgNjaSVaveNZkhYwuOkiEiX9bnzhawZs02k30nTuSyc+d+AAYP7svgwf1Mjt8+bjh9+8aY7BNkhkG6Uzk5S4acPZS2hSP1aBDNB8J8/LFFbN++n+jocIYN609cXDTBIYF4enpQXFzGsWOn2bY1Vf8i9fLy5O+Ln+G224Y1y8tDMD+7zd3srbSMBrHOLrnGPP/XD/juu52A1BI2ecqtZtN5CN5m97dlOfXuHU9ISCRZWWf0MycTEwcydOhNjWdWYQgFITFp2vdknrhksu+ff5/CuFvj9b937T3N9sY4YQH+vgwbHMkdt/fB11eqj8dOXGLyQ59TU9P8Hrg2LylGWCVQT22tjpkznyEt7XCjHuFMm/YboqP9XO55DiDQy6ltScU16x3uFHT0vVNrD5PB7Z0wgNLSCubOXURq6lHZsxMSYli6dD4REZbXPVNShqWbdt++dGY89IJd1/TmoieYMmWMyT5LL353KSdnyZCzhzNsAY7Rw5oTZguRkV1YsPDP3HST+Sjkck4YuJe9lZbRlk4YtF05DRkyhM8//9yufJ55+QfWfJ9uss/X14tFL41nyh39ZM4ysHd/HnP/mkxhcZXZ476+XpzY90eMF+82prS0lLlz55KamiorwxWe56A5YWpHFRHzg4ICWLHidTZuTCE5eQfHjp2mpKSMoKAAYmOjmDRpFFOmjMXLy9N6Zm0oQ2nUUk5qsAUoq8cbb85h0t4jpB3IJCvrDGfPXuLKlXJEUcTfvz1hYZ3o06cHt9x6I6NHD8bHR/7l3lY6qE2G0rRVOTmqTGpq6nnqxf/y2aqf+c2d/bhhYDe6RQTh7+dDdU0dly5XcDj9Ius3HePHPaet5iVFwL+C5Ii1Q1qs2wMQCQpqz4oVS9i48XuSkze5pb2VwtrHo4ZjUUVLmLtg6cvJUWg3kO0obQ9n2EKuJcyRWGoJ0zDQmpYwW7HUEuZOdB+0TnEZuYenKJq/M57n4PyWsJKa/zpcsRDfO7QXkwza01VDQ0NDQ0MDAEFw6/l6bodqnDBRFPVN5MePn6G4uJTg4EBiYiK5445RTJ7c+qZlJWXodDpycs6RkZFNZmY2GRnZnMg6Q3W1FPPmscfvZ86cB1p1/Y7SwdIXoKP0sNaK5Ag9nCHDGq2VYa2VSrO37bTeFtZbqVorQy22OHN4sl061NbWExMTwxNP/J6xt41G6l70RWic4C9SCBSZ5BV7n/Uxkb2igrl7VA9GDggnLNSPgPbeFJdVU1B8lYMnLpNy5CK7Dl8we272NyMbr0O6FinemCdSl6cOqEUUq9i48b8kJ29VrN46Hq3RypmoojvSXQbuWnqAzpmziK1bfpI97ogHqNID2sG99LCEGmRo9rYdd5GhFlvI6SGnw5IlSxg3bpyF/Jo7YXH3HZBN387Hk/kzbmDa2Fg8LSyoXlZZS+LDX5s9lv3NbwD5Rb0dMfhfIt6pXtGV2o0OdwqCfSZonp0Mbt8SVltbx+zZr5tMm546dTzR0eEUFBSydu02cnLOkpmZw6xZC1i9+j0CAvys5Op8GQ060+U1goIDCQ4OJC/X/FeYvThDB7XooQYZmr1/fTLUYAs5HTw9TVuLRHSADgHTdSNtwa+dF8v+egtDE7oAcP5yBZv3neVk/hUqrtYR6OdNz65BjBoUTlhHa9evQ1p/sgaoa/wtUFsrMnv2U6SlHQKkMBhTp95BdHSwQ+8/JdDGFTsXt3fCvvpqo/6hkJAQw/LlrxMUZFg77He/u4PZs98gJeUg2dln+fDDVcyb94jLyeg/II6eMd1ISIilX0IM3SLDWLduO/Off9+ufNpSB7XooQYZmr1/fTLUYAs5HY4ePUpOTg6RkcFMmHgjksPTAQi3W4/XZg3VO2D/WJfOB9+kU1ff0Czd259DeKglx+gSYH6dy6+++l7vgCUk9GX58hUEBXUAzgD1Drv/NNwft+6OrK/XkZQ0g+LiUgRBYP36D4iLi252ZlHRFcaOnUVVVTU+Pt7s2rXC5gjIjpRh72wa4wdoa7oSHF1OatHDHGqQodnbdWzhaBlqsYU9esjr0AGh0QmztTty1KBwPn1BisW1/IfjvLHC/nUum8j+ZojZ/c3LajVxcU0x+Apoisxve51ybndkae1mhzsFQT7jtOY1Gdx6GkRq6hGKi6UlJ4YPH2j2oQAQGhrMxIlJgNSkvn37PpeSoTRq0AHUY2+lZWj2dh1bOEuG0qhBB4A/3NUXgIqqWhavOqKIjOZlFWl01ND55KplJQgeDv/TkMetS2fPnkP67aSkRItpk5Ju0G/v3m37148zZCiNGnQA9dhbaRmavV3HFs6SoTRq0CGikz/DEsIA2HrgHFXVysTYa15WxrNmTWW6allpOA+3HhN28mS+fjshIdZi2n79DMdPncq3kNL5MpRGDTqAeuyttAzN3q5jC2fJUBo16HBjn+vw8JB6xY5mFwJw+5BIpo2NpW+PjnTw86Gkoob07CLWp5xhw08tu3bTsuoHNI2ba0Bav9KAa5aV1nPoTBR1wgRB6AVUiKJ4vvH3BOBxIArIA5aKorippfnn5p7Xb3ftannaeFhYJzw9PdDpGsjLu4AoigiC9crmDBlKowYdQD32VlqGZm/XsYWzZCiNGnToF9NRv11UWs3Sp0cxfliUSZqwjn6EDfHjtiGR/O7YJR57bxcl5TU25O5L0+s0N/eifm/XrgORnBoR+AVp9qSRPBctKw3noXR35BdAfwBBEKYC3yMt5rUaKAaSG/e3iPJyw1eFtUGyXl6e+inA9fU6qqqqXUaG0qhBB1CPvZWWodnbdWzhLBlKowYdOgcbYno9ef8gxg+Lorq2ni82n+CZD/bw1PspLP/hOJXV0vJTQ/p24d/zb8Xby5bXZAjQFehKeblhUfGQkBDgKnCOpgH5xrhiWQkK/NOQR+nuyD5AVuP2M8BzoigubjooCMJuYD5gPhqeFYwrrK+v9XgxxmkqK6/i7y8faM+ZMpRGDTqAeuyttAzN3q5jC2fJUBo16NDB33BNPSM6UFxWzfQFWzl1tlS///uUXFZuOsEXC24jLNSfAbGhzJzUm0+Sj9ksp6rK4IT5+noCFUghNczjamWlOU3ORemWsFogqHG7O7D9muM7gDiFr0FDQ0ND41eOxzW+xevL00wcsCbyCip46RPDkkcPTextQ+4FwMnGP+MIDwLQCYgGXCMYq4ZrobQTtgOY3rj9M3DLNcdvRWqnbRF+fu302zU15oPmGWOcxtavDWfIUBo16ADqsbfSMjR7u44tnCVDadSgQ8VVw8zEsspaftibJ5t258HzFBRLLVphHf2I6WpbTDi4tqyykVrBPJG6K5u3IrpeWXko8Kchh9Kl8zzwsCAInwO7gNcFQfhcEIT5giB8BnwAvCF3siAIfxQEIU0QhLRPPlnd7HhgoL9+u6SkeX+7MfX1OioqpJvK29vL5EaxhDNkKI0adAD12FtpGZq9XccWzpKhNGrQobzK4Oxk5ZWga7Ack/TY6WL9dlSXQJvlmJZVMVDY+EsAQk3SumpZaTgPRZ0wURRPAkMa5TwP+CO1jC0AYoFpoij+x8L5n4iiOFgUxcF//OO0Zse7d++q3z5//heL11JQUIiucV2yqKhwm2egOEOG0qhBB1CPvZWWodnbdWzhLBlKowYdTp83OI8VVfJjtJooN0oT6OdtIaUpzcvKOCyFaUuXK5aVIAgO/9OQR/F2QlEUc0VRnI40NiwcqU3WXxTFEaIoJrcm7/h4w/TizMxsi2kzMgzH4+KiLKR0vgylUYMOoB57Ky1Ds7fr2MJZMpRGDTqcyC/RbwfY4FQZO17lNjhtTTQvK+MWN9NXrquWlYbzcFpnrShxSRTFi6Io1gEIghApCMKnLc1z5EhD5OaUlIMW0xpHIzaOUuwKMpRGDTqAeuyttAzN3q5jC2fJUBo16LD/2C/68BO9o0PwvHak/jX07RGi3z5z0XIXrDHNy8rY4TNdKNw1y0pQ4E9DjrYeMdcRmNHSk4cOHUDHjtLky717j3DqlPmBlkVFV9iwYTcgTQceM2aoS8lQGjXoAOqxt9IyNHu7ji2cJUNp1KBDda2O7WnSPLAO/j5Musn8+pcAtyR2JSxUGtuVf6mc3IvlNstpXlbGC4tf1W+5allpccKci6JOmCAID1n6A+5sTf5eXp48+qgU61UURebNW0xpaYVJmpqaWubNW6yPczN9+iSrwQadLUNp1KADqMfeSsvQ7O06tnCWDKVRgw4AH3yTTl291BqJQ1LZAAAgAElEQVT14szBxHULapYmqksAr84aov/9r++bxwgbM7gbhuWITGleVq9TWtoUCuMK4B5lpeEcBFG0PEOkVZkLQgNQhWmnuDEeQDtRFD2t53bSbB61tXXMnPkSaWmZAISHd2LatPFER0dQUFDImjVbyck5C0BsbCSrVr1rMnvFFhwlQ5QtBjh3toA1a7aZ7DtxIpedO6V4NYMH92Xw4H4mx28fN5y+fWNM9sl9dTiynNSihxxqkKHZ23bcSYZabCGnh5wOp05d4N577yU8vBPh4Z0B6NQpjJiY3o35VWHcygRw97OpHMst4Vpm3dWXeQ9KXYbVtfWs2ZHDoZOFNIgiA2JDue/WWALaS12Iuw5f4Pdv7uDa1+TDE3vz4szBSAtyVwE1jdsi4EFtrcDMmU+SlnawsazCmTbtLqKjg1pQp+Kd2pRUVb/H4U6Bn9cIrTlMBqWdsHPAXFEU18kcHwT83BonDKC0tIK5cxeRmnpU9uyEhBiWLp1PRITldc+UlGHpAbpvXzozHnrBrmt6c9ETTJkyxmSfpaZfR5WTWvSwhBpkaPa2HXeRoRZbyOkhp8OQIUP4/PPPZfMzx3Mf7mXdj6fNHvvz5ATmTB2Aj5f8q2fD3jye+3Av1bW6ZscMTpg8paWlzJ07l9TUVNk0ttUpzQlTM0ovW/QzkAiYdcKQPhtabZygoABWrHidjRtTSE7ewbFjpykpKSMoKIDY2CgmTRrFlClj8bJww7mCDKVRgw6gHnsrLUOz969PhtKoQQeAj77NZOuBc0wbG0vSwHDCOvrh5eXB5SvVHMy6zDc7s0nNuCR7/pdbTvLizDCkkBPtkIKweiK9zhoAHUFBHqxY8TYbN24gOXm725SVNobLuSjdEpYEBIiiuFHmuD8wWBTF/1nPTb4lzF2w9BXrKJxxA6lFDw3b0OztOqjFFs7QI+6+A4rmn/3NEOuJHIJzW8KqdT853DjtPIdrN7gMiraEiaK428rxSsAGB0xDQ0NDQ0NDQ10o3R3pNERR1DeRHz9+huLiUoKDA4mJieSOO0YxeXLrm31bK8OWL0yl9XBE/tb0cAdbqEWGSPPxKk2Ul1eSsvsQ+/ZlcOxYDnn5BVRWVOHn147w8M4kJvZmypQx9B8QZ+Uq5SdR63Q6cnLOkZGRTWZmNhkZ2ZzIOkN1tbREzGOP38+cOQ+Y1fvQweOkp58iPT2bE9nZXCmpoPRKJYIg0KGDHz3jwhiW1IfbJyYS2MG2NfX27cliQ3Iax9LzKCmqwM/fl25RnRg9dgCP/O5Bs8vCtFQHe3CUDLXce87Q4+TXic32iaLIoUNZpKdnk5GeTc7pc5QUl1JSUo6npwcDBvTn5ptHcNNNQ4mNjcfT0w9B8Gg89zIil/V5xU6zraWtV1Qwdyf1YGT/MMJC/Qho701xWQ0FxVUcPHGZlPQCdh2+IHt+9ur47sANwODG/29ACu8EUiPGaJsuxGa0Ritnomh3pGNx/4H5bS1DDTpoMkyRc8L+tWwdS5Z8RW2t9Ujfd911MwtfnU379r4yKeSdsDlzFrF1y0+yx+Wci5qaWgYOuNfqtQEEh/jz7Mv3knRLP9k0tbX1LHp5Nds3HZZNExUVxgcfPE+v3j1M9rdUB3twlAxtAoPtMhrE+mb7ampqGTSw+RJ4AEuWLGHcuHGy+V3rhMXff0g2LUA7H0/mP3QD08bE4Okhfw+VVdaS+Mg3Zo89OD6eV2beaEmMw52wal2qAt2RwzTPTga3bwmrra1j9uzXTaZNT506nujocAoKClm7dhs5OWfJzMxh1qwFrF79HgEBfr86GWrQQZNhu4zc3At6BywysgvDbxpIn949CAnpQGlZBak/HWXLlp/Q6Rr4/vv/UVRcyrJlL+Nh4WVhjgadaQTwoOBAgoMDycuV/7I3pkuXUAYMjKdbzwDCwkNo7+9LTXUd+Wd+YefWo5zLL+RKSSUvP/M57yz9PTcOjzebz5svrWLH5iON1+DHnVOG0TMujNIrlWz54SDHM86Sn1/AH/6wkK+/eVcf5sAROtiC0jLUUGedJQMa692AOHr16k5ERGf8/ds3axEuKSmhtLSU7t27252/n68Xy+aNZmhCFwDOX65k8758Tp69QsXVOgL9fOgZ0YFRgyII6yjfymsmqv9V4BQwwO6LshGhzWO4/7pweyfsq6826m/YhIQYli9/naAgQxC93/3uDmbPfoOUlINkZ5/lww9XMW/eI786GWrQQZNhuwxBELh59GB+//t7GDKkeQvStGnjSEvL5I+zXqOqqpo9KYf59tud/OY3Y8zkJk//AXH0jOlGQkIs/RJi6BYZxrp125n//PsWz/P29uK/PywlNlZaL++XqyeapXlk9jjef+s7vvtGchbffyeZld8+2yzd7p0ZegesS3gwSz+dTZdww5Izk6fdxDsL17Ah+QCXLxfz1qJ/8/6Sv7ZaB3tQWoYa6qwzZHh7e7H+v0uIjY00czQAUSxE11DJBx+s4OOPvmTy5Mm89dZbdukA8NqsIXoH7B/rMvhgTTp11zjiAG9/cYjwUHkn8twvlQAfIkUa+BnIBCKBM3ZflM1ojVbOxK1d3vp6HR9//DUgvXTefvsvJjcsSMtBvPPOX/RjQVau/C8lJbavA6YGGWrQQZNhn4xnnp3BP//5olkHrInBgxN46ukH9b+//XaHzfk38eijU3n66RmMHz+CbpFhNp/n4eGhd8Dk8PT0YO5zdxMULL2k8s/8woVzRc3Srfh4q377qflTTBywJll/eX4yERFS69fmzXs5edKw7E5LdbAHJWWopc46Q4ZU78w5YACFiPyCh0cls2dPJjg40OZ8jRk1MJy7k6Qu7+Ubsvj76iNmHbAmLhZVyR7bJi2z9DiwHDgKFgaBarglbu2EpaYeobhYWg5i+PCBxMWZXwssNDSYiROTAKm5e/v2fb8qGWrQQZNhn4xrX15yjB8/Qr99ysgxcRW8vD3pFtVJ/7uo0HQNv7N5lzl1QurS6xbVieFJfczm49vOm/vuu13/e9PGFAWutm1QS511hgxb8fb2Ijo6vEXn/uHOvgBUVNWxeNURR16WUxAEweF/GvK4tRO2Z49hYGRSUvOZMMYYr1BvvHL9r0GGGnTQZNgnw1b8/Q3jUZpm6rkSDQ0NXLxgWHomtJNp68T+n07qt4fc1MtiXiONynr37oMOusK2Ry111pXui4aGBs5fuGw94TVEdPJnWGM35Na0s1TVNJ8coKFhjFuPCTt5Ml+/nZAQazFtv36G46dO5VtIqT4ZatBBk2GfDFs5dcrQ+tXUXecqiKLIv5Zuprix9SuuVwQR3UJN0pzJLtBv9+rT1WJ+ffr0xNPTA52ugZycs4iiqIqvdLXUWVe5L0RR5P3/+5LCy83XnbTGjb0749E4mP5ottR1fvuQSKbdGkvfHiF08POhpKKG9Jwi1qfksiHV8fd063H/e8KdcGsnLDf3vH67a1fL06HDwjrpH8B5eRdsfgCrQYYadNBk2CfDVr5evUW/ffPoGyykVJZ9e7KobWw1qK6u4/zZQnZtTyf75EVAmvH43IL7mp13Ns/QWhEW0bHZcWO8vDzp0iWUCxcuU1VVzaVLRYSFdbJ4jjugljrbFvfF7t0HqamRZhFXX60hL/8i27amkpWVC2A2rpwl+sUYPhKKSqtZ+lQS44eajn0M6+hHWEc/brsxkt8d/4XH/raLkvIau69dQx24tRNWXl6p3w4J6WAxrZeXJwEBfpSWVlBfr6OqqtqkK0bNMtSggybDPhm2cPBgFuvWSYPxfX19ePjhuxySb0tY9PJqiosqmu339vZkxM0JPPqXSUR0be5kVZRX67eDQvytygkODuRCYzdTWVmlKpwwtdTZtrgv5j//AYWFV5rt9/b24tZbb+Sxx8zHFJOjc7DBaXty2kB6RnSguraetT+e5tDJQhpEkf4xoUy9NQb/dt4M6XMd/37+Fqa9tMXi4H1nooWocC5uXdpVVYYHsK+vj9X0xmkqK6/+amSoQQdNhn0yrHH5cgl/efJdGhqkB//cJx5wSYckqsd13DAslpCO5icaXK0ytCD4+Fj/plSiLNsatdRZV7gvmujZsxvDhw/EP8A+x66Dn+GaekZ0oLismsnzN/HKvw/w3e4zfJ+Syxuf/cxdz22goHFW5ICYUGZO6u3Q628dggJ/GnK4dUuYhoaG/VRVVfPY7De5dEkas3Lz6ME88sjdbXpN321/BZDG41RV1nA6u4CtPxxk/bp9/O31daz7ag9v/t/DdI10PUdRw33ZnbIckOpdZeVVTp3M5/v1/+Obr7ewYMHHFBTU8Ze/PGdzfh7XdIm+/tnPnDpb2ixd3qUKXvrXfpbNGw3AQxN68cn3x1quiIbb4tYtYcb99TU11md2GaextelaDTLUoIMmwz4ZlvKa/ec3OHr0FACJiX1YvPgZlxmgLggC/gHt6D+oO0+9MIW3P3gET08PzuRc4qlHl3H1qml5tfczLLVUW2t9Jpojy9JVUEudbcv7QhAEAgL8uD6xN6+88ic+/vhFPD09uHSp2K58KqoNy4SVVdbyw175sC87D56noFhqDQvr6EdMV8tdsM5CUOCfhjxu7YQFBhrGgFgL2Fdfr6OiQqrw3t5eNg+4VIMMNeigybBPhjlqa+uY8/hbpKamAzBgQByfLHupVXkqzZCbejH+rsEAXDxfzOb1aSbHAwIN115aUok1rlwxxBnr0MH6GDJ3QC11tq3uC3OMTLqeeybfavd55ZUGxzAr/wq6BsvLMB47Y3Dyorq0LDishnvj1k5Y9+6GKennz/9iMW1BQSG6xoGPUVHhNn/5q0GGGnTQZNgn41rq6up58ol32bVLio/Vt29Plv3rlRatu+dshhrF/zqUdtrkWGS0IaxGwQXLrRb19Tp9F6yfXzu6dAm1mN5dUEudbYv7whJJI6+3+5zTFw1OfkWV9da88ipDy1mgn7fd8pRAC9bqXNzaCYuPN0z9zczMtpg2I8NwPC7O8nIpapOhBh00GfbJMKa+XsfTT/+NHTv2N8qP5t+fLrA5qn5b4+dv6HKsKDcdgN0j1rAE0Inj57HE8eOn9S/umJhI1bwc1FJnnX1fWKMlXZwn8gyxxQL8rE8uMHa8jB2ytsVDgT/7ECSmCYLwX0EQzgmCUCMIwkVBELYLgvAHQRBUM57drZ2wkSMNUZVTUixHwDaOqmwcbfnXIEMNOmgy7JPRhE6n47lnF7Nl808AxMZGsnzFQqshAFyJc/mF+u2gYNMuxCHD4/Xb+/c2XwTcmBSjKPnWIrK7E2qps868L2whL/+i3efsP/4LlY3jwnpHBePpYdnR79vdEHblzEXb18BUM4IghADbgFXAJKAr4AOEAbcCy4B9giAo4307Gbd2woYOHUDHjkEA7N17xCT6tzFFRVfYsGE3IE1rHjNm6K9Khhp00GTYJwOkpVfmz1/Khg3SOok9enRl+YpXCQ0NtiuftqShoYEfvjug/91voOl6gpHRnYnrLXVjncsvJDUly2w+NTV1fPONITDt+AkjFbjatkEtddZZ94UtNDQ0sHbtdrvPq67VsT1NapHt4O/DpJvMr38JcEtiV8JCGxenv1RO7sVy2bTOpC0H5guC4AMkIzlbAGeBl4DfAs8Cxxv3JwIbBUFwn69JGdzaCfPy8uTRR6cC0hTjefMWU1pqGvCxpqaWefMW62PQTJ8+ya5WADXIUIMOmgz7ZIiiyCsvf0TydzsBiI4OZ8Vnr9G5c4jNeSjJZyuSOXzYvMPURFVlNa+/sIpTWY0vtSA/xowf1Czdw38aq9/++xvruHTRdLmZhoYGFi/6Vh+kddy4/2/v3uO9mvM9jr/eXehGMaLdidy6KIqxo+HUyBCOw6BRZhoMDcYhjhkPcZiLawaDiCM6RoxTkfsMopty6Sahi0hX5Xp0oZFun/PH97vr127/9qV2e/3W6vN8PHq01net31qf72/v3/591vf7Xd91FK1b5/9yTJus/M7WxDmGDHmB6dPLbzFd9e139LtqALNnzSt3v3zuHfEea9eFbu/rzj2cVi0ab7HPPns14oY+nTauD35h9hb77KAuBrrE5WlARzO7ycyGmdkdhORrZNzejpCgpZrMyr97o3B8WGaga9as5bzzfs/UqTMBKCrag169TqRly+Z89tlXjBjxKh9/vBgIXTHDht2+2V04lZGFc2ShDn6OLc9hrC/z+Hfe+RgPDnoKCHeP9bv6PJo1q3gg+tFHH0b9+juXKs1/rfbJ4s8YMWLUZmVz5ixg7Ngw/qy4uB3FxQdvtr37CT/ivoHDGD16Ei33bU7nIzvQbL96NGnSkFq1xPJlq/jwgyVMGDODlSvCHXC169Ti+tt+SddjDykzjj/1+xtjRr4LhEccndqjM/u3KmLF8lWM/PvbzJ4R3sumTXfniSdvp6ho04D+ra1Du3YH5H1fqut9Kn2OfK0KafqdralzbLAtpyy59JL+jB49mZYti+jc+RBatWpJk912oXbtWnz/PTRp3IL585dsfJRR27Zt6NYtNMqYrQL+ufFY9z/zOSMnLWLWgi2fMXnBqe3o1zsM7F+9Zh0jxs7jnQ+/ZINBhwN/wJndDqBR/TAebPz0pfS5dSz5vornDu99c6mixsClcXkR8Fip7dOAp8s+WsU22KxqTwpqqV2FzWFxnNdSoClgwCFmNrOM/fYE5gENge+BfzGz/6veiGtO6pMwgBUrvuWyy/ozceJ7eV/dvv0BDBz4XzRvXv4zybJ8jizUwc+xuXxJ2NlnX8uUyVv8/arQqNGDaNFir1Kl+ZOwSZPe59xzrq3SOW7pfzmjR01k9OhJldq/eYvdufK6HhR3bp13nzVr1tH/D8MZ/fL0vPvss08z7r33Gtq03W+z8q2twxln/KTS+1fXOcrr2knL72xNnaO8JKwsRxxxBI89VjqfKd9V97/F06+V3WJ28Wnt6XvmIexUp3be17/41kKuuv8tVq8p+3MMMHd47yrFBAwBflXVF5UwZld7UiAOqkwS1p1NrVyjzOz4cvYdDPSJq33M7OFtjzIZmbjDoHHjRjzyyE289NLrPPfcGGbNmseyZStp3LgRBx64Dyef3JUzzjiOOuV8GHaEc2ShDn6ObLil/+W8+cZ0pkydwQez57Nw8RJWLl/FBjMaNNiZPZs1oVWb5hx9THuO6noQdeuW/6dqp53q8Mdbe3PiKYfz4rNTmPn+IpZ//S31G+5Mi733oNvxHTj/l2cX9Jxo2yorv7Pb8xw339KXk998l6lTZvLBB/NZvPhzli//BjOr9sl7//vZmbw6ZTG9jmtFlw5FNNu9AXXqiC+Xr2banC95cuzHTJz5ebWeM+W65yy/XMG+L7MpCTsRSG0SlomWMOd2VPlawqrX9h86+sV35Y/TqQ571m9T8U4Fzmcfr7yyWsKqU+uz3tmuxy8xd3jvGv2hG3O2Q0tYm8q0hL0MnBBXu5nZuHL23ReYH1dnm1m7bQwxMakemO+cc865TMgdb7Cggn0/gY1XoK2U4kn/MtEd6Zxzzrltl2Bra+7cOV/l3Qsws3WSVgK7EfKYhsC35b2mUKWoO7LqJF1oZg8mHce2yEIdIBv1yEIdwOtRSLJQB8hGPbJQh0Il6ULgwpyiB0u/15LWACWPEKhrVn5/sqQlQPO42tzMqj67bgHIehI21cyKk45jW2ShDpCNemShDuD1KCRZqANkox5ZqEOa7ahJmI8Jc84551zScrsTK3Mbc+7trIXxuIGt4EmYc84555K2PGd5j/J2jBO7ljwqYS2wansFtb1lPQnLQv9+FuoA2ahHFuoAXo9CkoU6QDbqkYU6pNmHOcv7VrBvC6Bkori5luJxVZkeE+acc865wifpDuB3cfVKM/tLOfv+DHgyrj5pZj23d3zbS9ZbwpxzzjlX+EbmLJ+Qd6/gxJzlimbXL2jeEuacc865RG3lA7xXAy3S/ABvbwlzzjnnXKLilBQ3x1UBj0raLXcfSfUIDyhvGIsGpjkBg4y0hElqAVwMHAU0i8WfAW8Ag8xscVKxOZBU18zWJh2Hc865wiVpJ2AU0CUWLQYGAXMJg/H7AAfFbbOAo8xsRU3HWZ1Sn4RJ+lfgJeBT4BWg5LH0ewHHA0XASWb2RjIRujgJX0czm510LM455wpXbP0aARxbzm7TgNPNbFHNRLX9ZCEJmwq8aWaX5dk+gJAtd6rZyKpOUhPgaGAZ8FbubbeSGgK/M7MbkoqvIpLuybPpEmAo8DVAvp9VoZDUBfjCzObE9f8g1GEfYCGhCfyBBEOsFEm1gGuAI4F/mNkgSefFslrA08B1ZrYmwTArJf7+/4KyW7uHmlkq5gmKP5ODgGVmtrTUtnpATzN7NJHgtoGkRcBPzOyjpGOpDEltgG/NbElcPwm4lM0/46ke8J1m8YHcPYGzgcMI84YtA2YCw4C/VjSjflpkIQn7Dji05AuzjO1tgXfMrH5Z2wuFpPaEZtimhC/IaUAPM1sYt+8FLDWz2vmPkixJG4B32XzSPYAfA1MJE+qZmZV3hZM4STOAvmY2VtIlwK3APcBsoA3QF7jWzO5LMMwKSbqRkDw+T7iqfCSu3wlsAK4gdNf/PqkYK0NSO+BVYBdgPJu3dnchzJbd3cxmJRNh5Ujam9Bq344w8Ph54HwzWxa3p+Ez/ts8m24j/F59BmBmd9ZYUFshXrxfZ2YvS+oJPA48QfiMtwZ6AWeb2RMJhul2AFlIwuYBN5nZw3m29yF8Ye5fs5FVjaTngXWEzH9XYADhqr+bmX2Ukj/Q1wAXAOeZ2Ws55WsJ3ZEF/SVZIib2bc1soaR3gLvNbEjO9jOBG82sbWJBVkL8bFxmZn+Picz7wDlm9njcfjpwu5kdmGScFZE0FvgCONfMVpfaVo+QXO5lZt0SCK/SJD0O7A1cBDQG/kL4rB9rZl+m5DO+AVhC+FuVqyXhzra1hAutQv97uwpob2YLJE0mtKbelbP9AuASMzs0sSDdDqFO0gFUgzuAByQdQbhaLj0m7FfAfyYTWpV0JiRcqwgtRj0l3QmMk9QNKPjBh2bWP35h/k3SE4QrzQ1Jx7UVviE0fy8kPCB2eqnt0wjdFoWuCHgPwMxmSVrP5nWZFvcpdEcCxaUTMAAzWy3pJmByzYdVZd2AU0vGRko6htAC81pcToOHgE7Az3N7H+KFVsG3RuZYQ0iEIczOPrrU9jHA3TUZkNsxpX6KCjO7n9B6dCihr3h8/Dcslp2ThvE7wM6ELoqNzOy3hCbycWy6I6SgmdlE4HDgAGCSpFYJh7Q1XiSMDwEYSxibkKsXmz9io1B9ChwMG8fA1CZ0hZVoT2hhKnTLCF1E+bSK+xS6Xcm5mIp3DP+cMM7lNVKQEJvZRcAtwChJFyYdzzYYA/SOy28TEuRcxwKf1GhEboeUhZYwzGw4MFxSXTY9+POrlE2LMAcoJtx2u5GZXREH8z6XSFRbId4y3Cs26b9B+pL9q4E3JE0AJgFXSOrKpjFhnYHTEoyvsh4nzLXzAuFLpj9wR+z22kCo54gE46ush4AhkvpTdmt3P+CuPK8tJB8DHYGNg9fNbL2kswgXWy8kFVhVmNkISVOA/40D2n+ddExb4RrgdUlFhIv2myQVs+kz3gtIc5LpUiL1Y8KyIo6n6mpmJ+XZfh9wsZmlKqGR1Br4EfCMma1MOp7KktSY8OX+U2B/QiL5KSGpvMvMpiYYXqXE5P1qwvv/upn9OX7h3wY0IHzpX5qGOwsl9QMuJ9wZWfJHS4SB4Heb2W1JxVZZkv5MuIloi0eyxNnCRxC6K1PxGZdUG7gBOJfwc+mQou5IJO1LmBz0FKBRLF4HTAFuM7PUXPi69PIkzDmXGpL2I2eKCjObn2Q8VRETrQb5LkZiUtOi5I7otIjj2X4M3GdmXyUcTpXF6RD2JFxopa0HxaWcJ2HOuVSLUz9cb2bnJx3LtshCPbJQB8hOPVzh8yTMOZdqkjoC0wp5aofKyEI9slAHyE49XOHLxMB851x2STqngl3SMF1IJuqRhTpAdurh0s9bwpxzBS1OEPpPSk3hkqMWUK/QWy2yUI8s1AGyUw+Xfqm4C8c5t0NbSpjvb5ey/hGet5oGWahHFuoA2amHSzlPwpxzhe5t4IflbDfCdBWFLgv1yEIdIDv1cCnnY8Kcc4XuDjbN41SWuWw543khykI9slAHyE49XMr5mDDnnHPOuQR4d6RzzjnnXAI8CXPOOeecS4AnYc4lTNJ6SdMlzZD0pKQG23CsRyT9LC4PltSunH2PkXTUVpxjgaQ9SpX9VdJFpcpOk/RSZWJ1zrkdkSdhziXvOzM71MwOBtYAv8ndGJ85WGVm9usKHqh8DFDlJCyPocBZpcrOiuXOOefK4EmYc4VlAnBgbKWaIOl5YJak2pJulzRF0nslrU4KBkqaI2kU4UHExG3jJBXH5RMlTZP0rqTRkvYlJHtXxFa4LpKaSnoqnmOKpKPja38g6RVJMyUNpuxb90cDbSUVxdc0BI4DnpX0h3i8GZIejA9M3kxu65qkYknjSo4j6WFJkyW9I+mnsbx9LJse349W1fDeO+dcjfIkzLkCEVu8TgLej0U/BC43s9ZAH2CFmXUCOgEXSNoPOB1oA7QDzqGMli1JTYGHgB5m1hE408wWAA8Ad8VWuAnAgLjeCegBDI6H+CPwupm1B56hjEe6mNl64CmgZyw6BRhnZiuBgWbWKbb01Qf+vQpvy7XAGDM7gjBlwO0xwfsNMMDMDgWKgU+qcEznnCsIPk+Yc8mrL2l6XJ4A/A8hmZpsZvNjeXegQ84YqsZAK6ArMDQmQUsljSnj+J2B8SXHMrOv88RxHNAup6FqV0mN4jnOiK/9h6RleV4/lDD/0gBCV+RjsbybpKuABsDuwEzghTzHKK07cKqkK+N6PUIS+BZwraQWwNNm9lElj+eccwXDkzDnkvddbNHZKCZCq3KLgL5mNrLUfv9WjXHUAkPDUl0AAAGASURBVDqb2eoyYqmMN4EiSR0JSeRZkuoB9wPFZrZY0p8IiVRp69jUMp+7XYQWvDml9p8taRJwMvCipIvMrKwE1DnnCpZ3RzqXDiOBiyXVBZDUOnbLjQd6xTFjRZQ9y/dEoGvsvkTS7rH8G2CXnP1eAfqWrEgqSQzHA7+IZScBu5UVoIWZn4cDQ4CXYjJXklB9FVvV8t0NuQA4PC73KFXvviXjyCQdFv/fH5hnZvcAzwEd8hzXOecKlidhzqXDYGAWME3SDGAQoSX7GeCjuO1RQjfdZszsS+BC4GlJ7xISJQhdgqeXDMwHLgOK40D3WWy6S/N6QhI3k9AtuaicOIcCHeP/mNlywni0GYSEakqe110PDJA0FVifU34jUBd4L57/xljeE5gRu3EPjnV3zrlU8ccWOeecc84lwFvCnHPOOecS4EmYc84551wCPAlzzjnnnEuAJ2HOOeeccwnwJMw555xzLgGehDnnnHPOJcCTMOecc865BHgS5pxzzjmXgP8HdmY1XohsskEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 720x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Experment (4)"
      ],
      "metadata": {
        "id": "vwYabYPrCzJ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelc4 = Sequential()\n",
        "\n",
        "input_shape=X_train2.shape[1:]\n",
        "\n",
        "modelc4.add(Conv2D(filters=16, kernel_size=2, input_shape=input_shape, activation='relu'))\n",
        "modelc4.add(MaxPooling2D(pool_size=(2,2)))\n",
        "modelc4.add(Dropout(0.8))\n",
        "\n",
        "modelc4.add(Conv2D(filters=32, kernel_size=2, activation='relu'))\n",
        "modelc4.add(MaxPooling2D(pool_size=(2,2)))\n",
        "modelc4.add(Dropout(0.5))\n",
        "\n",
        "modelc4.add(Conv2D(filters=64, kernel_size=2, activation='relu'))\n",
        "modelc4.add(MaxPooling2D(pool_size=(2,2)))\n",
        "modelc4.add(Dropout(0.5))\n",
        "\n",
        "modelc4.add(Conv2D(filters=128, kernel_size=2, activation='relu'))\n",
        "modelc4.add(MaxPooling2D(pool_size=(2,2)))\n",
        "modelc4.add(Dropout(0.4))\n",
        "modelc4.add(GlobalAveragePooling2D())\n",
        "modelc4.add(Flatten())\n",
        "\n",
        "modelc4.add(Dense(units = num_labels, activation=\"softmax\"))\n",
        "\n",
        "modelc4.summary()\n",
        "\n",
        "modelc4.compile(loss = 'categorical_crossentropy', \n",
        "              metrics = ['accuracy'],\n",
        "              optimizer = 'adam')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrkKsjd1CTmL",
        "outputId": "c78a8b31-b9e2-4860-b646-892e0eb0f114"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_15 (Conv2D)          (None, 39, 173, 16)       80        \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (None, 19, 86, 16)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 19, 86, 16)        0         \n",
            "                                                                 \n",
            " conv2d_16 (Conv2D)          (None, 18, 85, 32)        2080      \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPooling  (None, 9, 42, 32)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 9, 42, 32)         0         \n",
            "                                                                 \n",
            " conv2d_17 (Conv2D)          (None, 8, 41, 64)         8256      \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPooling  (None, 4, 20, 64)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 4, 20, 64)         0         \n",
            "                                                                 \n",
            " conv2d_18 (Conv2D)          (None, 3, 19, 128)        32896     \n",
            "                                                                 \n",
            " max_pooling2d_10 (MaxPoolin  (None, 1, 9, 128)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 1, 9, 128)         0         \n",
            "                                                                 \n",
            " global_average_pooling2d_1   (None, 128)              0         \n",
            " (GlobalAveragePooling2D)                                        \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 18)                2322      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 45,634\n",
            "Trainable params: 45,634\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "es = EarlyStopping(monitor='val_accuracy', min_delta= 0.01 , patience= 50, verbose= 1, mode='auto')\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath='new2(4).hdf5', \n",
        "                               verbose=1, save_best_only=True)\n",
        "start = datetime.now()\n",
        "\n",
        "\n",
        "modelc4.fit(X_train2, y_train,\n",
        "          batch_size = 50, \n",
        "          epochs = 500,\n",
        "          validation_data = (X_val2, y_val), \n",
        "          callbacks=[checkpointer, es])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPJ2uyl9DZBW",
        "outputId": "afb46a16-7edf-4fb3-cf6e-8703b26fcf77"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 2.4577 - accuracy: 0.1623\n",
            "Epoch 00001: val_loss improved from inf to 2.63796, saving model to new2(4).hdf5\n",
            "127/127 [==============================] - 2s 13ms/step - loss: 2.4577 - accuracy: 0.1623 - val_loss: 2.6380 - val_accuracy: 0.2112\n",
            "Epoch 2/500\n",
            "123/127 [============================>.] - ETA: 0s - loss: 2.2167 - accuracy: 0.2522\n",
            "Epoch 00002: val_loss improved from 2.63796 to 2.49812, saving model to new2(4).hdf5\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 2.2120 - accuracy: 0.2535 - val_loss: 2.4981 - val_accuracy: 0.2306\n",
            "Epoch 3/500\n",
            "126/127 [============================>.] - ETA: 0s - loss: 2.0473 - accuracy: 0.3029\n",
            "Epoch 00003: val_loss improved from 2.49812 to 2.47906, saving model to new2(4).hdf5\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 2.0445 - accuracy: 0.3043 - val_loss: 2.4791 - val_accuracy: 0.2405\n",
            "Epoch 4/500\n",
            "123/127 [============================>.] - ETA: 0s - loss: 1.9287 - accuracy: 0.3470\n",
            "Epoch 00004: val_loss improved from 2.47906 to 2.46623, saving model to new2(4).hdf5\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.9318 - accuracy: 0.3478 - val_loss: 2.4662 - val_accuracy: 0.2486\n",
            "Epoch 5/500\n",
            "126/127 [============================>.] - ETA: 0s - loss: 1.8504 - accuracy: 0.3873\n",
            "Epoch 00005: val_loss improved from 2.46623 to 2.35845, saving model to new2(4).hdf5\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.8470 - accuracy: 0.3893 - val_loss: 2.3584 - val_accuracy: 0.2831\n",
            "Epoch 6/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.7746 - accuracy: 0.4102\n",
            "Epoch 00006: val_loss improved from 2.35845 to 2.20603, saving model to new2(4).hdf5\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.7746 - accuracy: 0.4102 - val_loss: 2.2060 - val_accuracy: 0.3114\n",
            "Epoch 7/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 1.7226 - accuracy: 0.4294\n",
            "Epoch 00007: val_loss improved from 2.20603 to 2.17286, saving model to new2(4).hdf5\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.7216 - accuracy: 0.4290 - val_loss: 2.1729 - val_accuracy: 0.3592\n",
            "Epoch 8/500\n",
            "126/127 [============================>.] - ETA: 0s - loss: 1.6764 - accuracy: 0.4489\n",
            "Epoch 00008: val_loss improved from 2.17286 to 2.06447, saving model to new2(4).hdf5\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.6774 - accuracy: 0.4480 - val_loss: 2.0645 - val_accuracy: 0.3908\n",
            "Epoch 9/500\n",
            "126/127 [============================>.] - ETA: 0s - loss: 1.6420 - accuracy: 0.4538\n",
            "Epoch 00009: val_loss improved from 2.06447 to 2.01817, saving model to new2(4).hdf5\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.6409 - accuracy: 0.4542 - val_loss: 2.0182 - val_accuracy: 0.3998\n",
            "Epoch 10/500\n",
            "126/127 [============================>.] - ETA: 0s - loss: 1.6098 - accuracy: 0.4697\n",
            "Epoch 00010: val_loss improved from 2.01817 to 1.93260, saving model to new2(4).hdf5\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.6099 - accuracy: 0.4693 - val_loss: 1.9326 - val_accuracy: 0.4263\n",
            "Epoch 11/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.5884 - accuracy: 0.4794\n",
            "Epoch 00011: val_loss did not improve from 1.93260\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.5884 - accuracy: 0.4794 - val_loss: 1.9358 - val_accuracy: 0.4121\n",
            "Epoch 12/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 1.5613 - accuracy: 0.4963\n",
            "Epoch 00012: val_loss improved from 1.93260 to 1.87977, saving model to new2(4).hdf5\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.5598 - accuracy: 0.4959 - val_loss: 1.8798 - val_accuracy: 0.4244\n",
            "Epoch 13/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.5402 - accuracy: 0.4950\n",
            "Epoch 00013: val_loss did not improve from 1.87977\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.5402 - accuracy: 0.4950 - val_loss: 1.9272 - val_accuracy: 0.3847\n",
            "Epoch 14/500\n",
            "126/127 [============================>.] - ETA: 0s - loss: 1.5067 - accuracy: 0.5102\n",
            "Epoch 00014: val_loss did not improve from 1.87977\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.5057 - accuracy: 0.5106 - val_loss: 1.8830 - val_accuracy: 0.4164\n",
            "Epoch 15/500\n",
            "126/127 [============================>.] - ETA: 0s - loss: 1.4868 - accuracy: 0.5129\n",
            "Epoch 00015: val_loss improved from 1.87977 to 1.77901, saving model to new2(4).hdf5\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.4868 - accuracy: 0.5124 - val_loss: 1.7790 - val_accuracy: 0.4664\n",
            "Epoch 16/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.4712 - accuracy: 0.5216\n",
            "Epoch 00016: val_loss did not improve from 1.77901\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.4712 - accuracy: 0.5216 - val_loss: 1.7964 - val_accuracy: 0.4423\n",
            "Epoch 17/500\n",
            "126/127 [============================>.] - ETA: 0s - loss: 1.4506 - accuracy: 0.5283\n",
            "Epoch 00017: val_loss improved from 1.77901 to 1.77687, saving model to new2(4).hdf5\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.4520 - accuracy: 0.5274 - val_loss: 1.7769 - val_accuracy: 0.4490\n",
            "Epoch 18/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.4267 - accuracy: 0.5392\n",
            "Epoch 00018: val_loss improved from 1.77687 to 1.72720, saving model to new2(4).hdf5\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.4267 - accuracy: 0.5392 - val_loss: 1.7272 - val_accuracy: 0.4589\n",
            "Epoch 19/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.4080 - accuracy: 0.5332\n",
            "Epoch 00019: val_loss improved from 1.72720 to 1.72653, saving model to new2(4).hdf5\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.4080 - accuracy: 0.5332 - val_loss: 1.7265 - val_accuracy: 0.4716\n",
            "Epoch 20/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 1.4053 - accuracy: 0.5357\n",
            "Epoch 00020: val_loss did not improve from 1.72653\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.4083 - accuracy: 0.5347 - val_loss: 1.7890 - val_accuracy: 0.4367\n",
            "Epoch 21/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.4057 - accuracy: 0.5395\n",
            "Epoch 00021: val_loss did not improve from 1.72653\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.4057 - accuracy: 0.5395 - val_loss: 1.7906 - val_accuracy: 0.4414\n",
            "Epoch 22/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.3801 - accuracy: 0.5460\n",
            "Epoch 00022: val_loss improved from 1.72653 to 1.70245, saving model to new2(4).hdf5\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.3801 - accuracy: 0.5460 - val_loss: 1.7024 - val_accuracy: 0.4759\n",
            "Epoch 23/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.3629 - accuracy: 0.5528\n",
            "Epoch 00023: val_loss improved from 1.70245 to 1.64451, saving model to new2(4).hdf5\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.3629 - accuracy: 0.5528 - val_loss: 1.6445 - val_accuracy: 0.4863\n",
            "Epoch 24/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.3612 - accuracy: 0.5555\n",
            "Epoch 00024: val_loss did not improve from 1.64451\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.3612 - accuracy: 0.5555 - val_loss: 1.6936 - val_accuracy: 0.4683\n",
            "Epoch 25/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.3532 - accuracy: 0.5594\n",
            "Epoch 00025: val_loss did not improve from 1.64451\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.3532 - accuracy: 0.5594 - val_loss: 1.6569 - val_accuracy: 0.4891\n",
            "Epoch 26/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.3325 - accuracy: 0.5652\n",
            "Epoch 00026: val_loss improved from 1.64451 to 1.63026, saving model to new2(4).hdf5\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.3325 - accuracy: 0.5652 - val_loss: 1.6303 - val_accuracy: 0.4924\n",
            "Epoch 27/500\n",
            "126/127 [============================>.] - ETA: 0s - loss: 1.3311 - accuracy: 0.5668\n",
            "Epoch 00027: val_loss did not improve from 1.63026\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.3311 - accuracy: 0.5671 - val_loss: 1.6655 - val_accuracy: 0.4825\n",
            "Epoch 28/500\n",
            "126/127 [============================>.] - ETA: 0s - loss: 1.3246 - accuracy: 0.5643\n",
            "Epoch 00028: val_loss did not improve from 1.63026\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.3268 - accuracy: 0.5633 - val_loss: 1.6467 - val_accuracy: 0.4731\n",
            "Epoch 29/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 1.3212 - accuracy: 0.5626\n",
            "Epoch 00029: val_loss improved from 1.63026 to 1.61801, saving model to new2(4).hdf5\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.3174 - accuracy: 0.5643 - val_loss: 1.6180 - val_accuracy: 0.4976\n",
            "Epoch 30/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 1.3062 - accuracy: 0.5736\n",
            "Epoch 00030: val_loss improved from 1.61801 to 1.58207, saving model to new2(4).hdf5\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.3068 - accuracy: 0.5726 - val_loss: 1.5821 - val_accuracy: 0.5028\n",
            "Epoch 31/500\n",
            "126/127 [============================>.] - ETA: 0s - loss: 1.2940 - accuracy: 0.5722\n",
            "Epoch 00031: val_loss did not improve from 1.58207\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.2932 - accuracy: 0.5721 - val_loss: 1.5875 - val_accuracy: 0.5057\n",
            "Epoch 32/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 1.2863 - accuracy: 0.5781\n",
            "Epoch 00032: val_loss improved from 1.58207 to 1.49036, saving model to new2(4).hdf5\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.2888 - accuracy: 0.5780 - val_loss: 1.4904 - val_accuracy: 0.5274\n",
            "Epoch 33/500\n",
            "126/127 [============================>.] - ETA: 0s - loss: 1.2711 - accuracy: 0.5833\n",
            "Epoch 00033: val_loss did not improve from 1.49036\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.2701 - accuracy: 0.5835 - val_loss: 1.5587 - val_accuracy: 0.5052\n",
            "Epoch 34/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.2862 - accuracy: 0.5876\n",
            "Epoch 00034: val_loss did not improve from 1.49036\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.2862 - accuracy: 0.5876 - val_loss: 1.5448 - val_accuracy: 0.5000\n",
            "Epoch 35/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.2802 - accuracy: 0.5786\n",
            "Epoch 00035: val_loss did not improve from 1.49036\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.2802 - accuracy: 0.5786 - val_loss: 1.5054 - val_accuracy: 0.5383\n",
            "Epoch 36/500\n",
            "126/127 [============================>.] - ETA: 0s - loss: 1.2529 - accuracy: 0.5925\n",
            "Epoch 00036: val_loss did not improve from 1.49036\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.2539 - accuracy: 0.5917 - val_loss: 1.5697 - val_accuracy: 0.5161\n",
            "Epoch 37/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 1.2596 - accuracy: 0.5907\n",
            "Epoch 00037: val_loss did not improve from 1.49036\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.2601 - accuracy: 0.5907 - val_loss: 1.5056 - val_accuracy: 0.5180\n",
            "Epoch 38/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 1.2515 - accuracy: 0.5906\n",
            "Epoch 00038: val_loss did not improve from 1.49036\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.2503 - accuracy: 0.5911 - val_loss: 1.5344 - val_accuracy: 0.5265\n",
            "Epoch 39/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.2412 - accuracy: 0.5983\n",
            "Epoch 00039: val_loss did not improve from 1.49036\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.2412 - accuracy: 0.5983 - val_loss: 1.5127 - val_accuracy: 0.5250\n",
            "Epoch 40/500\n",
            "124/127 [============================>.] - ETA: 0s - loss: 1.2516 - accuracy: 0.5908\n",
            "Epoch 00040: val_loss did not improve from 1.49036\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.2513 - accuracy: 0.5914 - val_loss: 1.5478 - val_accuracy: 0.5208\n",
            "Epoch 41/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.2378 - accuracy: 0.5955\n",
            "Epoch 00041: val_loss improved from 1.49036 to 1.43172, saving model to new2(4).hdf5\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.2378 - accuracy: 0.5955 - val_loss: 1.4317 - val_accuracy: 0.5525\n",
            "Epoch 42/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.2279 - accuracy: 0.5940\n",
            "Epoch 00042: val_loss did not improve from 1.43172\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.2279 - accuracy: 0.5940 - val_loss: 1.4765 - val_accuracy: 0.5326\n",
            "Epoch 43/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.2152 - accuracy: 0.6055\n",
            "Epoch 00043: val_loss did not improve from 1.43172\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.2152 - accuracy: 0.6055 - val_loss: 1.4540 - val_accuracy: 0.5440\n",
            "Epoch 44/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.2248 - accuracy: 0.5978\n",
            "Epoch 00044: val_loss did not improve from 1.43172\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.2248 - accuracy: 0.5978 - val_loss: 1.5417 - val_accuracy: 0.5255\n",
            "Epoch 45/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 1.2208 - accuracy: 0.6011\n",
            "Epoch 00045: val_loss did not improve from 1.43172\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.2192 - accuracy: 0.6016 - val_loss: 1.5189 - val_accuracy: 0.5265\n",
            "Epoch 46/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.2129 - accuracy: 0.6037\n",
            "Epoch 00046: val_loss did not improve from 1.43172\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.2129 - accuracy: 0.6037 - val_loss: 1.4518 - val_accuracy: 0.5354\n",
            "Epoch 47/500\n",
            "126/127 [============================>.] - ETA: 0s - loss: 1.1974 - accuracy: 0.6098\n",
            "Epoch 00047: val_loss did not improve from 1.43172\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.1976 - accuracy: 0.6098 - val_loss: 1.4951 - val_accuracy: 0.5279\n",
            "Epoch 48/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.1895 - accuracy: 0.6142\n",
            "Epoch 00048: val_loss did not improve from 1.43172\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.1895 - accuracy: 0.6142 - val_loss: 1.4535 - val_accuracy: 0.5529\n",
            "Epoch 49/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 1.2013 - accuracy: 0.6008\n",
            "Epoch 00049: val_loss did not improve from 1.43172\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.2023 - accuracy: 0.6008 - val_loss: 1.4847 - val_accuracy: 0.5373\n",
            "Epoch 50/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.1848 - accuracy: 0.6089\n",
            "Epoch 00050: val_loss did not improve from 1.43172\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.1848 - accuracy: 0.6089 - val_loss: 1.4371 - val_accuracy: 0.5539\n",
            "Epoch 51/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.1860 - accuracy: 0.6073\n",
            "Epoch 00051: val_loss did not improve from 1.43172\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.1860 - accuracy: 0.6073 - val_loss: 1.4520 - val_accuracy: 0.5543\n",
            "Epoch 52/500\n",
            "126/127 [============================>.] - ETA: 0s - loss: 1.1828 - accuracy: 0.6170\n",
            "Epoch 00052: val_loss improved from 1.43172 to 1.42430, saving model to new2(4).hdf5\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.1843 - accuracy: 0.6161 - val_loss: 1.4243 - val_accuracy: 0.5539\n",
            "Epoch 53/500\n",
            "126/127 [============================>.] - ETA: 0s - loss: 1.1740 - accuracy: 0.6181\n",
            "Epoch 00053: val_loss improved from 1.42430 to 1.42352, saving model to new2(4).hdf5\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.1735 - accuracy: 0.6175 - val_loss: 1.4235 - val_accuracy: 0.5558\n",
            "Epoch 54/500\n",
            "126/127 [============================>.] - ETA: 0s - loss: 1.1784 - accuracy: 0.6189\n",
            "Epoch 00054: val_loss did not improve from 1.42352\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.1772 - accuracy: 0.6194 - val_loss: 1.4518 - val_accuracy: 0.5510\n",
            "Epoch 55/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 1.1749 - accuracy: 0.6142\n",
            "Epoch 00055: val_loss improved from 1.42352 to 1.42175, saving model to new2(4).hdf5\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.1795 - accuracy: 0.6141 - val_loss: 1.4218 - val_accuracy: 0.5595\n",
            "Epoch 56/500\n",
            "126/127 [============================>.] - ETA: 0s - loss: 1.1821 - accuracy: 0.6125\n",
            "Epoch 00056: val_loss did not improve from 1.42175\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.1846 - accuracy: 0.6117 - val_loss: 1.4245 - val_accuracy: 0.5491\n",
            "Epoch 57/500\n",
            "124/127 [============================>.] - ETA: 0s - loss: 1.1554 - accuracy: 0.6226\n",
            "Epoch 00057: val_loss improved from 1.42175 to 1.41392, saving model to new2(4).hdf5\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.1598 - accuracy: 0.6221 - val_loss: 1.4139 - val_accuracy: 0.5610\n",
            "Epoch 58/500\n",
            "126/127 [============================>.] - ETA: 0s - loss: 1.1674 - accuracy: 0.6198\n",
            "Epoch 00058: val_loss did not improve from 1.41392\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.1665 - accuracy: 0.6200 - val_loss: 1.4561 - val_accuracy: 0.5539\n",
            "Epoch 59/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 1.1530 - accuracy: 0.6282\n",
            "Epoch 00059: val_loss did not improve from 1.41392\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.1555 - accuracy: 0.6271 - val_loss: 1.4607 - val_accuracy: 0.5425\n",
            "Epoch 60/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.1495 - accuracy: 0.6296\n",
            "Epoch 00060: val_loss did not improve from 1.41392\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.1495 - accuracy: 0.6296 - val_loss: 1.4305 - val_accuracy: 0.5591\n",
            "Epoch 61/500\n",
            "126/127 [============================>.] - ETA: 0s - loss: 1.1470 - accuracy: 0.6217\n",
            "Epoch 00061: val_loss improved from 1.41392 to 1.35916, saving model to new2(4).hdf5\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.1511 - accuracy: 0.6204 - val_loss: 1.3592 - val_accuracy: 0.5836\n",
            "Epoch 62/500\n",
            "126/127 [============================>.] - ETA: 0s - loss: 1.1527 - accuracy: 0.6248\n",
            "Epoch 00062: val_loss did not improve from 1.35916\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.1503 - accuracy: 0.6256 - val_loss: 1.4208 - val_accuracy: 0.5562\n",
            "Epoch 63/500\n",
            "126/127 [============================>.] - ETA: 0s - loss: 1.1352 - accuracy: 0.6276\n",
            "Epoch 00063: val_loss did not improve from 1.35916\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.1354 - accuracy: 0.6279 - val_loss: 1.3955 - val_accuracy: 0.5643\n",
            "Epoch 64/500\n",
            "126/127 [============================>.] - ETA: 0s - loss: 1.1356 - accuracy: 0.6262\n",
            "Epoch 00064: val_loss did not improve from 1.35916\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.1354 - accuracy: 0.6260 - val_loss: 1.3966 - val_accuracy: 0.5614\n",
            "Epoch 65/500\n",
            "126/127 [============================>.] - ETA: 0s - loss: 1.1342 - accuracy: 0.6292\n",
            "Epoch 00065: val_loss did not improve from 1.35916\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.1351 - accuracy: 0.6293 - val_loss: 1.3677 - val_accuracy: 0.5780\n",
            "Epoch 66/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 1.1255 - accuracy: 0.6341\n",
            "Epoch 00066: val_loss did not improve from 1.35916\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.1254 - accuracy: 0.6337 - val_loss: 1.4113 - val_accuracy: 0.5671\n",
            "Epoch 67/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.1088 - accuracy: 0.6375\n",
            "Epoch 00067: val_loss did not improve from 1.35916\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.1088 - accuracy: 0.6375 - val_loss: 1.3976 - val_accuracy: 0.5643\n",
            "Epoch 68/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 1.1359 - accuracy: 0.6285\n",
            "Epoch 00068: val_loss did not improve from 1.35916\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.1363 - accuracy: 0.6284 - val_loss: 1.3782 - val_accuracy: 0.5685\n",
            "Epoch 69/500\n",
            "126/127 [============================>.] - ETA: 0s - loss: 1.1222 - accuracy: 0.6327\n",
            "Epoch 00069: val_loss did not improve from 1.35916\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.1214 - accuracy: 0.6328 - val_loss: 1.3862 - val_accuracy: 0.5591\n",
            "Epoch 70/500\n",
            "126/127 [============================>.] - ETA: 0s - loss: 1.1063 - accuracy: 0.6435\n",
            "Epoch 00070: val_loss did not improve from 1.35916\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.1059 - accuracy: 0.6437 - val_loss: 1.4286 - val_accuracy: 0.5468\n",
            "Epoch 71/500\n",
            "126/127 [============================>.] - ETA: 0s - loss: 1.1253 - accuracy: 0.6308\n",
            "Epoch 00071: val_loss did not improve from 1.35916\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.1248 - accuracy: 0.6312 - val_loss: 1.3711 - val_accuracy: 0.5865\n",
            "Epoch 72/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.1283 - accuracy: 0.6279\n",
            "Epoch 00072: val_loss did not improve from 1.35916\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.1283 - accuracy: 0.6279 - val_loss: 1.4419 - val_accuracy: 0.5629\n",
            "Epoch 73/500\n",
            "124/127 [============================>.] - ETA: 0s - loss: 1.1082 - accuracy: 0.6410\n",
            "Epoch 00073: val_loss did not improve from 1.35916\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.1066 - accuracy: 0.6413 - val_loss: 1.3722 - val_accuracy: 0.5747\n",
            "Epoch 74/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.1028 - accuracy: 0.6342\n",
            "Epoch 00074: val_loss did not improve from 1.35916\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.1028 - accuracy: 0.6342 - val_loss: 1.4546 - val_accuracy: 0.5454\n",
            "Epoch 75/500\n",
            "126/127 [============================>.] - ETA: 0s - loss: 1.1071 - accuracy: 0.6397\n",
            "Epoch 00075: val_loss did not improve from 1.35916\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.1086 - accuracy: 0.6397 - val_loss: 1.3718 - val_accuracy: 0.5836\n",
            "Epoch 76/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.1066 - accuracy: 0.6429\n",
            "Epoch 00076: val_loss did not improve from 1.35916\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.1066 - accuracy: 0.6429 - val_loss: 1.3795 - val_accuracy: 0.5747\n",
            "Epoch 77/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.1095 - accuracy: 0.6383\n",
            "Epoch 00077: val_loss did not improve from 1.35916\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.1095 - accuracy: 0.6383 - val_loss: 1.4374 - val_accuracy: 0.5529\n",
            "Epoch 78/500\n",
            "126/127 [============================>.] - ETA: 0s - loss: 1.1046 - accuracy: 0.6362\n",
            "Epoch 00078: val_loss did not improve from 1.35916\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.1054 - accuracy: 0.6355 - val_loss: 1.4093 - val_accuracy: 0.5714\n",
            "Epoch 79/500\n",
            "126/127 [============================>.] - ETA: 0s - loss: 1.0951 - accuracy: 0.6376\n",
            "Epoch 00079: val_loss did not improve from 1.35916\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.0940 - accuracy: 0.6375 - val_loss: 1.3641 - val_accuracy: 0.5714\n",
            "Epoch 80/500\n",
            "126/127 [============================>.] - ETA: 0s - loss: 1.0770 - accuracy: 0.6427\n",
            "Epoch 00080: val_loss did not improve from 1.35916\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.0751 - accuracy: 0.6432 - val_loss: 1.4051 - val_accuracy: 0.5572\n",
            "Epoch 81/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.0975 - accuracy: 0.6377\n",
            "Epoch 00081: val_loss did not improve from 1.35916\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.0975 - accuracy: 0.6377 - val_loss: 1.3697 - val_accuracy: 0.5690\n",
            "Epoch 82/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.1105 - accuracy: 0.6375\n",
            "Epoch 00082: val_loss did not improve from 1.35916\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.1105 - accuracy: 0.6375 - val_loss: 1.3899 - val_accuracy: 0.5709\n",
            "Epoch 83/500\n",
            "126/127 [============================>.] - ETA: 0s - loss: 1.1054 - accuracy: 0.6375\n",
            "Epoch 00083: val_loss improved from 1.35916 to 1.33824, saving model to new2(4).hdf5\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.1054 - accuracy: 0.6369 - val_loss: 1.3382 - val_accuracy: 0.5851\n",
            "Epoch 84/500\n",
            "126/127 [============================>.] - ETA: 0s - loss: 1.0758 - accuracy: 0.6457\n",
            "Epoch 00084: val_loss did not improve from 1.33824\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.0761 - accuracy: 0.6456 - val_loss: 1.3839 - val_accuracy: 0.5690\n",
            "Epoch 85/500\n",
            "126/127 [============================>.] - ETA: 0s - loss: 1.0976 - accuracy: 0.6375\n",
            "Epoch 00085: val_loss did not improve from 1.33824\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.0975 - accuracy: 0.6375 - val_loss: 1.4161 - val_accuracy: 0.5624\n",
            "Epoch 86/500\n",
            "126/127 [============================>.] - ETA: 0s - loss: 1.0864 - accuracy: 0.6406\n",
            "Epoch 00086: val_loss did not improve from 1.33824\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.0885 - accuracy: 0.6402 - val_loss: 1.4010 - val_accuracy: 0.5600\n",
            "Epoch 87/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 1.0852 - accuracy: 0.6446\n",
            "Epoch 00087: val_loss did not improve from 1.33824\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.0851 - accuracy: 0.6448 - val_loss: 1.3966 - val_accuracy: 0.5666\n",
            "Epoch 88/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.0803 - accuracy: 0.6470\n",
            "Epoch 00088: val_loss did not improve from 1.33824\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.0803 - accuracy: 0.6470 - val_loss: 1.3500 - val_accuracy: 0.5775\n",
            "Epoch 89/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 1.0725 - accuracy: 0.6480\n",
            "Epoch 00089: val_loss did not improve from 1.33824\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.0731 - accuracy: 0.6476 - val_loss: 1.3657 - val_accuracy: 0.5855\n",
            "Epoch 90/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.0751 - accuracy: 0.6503\n",
            "Epoch 00090: val_loss did not improve from 1.33824\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.0751 - accuracy: 0.6503 - val_loss: 1.3739 - val_accuracy: 0.5681\n",
            "Epoch 91/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.0655 - accuracy: 0.6498\n",
            "Epoch 00091: val_loss did not improve from 1.33824\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.0655 - accuracy: 0.6498 - val_loss: 1.4071 - val_accuracy: 0.5666\n",
            "Epoch 92/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.0575 - accuracy: 0.6553\n",
            "Epoch 00092: val_loss did not improve from 1.33824\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.0575 - accuracy: 0.6553 - val_loss: 1.4017 - val_accuracy: 0.5539\n",
            "Epoch 93/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 1.0618 - accuracy: 0.6410\n",
            "Epoch 00093: val_loss did not improve from 1.33824\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.0629 - accuracy: 0.6405 - val_loss: 1.3412 - val_accuracy: 0.5898\n",
            "Epoch 94/500\n",
            "126/127 [============================>.] - ETA: 0s - loss: 1.0770 - accuracy: 0.6486\n",
            "Epoch 00094: val_loss did not improve from 1.33824\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.0752 - accuracy: 0.6490 - val_loss: 1.4416 - val_accuracy: 0.5487\n",
            "Epoch 95/500\n",
            "126/127 [============================>.] - ETA: 0s - loss: 1.0611 - accuracy: 0.6527\n",
            "Epoch 00095: val_loss did not improve from 1.33824\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.0624 - accuracy: 0.6533 - val_loss: 1.3886 - val_accuracy: 0.5714\n",
            "Epoch 96/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 1.0650 - accuracy: 0.6493\n",
            "Epoch 00096: val_loss did not improve from 1.33824\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.0663 - accuracy: 0.6486 - val_loss: 1.3818 - val_accuracy: 0.5799\n",
            "Epoch 97/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 1.0556 - accuracy: 0.6526\n",
            "Epoch 00097: val_loss improved from 1.33824 to 1.32942, saving model to new2(4).hdf5\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.0591 - accuracy: 0.6517 - val_loss: 1.3294 - val_accuracy: 0.5903\n",
            "Epoch 98/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 1.0723 - accuracy: 0.6451\n",
            "Epoch 00098: val_loss did not improve from 1.32942\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.0714 - accuracy: 0.6454 - val_loss: 1.3753 - val_accuracy: 0.5699\n",
            "Epoch 99/500\n",
            "126/127 [============================>.] - ETA: 0s - loss: 1.0597 - accuracy: 0.6479\n",
            "Epoch 00099: val_loss did not improve from 1.32942\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.0598 - accuracy: 0.6482 - val_loss: 1.3937 - val_accuracy: 0.5704\n",
            "Epoch 100/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 1.0505 - accuracy: 0.6549\n",
            "Epoch 00100: val_loss did not improve from 1.32942\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.0476 - accuracy: 0.6552 - val_loss: 1.3874 - val_accuracy: 0.5647\n",
            "Epoch 101/500\n",
            "126/127 [============================>.] - ETA: 0s - loss: 1.0647 - accuracy: 0.6535\n",
            "Epoch 00101: val_loss did not improve from 1.32942\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.0651 - accuracy: 0.6531 - val_loss: 1.3879 - val_accuracy: 0.5619\n",
            "Epoch 102/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.0486 - accuracy: 0.6572\n",
            "Epoch 00102: val_loss improved from 1.32942 to 1.32482, saving model to new2(4).hdf5\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.0486 - accuracy: 0.6572 - val_loss: 1.3248 - val_accuracy: 0.5855\n",
            "Epoch 103/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 1.0528 - accuracy: 0.6536\n",
            "Epoch 00103: val_loss did not improve from 1.32482\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.0530 - accuracy: 0.6536 - val_loss: 1.3444 - val_accuracy: 0.5841\n",
            "Epoch 104/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.0550 - accuracy: 0.6575\n",
            "Epoch 00104: val_loss did not improve from 1.32482\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.0550 - accuracy: 0.6575 - val_loss: 1.4473 - val_accuracy: 0.5633\n",
            "Epoch 105/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 1.0431 - accuracy: 0.6539\n",
            "Epoch 00105: val_loss did not improve from 1.32482\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.0446 - accuracy: 0.6526 - val_loss: 1.3924 - val_accuracy: 0.5543\n",
            "Epoch 106/500\n",
            "126/127 [============================>.] - ETA: 0s - loss: 1.0558 - accuracy: 0.6498\n",
            "Epoch 00106: val_loss did not improve from 1.32482\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.0534 - accuracy: 0.6509 - val_loss: 1.3623 - val_accuracy: 0.5766\n",
            "Epoch 107/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.0472 - accuracy: 0.6593\n",
            "Epoch 00107: val_loss did not improve from 1.32482\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.0472 - accuracy: 0.6593 - val_loss: 1.4175 - val_accuracy: 0.5515\n",
            "Epoch 108/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.0438 - accuracy: 0.6545\n",
            "Epoch 00108: val_loss did not improve from 1.32482\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.0438 - accuracy: 0.6545 - val_loss: 1.3578 - val_accuracy: 0.5742\n",
            "Epoch 109/500\n",
            "126/127 [============================>.] - ETA: 0s - loss: 1.0376 - accuracy: 0.6544\n",
            "Epoch 00109: val_loss did not improve from 1.32482\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.0375 - accuracy: 0.6545 - val_loss: 1.3443 - val_accuracy: 0.5751\n",
            "Epoch 110/500\n",
            "125/127 [============================>.] - ETA: 0s - loss: 1.0473 - accuracy: 0.6571\n",
            "Epoch 00110: val_loss did not improve from 1.32482\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.0463 - accuracy: 0.6574 - val_loss: 1.3707 - val_accuracy: 0.5870\n",
            "Epoch 111/500\n",
            "123/127 [============================>.] - ETA: 0s - loss: 1.0333 - accuracy: 0.6556\n",
            "Epoch 00111: val_loss did not improve from 1.32482\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 1.0358 - accuracy: 0.6545 - val_loss: 1.3447 - val_accuracy: 0.5808\n",
            "Epoch 00111: early stopping\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4652644c10>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **LSTM**"
      ],
      "metadata": {
        "id": "-zUEhl41ETQi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Experment (1)"
      ],
      "metadata": {
        "id": "d4SnRPXZQbmP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelc6 = Sequential()\n",
        "\n",
        "input_shape=X_train.shape[1:]\n",
        "\n",
        "modelc6.add(LSTM(64, activation='relu', return_sequences=True, input_shape=input_shape, recurrent_dropout=.1))\n",
        "modelc6.add(LSTM(64, activation='relu'))\n",
        "\n",
        "modelc6.add(Dense(200))\n",
        "modelc6.add(Dropout(0.5))\n",
        "\n",
        "modelc6.add(Dense(100))\n",
        "modelc6.add(Dropout(0.5))\n",
        "\n",
        "modelc6.add(Dense(50))\n",
        "modelc6.add(Dropout(0.2))\n",
        "\n",
        "modelc6.add(Dense(units = num_labels, activation=\"softmax\"))\n",
        "\n",
        "\n",
        "modelc6.summary()\n",
        "modelc6.compile(loss = 'categorical_crossentropy', \n",
        "              metrics = ['accuracy'],\n",
        "              optimizer = 'adam')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HP1WD10mDZSy",
        "outputId": "53205493-eaeb-4431-ccd7-19b7934370af"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 40, 64)            61184     \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 64)                33024     \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 200)               13000     \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 200)               0         \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 100)               20100     \n",
            "                                                                 \n",
            " dropout_13 (Dropout)        (None, 100)               0         \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 50)                5050      \n",
            "                                                                 \n",
            " dropout_14 (Dropout)        (None, 50)                0         \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 18)                918       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 133,276\n",
            "Trainable params: 133,276\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "es = EarlyStopping(monitor='val_accuracy', min_delta= 0.01 , patience= 50, verbose= 1, mode='auto')\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath='(new2-LSTM(1)).hdf5', \n",
        "                               verbose=1, save_best_only=True)\n",
        "start = datetime.now()\n",
        "\n",
        "\n",
        "modelc6.fit(X_train, y_train,\n",
        "          batch_size = 50, \n",
        "          epochs = 500,\n",
        "          validation_data = (X_val, y_val), \n",
        "          callbacks=[checkpointer, es])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYFrOb8vDZUS",
        "outputId": "df5919cf-7ef8-4347-e762-f1fb96332127"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 2.5805 - accuracy: 0.1320\n",
            "Epoch 00001: val_loss improved from inf to 2.31795, saving model to (new2-LSTM(1)).hdf5\n",
            "127/127 [==============================] - 22s 155ms/step - loss: 2.5805 - accuracy: 0.1320 - val_loss: 2.3180 - val_accuracy: 0.2070\n",
            "Epoch 2/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 2.2399 - accuracy: 0.2172\n",
            "Epoch 00002: val_loss improved from 2.31795 to 2.02581, saving model to (new2-LSTM(1)).hdf5\n",
            "127/127 [==============================] - 19s 152ms/step - loss: 2.2399 - accuracy: 0.2172 - val_loss: 2.0258 - val_accuracy: 0.2717\n",
            "Epoch 3/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 2.0513 - accuracy: 0.2541\n",
            "Epoch 00003: val_loss improved from 2.02581 to 1.87739, saving model to (new2-LSTM(1)).hdf5\n",
            "127/127 [==============================] - 19s 152ms/step - loss: 2.0513 - accuracy: 0.2541 - val_loss: 1.8774 - val_accuracy: 0.2968\n",
            "Epoch 4/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.9052 - accuracy: 0.2962\n",
            "Epoch 00004: val_loss improved from 1.87739 to 1.80512, saving model to (new2-LSTM(1)).hdf5\n",
            "127/127 [==============================] - 19s 152ms/step - loss: 1.9052 - accuracy: 0.2962 - val_loss: 1.8051 - val_accuracy: 0.3270\n",
            "Epoch 5/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 1.8363 - accuracy: 0.3083\n",
            "Epoch 00005: val_loss improved from 1.80512 to 1.77837, saving model to (new2-LSTM(1)).hdf5\n",
            "127/127 [==============================] - 19s 151ms/step - loss: 1.8363 - accuracy: 0.3083 - val_loss: 1.7784 - val_accuracy: 0.3398\n",
            "Epoch 6/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 614.2006 - accuracy: 0.2371\n",
            "Epoch 00006: val_loss did not improve from 1.77837\n",
            "127/127 [==============================] - 19s 153ms/step - loss: 614.2006 - accuracy: 0.2371 - val_loss: 6434.4858 - val_accuracy: 0.1333\n",
            "Epoch 7/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 9690.9268 - accuracy: 0.0810\n",
            "Epoch 00007: val_loss did not improve from 1.77837\n",
            "127/127 [==============================] - 19s 151ms/step - loss: 9690.9268 - accuracy: 0.0810 - val_loss: 1338.3339 - val_accuracy: 0.0907\n",
            "Epoch 8/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 1797.7159 - accuracy: 0.0731\n",
            "Epoch 00008: val_loss did not improve from 1.77837\n",
            "127/127 [==============================] - 20s 154ms/step - loss: 1797.7159 - accuracy: 0.0731 - val_loss: 967.6431 - val_accuracy: 0.0955\n",
            "Epoch 9/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 1147.1315 - accuracy: 0.0720\n",
            "Epoch 00009: val_loss did not improve from 1.77837\n",
            "127/127 [==============================] - 20s 155ms/step - loss: 1147.1315 - accuracy: 0.0720 - val_loss: 373.3093 - val_accuracy: 0.0988\n",
            "Epoch 10/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 796.5868 - accuracy: 0.0777\n",
            "Epoch 00010: val_loss did not improve from 1.77837\n",
            "127/127 [==============================] - 20s 155ms/step - loss: 796.5868 - accuracy: 0.0777 - val_loss: 181.2931 - val_accuracy: 0.1040\n",
            "Epoch 11/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 605.6839 - accuracy: 0.0744\n",
            "Epoch 00011: val_loss did not improve from 1.77837\n",
            "127/127 [==============================] - 19s 150ms/step - loss: 605.6839 - accuracy: 0.0744 - val_loss: 111.6904 - val_accuracy: 0.1002\n",
            "Epoch 12/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 663.9558 - accuracy: 0.0772\n",
            "Epoch 00012: val_loss did not improve from 1.77837\n",
            "127/127 [==============================] - 19s 150ms/step - loss: 663.9558 - accuracy: 0.0772 - val_loss: 259.3351 - val_accuracy: 0.0992\n",
            "Epoch 13/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 1899.7452 - accuracy: 0.0762\n",
            "Epoch 00013: val_loss did not improve from 1.77837\n",
            "127/127 [==============================] - 19s 151ms/step - loss: 1899.7452 - accuracy: 0.0762 - val_loss: 848.3472 - val_accuracy: 0.0775\n",
            "Epoch 14/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 1150.5443 - accuracy: 0.0756\n",
            "Epoch 00014: val_loss did not improve from 1.77837\n",
            "127/127 [==============================] - 19s 151ms/step - loss: 1150.5443 - accuracy: 0.0756 - val_loss: 428.4761 - val_accuracy: 0.1134\n",
            "Epoch 15/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 669.2718 - accuracy: 0.0781\n",
            "Epoch 00015: val_loss did not improve from 1.77837\n",
            "127/127 [==============================] - 19s 151ms/step - loss: 669.2718 - accuracy: 0.0781 - val_loss: 358.4930 - val_accuracy: 0.0818\n",
            "Epoch 16/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 488.1534 - accuracy: 0.0772\n",
            "Epoch 00016: val_loss did not improve from 1.77837\n",
            "127/127 [==============================] - 19s 151ms/step - loss: 488.1534 - accuracy: 0.0772 - val_loss: 294.8045 - val_accuracy: 0.1191\n",
            "Epoch 17/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 336.5344 - accuracy: 0.0769\n",
            "Epoch 00017: val_loss did not improve from 1.77837\n",
            "127/127 [==============================] - 19s 150ms/step - loss: 336.5344 - accuracy: 0.0769 - val_loss: 217.9054 - val_accuracy: 0.0964\n",
            "Epoch 18/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 253.3899 - accuracy: 0.0805\n",
            "Epoch 00018: val_loss did not improve from 1.77837\n",
            "127/127 [==============================] - 19s 151ms/step - loss: 253.3899 - accuracy: 0.0805 - val_loss: 141.6969 - val_accuracy: 0.1082\n",
            "Epoch 19/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 193.6247 - accuracy: 0.0844\n",
            "Epoch 00019: val_loss did not improve from 1.77837\n",
            "127/127 [==============================] - 19s 150ms/step - loss: 193.6247 - accuracy: 0.0844 - val_loss: 109.6303 - val_accuracy: 0.1063\n",
            "Epoch 20/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 150.3177 - accuracy: 0.0780\n",
            "Epoch 00020: val_loss did not improve from 1.77837\n",
            "127/127 [==============================] - 19s 150ms/step - loss: 150.3177 - accuracy: 0.0780 - val_loss: 109.6455 - val_accuracy: 0.1144\n",
            "Epoch 21/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 118.6866 - accuracy: 0.0848\n",
            "Epoch 00021: val_loss did not improve from 1.77837\n",
            "127/127 [==============================] - 19s 151ms/step - loss: 118.6866 - accuracy: 0.0848 - val_loss: 55.0028 - val_accuracy: 0.1002\n",
            "Epoch 22/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 95.1811 - accuracy: 0.0893\n",
            "Epoch 00022: val_loss did not improve from 1.77837\n",
            "127/127 [==============================] - 19s 151ms/step - loss: 95.1811 - accuracy: 0.0893 - val_loss: 45.5935 - val_accuracy: 0.1082\n",
            "Epoch 23/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 80.8793 - accuracy: 0.0781\n",
            "Epoch 00023: val_loss did not improve from 1.77837\n",
            "127/127 [==============================] - 19s 152ms/step - loss: 80.8793 - accuracy: 0.0781 - val_loss: 41.6803 - val_accuracy: 0.0978\n",
            "Epoch 24/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 72.0802 - accuracy: 0.0893\n",
            "Epoch 00024: val_loss did not improve from 1.77837\n",
            "127/127 [==============================] - 19s 150ms/step - loss: 72.0802 - accuracy: 0.0893 - val_loss: 39.6440 - val_accuracy: 0.1285\n",
            "Epoch 25/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 59.7048 - accuracy: 0.0838\n",
            "Epoch 00025: val_loss did not improve from 1.77837\n",
            "127/127 [==============================] - 19s 151ms/step - loss: 59.7048 - accuracy: 0.0838 - val_loss: 31.1427 - val_accuracy: 0.1125\n",
            "Epoch 26/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 48.6699 - accuracy: 0.0868\n",
            "Epoch 00026: val_loss did not improve from 1.77837\n",
            "127/127 [==============================] - 19s 151ms/step - loss: 48.6699 - accuracy: 0.0868 - val_loss: 27.5826 - val_accuracy: 0.1139\n",
            "Epoch 27/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 41.6797 - accuracy: 0.0870\n",
            "Epoch 00027: val_loss did not improve from 1.77837\n",
            "127/127 [==============================] - 19s 151ms/step - loss: 41.6797 - accuracy: 0.0870 - val_loss: 24.6663 - val_accuracy: 0.1078\n",
            "Epoch 28/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 41.9200 - accuracy: 0.0808\n",
            "Epoch 00028: val_loss did not improve from 1.77837\n",
            "127/127 [==============================] - 19s 150ms/step - loss: 41.9200 - accuracy: 0.0808 - val_loss: 18.9336 - val_accuracy: 0.1139\n",
            "Epoch 29/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 34.8906 - accuracy: 0.0849\n",
            "Epoch 00029: val_loss did not improve from 1.77837\n",
            "127/127 [==============================] - 19s 151ms/step - loss: 34.8906 - accuracy: 0.0849 - val_loss: 16.8829 - val_accuracy: 0.1016\n",
            "Epoch 30/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 35.9351 - accuracy: 0.0844\n",
            "Epoch 00030: val_loss did not improve from 1.77837\n",
            "127/127 [==============================] - 19s 151ms/step - loss: 35.9351 - accuracy: 0.0844 - val_loss: 9.8328 - val_accuracy: 0.1267\n",
            "Epoch 31/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 28.5292 - accuracy: 0.0825\n",
            "Epoch 00031: val_loss did not improve from 1.77837\n",
            "127/127 [==============================] - 19s 151ms/step - loss: 28.5292 - accuracy: 0.0825 - val_loss: 10.9567 - val_accuracy: 0.1215\n",
            "Epoch 32/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 24.5958 - accuracy: 0.0773\n",
            "Epoch 00032: val_loss did not improve from 1.77837\n",
            "127/127 [==============================] - 19s 150ms/step - loss: 24.5958 - accuracy: 0.0773 - val_loss: 8.3964 - val_accuracy: 0.1101\n",
            "Epoch 33/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 21.8089 - accuracy: 0.0745\n",
            "Epoch 00033: val_loss did not improve from 1.77837\n",
            "127/127 [==============================] - 19s 151ms/step - loss: 21.8089 - accuracy: 0.0745 - val_loss: 6.0574 - val_accuracy: 0.1352\n",
            "Epoch 34/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 21.8507 - accuracy: 0.0796\n",
            "Epoch 00034: val_loss did not improve from 1.77837\n",
            "127/127 [==============================] - 19s 150ms/step - loss: 21.8507 - accuracy: 0.0796 - val_loss: 5.5348 - val_accuracy: 0.1196\n",
            "Epoch 35/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 21.1803 - accuracy: 0.0816\n",
            "Epoch 00035: val_loss did not improve from 1.77837\n",
            "127/127 [==============================] - 19s 151ms/step - loss: 21.1803 - accuracy: 0.0816 - val_loss: 7.9210 - val_accuracy: 0.1276\n",
            "Epoch 36/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 25.1229 - accuracy: 0.0860\n",
            "Epoch 00036: val_loss did not improve from 1.77837\n",
            "127/127 [==============================] - 19s 151ms/step - loss: 25.1229 - accuracy: 0.0860 - val_loss: 9.3478 - val_accuracy: 0.1106\n",
            "Epoch 37/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 22.2345 - accuracy: 0.0848\n",
            "Epoch 00037: val_loss did not improve from 1.77837\n",
            "127/127 [==============================] - 19s 151ms/step - loss: 22.2345 - accuracy: 0.0848 - val_loss: 9.9199 - val_accuracy: 0.1285\n",
            "Epoch 38/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 21.9175 - accuracy: 0.0825\n",
            "Epoch 00038: val_loss did not improve from 1.77837\n",
            "127/127 [==============================] - 19s 150ms/step - loss: 21.9175 - accuracy: 0.0825 - val_loss: 6.4549 - val_accuracy: 0.1016\n",
            "Epoch 39/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 20.0567 - accuracy: 0.0876\n",
            "Epoch 00039: val_loss did not improve from 1.77837\n",
            "127/127 [==============================] - 19s 152ms/step - loss: 20.0567 - accuracy: 0.0876 - val_loss: 8.8112 - val_accuracy: 0.1167\n",
            "Epoch 40/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 23.1409 - accuracy: 0.0868\n",
            "Epoch 00040: val_loss did not improve from 1.77837\n",
            "127/127 [==============================] - 19s 151ms/step - loss: 23.1409 - accuracy: 0.0868 - val_loss: 14.2893 - val_accuracy: 0.1229\n",
            "Epoch 41/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 24.8458 - accuracy: 0.0890\n",
            "Epoch 00041: val_loss did not improve from 1.77837\n",
            "127/127 [==============================] - 19s 152ms/step - loss: 24.8458 - accuracy: 0.0890 - val_loss: 13.9007 - val_accuracy: 0.1224\n",
            "Epoch 42/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 21.8179 - accuracy: 0.0870\n",
            "Epoch 00042: val_loss did not improve from 1.77837\n",
            "127/127 [==============================] - 19s 152ms/step - loss: 21.8179 - accuracy: 0.0870 - val_loss: 8.5394 - val_accuracy: 0.1196\n",
            "Epoch 43/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 20.3215 - accuracy: 0.0870\n",
            "Epoch 00043: val_loss did not improve from 1.77837\n",
            "127/127 [==============================] - 19s 153ms/step - loss: 20.3215 - accuracy: 0.0870 - val_loss: 6.2021 - val_accuracy: 0.1361\n",
            "Epoch 44/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 17.4768 - accuracy: 0.0887\n",
            "Epoch 00044: val_loss did not improve from 1.77837\n",
            "127/127 [==============================] - 19s 151ms/step - loss: 17.4768 - accuracy: 0.0887 - val_loss: 7.8504 - val_accuracy: 0.1210\n",
            "Epoch 45/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 17.3239 - accuracy: 0.0863\n",
            "Epoch 00045: val_loss did not improve from 1.77837\n",
            "127/127 [==============================] - 19s 150ms/step - loss: 17.3239 - accuracy: 0.0863 - val_loss: 6.3932 - val_accuracy: 0.1215\n",
            "Epoch 46/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 17.2223 - accuracy: 0.0904\n",
            "Epoch 00046: val_loss did not improve from 1.77837\n",
            "127/127 [==============================] - 19s 150ms/step - loss: 17.2223 - accuracy: 0.0904 - val_loss: 6.4439 - val_accuracy: 0.1427\n",
            "Epoch 47/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 19.9643 - accuracy: 0.0873\n",
            "Epoch 00047: val_loss did not improve from 1.77837\n",
            "127/127 [==============================] - 19s 151ms/step - loss: 19.9643 - accuracy: 0.0873 - val_loss: 7.1300 - val_accuracy: 0.0922\n",
            "Epoch 48/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 9.4461 - accuracy: 0.0980\n",
            "Epoch 00048: val_loss did not improve from 1.77837\n",
            "127/127 [==============================] - 19s 150ms/step - loss: 9.4461 - accuracy: 0.0980 - val_loss: 2.8800 - val_accuracy: 0.1470\n",
            "Epoch 49/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 4.5451 - accuracy: 0.1065\n",
            "Epoch 00049: val_loss did not improve from 1.77837\n",
            "127/127 [==============================] - 19s 151ms/step - loss: 4.5451 - accuracy: 0.1065 - val_loss: 2.7795 - val_accuracy: 0.1536\n",
            "Epoch 50/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 4.5690 - accuracy: 0.1049\n",
            "Epoch 00050: val_loss did not improve from 1.77837\n",
            "127/127 [==============================] - 19s 151ms/step - loss: 4.5690 - accuracy: 0.1049 - val_loss: 2.7873 - val_accuracy: 0.1328\n",
            "Epoch 51/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 4.5768 - accuracy: 0.0969\n",
            "Epoch 00051: val_loss did not improve from 1.77837\n",
            "127/127 [==============================] - 19s 152ms/step - loss: 4.5768 - accuracy: 0.0969 - val_loss: 3.2204 - val_accuracy: 0.1319\n",
            "Epoch 52/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 4.4345 - accuracy: 0.1082\n",
            "Epoch 00052: val_loss did not improve from 1.77837\n",
            "127/127 [==============================] - 19s 151ms/step - loss: 4.4345 - accuracy: 0.1082 - val_loss: 2.7970 - val_accuracy: 0.1035\n",
            "Epoch 53/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 4.8676 - accuracy: 0.1133\n",
            "Epoch 00053: val_loss did not improve from 1.77837\n",
            "127/127 [==============================] - 19s 151ms/step - loss: 4.8676 - accuracy: 0.1133 - val_loss: 2.8429 - val_accuracy: 0.1337\n",
            "Epoch 54/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 4.5133 - accuracy: 0.1057\n",
            "Epoch 00054: val_loss did not improve from 1.77837\n",
            "127/127 [==============================] - 19s 152ms/step - loss: 4.5133 - accuracy: 0.1057 - val_loss: 2.7922 - val_accuracy: 0.1243\n",
            "Epoch 55/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 4.2792 - accuracy: 0.1065\n",
            "Epoch 00055: val_loss did not improve from 1.77837\n",
            "127/127 [==============================] - 19s 151ms/step - loss: 4.2792 - accuracy: 0.1065 - val_loss: 2.7415 - val_accuracy: 0.1309\n",
            "Epoch 00055: early stopping\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4653628d90>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Experment (2)"
      ],
      "metadata": {
        "id": "rtQNrpaZlJjY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelc7 = Sequential()\n",
        "\n",
        "input_shape=X_train.shape[1:]\n",
        "\n",
        "#modelc6.add(Conv2D(filters=16, kernel_size=2, input_shape=input_shape, activation='relu'))\n",
        "modelc7.add(LSTM(64, activation='relu', return_sequences=True, input_shape=input_shape, recurrent_dropout=.1))\n",
        "modelc7.add(LSTM(50, activation='relu'))\n",
        "\n",
        "\n",
        "#modelc7.add(Flatten())\n",
        "\n",
        "#modelc7.add(Dense(100))\n",
        "#modelc7.add(Activation('relu'))\n",
        "#modelc7.add(BatchNormalization())\n",
        "#modelc7.add(Dropout(0.5))\n",
        "\n",
        "modelc7.add(Dense(200))\n",
        "modelc7.add(Dropout(0.5))\n",
        "\n",
        "\n",
        "#modelc6.add(LSTM(50, activation='relu'))\n",
        "\n",
        "modelc7.add(Dense(units = num_labels, activation=\"softmax\"))\n",
        "\n",
        "\n",
        "modelc7.summary()\n",
        "modelc7.compile(loss = 'categorical_crossentropy', \n",
        "              metrics = ['accuracy'],\n",
        "              optimizer = 'adam')"
      ],
      "metadata": {
        "id": "R1evtkmF_4Wr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30e994c2-1e7c-47e9-b72d-f580e4ed2f17"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_4 (LSTM)               (None, 40, 64)            61184     \n",
            "                                                                 \n",
            " lstm_5 (LSTM)               (None, 50)                23000     \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 200)               10200     \n",
            "                                                                 \n",
            " dropout_15 (Dropout)        (None, 200)               0         \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 18)                3618      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 98,002\n",
            "Trainable params: 98,002\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "es = EarlyStopping(monitor='val_accuracy', min_delta= 0.01 , patience= 50, verbose= 1, mode='auto')\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath='(new2-LSTM(2-1)).hdf5', \n",
        "                               verbose=1, save_best_only=True)\n",
        "start = datetime.now()\n",
        "\n",
        "\n",
        "modelc7.fit(X_train, y_train,\n",
        "          batch_size = 50, \n",
        "          epochs = 500,\n",
        "          validation_data = (X_val, y_val), \n",
        "          callbacks=[checkpointer, es])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uMeeDbpOpLI",
        "outputId": "f0f27639-713d-4c6b-967d-03ecb70b82b2"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 2.7177 - accuracy: 0.1150\n",
            "Epoch 00001: val_loss improved from inf to 2.50334, saving model to (new2-LSTM(2-1)).hdf5\n",
            "127/127 [==============================] - 22s 157ms/step - loss: 2.7177 - accuracy: 0.1150 - val_loss: 2.5033 - val_accuracy: 0.1711\n",
            "Epoch 2/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 2.3536 - accuracy: 0.1846\n",
            "Epoch 00002: val_loss improved from 2.50334 to 2.20924, saving model to (new2-LSTM(2-1)).hdf5\n",
            "127/127 [==============================] - 19s 153ms/step - loss: 2.3536 - accuracy: 0.1846 - val_loss: 2.2092 - val_accuracy: 0.2273\n",
            "Epoch 3/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 2.1995 - accuracy: 0.2199\n",
            "Epoch 00003: val_loss improved from 2.20924 to 2.12949, saving model to (new2-LSTM(2-1)).hdf5\n",
            "127/127 [==============================] - 19s 152ms/step - loss: 2.1995 - accuracy: 0.2199 - val_loss: 2.1295 - val_accuracy: 0.2552\n",
            "Epoch 4/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 2.0819 - accuracy: 0.2467\n",
            "Epoch 00004: val_loss improved from 2.12949 to 1.97725, saving model to (new2-LSTM(2-1)).hdf5\n",
            "127/127 [==============================] - 19s 153ms/step - loss: 2.0819 - accuracy: 0.2467 - val_loss: 1.9773 - val_accuracy: 0.2628\n",
            "Epoch 5/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 52.1693 - accuracy: 0.2706\n",
            "Epoch 00005: val_loss did not improve from 1.97725\n",
            "127/127 [==============================] - 19s 152ms/step - loss: 52.1693 - accuracy: 0.2706 - val_loss: 15961.4727 - val_accuracy: 0.0893\n",
            "Epoch 6/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 865234.1875 - accuracy: 0.0884\n",
            "Epoch 00006: val_loss did not improve from 1.97725\n",
            "127/127 [==============================] - 20s 154ms/step - loss: 865234.1875 - accuracy: 0.0884 - val_loss: 1068.7643 - val_accuracy: 0.0940\n",
            "Epoch 7/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 34421.5156 - accuracy: 0.0819\n",
            "Epoch 00007: val_loss did not improve from 1.97725\n",
            "127/127 [==============================] - 20s 155ms/step - loss: 34421.5156 - accuracy: 0.0819 - val_loss: 2.9774 - val_accuracy: 0.0992\n",
            "Epoch 8/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 6873.9116 - accuracy: 0.0799\n",
            "Epoch 00008: val_loss did not improve from 1.97725\n",
            "127/127 [==============================] - 20s 154ms/step - loss: 6873.9116 - accuracy: 0.0799 - val_loss: 2.7899 - val_accuracy: 0.0888\n",
            "Epoch 9/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 3893.9348 - accuracy: 0.0844\n",
            "Epoch 00009: val_loss did not improve from 1.97725\n",
            "127/127 [==============================] - 20s 154ms/step - loss: 3893.9348 - accuracy: 0.0844 - val_loss: 2.7217 - val_accuracy: 0.0964\n",
            "Epoch 10/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 3261.5149 - accuracy: 0.0877\n",
            "Epoch 00010: val_loss did not improve from 1.97725\n",
            "127/127 [==============================] - 20s 155ms/step - loss: 3261.5149 - accuracy: 0.0877 - val_loss: 2.6748 - val_accuracy: 0.0955\n",
            "Epoch 11/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 2456.2031 - accuracy: 0.0821\n",
            "Epoch 00011: val_loss did not improve from 1.97725\n",
            "127/127 [==============================] - 19s 151ms/step - loss: 2456.2031 - accuracy: 0.0821 - val_loss: 2.6528 - val_accuracy: 0.0926\n",
            "Epoch 12/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 1895.4915 - accuracy: 0.0766\n",
            "Epoch 00012: val_loss did not improve from 1.97725\n",
            "127/127 [==============================] - 19s 151ms/step - loss: 1895.4915 - accuracy: 0.0766 - val_loss: 2.6903 - val_accuracy: 0.0950\n",
            "Epoch 13/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 1856.2812 - accuracy: 0.0851\n",
            "Epoch 00013: val_loss did not improve from 1.97725\n",
            "127/127 [==============================] - 19s 151ms/step - loss: 1856.2812 - accuracy: 0.0851 - val_loss: 2.6779 - val_accuracy: 0.0870\n",
            "Epoch 14/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 1355.5490 - accuracy: 0.0888\n",
            "Epoch 00014: val_loss did not improve from 1.97725\n",
            "127/127 [==============================] - 19s 152ms/step - loss: 1355.5490 - accuracy: 0.0888 - val_loss: 2.6685 - val_accuracy: 0.0912\n",
            "Epoch 15/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 1487.7733 - accuracy: 0.0884\n",
            "Epoch 00015: val_loss did not improve from 1.97725\n",
            "127/127 [==============================] - 19s 151ms/step - loss: 1487.7733 - accuracy: 0.0884 - val_loss: 2.6595 - val_accuracy: 0.0766\n",
            "Epoch 16/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 1233.4590 - accuracy: 0.0967\n",
            "Epoch 00016: val_loss did not improve from 1.97725\n",
            "127/127 [==============================] - 19s 150ms/step - loss: 1233.4590 - accuracy: 0.0967 - val_loss: 2.6521 - val_accuracy: 0.0818\n",
            "Epoch 17/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 1169.3700 - accuracy: 0.0992\n",
            "Epoch 00017: val_loss did not improve from 1.97725\n",
            "127/127 [==============================] - 19s 153ms/step - loss: 1169.3700 - accuracy: 0.0992 - val_loss: 2.6501 - val_accuracy: 0.0832\n",
            "Epoch 18/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 1426.5974 - accuracy: 0.1068\n",
            "Epoch 00018: val_loss did not improve from 1.97725\n",
            "127/127 [==============================] - 20s 155ms/step - loss: 1426.5974 - accuracy: 0.1068 - val_loss: 2.6241 - val_accuracy: 0.1323\n",
            "Epoch 19/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 1243.1910 - accuracy: 0.1312\n",
            "Epoch 00019: val_loss did not improve from 1.97725\n",
            "127/127 [==============================] - 20s 155ms/step - loss: 1243.1910 - accuracy: 0.1312 - val_loss: 2.6126 - val_accuracy: 0.1196\n",
            "Epoch 20/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 678.0136 - accuracy: 0.1279\n",
            "Epoch 00020: val_loss did not improve from 1.97725\n",
            "127/127 [==============================] - 20s 155ms/step - loss: 678.0136 - accuracy: 0.1279 - val_loss: 2.5877 - val_accuracy: 0.1262\n",
            "Epoch 21/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 948.0978 - accuracy: 0.1372\n",
            "Epoch 00021: val_loss did not improve from 1.97725\n",
            "127/127 [==============================] - 20s 155ms/step - loss: 948.0978 - accuracy: 0.1372 - val_loss: 2.5332 - val_accuracy: 0.1526\n",
            "Epoch 22/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 448.8124 - accuracy: 0.1443\n",
            "Epoch 00022: val_loss did not improve from 1.97725\n",
            "127/127 [==============================] - 19s 153ms/step - loss: 448.8124 - accuracy: 0.1443 - val_loss: 2.4860 - val_accuracy: 0.1366\n",
            "Epoch 23/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 848.7160 - accuracy: 0.1400\n",
            "Epoch 00023: val_loss did not improve from 1.97725\n",
            "127/127 [==============================] - 19s 152ms/step - loss: 848.7160 - accuracy: 0.1400 - val_loss: 2.4327 - val_accuracy: 0.1668\n",
            "Epoch 24/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 510.9547 - accuracy: 0.1564\n",
            "Epoch 00024: val_loss did not improve from 1.97725\n",
            "127/127 [==============================] - 19s 151ms/step - loss: 510.9547 - accuracy: 0.1564 - val_loss: 2.4041 - val_accuracy: 0.1701\n",
            "Epoch 25/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 491.7929 - accuracy: 0.1563\n",
            "Epoch 00025: val_loss did not improve from 1.97725\n",
            "127/127 [==============================] - 19s 153ms/step - loss: 491.7929 - accuracy: 0.1563 - val_loss: 2.3767 - val_accuracy: 0.1753\n",
            "Epoch 26/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 522.2287 - accuracy: 0.1501\n",
            "Epoch 00026: val_loss did not improve from 1.97725\n",
            "127/127 [==============================] - 19s 152ms/step - loss: 522.2287 - accuracy: 0.1501 - val_loss: 2.3674 - val_accuracy: 0.1749\n",
            "Epoch 27/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 104.4486 - accuracy: 0.1552\n",
            "Epoch 00027: val_loss did not improve from 1.97725\n",
            "127/127 [==============================] - 19s 152ms/step - loss: 104.4486 - accuracy: 0.1552 - val_loss: 2.3422 - val_accuracy: 0.1838\n",
            "Epoch 28/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 12.7344 - accuracy: 0.1558\n",
            "Epoch 00028: val_loss did not improve from 1.97725\n",
            "127/127 [==============================] - 19s 151ms/step - loss: 12.7344 - accuracy: 0.1558 - val_loss: 2.3317 - val_accuracy: 0.1810\n",
            "Epoch 29/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 2.5312 - accuracy: 0.1637\n",
            "Epoch 00029: val_loss did not improve from 1.97725\n",
            "127/127 [==============================] - 19s 152ms/step - loss: 2.5312 - accuracy: 0.1637 - val_loss: 2.3218 - val_accuracy: 0.1876\n",
            "Epoch 30/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 9.8922 - accuracy: 0.1716\n",
            "Epoch 00030: val_loss did not improve from 1.97725\n",
            "127/127 [==============================] - 19s 151ms/step - loss: 9.8922 - accuracy: 0.1716 - val_loss: 2.3076 - val_accuracy: 0.1895\n",
            "Epoch 31/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 11.3658 - accuracy: 0.1731\n",
            "Epoch 00031: val_loss did not improve from 1.97725\n",
            "127/127 [==============================] - 19s 153ms/step - loss: 11.3658 - accuracy: 0.1731 - val_loss: 2.2952 - val_accuracy: 0.1900\n",
            "Epoch 32/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 2.4757 - accuracy: 0.1717\n",
            "Epoch 00032: val_loss did not improve from 1.97725\n",
            "127/127 [==============================] - 19s 152ms/step - loss: 2.4757 - accuracy: 0.1717 - val_loss: 2.5386 - val_accuracy: 0.1470\n",
            "Epoch 33/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 20.0296 - accuracy: 0.1311\n",
            "Epoch 00033: val_loss did not improve from 1.97725\n",
            "127/127 [==============================] - 19s 151ms/step - loss: 20.0296 - accuracy: 0.1311 - val_loss: 2.3519 - val_accuracy: 0.1664\n",
            "Epoch 34/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 23.7963 - accuracy: 0.1585\n",
            "Epoch 00034: val_loss did not improve from 1.97725\n",
            "127/127 [==============================] - 19s 152ms/step - loss: 23.7963 - accuracy: 0.1585 - val_loss: 2.3008 - val_accuracy: 0.1923\n",
            "Epoch 35/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 2.3461 - accuracy: 0.1733\n",
            "Epoch 00035: val_loss did not improve from 1.97725\n",
            "127/127 [==============================] - 19s 152ms/step - loss: 2.3461 - accuracy: 0.1733 - val_loss: 2.2861 - val_accuracy: 0.1853\n",
            "Epoch 36/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 9.9175 - accuracy: 0.1689\n",
            "Epoch 00036: val_loss did not improve from 1.97725\n",
            "127/127 [==============================] - 19s 152ms/step - loss: 9.9175 - accuracy: 0.1689 - val_loss: 2.2806 - val_accuracy: 0.1867\n",
            "Epoch 37/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 6.5222 - accuracy: 0.1741\n",
            "Epoch 00037: val_loss did not improve from 1.97725\n",
            "127/127 [==============================] - 19s 152ms/step - loss: 6.5222 - accuracy: 0.1741 - val_loss: 2.2689 - val_accuracy: 0.1810\n",
            "Epoch 38/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 2.3190 - accuracy: 0.1829\n",
            "Epoch 00038: val_loss did not improve from 1.97725\n",
            "127/127 [==============================] - 19s 151ms/step - loss: 2.3190 - accuracy: 0.1829 - val_loss: 2.2636 - val_accuracy: 0.1862\n",
            "Epoch 39/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 3.1407 - accuracy: 0.1750\n",
            "Epoch 00039: val_loss did not improve from 1.97725\n",
            "127/127 [==============================] - 19s 153ms/step - loss: 3.1407 - accuracy: 0.1750 - val_loss: 2.2579 - val_accuracy: 0.1886\n",
            "Epoch 40/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 2.5094 - accuracy: 0.1767\n",
            "Epoch 00040: val_loss did not improve from 1.97725\n",
            "127/127 [==============================] - 19s 152ms/step - loss: 2.5094 - accuracy: 0.1767 - val_loss: 2.2523 - val_accuracy: 0.1881\n",
            "Epoch 41/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 9.8845 - accuracy: 0.1769\n",
            "Epoch 00041: val_loss did not improve from 1.97725\n",
            "127/127 [==============================] - 19s 152ms/step - loss: 9.8845 - accuracy: 0.1769 - val_loss: 2.2480 - val_accuracy: 0.1886\n",
            "Epoch 42/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 18.8182 - accuracy: 0.1823\n",
            "Epoch 00042: val_loss did not improve from 1.97725\n",
            "127/127 [==============================] - 19s 152ms/step - loss: 18.8182 - accuracy: 0.1823 - val_loss: 2.2444 - val_accuracy: 0.1914\n",
            "Epoch 43/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 27.6609 - accuracy: 0.1818\n",
            "Epoch 00043: val_loss did not improve from 1.97725\n",
            "127/127 [==============================] - 19s 153ms/step - loss: 27.6609 - accuracy: 0.1818 - val_loss: 2.2396 - val_accuracy: 0.1947\n",
            "Epoch 44/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 3.2287 - accuracy: 0.1842\n",
            "Epoch 00044: val_loss did not improve from 1.97725\n",
            "127/127 [==============================] - 20s 156ms/step - loss: 3.2287 - accuracy: 0.1842 - val_loss: 2.2397 - val_accuracy: 0.1952\n",
            "Epoch 45/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 2.4100 - accuracy: 0.1865\n",
            "Epoch 00045: val_loss did not improve from 1.97725\n",
            "127/127 [==============================] - 19s 152ms/step - loss: 2.4100 - accuracy: 0.1865 - val_loss: 2.2307 - val_accuracy: 0.1999\n",
            "Epoch 46/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 40.0465 - accuracy: 0.1794\n",
            "Epoch 00046: val_loss did not improve from 1.97725\n",
            "127/127 [==============================] - 19s 152ms/step - loss: 40.0465 - accuracy: 0.1794 - val_loss: 2.2278 - val_accuracy: 0.1942\n",
            "Epoch 47/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 7.9650 - accuracy: 0.1898\n",
            "Epoch 00047: val_loss did not improve from 1.97725\n",
            "127/127 [==============================] - 19s 152ms/step - loss: 7.9650 - accuracy: 0.1898 - val_loss: 2.2154 - val_accuracy: 0.2037\n",
            "Epoch 48/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 3.7738 - accuracy: 0.1838\n",
            "Epoch 00048: val_loss did not improve from 1.97725\n",
            "127/127 [==============================] - 19s 152ms/step - loss: 3.7738 - accuracy: 0.1838 - val_loss: 2.2150 - val_accuracy: 0.2070\n",
            "Epoch 49/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 6.7252 - accuracy: 0.1952\n",
            "Epoch 00049: val_loss did not improve from 1.97725\n",
            "127/127 [==============================] - 19s 152ms/step - loss: 6.7252 - accuracy: 0.1952 - val_loss: 2.2077 - val_accuracy: 0.1952\n",
            "Epoch 50/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 3.1820 - accuracy: 0.1834\n",
            "Epoch 00050: val_loss did not improve from 1.97725\n",
            "127/127 [==============================] - 19s 151ms/step - loss: 3.1820 - accuracy: 0.1834 - val_loss: 2.2012 - val_accuracy: 0.2018\n",
            "Epoch 51/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 3.0232 - accuracy: 0.1916\n",
            "Epoch 00051: val_loss did not improve from 1.97725\n",
            "127/127 [==============================] - 20s 154ms/step - loss: 3.0232 - accuracy: 0.1916 - val_loss: 2.1985 - val_accuracy: 0.1971\n",
            "Epoch 52/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 2.2531 - accuracy: 0.1925\n",
            "Epoch 00052: val_loss did not improve from 1.97725\n",
            "127/127 [==============================] - 19s 152ms/step - loss: 2.2531 - accuracy: 0.1925 - val_loss: 2.2003 - val_accuracy: 0.1957\n",
            "Epoch 53/500\n",
            "127/127 [==============================] - ETA: 0s - loss: 50.8239 - accuracy: 0.1949\n",
            "Epoch 00053: val_loss did not improve from 1.97725\n",
            "127/127 [==============================] - 19s 153ms/step - loss: 50.8239 - accuracy: 0.1949 - val_loss: 2.1867 - val_accuracy: 0.2013\n",
            "Epoch 00053: early stopping\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f442e1e5810>"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Modeling (CNN - LSTM).ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}